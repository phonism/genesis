<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A lightweight deep learning framework built from scratch with Python + Triton + CUDA"><meta name=author content="Genesis Team"><link href=https://phonism.github.io/genesis/en/tutorials/mixed-precision/ rel=canonical><link href=../llm-training/ rel=prev><link href=../../core-components/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.16"><title>Mixed Precision - Genesis Deep Learning Framework</title><link rel=stylesheet href=../../assets/stylesheets/main.7e37652d.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../shared/stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config",""),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#mixed-precision-training-guide class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Genesis Deep Learning Framework" class="md-header__button md-logo" aria-label="Genesis Deep Learning Framework" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Genesis Deep Learning Framework </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Mixed Precision </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to system preference" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5M7 15a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/phonism/genesis title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> genesis </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../getting-started/ class=md-tabs__link> Getting Started </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../ class=md-tabs__link> Tutorials </a> </li> <li class=md-tabs__item> <a href=../../core-components/ class=md-tabs__link> Core Components </a> </li> <li class=md-tabs__item> <a href=../../architecture/ class=md-tabs__link> Architecture </a> </li> <li class=md-tabs__item> <a href=../../models/qwen/ class=md-tabs__link> Models </a> </li> <li class=md-tabs__item> <a href=../../performance/optimization-guide/ class=md-tabs__link> Performance </a> </li> <li class=md-tabs__item> <a href=../../training/advanced-features/ class=md-tabs__link> Training </a> </li> <li class=md-tabs__item> <a href=../../benchmark/ class=md-tabs__link> Benchmark </a> </li> <li class=md-tabs__item> <a href=../../api-reference/ class=md-tabs__link> API Reference </a> </li> <li class=md-tabs__item> <a href=../../contributing/ class=md-tabs__link> Contributing </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Genesis Deep Learning Framework" class="md-nav__button md-logo" aria-label="Genesis Deep Learning Framework" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> Genesis Deep Learning Framework </label> <div class=md-nav__source> <a href=https://github.com/phonism/genesis title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> genesis </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../getting-started/ class=md-nav__link> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> Tutorials </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../basic-training/ class=md-nav__link> <span class=md-ellipsis> Basic Training </span> </a> </li> <li class=md-nav__item> <a href=../custom-ops/ class=md-nav__link> <span class=md-ellipsis> Custom Operations </span> </a> </li> <li class=md-nav__item> <a href=../performance-tuning/ class=md-nav__link> <span class=md-ellipsis> Performance Tuning </span> </a> </li> <li class=md-nav__item> <a href=../llm-training/ class=md-nav__link> <span class=md-ellipsis> LLM Training </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Mixed Precision </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Mixed Precision </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#overview class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> <nav class=md-nav aria-label=Overview> <ul class=md-nav__list> <li class=md-nav__item> <a href=#benefits-of-mixed-precision-training class=md-nav__link> <span class=md-ellipsis> Benefits of Mixed Precision Training </span> </a> </li> <li class=md-nav__item> <a href=#supported-precision-types class=md-nav__link> <span class=md-ellipsis> Supported Precision Types </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#data-type-system class=md-nav__link> <span class=md-ellipsis> Data Type System </span> </a> <nav class=md-nav aria-label="Data Type System"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#understanding-genesis-dtypes class=md-nav__link> <span class=md-ellipsis> Understanding Genesis DTypes </span> </a> </li> <li class=md-nav__item> <a href=#creating-mixed-precision-tensors class=md-nav__link> <span class=md-ellipsis> Creating Mixed Precision Tensors </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#automatic-mixed-precision-amp class=md-nav__link> <span class=md-ellipsis> Automatic Mixed Precision (AMP) </span> </a> <nav class=md-nav aria-label="Automatic Mixed Precision (AMP)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#basic-amp-usage class=md-nav__link> <span class=md-ellipsis> Basic AMP Usage </span> </a> </li> <li class=md-nav__item> <a href=#manual-amp-control class=md-nav__link> <span class=md-ellipsis> Manual AMP Control </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#training-with-mixed-precision class=md-nav__link> <span class=md-ellipsis> Training with Mixed Precision </span> </a> <nav class=md-nav aria-label="Training with Mixed Precision"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#simple-mixed-precision-training-loop class=md-nav__link> <span class=md-ellipsis> Simple Mixed Precision Training Loop </span> </a> </li> <li class=md-nav__item> <a href=#advanced-mixed-precision-with-loss-scaling class=md-nav__link> <span class=md-ellipsis> Advanced Mixed Precision with Loss Scaling </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#precision-specific-considerations class=md-nav__link> <span class=md-ellipsis> Precision-Specific Considerations </span> </a> <nav class=md-nav aria-label="Precision-Specific Considerations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#fp16-half-precision class=md-nav__link> <span class=md-ellipsis> FP16 (Half Precision) </span> </a> </li> <li class=md-nav__item> <a href=#bf16-brain-float class=md-nav__link> <span class=md-ellipsis> BF16 (Brain Float) </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#memory-optimization class=md-nav__link> <span class=md-ellipsis> Memory Optimization </span> </a> <nav class=md-nav aria-label="Memory Optimization"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#memory-usage-analysis class=md-nav__link> <span class=md-ellipsis> Memory Usage Analysis </span> </a> </li> <li class=md-nav__item> <a href=#gradient-checkpointing-with-mixed-precision class=md-nav__link> <span class=md-ellipsis> Gradient Checkpointing with Mixed Precision </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#performance-benchmarking class=md-nav__link> <span class=md-ellipsis> Performance Benchmarking </span> </a> <nav class=md-nav aria-label="Performance Benchmarking"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#mixed-precision-performance-comparison class=md-nav__link> <span class=md-ellipsis> Mixed Precision Performance Comparison </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#best-practices-and-troubleshooting class=md-nav__link> <span class=md-ellipsis> Best Practices and Troubleshooting </span> </a> <nav class=md-nav aria-label="Best Practices and Troubleshooting"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#best-practices class=md-nav__link> <span class=md-ellipsis> Best Practices </span> </a> </li> <li class=md-nav__item> <a href=#common-issues-and-solutions class=md-nav__link> <span class=md-ellipsis> Common Issues and Solutions </span> </a> </li> <li class=md-nav__item> <a href=#debugging-mixed-precision-training class=md-nav__link> <span class=md-ellipsis> Debugging Mixed Precision Training </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../core-components/ class=md-nav__link> <span class=md-ellipsis> Core Components </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../architecture/ class=md-nav__link> <span class=md-ellipsis> Architecture </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../models/qwen/ class=md-nav__link> <span class=md-ellipsis> Models </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../performance/optimization-guide/ class=md-nav__link> <span class=md-ellipsis> Performance </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../training/advanced-features/ class=md-nav__link> <span class=md-ellipsis> Training </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../benchmark/ class=md-nav__link> <span class=md-ellipsis> Benchmark </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../api-reference/ class=md-nav__link> <span class=md-ellipsis> API Reference </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../contributing/ class=md-nav__link> <span class=md-ellipsis> Contributing </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/phonism/genesis/edit/main/docs/tutorials/mixed-precision.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/phonism/genesis/raw/main/docs/tutorials/mixed-precision.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=mixed-precision-training-guide>Mixed Precision Training Guide<a class=headerlink href=#mixed-precision-training-guide title="Permanent link">&para;</a></h1> <p>Mixed precision training is a technique that uses both 16-bit (half precision) and 32-bit (single precision) floating-point numbers during training to reduce memory usage and accelerate training while maintaining model accuracy. Genesis provides comprehensive support for mixed precision training with automatic mixed precision (AMP) capabilities.</p> <h2 id=overview>Overview<a class=headerlink href=#overview title="Permanent link">&para;</a></h2> <h3 id=benefits-of-mixed-precision-training>Benefits of Mixed Precision Training<a class=headerlink href=#benefits-of-mixed-precision-training title="Permanent link">&para;</a></h3> <ul> <li><strong>Memory Efficiency</strong>: Reduces memory usage by ~50%</li> <li><strong>Speed Improvement</strong>: Faster training on modern GPUs with Tensor Cores</li> <li><strong>Model Accuracy</strong>: Maintains training stability with automatic loss scaling</li> <li><strong>Larger Models</strong>: Enables training of larger models on the same hardware</li> </ul> <h3 id=supported-precision-types>Supported Precision Types<a class=headerlink href=#supported-precision-types title="Permanent link">&para;</a></h3> <p>Genesis supports multiple precision formats:</p> <ul> <li><strong>float32 (FP32)</strong>: Standard single precision (default)</li> <li><strong>float16 (FP16)</strong>: IEEE half precision </li> <li><strong>bfloat16 (BF16)</strong>: Brain float format with larger dynamic range</li> </ul> <h2 id=data-type-system>Data Type System<a class=headerlink href=#data-type-system title="Permanent link">&para;</a></h2> <h3 id=understanding-genesis-dtypes>Understanding Genesis DTypes<a class=headerlink href=#understanding-genesis-dtypes title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>import</span><span class=w> </span><span class=nn>genesis</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=c1># Available precision types</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Available dtypes:&quot;</span><span class=p>)</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;FP32: </span><span class=si>{</span><span class=n>genesis</span><span class=o>.</span><span class=n>float32</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># Standard precision</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;FP16: </span><span class=si>{</span><span class=n>genesis</span><span class=o>.</span><span class=n>float16</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># Half precision</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;BF16: </span><span class=si>{</span><span class=n>genesis</span><span class=o>.</span><span class=n>bfloat16</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span> <span class=c1># Brain float</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a><span class=c1># Check dtype properties</span>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=n>dtype</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>float16</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Name: </span><span class=si>{</span><span class=n>dtype</span><span class=o>.</span><span class=n>name</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Size: </span><span class=si>{</span><span class=n>dtype</span><span class=o>.</span><span class=n>itemsize</span><span class=si>}</span><span class=s2> bytes&quot;</span><span class=p>)</span>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Is floating: </span><span class=si>{</span><span class=n>dtype</span><span class=o>.</span><span class=n>is_floating_point</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;NumPy type: </span><span class=si>{</span><span class=n>dtype</span><span class=o>.</span><span class=n>numpy_dtype</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=creating-mixed-precision-tensors>Creating Mixed Precision Tensors<a class=headerlink href=#creating-mixed-precision-tensors title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=kn>import</span><span class=w> </span><span class=nn>genesis</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a><span class=c1># Create tensors with different precisions</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a><span class=n>fp32_tensor</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1000</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>genesis</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class=n>fp16_tensor</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1000</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>genesis</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span> 
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a><span class=n>bf16_tensor</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1000</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>genesis</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>)</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a>
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;FP32 memory: </span><span class=si>{</span><span class=n>fp32_tensor</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>4</span><span class=si>}</span><span class=s2> bytes&quot;</span><span class=p>)</span>
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;FP16 memory: </span><span class=si>{</span><span class=n>fp16_tensor</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>2</span><span class=si>}</span><span class=s2> bytes&quot;</span><span class=p>)</span> 
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;BF16 memory: </span><span class=si>{</span><span class=n>bf16_tensor</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>2</span><span class=si>}</span><span class=s2> bytes&quot;</span><span class=p>)</span>
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a>
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a><span class=c1># Type conversion</span>
</span><span id=__span-1-13><a id=__codelineno-1-13 name=__codelineno-1-13 href=#__codelineno-1-13></a><span class=n>fp16_from_fp32</span> <span class=o>=</span> <span class=n>fp32_tensor</span><span class=o>.</span><span class=n>half</span><span class=p>()</span>    <span class=c1># Convert to FP16</span>
</span><span id=__span-1-14><a id=__codelineno-1-14 name=__codelineno-1-14 href=#__codelineno-1-14></a><span class=n>fp32_from_fp16</span> <span class=o>=</span> <span class=n>fp16_tensor</span><span class=o>.</span><span class=n>float</span><span class=p>()</span>   <span class=c1># Convert to FP32</span>
</span></code></pre></div> <h2 id=automatic-mixed-precision-amp>Automatic Mixed Precision (AMP)<a class=headerlink href=#automatic-mixed-precision-amp title="Permanent link">&para;</a></h2> <h3 id=basic-amp-usage>Basic AMP Usage<a class=headerlink href=#basic-amp-usage title="Permanent link">&para;</a></h3> <p>Genesis provides automatic mixed precision through the <code>autocast</code> context and enable flag:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=kn>import</span><span class=w> </span><span class=nn>genesis</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=kn>import</span><span class=w> </span><span class=nn>genesis.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a><span class=c1># Enable automatic mixed precision globally</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a><span class=n>genesis</span><span class=o>.</span><span class=n>enable_autocast</span> <span class=o>=</span> <span class=kc>True</span>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a><span class=c1># Create model and data</span>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a><span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>784</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a><span class=n>x</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=mi>784</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a><span class=n>labels</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=p>(</span><span class=mi>32</span><span class=p>,),</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a><span class=c1># Forward pass with automatic casting</span>
</span><span id=__span-2-13><a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a><span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># Automatically uses mixed precision</span>
</span><span id=__span-2-14><a id=__codelineno-2-14 name=__codelineno-2-14 href=#__codelineno-2-14></a>
</span><span id=__span-2-15><a id=__codelineno-2-15 name=__codelineno-2-15 href=#__codelineno-2-15></a><span class=c1># Loss computation (typically done in FP32)</span>
</span><span id=__span-2-16><a id=__codelineno-2-16 name=__codelineno-2-16 href=#__codelineno-2-16></a><span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</span><span id=__span-2-17><a id=__codelineno-2-17 name=__codelineno-2-17 href=#__codelineno-2-17></a><span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span><span id=__span-2-18><a id=__codelineno-2-18 name=__codelineno-2-18 href=#__codelineno-2-18></a>
</span><span id=__span-2-19><a id=__codelineno-2-19 name=__codelineno-2-19 href=#__codelineno-2-19></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Input dtype: </span><span class=si>{</span><span class=n>x</span><span class=o>.</span><span class=n>dtype</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-2-20><a id=__codelineno-2-20 name=__codelineno-2-20 href=#__codelineno-2-20></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Output dtype: </span><span class=si>{</span><span class=n>outputs</span><span class=o>.</span><span class=n>dtype</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-2-21><a id=__codelineno-2-21 name=__codelineno-2-21 href=#__codelineno-2-21></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Loss dtype: </span><span class=si>{</span><span class=n>loss</span><span class=o>.</span><span class=n>dtype</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=manual-amp-control>Manual AMP Control<a class=headerlink href=#manual-amp-control title="Permanent link">&para;</a></h3> <p>For fine-grained control, use the <code>autocast</code> context manager:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=kn>import</span><span class=w> </span><span class=nn>genesis</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=c1># Disable global autocast</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a><span class=n>genesis</span><span class=o>.</span><span class=n>enable_autocast</span> <span class=o>=</span> <span class=kc>False</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a><span class=c1># Model setup</span>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a><span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>784</span><span class=p>,</span> <span class=mi>256</span><span class=p>),</span>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a>    <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span><span id=__span-3-12><a id=__codelineno-3-12 name=__codelineno-3-12 href=#__codelineno-3-12></a>
</span><span id=__span-3-13><a id=__codelineno-3-13 name=__codelineno-3-13 href=#__codelineno-3-13></a><span class=n>x</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=mi>784</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span><span id=__span-3-14><a id=__codelineno-3-14 name=__codelineno-3-14 href=#__codelineno-3-14></a>
</span><span id=__span-3-15><a id=__codelineno-3-15 name=__codelineno-3-15 href=#__codelineno-3-15></a><span class=c1># Manual mixed precision control</span>
</span><span id=__span-3-16><a id=__codelineno-3-16 name=__codelineno-3-16 href=#__codelineno-3-16></a><span class=k>with</span> <span class=n>genesis</span><span class=o>.</span><span class=n>autocast</span><span class=p>():</span>
</span><span id=__span-3-17><a id=__codelineno-3-17 name=__codelineno-3-17 href=#__codelineno-3-17></a>    <span class=c1># Operations inside this block use FP16/BF16</span>
</span><span id=__span-3-18><a id=__codelineno-3-18 name=__codelineno-3-18 href=#__codelineno-3-18></a>    <span class=n>hidden</span> <span class=o>=</span> <span class=n>model</span><span class=p>[</span><span class=mi>0</span><span class=p>](</span><span class=n>x</span><span class=p>)</span>  <span class=c1># Linear layer in FP16</span>
</span><span id=__span-3-19><a id=__codelineno-3-19 name=__codelineno-3-19 href=#__codelineno-3-19></a>    <span class=n>activated</span> <span class=o>=</span> <span class=n>model</span><span class=p>[</span><span class=mi>1</span><span class=p>](</span><span class=n>hidden</span><span class=p>)</span>  <span class=c1># ReLU in FP16</span>
</span><span id=__span-3-20><a id=__codelineno-3-20 name=__codelineno-3-20 href=#__codelineno-3-20></a>
</span><span id=__span-3-21><a id=__codelineno-3-21 name=__codelineno-3-21 href=#__codelineno-3-21></a><span class=c1># Operations outside use default precision</span>
</span><span id=__span-3-22><a id=__codelineno-3-22 name=__codelineno-3-22 href=#__codelineno-3-22></a><span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>[</span><span class=mi>2</span><span class=p>](</span><span class=n>activated</span><span class=p>)</span>  <span class=c1># This will be FP32</span>
</span><span id=__span-3-23><a id=__codelineno-3-23 name=__codelineno-3-23 href=#__codelineno-3-23></a>
</span><span id=__span-3-24><a id=__codelineno-3-24 name=__codelineno-3-24 href=#__codelineno-3-24></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Hidden dtype: </span><span class=si>{</span><span class=n>hidden</span><span class=o>.</span><span class=n>dtype</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-3-25><a id=__codelineno-3-25 name=__codelineno-3-25 href=#__codelineno-3-25></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Activated dtype: </span><span class=si>{</span><span class=n>activated</span><span class=o>.</span><span class=n>dtype</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-3-26><a id=__codelineno-3-26 name=__codelineno-3-26 href=#__codelineno-3-26></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Output dtype: </span><span class=si>{</span><span class=n>outputs</span><span class=o>.</span><span class=n>dtype</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <h2 id=training-with-mixed-precision>Training with Mixed Precision<a class=headerlink href=#training-with-mixed-precision title="Permanent link">&para;</a></h2> <h3 id=simple-mixed-precision-training-loop>Simple Mixed Precision Training Loop<a class=headerlink href=#simple-mixed-precision-training-loop title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=kn>import</span><span class=w> </span><span class=nn>genesis</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=kn>import</span><span class=w> </span><span class=nn>genesis.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=kn>import</span><span class=w> </span><span class=nn>genesis.optim</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>optim</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=c1># Model setup</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a><span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>784</span><span class=p>,</span> <span class=mi>512</span><span class=p>),</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>    <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.2</span><span class=p>),</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>256</span><span class=p>),</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a>    <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.2</span><span class=p>),</span>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a>    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span><span id=__span-4-15><a id=__codelineno-4-15 name=__codelineno-4-15 href=#__codelineno-4-15></a>
</span><span id=__span-4-16><a id=__codelineno-4-16 name=__codelineno-4-16 href=#__codelineno-4-16></a><span class=c1># Optimizer</span>
</span><span id=__span-4-17><a id=__codelineno-4-17 name=__codelineno-4-17 href=#__codelineno-4-17></a><span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>)</span>
</span><span id=__span-4-18><a id=__codelineno-4-18 name=__codelineno-4-18 href=#__codelineno-4-18></a>
</span><span id=__span-4-19><a id=__codelineno-4-19 name=__codelineno-4-19 href=#__codelineno-4-19></a><span class=c1># Loss function</span>
</span><span id=__span-4-20><a id=__codelineno-4-20 name=__codelineno-4-20 href=#__codelineno-4-20></a><span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</span><span id=__span-4-21><a id=__codelineno-4-21 name=__codelineno-4-21 href=#__codelineno-4-21></a>
</span><span id=__span-4-22><a id=__codelineno-4-22 name=__codelineno-4-22 href=#__codelineno-4-22></a><span class=c1># Enable mixed precision</span>
</span><span id=__span-4-23><a id=__codelineno-4-23 name=__codelineno-4-23 href=#__codelineno-4-23></a><span class=n>genesis</span><span class=o>.</span><span class=n>enable_autocast</span> <span class=o>=</span> <span class=kc>True</span>
</span><span id=__span-4-24><a id=__codelineno-4-24 name=__codelineno-4-24 href=#__codelineno-4-24></a>
</span><span id=__span-4-25><a id=__codelineno-4-25 name=__codelineno-4-25 href=#__codelineno-4-25></a><span class=k>def</span><span class=w> </span><span class=nf>train_epoch_amp</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>dataloader</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>criterion</span><span class=p>):</span>
</span><span id=__span-4-26><a id=__codelineno-4-26 name=__codelineno-4-26 href=#__codelineno-4-26></a>    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span><span id=__span-4-27><a id=__codelineno-4-27 name=__codelineno-4-27 href=#__codelineno-4-27></a>    <span class=n>total_loss</span> <span class=o>=</span> <span class=mf>0.0</span>
</span><span id=__span-4-28><a id=__codelineno-4-28 name=__codelineno-4-28 href=#__codelineno-4-28></a>
</span><span id=__span-4-29><a id=__codelineno-4-29 name=__codelineno-4-29 href=#__codelineno-4-29></a>    <span class=k>for</span> <span class=n>batch_idx</span><span class=p>,</span> <span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>targets</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>dataloader</span><span class=p>):</span>
</span><span id=__span-4-30><a id=__codelineno-4-30 name=__codelineno-4-30 href=#__codelineno-4-30></a>        <span class=n>data</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span><span id=__span-4-31><a id=__codelineno-4-31 name=__codelineno-4-31 href=#__codelineno-4-31></a>        <span class=n>targets</span> <span class=o>=</span> <span class=n>targets</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span><span id=__span-4-32><a id=__codelineno-4-32 name=__codelineno-4-32 href=#__codelineno-4-32></a>
</span><span id=__span-4-33><a id=__codelineno-4-33 name=__codelineno-4-33 href=#__codelineno-4-33></a>        <span class=c1># Zero gradients</span>
</span><span id=__span-4-34><a id=__codelineno-4-34 name=__codelineno-4-34 href=#__codelineno-4-34></a>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span><span id=__span-4-35><a id=__codelineno-4-35 name=__codelineno-4-35 href=#__codelineno-4-35></a>
</span><span id=__span-4-36><a id=__codelineno-4-36 name=__codelineno-4-36 href=#__codelineno-4-36></a>        <span class=c1># Forward pass with mixed precision</span>
</span><span id=__span-4-37><a id=__codelineno-4-37 name=__codelineno-4-37 href=#__codelineno-4-37></a>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span><span id=__span-4-38><a id=__codelineno-4-38 name=__codelineno-4-38 href=#__codelineno-4-38></a>        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>targets</span><span class=p>)</span>
</span><span id=__span-4-39><a id=__codelineno-4-39 name=__codelineno-4-39 href=#__codelineno-4-39></a>
</span><span id=__span-4-40><a id=__codelineno-4-40 name=__codelineno-4-40 href=#__codelineno-4-40></a>        <span class=c1># Backward pass</span>
</span><span id=__span-4-41><a id=__codelineno-4-41 name=__codelineno-4-41 href=#__codelineno-4-41></a>        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-4-42><a id=__codelineno-4-42 name=__codelineno-4-42 href=#__codelineno-4-42></a>
</span><span id=__span-4-43><a id=__codelineno-4-43 name=__codelineno-4-43 href=#__codelineno-4-43></a>        <span class=c1># Gradient clipping (important for stability)</span>
</span><span id=__span-4-44><a id=__codelineno-4-44 name=__codelineno-4-44 href=#__codelineno-4-44></a>        <span class=n>nn</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>clip_grad_norm_</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>max_norm</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span>
</span><span id=__span-4-45><a id=__codelineno-4-45 name=__codelineno-4-45 href=#__codelineno-4-45></a>
</span><span id=__span-4-46><a id=__codelineno-4-46 name=__codelineno-4-46 href=#__codelineno-4-46></a>        <span class=c1># Optimizer step</span>
</span><span id=__span-4-47><a id=__codelineno-4-47 name=__codelineno-4-47 href=#__codelineno-4-47></a>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span><span id=__span-4-48><a id=__codelineno-4-48 name=__codelineno-4-48 href=#__codelineno-4-48></a>
</span><span id=__span-4-49><a id=__codelineno-4-49 name=__codelineno-4-49 href=#__codelineno-4-49></a>        <span class=n>total_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span><span id=__span-4-50><a id=__codelineno-4-50 name=__codelineno-4-50 href=#__codelineno-4-50></a>
</span><span id=__span-4-51><a id=__codelineno-4-51 name=__codelineno-4-51 href=#__codelineno-4-51></a>        <span class=k>if</span> <span class=n>batch_idx</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-4-52><a id=__codelineno-4-52 name=__codelineno-4-52 href=#__codelineno-4-52></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Batch </span><span class=si>{</span><span class=n>batch_idx</span><span class=si>}</span><span class=s1>: loss=</span><span class=si>{</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span><span id=__span-4-53><a id=__codelineno-4-53 name=__codelineno-4-53 href=#__codelineno-4-53></a>
</span><span id=__span-4-54><a id=__codelineno-4-54 name=__codelineno-4-54 href=#__codelineno-4-54></a>    <span class=k>return</span> <span class=n>total_loss</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>dataloader</span><span class=p>)</span>
</span><span id=__span-4-55><a id=__codelineno-4-55 name=__codelineno-4-55 href=#__codelineno-4-55></a>
</span><span id=__span-4-56><a id=__codelineno-4-56 name=__codelineno-4-56 href=#__codelineno-4-56></a><span class=c1># Training</span>
</span><span id=__span-4-57><a id=__codelineno-4-57 name=__codelineno-4-57 href=#__codelineno-4-57></a><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
</span><span id=__span-4-58><a id=__codelineno-4-58 name=__codelineno-4-58 href=#__codelineno-4-58></a>    <span class=n>avg_loss</span> <span class=o>=</span> <span class=n>train_epoch_amp</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>train_loader</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>criterion</span><span class=p>)</span>
</span><span id=__span-4-59><a id=__codelineno-4-59 name=__codelineno-4-59 href=#__codelineno-4-59></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Epoch </span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s1>: avg loss = </span><span class=si>{</span><span class=n>avg_loss</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=advanced-mixed-precision-with-loss-scaling>Advanced Mixed Precision with Loss Scaling<a class=headerlink href=#advanced-mixed-precision-with-loss-scaling title="Permanent link">&para;</a></h3> <p>For training stability, especially with FP16, loss scaling is recommended:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=k>class</span><span class=w> </span><span class=nc>GradScaler</span><span class=p>:</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Gradient scaler for mixed precision training.&quot;&quot;&quot;</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>init_scale</span><span class=o>=</span><span class=mi>2</span><span class=o>**</span><span class=mi>16</span><span class=p>,</span> <span class=n>growth_factor</span><span class=o>=</span><span class=mf>2.0</span><span class=p>,</span> <span class=n>backoff_factor</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> 
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a>                 <span class=n>growth_interval</span><span class=o>=</span><span class=mi>2000</span><span class=p>):</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>        <span class=bp>self</span><span class=o>.</span><span class=n>scale</span> <span class=o>=</span> <span class=n>init_scale</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a>        <span class=bp>self</span><span class=o>.</span><span class=n>growth_factor</span> <span class=o>=</span> <span class=n>growth_factor</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a>        <span class=bp>self</span><span class=o>.</span><span class=n>backoff_factor</span> <span class=o>=</span> <span class=n>backoff_factor</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a>        <span class=bp>self</span><span class=o>.</span><span class=n>growth_interval</span> <span class=o>=</span> <span class=n>growth_interval</span>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a>        <span class=bp>self</span><span class=o>.</span><span class=n>_growth_tracker</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a>    <span class=k>def</span><span class=w> </span><span class=nf>scale_loss</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>loss</span><span class=p>):</span>
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Scale loss to prevent gradient underflow.&quot;&quot;&quot;</span>
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a>        <span class=k>return</span> <span class=n>loss</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>scale</span>
</span><span id=__span-5-15><a id=__codelineno-5-15 name=__codelineno-5-15 href=#__codelineno-5-15></a>
</span><span id=__span-5-16><a id=__codelineno-5-16 name=__codelineno-5-16 href=#__codelineno-5-16></a>    <span class=k>def</span><span class=w> </span><span class=nf>unscale_gradients</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>):</span>
</span><span id=__span-5-17><a id=__codelineno-5-17 name=__codelineno-5-17 href=#__codelineno-5-17></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Unscale gradients before optimizer step.&quot;&quot;&quot;</span>
</span><span id=__span-5-18><a id=__codelineno-5-18 name=__codelineno-5-18 href=#__codelineno-5-18></a>        <span class=k>for</span> <span class=n>param_group</span> <span class=ow>in</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>param_groups</span><span class=p>:</span>
</span><span id=__span-5-19><a id=__codelineno-5-19 name=__codelineno-5-19 href=#__codelineno-5-19></a>            <span class=k>for</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>param_group</span><span class=p>[</span><span class=s1>&#39;params&#39;</span><span class=p>]:</span>
</span><span id=__span-5-20><a id=__codelineno-5-20 name=__codelineno-5-20 href=#__codelineno-5-20></a>                <span class=k>if</span> <span class=n>param</span><span class=o>.</span><span class=n>grad</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-5-21><a id=__codelineno-5-21 name=__codelineno-5-21 href=#__codelineno-5-21></a>                    <span class=n>param</span><span class=o>.</span><span class=n>grad</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>div_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>scale</span><span class=p>)</span>
</span><span id=__span-5-22><a id=__codelineno-5-22 name=__codelineno-5-22 href=#__codelineno-5-22></a>
</span><span id=__span-5-23><a id=__codelineno-5-23 name=__codelineno-5-23 href=#__codelineno-5-23></a>    <span class=k>def</span><span class=w> </span><span class=nf>step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>):</span>
</span><span id=__span-5-24><a id=__codelineno-5-24 name=__codelineno-5-24 href=#__codelineno-5-24></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Step optimizer with gradient overflow detection.&quot;&quot;&quot;</span>
</span><span id=__span-5-25><a id=__codelineno-5-25 name=__codelineno-5-25 href=#__codelineno-5-25></a>        <span class=c1># Check for gradient overflow</span>
</span><span id=__span-5-26><a id=__codelineno-5-26 name=__codelineno-5-26 href=#__codelineno-5-26></a>        <span class=n>has_overflow</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_check_overflow</span><span class=p>(</span><span class=n>optimizer</span><span class=p>)</span>
</span><span id=__span-5-27><a id=__codelineno-5-27 name=__codelineno-5-27 href=#__codelineno-5-27></a>
</span><span id=__span-5-28><a id=__codelineno-5-28 name=__codelineno-5-28 href=#__codelineno-5-28></a>        <span class=k>if</span> <span class=n>has_overflow</span><span class=p>:</span>
</span><span id=__span-5-29><a id=__codelineno-5-29 name=__codelineno-5-29 href=#__codelineno-5-29></a>            <span class=c1># Skip optimizer step and reduce scale</span>
</span><span id=__span-5-30><a id=__codelineno-5-30 name=__codelineno-5-30 href=#__codelineno-5-30></a>            <span class=bp>self</span><span class=o>.</span><span class=n>scale</span> <span class=o>*=</span> <span class=bp>self</span><span class=o>.</span><span class=n>backoff_factor</span>
</span><span id=__span-5-31><a id=__codelineno-5-31 name=__codelineno-5-31 href=#__codelineno-5-31></a>            <span class=bp>self</span><span class=o>.</span><span class=n>scale</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>scale</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>)</span>
</span><span id=__span-5-32><a id=__codelineno-5-32 name=__codelineno-5-32 href=#__codelineno-5-32></a>            <span class=bp>self</span><span class=o>.</span><span class=n>_growth_tracker</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-5-33><a id=__codelineno-5-33 name=__codelineno-5-33 href=#__codelineno-5-33></a>            <span class=k>return</span> <span class=kc>False</span>
</span><span id=__span-5-34><a id=__codelineno-5-34 name=__codelineno-5-34 href=#__codelineno-5-34></a>        <span class=k>else</span><span class=p>:</span>
</span><span id=__span-5-35><a id=__codelineno-5-35 name=__codelineno-5-35 href=#__codelineno-5-35></a>            <span class=c1># Normal optimizer step</span>
</span><span id=__span-5-36><a id=__codelineno-5-36 name=__codelineno-5-36 href=#__codelineno-5-36></a>            <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span><span id=__span-5-37><a id=__codelineno-5-37 name=__codelineno-5-37 href=#__codelineno-5-37></a>
</span><span id=__span-5-38><a id=__codelineno-5-38 name=__codelineno-5-38 href=#__codelineno-5-38></a>            <span class=c1># Increase scale periodically</span>
</span><span id=__span-5-39><a id=__codelineno-5-39 name=__codelineno-5-39 href=#__codelineno-5-39></a>            <span class=bp>self</span><span class=o>.</span><span class=n>_growth_tracker</span> <span class=o>+=</span> <span class=mi>1</span>
</span><span id=__span-5-40><a id=__codelineno-5-40 name=__codelineno-5-40 href=#__codelineno-5-40></a>            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_growth_tracker</span> <span class=o>&gt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>growth_interval</span><span class=p>:</span>
</span><span id=__span-5-41><a id=__codelineno-5-41 name=__codelineno-5-41 href=#__codelineno-5-41></a>                <span class=bp>self</span><span class=o>.</span><span class=n>scale</span> <span class=o>*=</span> <span class=bp>self</span><span class=o>.</span><span class=n>growth_factor</span>
</span><span id=__span-5-42><a id=__codelineno-5-42 name=__codelineno-5-42 href=#__codelineno-5-42></a>                <span class=bp>self</span><span class=o>.</span><span class=n>_growth_tracker</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-5-43><a id=__codelineno-5-43 name=__codelineno-5-43 href=#__codelineno-5-43></a>
</span><span id=__span-5-44><a id=__codelineno-5-44 name=__codelineno-5-44 href=#__codelineno-5-44></a>            <span class=k>return</span> <span class=kc>True</span>
</span><span id=__span-5-45><a id=__codelineno-5-45 name=__codelineno-5-45 href=#__codelineno-5-45></a>
</span><span id=__span-5-46><a id=__codelineno-5-46 name=__codelineno-5-46 href=#__codelineno-5-46></a>    <span class=k>def</span><span class=w> </span><span class=nf>_check_overflow</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>):</span>
</span><span id=__span-5-47><a id=__codelineno-5-47 name=__codelineno-5-47 href=#__codelineno-5-47></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Check if any gradients have overflowed.&quot;&quot;&quot;</span>
</span><span id=__span-5-48><a id=__codelineno-5-48 name=__codelineno-5-48 href=#__codelineno-5-48></a>        <span class=k>for</span> <span class=n>param_group</span> <span class=ow>in</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>param_groups</span><span class=p>:</span>
</span><span id=__span-5-49><a id=__codelineno-5-49 name=__codelineno-5-49 href=#__codelineno-5-49></a>            <span class=k>for</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>param_group</span><span class=p>[</span><span class=s1>&#39;params&#39;</span><span class=p>]:</span>
</span><span id=__span-5-50><a id=__codelineno-5-50 name=__codelineno-5-50 href=#__codelineno-5-50></a>                <span class=k>if</span> <span class=n>param</span><span class=o>.</span><span class=n>grad</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-5-51><a id=__codelineno-5-51 name=__codelineno-5-51 href=#__codelineno-5-51></a>                    <span class=k>if</span> <span class=n>genesis</span><span class=o>.</span><span class=n>isnan</span><span class=p>(</span><span class=n>param</span><span class=o>.</span><span class=n>grad</span><span class=p>)</span><span class=o>.</span><span class=n>any</span><span class=p>()</span> <span class=ow>or</span> <span class=n>genesis</span><span class=o>.</span><span class=n>isinf</span><span class=p>(</span><span class=n>param</span><span class=o>.</span><span class=n>grad</span><span class=p>)</span><span class=o>.</span><span class=n>any</span><span class=p>():</span>
</span><span id=__span-5-52><a id=__codelineno-5-52 name=__codelineno-5-52 href=#__codelineno-5-52></a>                        <span class=k>return</span> <span class=kc>True</span>
</span><span id=__span-5-53><a id=__codelineno-5-53 name=__codelineno-5-53 href=#__codelineno-5-53></a>        <span class=k>return</span> <span class=kc>False</span>
</span><span id=__span-5-54><a id=__codelineno-5-54 name=__codelineno-5-54 href=#__codelineno-5-54></a>
</span><span id=__span-5-55><a id=__codelineno-5-55 name=__codelineno-5-55 href=#__codelineno-5-55></a><span class=c1># Training with gradient scaling</span>
</span><span id=__span-5-56><a id=__codelineno-5-56 name=__codelineno-5-56 href=#__codelineno-5-56></a><span class=n>scaler</span> <span class=o>=</span> <span class=n>GradScaler</span><span class=p>()</span>
</span><span id=__span-5-57><a id=__codelineno-5-57 name=__codelineno-5-57 href=#__codelineno-5-57></a>
</span><span id=__span-5-58><a id=__codelineno-5-58 name=__codelineno-5-58 href=#__codelineno-5-58></a><span class=k>def</span><span class=w> </span><span class=nf>train_with_scaling</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>dataloader</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>criterion</span><span class=p>,</span> <span class=n>scaler</span><span class=p>):</span>
</span><span id=__span-5-59><a id=__codelineno-5-59 name=__codelineno-5-59 href=#__codelineno-5-59></a>    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span><span id=__span-5-60><a id=__codelineno-5-60 name=__codelineno-5-60 href=#__codelineno-5-60></a>    <span class=n>total_loss</span> <span class=o>=</span> <span class=mf>0.0</span>
</span><span id=__span-5-61><a id=__codelineno-5-61 name=__codelineno-5-61 href=#__codelineno-5-61></a>    <span class=n>successful_steps</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-5-62><a id=__codelineno-5-62 name=__codelineno-5-62 href=#__codelineno-5-62></a>
</span><span id=__span-5-63><a id=__codelineno-5-63 name=__codelineno-5-63 href=#__codelineno-5-63></a>    <span class=k>for</span> <span class=n>batch_idx</span><span class=p>,</span> <span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>targets</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>dataloader</span><span class=p>):</span>
</span><span id=__span-5-64><a id=__codelineno-5-64 name=__codelineno-5-64 href=#__codelineno-5-64></a>        <span class=n>data</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span><span id=__span-5-65><a id=__codelineno-5-65 name=__codelineno-5-65 href=#__codelineno-5-65></a>        <span class=n>targets</span> <span class=o>=</span> <span class=n>targets</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span><span id=__span-5-66><a id=__codelineno-5-66 name=__codelineno-5-66 href=#__codelineno-5-66></a>
</span><span id=__span-5-67><a id=__codelineno-5-67 name=__codelineno-5-67 href=#__codelineno-5-67></a>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span><span id=__span-5-68><a id=__codelineno-5-68 name=__codelineno-5-68 href=#__codelineno-5-68></a>
</span><span id=__span-5-69><a id=__codelineno-5-69 name=__codelineno-5-69 href=#__codelineno-5-69></a>        <span class=c1># Forward pass with mixed precision</span>
</span><span id=__span-5-70><a id=__codelineno-5-70 name=__codelineno-5-70 href=#__codelineno-5-70></a>        <span class=k>with</span> <span class=n>genesis</span><span class=o>.</span><span class=n>autocast</span><span class=p>():</span>
</span><span id=__span-5-71><a id=__codelineno-5-71 name=__codelineno-5-71 href=#__codelineno-5-71></a>            <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span><span id=__span-5-72><a id=__codelineno-5-72 name=__codelineno-5-72 href=#__codelineno-5-72></a>            <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>targets</span><span class=p>)</span>
</span><span id=__span-5-73><a id=__codelineno-5-73 name=__codelineno-5-73 href=#__codelineno-5-73></a>
</span><span id=__span-5-74><a id=__codelineno-5-74 name=__codelineno-5-74 href=#__codelineno-5-74></a>        <span class=c1># Scale loss to prevent gradient underflow</span>
</span><span id=__span-5-75><a id=__codelineno-5-75 name=__codelineno-5-75 href=#__codelineno-5-75></a>        <span class=n>scaled_loss</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>scale_loss</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span>
</span><span id=__span-5-76><a id=__codelineno-5-76 name=__codelineno-5-76 href=#__codelineno-5-76></a>        <span class=n>scaled_loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-5-77><a id=__codelineno-5-77 name=__codelineno-5-77 href=#__codelineno-5-77></a>
</span><span id=__span-5-78><a id=__codelineno-5-78 name=__codelineno-5-78 href=#__codelineno-5-78></a>        <span class=c1># Unscale gradients and check for overflow</span>
</span><span id=__span-5-79><a id=__codelineno-5-79 name=__codelineno-5-79 href=#__codelineno-5-79></a>        <span class=n>scaler</span><span class=o>.</span><span class=n>unscale_gradients</span><span class=p>(</span><span class=n>optimizer</span><span class=p>)</span>
</span><span id=__span-5-80><a id=__codelineno-5-80 name=__codelineno-5-80 href=#__codelineno-5-80></a>
</span><span id=__span-5-81><a id=__codelineno-5-81 name=__codelineno-5-81 href=#__codelineno-5-81></a>        <span class=c1># Gradient clipping on unscaled gradients</span>
</span><span id=__span-5-82><a id=__codelineno-5-82 name=__codelineno-5-82 href=#__codelineno-5-82></a>        <span class=n>nn</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>clip_grad_norm_</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>max_norm</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span>
</span><span id=__span-5-83><a id=__codelineno-5-83 name=__codelineno-5-83 href=#__codelineno-5-83></a>
</span><span id=__span-5-84><a id=__codelineno-5-84 name=__codelineno-5-84 href=#__codelineno-5-84></a>        <span class=c1># Step optimizer with overflow detection</span>
</span><span id=__span-5-85><a id=__codelineno-5-85 name=__codelineno-5-85 href=#__codelineno-5-85></a>        <span class=k>if</span> <span class=n>scaler</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>optimizer</span><span class=p>):</span>
</span><span id=__span-5-86><a id=__codelineno-5-86 name=__codelineno-5-86 href=#__codelineno-5-86></a>            <span class=n>successful_steps</span> <span class=o>+=</span> <span class=mi>1</span>
</span><span id=__span-5-87><a id=__codelineno-5-87 name=__codelineno-5-87 href=#__codelineno-5-87></a>
</span><span id=__span-5-88><a id=__codelineno-5-88 name=__codelineno-5-88 href=#__codelineno-5-88></a>        <span class=n>total_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span><span id=__span-5-89><a id=__codelineno-5-89 name=__codelineno-5-89 href=#__codelineno-5-89></a>
</span><span id=__span-5-90><a id=__codelineno-5-90 name=__codelineno-5-90 href=#__codelineno-5-90></a>        <span class=k>if</span> <span class=n>batch_idx</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-5-91><a id=__codelineno-5-91 name=__codelineno-5-91 href=#__codelineno-5-91></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Batch </span><span class=si>{</span><span class=n>batch_idx</span><span class=si>}</span><span class=s1>: loss=</span><span class=si>{</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>, scale=</span><span class=si>{</span><span class=n>scaler</span><span class=o>.</span><span class=n>scale</span><span class=si>:</span><span class=s1>.0f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span><span id=__span-5-92><a id=__codelineno-5-92 name=__codelineno-5-92 href=#__codelineno-5-92></a>
</span><span id=__span-5-93><a id=__codelineno-5-93 name=__codelineno-5-93 href=#__codelineno-5-93></a>    <span class=n>success_rate</span> <span class=o>=</span> <span class=n>successful_steps</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>dataloader</span><span class=p>)</span>
</span><span id=__span-5-94><a id=__codelineno-5-94 name=__codelineno-5-94 href=#__codelineno-5-94></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Training success rate: </span><span class=si>{</span><span class=n>success_rate</span><span class=si>:</span><span class=s1>.1%</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span><span id=__span-5-95><a id=__codelineno-5-95 name=__codelineno-5-95 href=#__codelineno-5-95></a>
</span><span id=__span-5-96><a id=__codelineno-5-96 name=__codelineno-5-96 href=#__codelineno-5-96></a>    <span class=k>return</span> <span class=n>total_loss</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>dataloader</span><span class=p>)</span>
</span></code></pre></div> <h2 id=precision-specific-considerations>Precision-Specific Considerations<a class=headerlink href=#precision-specific-considerations title="Permanent link">&para;</a></h2> <h3 id=fp16-half-precision>FP16 (Half Precision)<a class=headerlink href=#fp16-half-precision title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=kn>import</span><span class=w> </span><span class=nn>genesis</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a><span class=c1># FP16 characteristics</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=n>fp16_info</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>    <span class=s1>&#39;range&#39;</span><span class=p>:</span> <span class=s1>&#39;65,504&#39;</span><span class=p>,</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>    <span class=s1>&#39;precision&#39;</span><span class=p>:</span> <span class=s1>&#39;~3-4 decimal digits&#39;</span><span class=p>,</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>    <span class=s1>&#39;special_values&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;inf&#39;</span><span class=p>,</span> <span class=s1>&#39;-inf&#39;</span><span class=p>,</span> <span class=s1>&#39;nan&#39;</span><span class=p>],</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>    <span class=s1>&#39;benefits&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Faster on Tensor Cores&#39;</span><span class=p>,</span> <span class=s1>&#39;50% memory reduction&#39;</span><span class=p>],</span>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a>    <span class=s1>&#39;challenges&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Limited range&#39;</span><span class=p>,</span> <span class=s1>&#39;Gradient underflow&#39;</span><span class=p>]</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a><span class=p>}</span>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a><span class=c1># Best practices for FP16</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a><span class=k>def</span><span class=w> </span><span class=nf>create_fp16_model</span><span class=p>():</span>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a>        <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>784</span><span class=p>,</span> <span class=mi>256</span><span class=p>),</span>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a>        <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=mi>256</span><span class=p>),</span>  <span class=c1># LayerNorm works well with FP16</span>
</span><span id=__span-6-17><a id=__codelineno-6-17 name=__codelineno-6-17 href=#__codelineno-6-17></a>        <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span><span id=__span-6-18><a id=__codelineno-6-18 name=__codelineno-6-18 href=#__codelineno-6-18></a>        <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
</span><span id=__span-6-19><a id=__codelineno-6-19 name=__codelineno-6-19 href=#__codelineno-6-19></a>    <span class=p>)</span>
</span><span id=__span-6-20><a id=__codelineno-6-20 name=__codelineno-6-20 href=#__codelineno-6-20></a>
</span><span id=__span-6-21><a id=__codelineno-6-21 name=__codelineno-6-21 href=#__codelineno-6-21></a>    <span class=c1># Initialize with appropriate scale for FP16</span>
</span><span id=__span-6-22><a id=__codelineno-6-22 name=__codelineno-6-22 href=#__codelineno-6-22></a>    <span class=k>for</span> <span class=n>module</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>modules</span><span class=p>():</span>
</span><span id=__span-6-23><a id=__codelineno-6-23 name=__codelineno-6-23 href=#__codelineno-6-23></a>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>):</span>
</span><span id=__span-6-24><a id=__codelineno-6-24 name=__codelineno-6-24 href=#__codelineno-6-24></a>            <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>xavier_uniform_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=n>gain</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span>
</span><span id=__span-6-25><a id=__codelineno-6-25 name=__codelineno-6-25 href=#__codelineno-6-25></a>            <span class=k>if</span> <span class=n>module</span><span class=o>.</span><span class=n>bias</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-6-26><a id=__codelineno-6-26 name=__codelineno-6-26 href=#__codelineno-6-26></a>                <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>zeros_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>bias</span><span class=p>)</span>
</span><span id=__span-6-27><a id=__codelineno-6-27 name=__codelineno-6-27 href=#__codelineno-6-27></a>
</span><span id=__span-6-28><a id=__codelineno-6-28 name=__codelineno-6-28 href=#__codelineno-6-28></a>    <span class=k>return</span> <span class=n>model</span>
</span><span id=__span-6-29><a id=__codelineno-6-29 name=__codelineno-6-29 href=#__codelineno-6-29></a>
</span><span id=__span-6-30><a id=__codelineno-6-30 name=__codelineno-6-30 href=#__codelineno-6-30></a><span class=c1># Monitor FP16 training</span>
</span><span id=__span-6-31><a id=__codelineno-6-31 name=__codelineno-6-31 href=#__codelineno-6-31></a><span class=k>def</span><span class=w> </span><span class=nf>check_fp16_health</span><span class=p>(</span><span class=n>model</span><span class=p>):</span>
</span><span id=__span-6-32><a id=__codelineno-6-32 name=__codelineno-6-32 href=#__codelineno-6-32></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Check model health during FP16 training.&quot;&quot;&quot;</span>
</span><span id=__span-6-33><a id=__codelineno-6-33 name=__codelineno-6-33 href=#__codelineno-6-33></a>    <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
</span><span id=__span-6-34><a id=__codelineno-6-34 name=__codelineno-6-34 href=#__codelineno-6-34></a>        <span class=k>if</span> <span class=n>param</span><span class=o>.</span><span class=n>grad</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-6-35><a id=__codelineno-6-35 name=__codelineno-6-35 href=#__codelineno-6-35></a>            <span class=n>grad_norm</span> <span class=o>=</span> <span class=n>param</span><span class=o>.</span><span class=n>grad</span><span class=o>.</span><span class=n>norm</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span><span id=__span-6-36><a id=__codelineno-6-36 name=__codelineno-6-36 href=#__codelineno-6-36></a>            <span class=n>param_norm</span> <span class=o>=</span> <span class=n>param</span><span class=o>.</span><span class=n>norm</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span><span id=__span-6-37><a id=__codelineno-6-37 name=__codelineno-6-37 href=#__codelineno-6-37></a>
</span><span id=__span-6-38><a id=__codelineno-6-38 name=__codelineno-6-38 href=#__codelineno-6-38></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>:&quot;</span><span class=p>)</span>
</span><span id=__span-6-39><a id=__codelineno-6-39 name=__codelineno-6-39 href=#__codelineno-6-39></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Param norm: </span><span class=si>{</span><span class=n>param_norm</span><span class=si>:</span><span class=s2>.2e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-6-40><a id=__codelineno-6-40 name=__codelineno-6-40 href=#__codelineno-6-40></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Grad norm: </span><span class=si>{</span><span class=n>grad_norm</span><span class=si>:</span><span class=s2>.2e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-6-41><a id=__codelineno-6-41 name=__codelineno-6-41 href=#__codelineno-6-41></a>
</span><span id=__span-6-42><a id=__codelineno-6-42 name=__codelineno-6-42 href=#__codelineno-6-42></a>            <span class=c1># Check for problematic values</span>
</span><span id=__span-6-43><a id=__codelineno-6-43 name=__codelineno-6-43 href=#__codelineno-6-43></a>            <span class=k>if</span> <span class=n>grad_norm</span> <span class=o>&lt;</span> <span class=mf>1e-7</span><span class=p>:</span>
</span><span id=__span-6-44><a id=__codelineno-6-44 name=__codelineno-6-44 href=#__codelineno-6-44></a>                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  WARNING: Very small gradients detected!&quot;</span><span class=p>)</span>
</span><span id=__span-6-45><a id=__codelineno-6-45 name=__codelineno-6-45 href=#__codelineno-6-45></a>            <span class=k>if</span> <span class=n>grad_norm</span> <span class=o>&gt;</span> <span class=mf>1e4</span><span class=p>:</span>
</span><span id=__span-6-46><a id=__codelineno-6-46 name=__codelineno-6-46 href=#__codelineno-6-46></a>                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  WARNING: Very large gradients detected!&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=bf16-brain-float>BF16 (Brain Float)<a class=headerlink href=#bf16-brain-float title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=kn>import</span><span class=w> </span><span class=nn>genesis</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=c1># BF16 advantages</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=n>bf16_info</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a>    <span class=s1>&#39;range&#39;</span><span class=p>:</span> <span class=s1>&#39;Same as FP32 (3.410^38)&#39;</span><span class=p>,</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>    <span class=s1>&#39;precision&#39;</span><span class=p>:</span> <span class=s1>&#39;~2-3 decimal digits&#39;</span><span class=p>,</span> 
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>    <span class=s1>&#39;benefits&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Larger range than FP16&#39;</span><span class=p>,</span> <span class=s1>&#39;More stable training&#39;</span><span class=p>],</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a>    <span class=s1>&#39;hardware&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;A100&#39;</span><span class=p>,</span> <span class=s1>&#39;H100&#39;</span><span class=p>,</span> <span class=s1>&#39;TPUs&#39;</span><span class=p>]</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a><span class=p>}</span>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a><span class=c1># BF16 is often more stable than FP16</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a><span class=k>def</span><span class=w> </span><span class=nf>train_with_bf16</span><span class=p>():</span>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a>    <span class=c1># Create model with BF16</span>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1000</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span><span id=__span-7-15><a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a>    <span class=n>x</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>genesis</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span><span id=__span-7-16><a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a>
</span><span id=__span-7-17><a id=__codelineno-7-17 name=__codelineno-7-17 href=#__codelineno-7-17></a>    <span class=c1># BF16 forward pass</span>
</span><span id=__span-7-18><a id=__codelineno-7-18 name=__codelineno-7-18 href=#__codelineno-7-18></a>    <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span><span id=__span-7-19><a id=__codelineno-7-19 name=__codelineno-7-19 href=#__codelineno-7-19></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Input: </span><span class=si>{</span><span class=n>x</span><span class=o>.</span><span class=n>dtype</span><span class=si>}</span><span class=s2>, Output: </span><span class=si>{</span><span class=n>output</span><span class=o>.</span><span class=n>dtype</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-7-20><a id=__codelineno-7-20 name=__codelineno-7-20 href=#__codelineno-7-20></a>
</span><span id=__span-7-21><a id=__codelineno-7-21 name=__codelineno-7-21 href=#__codelineno-7-21></a>    <span class=c1># BF16 typically doesn&#39;t need loss scaling</span>
</span><span id=__span-7-22><a id=__codelineno-7-22 name=__codelineno-7-22 href=#__codelineno-7-22></a>    <span class=n>loss</span> <span class=o>=</span> <span class=n>output</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
</span><span id=__span-7-23><a id=__codelineno-7-23 name=__codelineno-7-23 href=#__codelineno-7-23></a>    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-7-24><a id=__codelineno-7-24 name=__codelineno-7-24 href=#__codelineno-7-24></a>
</span><span id=__span-7-25><a id=__codelineno-7-25 name=__codelineno-7-25 href=#__codelineno-7-25></a>    <span class=k>return</span> <span class=n>model</span>
</span><span id=__span-7-26><a id=__codelineno-7-26 name=__codelineno-7-26 href=#__codelineno-7-26></a>
</span><span id=__span-7-27><a id=__codelineno-7-27 name=__codelineno-7-27 href=#__codelineno-7-27></a><span class=c1># Compare precisions</span>
</span><span id=__span-7-28><a id=__codelineno-7-28 name=__codelineno-7-28 href=#__codelineno-7-28></a><span class=k>def</span><span class=w> </span><span class=nf>compare_precisions</span><span class=p>():</span>
</span><span id=__span-7-29><a id=__codelineno-7-29 name=__codelineno-7-29 href=#__codelineno-7-29></a>    <span class=n>sizes</span> <span class=o>=</span> <span class=p>[</span><span class=mi>100</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=mi>10000</span><span class=p>]</span>
</span><span id=__span-7-30><a id=__codelineno-7-30 name=__codelineno-7-30 href=#__codelineno-7-30></a>
</span><span id=__span-7-31><a id=__codelineno-7-31 name=__codelineno-7-31 href=#__codelineno-7-31></a>    <span class=k>for</span> <span class=n>size</span> <span class=ow>in</span> <span class=n>sizes</span><span class=p>:</span>
</span><span id=__span-7-32><a id=__codelineno-7-32 name=__codelineno-7-32 href=#__codelineno-7-32></a>        <span class=c1># Create test data</span>
</span><span id=__span-7-33><a id=__codelineno-7-33 name=__codelineno-7-33 href=#__codelineno-7-33></a>        <span class=n>data_fp32</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=p>,</span> <span class=n>size</span><span class=p>)</span>
</span><span id=__span-7-34><a id=__codelineno-7-34 name=__codelineno-7-34 href=#__codelineno-7-34></a>        <span class=n>data_fp16</span> <span class=o>=</span> <span class=n>data_fp32</span><span class=o>.</span><span class=n>half</span><span class=p>()</span>
</span><span id=__span-7-35><a id=__codelineno-7-35 name=__codelineno-7-35 href=#__codelineno-7-35></a>        <span class=n>data_bf16</span> <span class=o>=</span> <span class=n>data_fp32</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>genesis</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>)</span>
</span><span id=__span-7-36><a id=__codelineno-7-36 name=__codelineno-7-36 href=#__codelineno-7-36></a>
</span><span id=__span-7-37><a id=__codelineno-7-37 name=__codelineno-7-37 href=#__codelineno-7-37></a>        <span class=c1># Simple computation</span>
</span><span id=__span-7-38><a id=__codelineno-7-38 name=__codelineno-7-38 href=#__codelineno-7-38></a>        <span class=n>result_fp32</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>data_fp32</span><span class=p>,</span> <span class=n>data_fp32</span><span class=p>)</span>
</span><span id=__span-7-39><a id=__codelineno-7-39 name=__codelineno-7-39 href=#__codelineno-7-39></a>        <span class=n>result_fp16</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>data_fp16</span><span class=p>,</span> <span class=n>data_fp16</span><span class=p>)</span>
</span><span id=__span-7-40><a id=__codelineno-7-40 name=__codelineno-7-40 href=#__codelineno-7-40></a>        <span class=n>result_bf16</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>data_bf16</span><span class=p>,</span> <span class=n>data_bf16</span><span class=p>)</span>
</span><span id=__span-7-41><a id=__codelineno-7-41 name=__codelineno-7-41 href=#__codelineno-7-41></a>
</span><span id=__span-7-42><a id=__codelineno-7-42 name=__codelineno-7-42 href=#__codelineno-7-42></a>        <span class=c1># Compare accuracy</span>
</span><span id=__span-7-43><a id=__codelineno-7-43 name=__codelineno-7-43 href=#__codelineno-7-43></a>        <span class=n>error_fp16</span> <span class=o>=</span> <span class=p>(</span><span class=n>result_fp32</span> <span class=o>-</span> <span class=n>result_fp16</span><span class=o>.</span><span class=n>float</span><span class=p>())</span><span class=o>.</span><span class=n>abs</span><span class=p>()</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span><span id=__span-7-44><a id=__codelineno-7-44 name=__codelineno-7-44 href=#__codelineno-7-44></a>        <span class=n>error_bf16</span> <span class=o>=</span> <span class=p>(</span><span class=n>result_fp32</span> <span class=o>-</span> <span class=n>result_bf16</span><span class=o>.</span><span class=n>float</span><span class=p>())</span><span class=o>.</span><span class=n>abs</span><span class=p>()</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span><span id=__span-7-45><a id=__codelineno-7-45 name=__codelineno-7-45 href=#__codelineno-7-45></a>
</span><span id=__span-7-46><a id=__codelineno-7-46 name=__codelineno-7-46 href=#__codelineno-7-46></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Size </span><span class=si>{</span><span class=n>size</span><span class=si>}</span><span class=s2>x</span><span class=si>{</span><span class=n>size</span><span class=si>}</span><span class=s2>:&quot;</span><span class=p>)</span>
</span><span id=__span-7-47><a id=__codelineno-7-47 name=__codelineno-7-47 href=#__codelineno-7-47></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  FP16 error: </span><span class=si>{</span><span class=n>error_fp16</span><span class=si>:</span><span class=s2>.2e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-7-48><a id=__codelineno-7-48 name=__codelineno-7-48 href=#__codelineno-7-48></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  BF16 error: </span><span class=si>{</span><span class=n>error_bf16</span><span class=si>:</span><span class=s2>.2e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <h2 id=memory-optimization>Memory Optimization<a class=headerlink href=#memory-optimization title="Permanent link">&para;</a></h2> <h3 id=memory-usage-analysis>Memory Usage Analysis<a class=headerlink href=#memory-usage-analysis title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=kn>import</span><span class=w> </span><span class=nn>genesis</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=k>def</span><span class=w> </span><span class=nf>analyze_memory_usage</span><span class=p>():</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Analyze memory usage of different precision types.&quot;&quot;&quot;</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a>    <span class=c1># Model sizes</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a>    <span class=n>sizes</span> <span class=o>=</span> <span class=p>[(</span><span class=mi>1000</span><span class=p>,</span> <span class=mi>1000</span><span class=p>),</span> <span class=p>(</span><span class=mi>2000</span><span class=p>,</span> <span class=mi>2000</span><span class=p>),</span> <span class=p>(</span><span class=mi>5000</span><span class=p>,</span> <span class=mi>5000</span><span class=p>)]</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a>    <span class=k>for</span> <span class=n>h</span><span class=p>,</span> <span class=n>w</span> <span class=ow>in</span> <span class=n>sizes</span><span class=p>:</span>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Tensor size: </span><span class=si>{</span><span class=n>h</span><span class=si>}</span><span class=s2>x</span><span class=si>{</span><span class=n>w</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a>        <span class=c1># Create tensors</span>
</span><span id=__span-8-13><a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a>        <span class=n>fp32_tensor</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>genesis</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span><span id=__span-8-14><a id=__codelineno-8-14 name=__codelineno-8-14 href=#__codelineno-8-14></a>        <span class=n>fp16_tensor</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>genesis</span><span class=o>.</span><span class=n>float16</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span><span id=__span-8-15><a id=__codelineno-8-15 name=__codelineno-8-15 href=#__codelineno-8-15></a>        <span class=n>bf16_tensor</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>genesis</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span><span id=__span-8-16><a id=__codelineno-8-16 name=__codelineno-8-16 href=#__codelineno-8-16></a>
</span><span id=__span-8-17><a id=__codelineno-8-17 name=__codelineno-8-17 href=#__codelineno-8-17></a>        <span class=c1># Memory usage</span>
</span><span id=__span-8-18><a id=__codelineno-8-18 name=__codelineno-8-18 href=#__codelineno-8-18></a>        <span class=n>fp32_memory</span> <span class=o>=</span> <span class=n>fp32_tensor</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span> <span class=o>*</span> <span class=mi>4</span>  <span class=c1># 4 bytes per float32</span>
</span><span id=__span-8-19><a id=__codelineno-8-19 name=__codelineno-8-19 href=#__codelineno-8-19></a>        <span class=n>fp16_memory</span> <span class=o>=</span> <span class=n>fp16_tensor</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span> <span class=o>*</span> <span class=mi>2</span>  <span class=c1># 2 bytes per float16</span>
</span><span id=__span-8-20><a id=__codelineno-8-20 name=__codelineno-8-20 href=#__codelineno-8-20></a>        <span class=n>bf16_memory</span> <span class=o>=</span> <span class=n>bf16_tensor</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span> <span class=o>*</span> <span class=mi>2</span>  <span class=c1># 2 bytes per bfloat16</span>
</span><span id=__span-8-21><a id=__codelineno-8-21 name=__codelineno-8-21 href=#__codelineno-8-21></a>
</span><span id=__span-8-22><a id=__codelineno-8-22 name=__codelineno-8-22 href=#__codelineno-8-22></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  FP32: </span><span class=si>{</span><span class=n>fp32_memory</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=mf>1e6</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> MB&quot;</span><span class=p>)</span>
</span><span id=__span-8-23><a id=__codelineno-8-23 name=__codelineno-8-23 href=#__codelineno-8-23></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  FP16: </span><span class=si>{</span><span class=n>fp16_memory</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=mf>1e6</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> MB (</span><span class=si>{</span><span class=n>fp16_memory</span><span class=o>/</span><span class=n>fp32_memory</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
</span><span id=__span-8-24><a id=__codelineno-8-24 name=__codelineno-8-24 href=#__codelineno-8-24></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  BF16: </span><span class=si>{</span><span class=n>bf16_memory</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=mf>1e6</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> MB (</span><span class=si>{</span><span class=n>bf16_memory</span><span class=o>/</span><span class=n>fp32_memory</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
</span><span id=__span-8-25><a id=__codelineno-8-25 name=__codelineno-8-25 href=#__codelineno-8-25></a>
</span><span id=__span-8-26><a id=__codelineno-8-26 name=__codelineno-8-26 href=#__codelineno-8-26></a>        <span class=c1># Cleanup</span>
</span><span id=__span-8-27><a id=__codelineno-8-27 name=__codelineno-8-27 href=#__codelineno-8-27></a>        <span class=k>del</span> <span class=n>fp32_tensor</span><span class=p>,</span> <span class=n>fp16_tensor</span><span class=p>,</span> <span class=n>bf16_tensor</span>
</span><span id=__span-8-28><a id=__codelineno-8-28 name=__codelineno-8-28 href=#__codelineno-8-28></a>        <span class=n>genesis</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>empty_cache</span><span class=p>()</span>
</span><span id=__span-8-29><a id=__codelineno-8-29 name=__codelineno-8-29 href=#__codelineno-8-29></a>
</span><span id=__span-8-30><a id=__codelineno-8-30 name=__codelineno-8-30 href=#__codelineno-8-30></a><span class=n>analyze_memory_usage</span><span class=p>()</span>
</span></code></pre></div> <h3 id=gradient-checkpointing-with-mixed-precision>Gradient Checkpointing with Mixed Precision<a class=headerlink href=#gradient-checkpointing-with-mixed-precision title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=kn>import</span><span class=w> </span><span class=nn>genesis</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=kn>import</span><span class=w> </span><span class=nn>genesis.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=k>class</span><span class=w> </span><span class=nc>CheckpointedModule</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Module with gradient checkpointing support.&quot;&quot;&quot;</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>layers</span><span class=p>):</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a>        <span class=bp>self</span><span class=o>.</span><span class=n>layers</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>(</span><span class=n>layers</span><span class=p>)</span>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a>        <span class=bp>self</span><span class=o>.</span><span class=n>checkpoint</span> <span class=o>=</span> <span class=kc>True</span>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span><span id=__span-9-13><a id=__codelineno-9-13 name=__codelineno-9-13 href=#__codelineno-9-13></a>        <span class=k>def</span><span class=w> </span><span class=nf>run_layers</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>layers</span><span class=p>):</span>
</span><span id=__span-9-14><a id=__codelineno-9-14 name=__codelineno-9-14 href=#__codelineno-9-14></a>            <span class=k>for</span> <span class=n>layer</span> <span class=ow>in</span> <span class=n>layers</span><span class=p>:</span>
</span><span id=__span-9-15><a id=__codelineno-9-15 name=__codelineno-9-15 href=#__codelineno-9-15></a>                <span class=n>x</span> <span class=o>=</span> <span class=n>layer</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span><span id=__span-9-16><a id=__codelineno-9-16 name=__codelineno-9-16 href=#__codelineno-9-16></a>            <span class=k>return</span> <span class=n>x</span>
</span><span id=__span-9-17><a id=__codelineno-9-17 name=__codelineno-9-17 href=#__codelineno-9-17></a>
</span><span id=__span-9-18><a id=__codelineno-9-18 name=__codelineno-9-18 href=#__codelineno-9-18></a>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>training</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>checkpoint</span><span class=p>:</span>
</span><span id=__span-9-19><a id=__codelineno-9-19 name=__codelineno-9-19 href=#__codelineno-9-19></a>            <span class=c1># Use gradient checkpointing to save memory</span>
</span><span id=__span-9-20><a id=__codelineno-9-20 name=__codelineno-9-20 href=#__codelineno-9-20></a>            <span class=k>return</span> <span class=n>genesis</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>checkpoint</span><span class=p>(</span><span class=n>run_layers</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>layers</span><span class=p>)</span>
</span><span id=__span-9-21><a id=__codelineno-9-21 name=__codelineno-9-21 href=#__codelineno-9-21></a>        <span class=k>else</span><span class=p>:</span>
</span><span id=__span-9-22><a id=__codelineno-9-22 name=__codelineno-9-22 href=#__codelineno-9-22></a>            <span class=k>return</span> <span class=n>run_layers</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>layers</span><span class=p>)</span>
</span><span id=__span-9-23><a id=__codelineno-9-23 name=__codelineno-9-23 href=#__codelineno-9-23></a>
</span><span id=__span-9-24><a id=__codelineno-9-24 name=__codelineno-9-24 href=#__codelineno-9-24></a><span class=c1># Create memory-efficient model</span>
</span><span id=__span-9-25><a id=__codelineno-9-25 name=__codelineno-9-25 href=#__codelineno-9-25></a><span class=k>def</span><span class=w> </span><span class=nf>create_checkpointed_model</span><span class=p>():</span>
</span><span id=__span-9-26><a id=__codelineno-9-26 name=__codelineno-9-26 href=#__codelineno-9-26></a>    <span class=n>layers</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-9-27><a id=__codelineno-9-27 name=__codelineno-9-27 href=#__codelineno-9-27></a>        <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>1024</span><span class=p>),</span>
</span><span id=__span-9-28><a id=__codelineno-9-28 name=__codelineno-9-28 href=#__codelineno-9-28></a>        <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span><span id=__span-9-29><a id=__codelineno-9-29 name=__codelineno-9-29 href=#__codelineno-9-29></a>        <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>1024</span><span class=p>),</span>
</span><span id=__span-9-30><a id=__codelineno-9-30 name=__codelineno-9-30 href=#__codelineno-9-30></a>        <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span><span id=__span-9-31><a id=__codelineno-9-31 name=__codelineno-9-31 href=#__codelineno-9-31></a>        <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>512</span><span class=p>),</span>
</span><span id=__span-9-32><a id=__codelineno-9-32 name=__codelineno-9-32 href=#__codelineno-9-32></a>        <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span><span id=__span-9-33><a id=__codelineno-9-33 name=__codelineno-9-33 href=#__codelineno-9-33></a>        <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
</span><span id=__span-9-34><a id=__codelineno-9-34 name=__codelineno-9-34 href=#__codelineno-9-34></a>    <span class=p>]</span>
</span><span id=__span-9-35><a id=__codelineno-9-35 name=__codelineno-9-35 href=#__codelineno-9-35></a>
</span><span id=__span-9-36><a id=__codelineno-9-36 name=__codelineno-9-36 href=#__codelineno-9-36></a>    <span class=k>return</span> <span class=n>CheckpointedModule</span><span class=p>(</span><span class=n>layers</span><span class=p>)</span>
</span><span id=__span-9-37><a id=__codelineno-9-37 name=__codelineno-9-37 href=#__codelineno-9-37></a>
</span><span id=__span-9-38><a id=__codelineno-9-38 name=__codelineno-9-38 href=#__codelineno-9-38></a><span class=c1># Training with checkpointing and mixed precision</span>
</span><span id=__span-9-39><a id=__codelineno-9-39 name=__codelineno-9-39 href=#__codelineno-9-39></a><span class=k>def</span><span class=w> </span><span class=nf>train_memory_efficient</span><span class=p>():</span>
</span><span id=__span-9-40><a id=__codelineno-9-40 name=__codelineno-9-40 href=#__codelineno-9-40></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>create_checkpointed_model</span><span class=p>()</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span><span id=__span-9-41><a id=__codelineno-9-41 name=__codelineno-9-41 href=#__codelineno-9-41></a>    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>)</span>
</span><span id=__span-9-42><a id=__codelineno-9-42 name=__codelineno-9-42 href=#__codelineno-9-42></a>
</span><span id=__span-9-43><a id=__codelineno-9-43 name=__codelineno-9-43 href=#__codelineno-9-43></a>    <span class=c1># Enable mixed precision</span>
</span><span id=__span-9-44><a id=__codelineno-9-44 name=__codelineno-9-44 href=#__codelineno-9-44></a>    <span class=n>genesis</span><span class=o>.</span><span class=n>enable_autocast</span> <span class=o>=</span> <span class=kc>True</span>
</span><span id=__span-9-45><a id=__codelineno-9-45 name=__codelineno-9-45 href=#__codelineno-9-45></a>
</span><span id=__span-9-46><a id=__codelineno-9-46 name=__codelineno-9-46 href=#__codelineno-9-46></a>    <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
</span><span id=__span-9-47><a id=__codelineno-9-47 name=__codelineno-9-47 href=#__codelineno-9-47></a>        <span class=k>for</span> <span class=n>batch</span> <span class=ow>in</span> <span class=n>dataloader</span><span class=p>:</span>
</span><span id=__span-9-48><a id=__codelineno-9-48 name=__codelineno-9-48 href=#__codelineno-9-48></a>            <span class=n>data</span><span class=p>,</span> <span class=n>targets</span> <span class=o>=</span> <span class=n>batch</span>
</span><span id=__span-9-49><a id=__codelineno-9-49 name=__codelineno-9-49 href=#__codelineno-9-49></a>            <span class=n>data</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span><span id=__span-9-50><a id=__codelineno-9-50 name=__codelineno-9-50 href=#__codelineno-9-50></a>            <span class=n>targets</span> <span class=o>=</span> <span class=n>targets</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span><span id=__span-9-51><a id=__codelineno-9-51 name=__codelineno-9-51 href=#__codelineno-9-51></a>
</span><span id=__span-9-52><a id=__codelineno-9-52 name=__codelineno-9-52 href=#__codelineno-9-52></a>            <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span><span id=__span-9-53><a id=__codelineno-9-53 name=__codelineno-9-53 href=#__codelineno-9-53></a>
</span><span id=__span-9-54><a id=__codelineno-9-54 name=__codelineno-9-54 href=#__codelineno-9-54></a>            <span class=c1># Forward pass with checkpointing and mixed precision</span>
</span><span id=__span-9-55><a id=__codelineno-9-55 name=__codelineno-9-55 href=#__codelineno-9-55></a>            <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span><span id=__span-9-56><a id=__codelineno-9-56 name=__codelineno-9-56 href=#__codelineno-9-56></a>            <span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>targets</span><span class=p>)</span>
</span><span id=__span-9-57><a id=__codelineno-9-57 name=__codelineno-9-57 href=#__codelineno-9-57></a>
</span><span id=__span-9-58><a id=__codelineno-9-58 name=__codelineno-9-58 href=#__codelineno-9-58></a>            <span class=c1># Backward pass</span>
</span><span id=__span-9-59><a id=__codelineno-9-59 name=__codelineno-9-59 href=#__codelineno-9-59></a>            <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-9-60><a id=__codelineno-9-60 name=__codelineno-9-60 href=#__codelineno-9-60></a>            <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span><span id=__span-9-61><a id=__codelineno-9-61 name=__codelineno-9-61 href=#__codelineno-9-61></a>
</span><span id=__span-9-62><a id=__codelineno-9-62 name=__codelineno-9-62 href=#__codelineno-9-62></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Epoch </span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s2> completed&quot;</span><span class=p>)</span>
</span></code></pre></div> <h2 id=performance-benchmarking>Performance Benchmarking<a class=headerlink href=#performance-benchmarking title="Permanent link">&para;</a></h2> <h3 id=mixed-precision-performance-comparison>Mixed Precision Performance Comparison<a class=headerlink href=#mixed-precision-performance-comparison title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=kn>import</span><span class=w> </span><span class=nn>genesis</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=kn>import</span><span class=w> </span><span class=nn>time</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a><span class=k>def</span><span class=w> </span><span class=nf>benchmark_precision_performance</span><span class=p>():</span>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Benchmark different precision formats.&quot;&quot;&quot;</span>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a>    <span class=c1># Model setup</span>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a>    <span class=n>sizes</span> <span class=o>=</span> <span class=p>[</span><span class=mi>512</span><span class=p>,</span> <span class=mi>1024</span><span class=p>,</span> <span class=mi>2048</span><span class=p>]</span>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a>    <span class=n>batch_sizes</span> <span class=o>=</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>64</span><span class=p>]</span>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a>
</span><span id=__span-10-11><a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a>    <span class=n>results</span> <span class=o>=</span> <span class=p>{}</span>
</span><span id=__span-10-12><a id=__codelineno-10-12 name=__codelineno-10-12 href=#__codelineno-10-12></a>
</span><span id=__span-10-13><a id=__codelineno-10-13 name=__codelineno-10-13 href=#__codelineno-10-13></a>    <span class=k>for</span> <span class=n>size</span> <span class=ow>in</span> <span class=n>sizes</span><span class=p>:</span>
</span><span id=__span-10-14><a id=__codelineno-10-14 name=__codelineno-10-14 href=#__codelineno-10-14></a>        <span class=k>for</span> <span class=n>batch_size</span> <span class=ow>in</span> <span class=n>batch_sizes</span><span class=p>:</span>
</span><span id=__span-10-15><a id=__codelineno-10-15 name=__codelineno-10-15 href=#__codelineno-10-15></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Benchmarking: size=</span><span class=si>{</span><span class=n>size</span><span class=si>}</span><span class=s2>, batch_size=</span><span class=si>{</span><span class=n>batch_size</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-10-16><a id=__codelineno-10-16 name=__codelineno-10-16 href=#__codelineno-10-16></a>
</span><span id=__span-10-17><a id=__codelineno-10-17 name=__codelineno-10-17 href=#__codelineno-10-17></a>            <span class=c1># Create models</span>
</span><span id=__span-10-18><a id=__codelineno-10-18 name=__codelineno-10-18 href=#__codelineno-10-18></a>            <span class=n>model_fp32</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>size</span><span class=p>,</span> <span class=n>size</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span><span id=__span-10-19><a id=__codelineno-10-19 name=__codelineno-10-19 href=#__codelineno-10-19></a>            <span class=n>model_fp16</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>size</span><span class=p>,</span> <span class=n>size</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span><span class=o>.</span><span class=n>half</span><span class=p>()</span>
</span><span id=__span-10-20><a id=__codelineno-10-20 name=__codelineno-10-20 href=#__codelineno-10-20></a>
</span><span id=__span-10-21><a id=__codelineno-10-21 name=__codelineno-10-21 href=#__codelineno-10-21></a>            <span class=c1># Create data</span>
</span><span id=__span-10-22><a id=__codelineno-10-22 name=__codelineno-10-22 href=#__codelineno-10-22></a>            <span class=n>data_fp32</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span><span id=__span-10-23><a id=__codelineno-10-23 name=__codelineno-10-23 href=#__codelineno-10-23></a>            <span class=n>data_fp16</span> <span class=o>=</span> <span class=n>data_fp32</span><span class=o>.</span><span class=n>half</span><span class=p>()</span>
</span><span id=__span-10-24><a id=__codelineno-10-24 name=__codelineno-10-24 href=#__codelineno-10-24></a>
</span><span id=__span-10-25><a id=__codelineno-10-25 name=__codelineno-10-25 href=#__codelineno-10-25></a>            <span class=c1># Benchmark FP32</span>
</span><span id=__span-10-26><a id=__codelineno-10-26 name=__codelineno-10-26 href=#__codelineno-10-26></a>            <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>synchronize</span><span class=p>()</span>
</span><span id=__span-10-27><a id=__codelineno-10-27 name=__codelineno-10-27 href=#__codelineno-10-27></a>            <span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span><span id=__span-10-28><a id=__codelineno-10-28 name=__codelineno-10-28 href=#__codelineno-10-28></a>
</span><span id=__span-10-29><a id=__codelineno-10-29 name=__codelineno-10-29 href=#__codelineno-10-29></a>            <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>100</span><span class=p>):</span>
</span><span id=__span-10-30><a id=__codelineno-10-30 name=__codelineno-10-30 href=#__codelineno-10-30></a>                <span class=n>output_fp32</span> <span class=o>=</span> <span class=n>model_fp32</span><span class=p>(</span><span class=n>data_fp32</span><span class=p>)</span>
</span><span id=__span-10-31><a id=__codelineno-10-31 name=__codelineno-10-31 href=#__codelineno-10-31></a>
</span><span id=__span-10-32><a id=__codelineno-10-32 name=__codelineno-10-32 href=#__codelineno-10-32></a>            <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>synchronize</span><span class=p>()</span>
</span><span id=__span-10-33><a id=__codelineno-10-33 name=__codelineno-10-33 href=#__codelineno-10-33></a>            <span class=n>fp32_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start_time</span>
</span><span id=__span-10-34><a id=__codelineno-10-34 name=__codelineno-10-34 href=#__codelineno-10-34></a>
</span><span id=__span-10-35><a id=__codelineno-10-35 name=__codelineno-10-35 href=#__codelineno-10-35></a>            <span class=c1># Benchmark FP16</span>
</span><span id=__span-10-36><a id=__codelineno-10-36 name=__codelineno-10-36 href=#__codelineno-10-36></a>            <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>synchronize</span><span class=p>()</span>
</span><span id=__span-10-37><a id=__codelineno-10-37 name=__codelineno-10-37 href=#__codelineno-10-37></a>            <span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span><span id=__span-10-38><a id=__codelineno-10-38 name=__codelineno-10-38 href=#__codelineno-10-38></a>
</span><span id=__span-10-39><a id=__codelineno-10-39 name=__codelineno-10-39 href=#__codelineno-10-39></a>            <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>100</span><span class=p>):</span>
</span><span id=__span-10-40><a id=__codelineno-10-40 name=__codelineno-10-40 href=#__codelineno-10-40></a>                <span class=n>output_fp16</span> <span class=o>=</span> <span class=n>model_fp16</span><span class=p>(</span><span class=n>data_fp16</span><span class=p>)</span>
</span><span id=__span-10-41><a id=__codelineno-10-41 name=__codelineno-10-41 href=#__codelineno-10-41></a>
</span><span id=__span-10-42><a id=__codelineno-10-42 name=__codelineno-10-42 href=#__codelineno-10-42></a>            <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>synchronize</span><span class=p>()</span>
</span><span id=__span-10-43><a id=__codelineno-10-43 name=__codelineno-10-43 href=#__codelineno-10-43></a>            <span class=n>fp16_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start_time</span>
</span><span id=__span-10-44><a id=__codelineno-10-44 name=__codelineno-10-44 href=#__codelineno-10-44></a>
</span><span id=__span-10-45><a id=__codelineno-10-45 name=__codelineno-10-45 href=#__codelineno-10-45></a>            <span class=c1># Results</span>
</span><span id=__span-10-46><a id=__codelineno-10-46 name=__codelineno-10-46 href=#__codelineno-10-46></a>            <span class=n>speedup</span> <span class=o>=</span> <span class=n>fp32_time</span> <span class=o>/</span> <span class=n>fp16_time</span>
</span><span id=__span-10-47><a id=__codelineno-10-47 name=__codelineno-10-47 href=#__codelineno-10-47></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  FP32 time: </span><span class=si>{</span><span class=n>fp32_time</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>s&quot;</span><span class=p>)</span>
</span><span id=__span-10-48><a id=__codelineno-10-48 name=__codelineno-10-48 href=#__codelineno-10-48></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  FP16 time: </span><span class=si>{</span><span class=n>fp16_time</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>s&quot;</span><span class=p>)</span> 
</span><span id=__span-10-49><a id=__codelineno-10-49 name=__codelineno-10-49 href=#__codelineno-10-49></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Speedup: </span><span class=si>{</span><span class=n>speedup</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>x&quot;</span><span class=p>)</span>
</span><span id=__span-10-50><a id=__codelineno-10-50 name=__codelineno-10-50 href=#__codelineno-10-50></a>
</span><span id=__span-10-51><a id=__codelineno-10-51 name=__codelineno-10-51 href=#__codelineno-10-51></a>            <span class=n>results</span><span class=p>[(</span><span class=n>size</span><span class=p>,</span> <span class=n>batch_size</span><span class=p>)]</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-10-52><a id=__codelineno-10-52 name=__codelineno-10-52 href=#__codelineno-10-52></a>                <span class=s1>&#39;fp32_time&#39;</span><span class=p>:</span> <span class=n>fp32_time</span><span class=p>,</span>
</span><span id=__span-10-53><a id=__codelineno-10-53 name=__codelineno-10-53 href=#__codelineno-10-53></a>                <span class=s1>&#39;fp16_time&#39;</span><span class=p>:</span> <span class=n>fp16_time</span><span class=p>,</span>
</span><span id=__span-10-54><a id=__codelineno-10-54 name=__codelineno-10-54 href=#__codelineno-10-54></a>                <span class=s1>&#39;speedup&#39;</span><span class=p>:</span> <span class=n>speedup</span>
</span><span id=__span-10-55><a id=__codelineno-10-55 name=__codelineno-10-55 href=#__codelineno-10-55></a>            <span class=p>}</span>
</span><span id=__span-10-56><a id=__codelineno-10-56 name=__codelineno-10-56 href=#__codelineno-10-56></a>
</span><span id=__span-10-57><a id=__codelineno-10-57 name=__codelineno-10-57 href=#__codelineno-10-57></a>    <span class=k>return</span> <span class=n>results</span>
</span><span id=__span-10-58><a id=__codelineno-10-58 name=__codelineno-10-58 href=#__codelineno-10-58></a>
</span><span id=__span-10-59><a id=__codelineno-10-59 name=__codelineno-10-59 href=#__codelineno-10-59></a><span class=c1># Run benchmark</span>
</span><span id=__span-10-60><a id=__codelineno-10-60 name=__codelineno-10-60 href=#__codelineno-10-60></a><span class=n>benchmark_results</span> <span class=o>=</span> <span class=n>benchmark_precision_performance</span><span class=p>()</span>
</span></code></pre></div> <h2 id=best-practices-and-troubleshooting>Best Practices and Troubleshooting<a class=headerlink href=#best-practices-and-troubleshooting title="Permanent link">&para;</a></h2> <h3 id=best-practices>Best Practices<a class=headerlink href=#best-practices title="Permanent link">&para;</a></h3> <ol> <li><strong>Start Simple</strong>: Begin with automatic mixed precision before manual control</li> <li><strong>Monitor Training</strong>: Watch for gradient underflow/overflow</li> <li><strong>Use Loss Scaling</strong>: Essential for FP16 stability</li> <li><strong>Gradient Clipping</strong>: Helps prevent gradient explosion</li> <li><strong>Layer-wise Precision</strong>: Some layers may need FP32 (e.g., batch norm)</li> </ol> <h3 id=common-issues-and-solutions>Common Issues and Solutions<a class=headerlink href=#common-issues-and-solutions title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=c1># Issue 1: Gradient Underflow</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a><span class=k>def</span><span class=w> </span><span class=nf>handle_gradient_underflow</span><span class=p>():</span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Handle gradient underflow in FP16 training.&quot;&quot;&quot;</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a>    <span class=c1># Solution 1: Use loss scaling</span>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a>    <span class=n>scaler</span> <span class=o>=</span> <span class=n>GradScaler</span><span class=p>(</span><span class=n>init_scale</span><span class=o>=</span><span class=mi>2</span><span class=o>**</span><span class=mi>16</span><span class=p>)</span>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a>
</span><span id=__span-11-8><a id=__codelineno-11-8 name=__codelineno-11-8 href=#__codelineno-11-8></a>    <span class=c1># Solution 2: Skip problematic batches</span>
</span><span id=__span-11-9><a id=__codelineno-11-9 name=__codelineno-11-9 href=#__codelineno-11-9></a>    <span class=k>def</span><span class=w> </span><span class=nf>safe_backward</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=n>scaler</span><span class=p>):</span>
</span><span id=__span-11-10><a id=__codelineno-11-10 name=__codelineno-11-10 href=#__codelineno-11-10></a>        <span class=n>scaled_loss</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>scale_loss</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span>
</span><span id=__span-11-11><a id=__codelineno-11-11 name=__codelineno-11-11 href=#__codelineno-11-11></a>        <span class=n>scaled_loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-11-12><a id=__codelineno-11-12 name=__codelineno-11-12 href=#__codelineno-11-12></a>
</span><span id=__span-11-13><a id=__codelineno-11-13 name=__codelineno-11-13 href=#__codelineno-11-13></a>        <span class=c1># Check for problems before optimizer step</span>
</span><span id=__span-11-14><a id=__codelineno-11-14 name=__codelineno-11-14 href=#__codelineno-11-14></a>        <span class=n>has_inf_or_nan</span> <span class=o>=</span> <span class=nb>any</span><span class=p>(</span>
</span><span id=__span-11-15><a id=__codelineno-11-15 name=__codelineno-11-15 href=#__codelineno-11-15></a>            <span class=n>genesis</span><span class=o>.</span><span class=n>isinf</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>grad</span><span class=p>)</span><span class=o>.</span><span class=n>any</span><span class=p>()</span> <span class=ow>or</span> <span class=n>genesis</span><span class=o>.</span><span class=n>isnan</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>grad</span><span class=p>)</span><span class=o>.</span><span class=n>any</span><span class=p>()</span>
</span><span id=__span-11-16><a id=__codelineno-11-16 name=__codelineno-11-16 href=#__codelineno-11-16></a>            <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>()</span> 
</span><span id=__span-11-17><a id=__codelineno-11-17 name=__codelineno-11-17 href=#__codelineno-11-17></a>            <span class=k>if</span> <span class=n>p</span><span class=o>.</span><span class=n>grad</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span>
</span><span id=__span-11-18><a id=__codelineno-11-18 name=__codelineno-11-18 href=#__codelineno-11-18></a>        <span class=p>)</span>
</span><span id=__span-11-19><a id=__codelineno-11-19 name=__codelineno-11-19 href=#__codelineno-11-19></a>
</span><span id=__span-11-20><a id=__codelineno-11-20 name=__codelineno-11-20 href=#__codelineno-11-20></a>        <span class=k>if</span> <span class=n>has_inf_or_nan</span><span class=p>:</span>
</span><span id=__span-11-21><a id=__codelineno-11-21 name=__codelineno-11-21 href=#__codelineno-11-21></a>            <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Skipping step due to inf/nan gradients&quot;</span><span class=p>)</span>
</span><span id=__span-11-22><a id=__codelineno-11-22 name=__codelineno-11-22 href=#__codelineno-11-22></a>            <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span><span id=__span-11-23><a id=__codelineno-11-23 name=__codelineno-11-23 href=#__codelineno-11-23></a>            <span class=k>return</span> <span class=kc>False</span>
</span><span id=__span-11-24><a id=__codelineno-11-24 name=__codelineno-11-24 href=#__codelineno-11-24></a>
</span><span id=__span-11-25><a id=__codelineno-11-25 name=__codelineno-11-25 href=#__codelineno-11-25></a>        <span class=k>return</span> <span class=kc>True</span>
</span><span id=__span-11-26><a id=__codelineno-11-26 name=__codelineno-11-26 href=#__codelineno-11-26></a>
</span><span id=__span-11-27><a id=__codelineno-11-27 name=__codelineno-11-27 href=#__codelineno-11-27></a><span class=c1># Issue 2: Model Divergence</span>
</span><span id=__span-11-28><a id=__codelineno-11-28 name=__codelineno-11-28 href=#__codelineno-11-28></a><span class=k>def</span><span class=w> </span><span class=nf>prevent_model_divergence</span><span class=p>():</span>
</span><span id=__span-11-29><a id=__codelineno-11-29 name=__codelineno-11-29 href=#__codelineno-11-29></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Prevent model divergence in mixed precision.&quot;&quot;&quot;</span>
</span><span id=__span-11-30><a id=__codelineno-11-30 name=__codelineno-11-30 href=#__codelineno-11-30></a>
</span><span id=__span-11-31><a id=__codelineno-11-31 name=__codelineno-11-31 href=#__codelineno-11-31></a>    <span class=c1># Solution 1: Lower learning rate</span>
</span><span id=__span-11-32><a id=__codelineno-11-32 name=__codelineno-11-32 href=#__codelineno-11-32></a>    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.0001</span><span class=p>)</span>  <span class=c1># Lower LR</span>
</span><span id=__span-11-33><a id=__codelineno-11-33 name=__codelineno-11-33 href=#__codelineno-11-33></a>
</span><span id=__span-11-34><a id=__codelineno-11-34 name=__codelineno-11-34 href=#__codelineno-11-34></a>    <span class=c1># Solution 2: Warmup schedule</span>
</span><span id=__span-11-35><a id=__codelineno-11-35 name=__codelineno-11-35 href=#__codelineno-11-35></a>    <span class=n>scheduler</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>get_cosine_schedule_with_warmup</span><span class=p>(</span>
</span><span id=__span-11-36><a id=__codelineno-11-36 name=__codelineno-11-36 href=#__codelineno-11-36></a>        <span class=n>optimizer</span><span class=p>,</span> <span class=n>num_warmup_steps</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>num_training_steps</span><span class=o>=</span><span class=mi>10000</span>
</span><span id=__span-11-37><a id=__codelineno-11-37 name=__codelineno-11-37 href=#__codelineno-11-37></a>    <span class=p>)</span>
</span><span id=__span-11-38><a id=__codelineno-11-38 name=__codelineno-11-38 href=#__codelineno-11-38></a>
</span><span id=__span-11-39><a id=__codelineno-11-39 name=__codelineno-11-39 href=#__codelineno-11-39></a>    <span class=c1># Solution 3: Monitor loss closely</span>
</span><span id=__span-11-40><a id=__codelineno-11-40 name=__codelineno-11-40 href=#__codelineno-11-40></a>    <span class=k>def</span><span class=w> </span><span class=nf>check_loss_stability</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=n>loss_history</span><span class=p>):</span>
</span><span id=__span-11-41><a id=__codelineno-11-41 name=__codelineno-11-41 href=#__codelineno-11-41></a>        <span class=n>loss_history</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>())</span>
</span><span id=__span-11-42><a id=__codelineno-11-42 name=__codelineno-11-42 href=#__codelineno-11-42></a>
</span><span id=__span-11-43><a id=__codelineno-11-43 name=__codelineno-11-43 href=#__codelineno-11-43></a>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>loss_history</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>100</span><span class=p>:</span>
</span><span id=__span-11-44><a id=__codelineno-11-44 name=__codelineno-11-44 href=#__codelineno-11-44></a>            <span class=n>recent_losses</span> <span class=o>=</span> <span class=n>loss_history</span><span class=p>[</span><span class=o>-</span><span class=mi>50</span><span class=p>:]</span>
</span><span id=__span-11-45><a id=__codelineno-11-45 name=__codelineno-11-45 href=#__codelineno-11-45></a>            <span class=k>if</span> <span class=nb>any</span><span class=p>(</span><span class=n>l</span> <span class=o>&gt;</span> <span class=mi>10</span> <span class=o>*</span> <span class=nb>min</span><span class=p>(</span><span class=n>recent_losses</span><span class=p>)</span> <span class=k>for</span> <span class=n>l</span> <span class=ow>in</span> <span class=n>recent_losses</span><span class=p>):</span>
</span><span id=__span-11-46><a id=__codelineno-11-46 name=__codelineno-11-46 href=#__codelineno-11-46></a>                <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;WARNING: Loss instability detected!&quot;</span><span class=p>)</span>
</span><span id=__span-11-47><a id=__codelineno-11-47 name=__codelineno-11-47 href=#__codelineno-11-47></a>                <span class=k>return</span> <span class=kc>False</span>
</span><span id=__span-11-48><a id=__codelineno-11-48 name=__codelineno-11-48 href=#__codelineno-11-48></a>
</span><span id=__span-11-49><a id=__codelineno-11-49 name=__codelineno-11-49 href=#__codelineno-11-49></a>        <span class=k>return</span> <span class=kc>True</span>
</span><span id=__span-11-50><a id=__codelineno-11-50 name=__codelineno-11-50 href=#__codelineno-11-50></a>
</span><span id=__span-11-51><a id=__codelineno-11-51 name=__codelineno-11-51 href=#__codelineno-11-51></a><span class=c1># Issue 3: Accuracy Degradation</span>
</span><span id=__span-11-52><a id=__codelineno-11-52 name=__codelineno-11-52 href=#__codelineno-11-52></a><span class=k>def</span><span class=w> </span><span class=nf>maintain_accuracy</span><span class=p>():</span>
</span><span id=__span-11-53><a id=__codelineno-11-53 name=__codelineno-11-53 href=#__codelineno-11-53></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Maintain model accuracy with mixed precision.&quot;&quot;&quot;</span>
</span><span id=__span-11-54><a id=__codelineno-11-54 name=__codelineno-11-54 href=#__codelineno-11-54></a>
</span><span id=__span-11-55><a id=__codelineno-11-55 name=__codelineno-11-55 href=#__codelineno-11-55></a>    <span class=c1># Solution 1: Use BF16 instead of FP16</span>
</span><span id=__span-11-56><a id=__codelineno-11-56 name=__codelineno-11-56 href=#__codelineno-11-56></a>    <span class=n>genesis</span><span class=o>.</span><span class=n>enable_autocast</span> <span class=o>=</span> <span class=kc>True</span>
</span><span id=__span-11-57><a id=__codelineno-11-57 name=__codelineno-11-57 href=#__codelineno-11-57></a>    <span class=n>default_dtype</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>bfloat16</span>
</span><span id=__span-11-58><a id=__codelineno-11-58 name=__codelineno-11-58 href=#__codelineno-11-58></a>
</span><span id=__span-11-59><a id=__codelineno-11-59 name=__codelineno-11-59 href=#__codelineno-11-59></a>    <span class=c1># Solution 2: Keep critical layers in FP32</span>
</span><span id=__span-11-60><a id=__codelineno-11-60 name=__codelineno-11-60 href=#__codelineno-11-60></a>    <span class=k>class</span><span class=w> </span><span class=nc>MixedPrecisionModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-11-61><a id=__codelineno-11-61 name=__codelineno-11-61 href=#__codelineno-11-61></a>        <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-11-62><a id=__codelineno-11-62 name=__codelineno-11-62 href=#__codelineno-11-62></a>            <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-11-63><a id=__codelineno-11-63 name=__codelineno-11-63 href=#__codelineno-11-63></a>            <span class=bp>self</span><span class=o>.</span><span class=n>features</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span><span id=__span-11-64><a id=__codelineno-11-64 name=__codelineno-11-64 href=#__codelineno-11-64></a>                <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>784</span><span class=p>,</span> <span class=mi>256</span><span class=p>),</span>  <span class=c1># FP16/BF16</span>
</span><span id=__span-11-65><a id=__codelineno-11-65 name=__codelineno-11-65 href=#__codelineno-11-65></a>                <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span><span id=__span-11-66><a id=__codelineno-11-66 name=__codelineno-11-66 href=#__codelineno-11-66></a>                <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>128</span><span class=p>),</span>  <span class=c1># FP16/BF16</span>
</span><span id=__span-11-67><a id=__codelineno-11-67 name=__codelineno-11-67 href=#__codelineno-11-67></a>                <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()</span>
</span><span id=__span-11-68><a id=__codelineno-11-68 name=__codelineno-11-68 href=#__codelineno-11-68></a>            <span class=p>)</span>
</span><span id=__span-11-69><a id=__codelineno-11-69 name=__codelineno-11-69 href=#__codelineno-11-69></a>
</span><span id=__span-11-70><a id=__codelineno-11-70 name=__codelineno-11-70 href=#__codelineno-11-70></a>            <span class=c1># Keep output layer in FP32 for stability</span>
</span><span id=__span-11-71><a id=__codelineno-11-71 name=__codelineno-11-71 href=#__codelineno-11-71></a>            <span class=bp>self</span><span class=o>.</span><span class=n>classifier</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span><span class=o>.</span><span class=n>float</span><span class=p>()</span>
</span><span id=__span-11-72><a id=__codelineno-11-72 name=__codelineno-11-72 href=#__codelineno-11-72></a>
</span><span id=__span-11-73><a id=__codelineno-11-73 name=__codelineno-11-73 href=#__codelineno-11-73></a>        <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span><span id=__span-11-74><a id=__codelineno-11-74 name=__codelineno-11-74 href=#__codelineno-11-74></a>            <span class=k>with</span> <span class=n>genesis</span><span class=o>.</span><span class=n>autocast</span><span class=p>():</span>
</span><span id=__span-11-75><a id=__codelineno-11-75 name=__codelineno-11-75 href=#__codelineno-11-75></a>                <span class=n>features</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>features</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span><span id=__span-11-76><a id=__codelineno-11-76 name=__codelineno-11-76 href=#__codelineno-11-76></a>
</span><span id=__span-11-77><a id=__codelineno-11-77 name=__codelineno-11-77 href=#__codelineno-11-77></a>            <span class=c1># Output layer in FP32</span>
</span><span id=__span-11-78><a id=__codelineno-11-78 name=__codelineno-11-78 href=#__codelineno-11-78></a>            <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>classifier</span><span class=p>(</span><span class=n>features</span><span class=o>.</span><span class=n>float</span><span class=p>())</span>
</span><span id=__span-11-79><a id=__codelineno-11-79 name=__codelineno-11-79 href=#__codelineno-11-79></a>            <span class=k>return</span> <span class=n>output</span>
</span></code></pre></div> <h3 id=debugging-mixed-precision-training>Debugging Mixed Precision Training<a class=headerlink href=#debugging-mixed-precision-training title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=k>def</span><span class=w> </span><span class=nf>debug_mixed_precision</span><span class=p>():</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Debug mixed precision training issues.&quot;&quot;&quot;</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a>    <span class=c1># 1. Check tensor dtypes throughout the model</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>    <span class=k>def</span><span class=w> </span><span class=nf>print_tensor_info</span><span class=p>(</span><span class=n>tensor</span><span class=p>,</span> <span class=n>name</span><span class=p>):</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>:&quot;</span><span class=p>)</span>
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Shape: </span><span class=si>{</span><span class=n>tensor</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-12-8><a id=__codelineno-12-8 name=__codelineno-12-8 href=#__codelineno-12-8></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Dtype: </span><span class=si>{</span><span class=n>tensor</span><span class=o>.</span><span class=n>dtype</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-12-9><a id=__codelineno-12-9 name=__codelineno-12-9 href=#__codelineno-12-9></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Device: </span><span class=si>{</span><span class=n>tensor</span><span class=o>.</span><span class=n>device</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-12-10><a id=__codelineno-12-10 name=__codelineno-12-10 href=#__codelineno-12-10></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Requires grad: </span><span class=si>{</span><span class=n>tensor</span><span class=o>.</span><span class=n>requires_grad</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-12-11><a id=__codelineno-12-11 name=__codelineno-12-11 href=#__codelineno-12-11></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Min/Max: </span><span class=si>{</span><span class=n>tensor</span><span class=o>.</span><span class=n>min</span><span class=p>()</span><span class=si>:</span><span class=s2>.2e</span><span class=si>}</span><span class=s2> / </span><span class=si>{</span><span class=n>tensor</span><span class=o>.</span><span class=n>max</span><span class=p>()</span><span class=si>:</span><span class=s2>.2e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-12-12><a id=__codelineno-12-12 name=__codelineno-12-12 href=#__codelineno-12-12></a>        <span class=nb>print</span><span class=p>()</span>
</span><span id=__span-12-13><a id=__codelineno-12-13 name=__codelineno-12-13 href=#__codelineno-12-13></a>
</span><span id=__span-12-14><a id=__codelineno-12-14 name=__codelineno-12-14 href=#__codelineno-12-14></a>    <span class=c1># 2. Monitor gradient norms</span>
</span><span id=__span-12-15><a id=__codelineno-12-15 name=__codelineno-12-15 href=#__codelineno-12-15></a>    <span class=k>def</span><span class=w> </span><span class=nf>check_gradient_norms</span><span class=p>(</span><span class=n>model</span><span class=p>):</span>
</span><span id=__span-12-16><a id=__codelineno-12-16 name=__codelineno-12-16 href=#__codelineno-12-16></a>        <span class=n>total_norm</span> <span class=o>=</span> <span class=mf>0.0</span>
</span><span id=__span-12-17><a id=__codelineno-12-17 name=__codelineno-12-17 href=#__codelineno-12-17></a>        <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
</span><span id=__span-12-18><a id=__codelineno-12-18 name=__codelineno-12-18 href=#__codelineno-12-18></a>            <span class=k>if</span> <span class=n>param</span><span class=o>.</span><span class=n>grad</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-12-19><a id=__codelineno-12-19 name=__codelineno-12-19 href=#__codelineno-12-19></a>                <span class=n>grad_norm</span> <span class=o>=</span> <span class=n>param</span><span class=o>.</span><span class=n>grad</span><span class=o>.</span><span class=n>norm</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span><span id=__span-12-20><a id=__codelineno-12-20 name=__codelineno-12-20 href=#__codelineno-12-20></a>                <span class=n>total_norm</span> <span class=o>+=</span> <span class=n>grad_norm</span> <span class=o>**</span> <span class=mi>2</span>
</span><span id=__span-12-21><a id=__codelineno-12-21 name=__codelineno-12-21 href=#__codelineno-12-21></a>                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>: grad_norm = </span><span class=si>{</span><span class=n>grad_norm</span><span class=si>:</span><span class=s2>.2e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-12-22><a id=__codelineno-12-22 name=__codelineno-12-22 href=#__codelineno-12-22></a>
</span><span id=__span-12-23><a id=__codelineno-12-23 name=__codelineno-12-23 href=#__codelineno-12-23></a>        <span class=n>total_norm</span> <span class=o>=</span> <span class=n>total_norm</span> <span class=o>**</span> <span class=mf>0.5</span>
</span><span id=__span-12-24><a id=__codelineno-12-24 name=__codelineno-12-24 href=#__codelineno-12-24></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Total gradient norm: </span><span class=si>{</span><span class=n>total_norm</span><span class=si>:</span><span class=s2>.2e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-12-25><a id=__codelineno-12-25 name=__codelineno-12-25 href=#__codelineno-12-25></a>        <span class=k>return</span> <span class=n>total_norm</span>
</span><span id=__span-12-26><a id=__codelineno-12-26 name=__codelineno-12-26 href=#__codelineno-12-26></a>
</span><span id=__span-12-27><a id=__codelineno-12-27 name=__codelineno-12-27 href=#__codelineno-12-27></a>    <span class=c1># 3. Validate numerical stability</span>
</span><span id=__span-12-28><a id=__codelineno-12-28 name=__codelineno-12-28 href=#__codelineno-12-28></a>    <span class=k>def</span><span class=w> </span><span class=nf>check_numerical_stability</span><span class=p>(</span><span class=n>tensor</span><span class=p>):</span>
</span><span id=__span-12-29><a id=__codelineno-12-29 name=__codelineno-12-29 href=#__codelineno-12-29></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Check for numerical issues.&quot;&quot;&quot;</span>
</span><span id=__span-12-30><a id=__codelineno-12-30 name=__codelineno-12-30 href=#__codelineno-12-30></a>        <span class=n>has_nan</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>isnan</span><span class=p>(</span><span class=n>tensor</span><span class=p>)</span><span class=o>.</span><span class=n>any</span><span class=p>()</span>
</span><span id=__span-12-31><a id=__codelineno-12-31 name=__codelineno-12-31 href=#__codelineno-12-31></a>        <span class=n>has_inf</span> <span class=o>=</span> <span class=n>genesis</span><span class=o>.</span><span class=n>isinf</span><span class=p>(</span><span class=n>tensor</span><span class=p>)</span><span class=o>.</span><span class=n>any</span><span class=p>()</span>
</span><span id=__span-12-32><a id=__codelineno-12-32 name=__codelineno-12-32 href=#__codelineno-12-32></a>
</span><span id=__span-12-33><a id=__codelineno-12-33 name=__codelineno-12-33 href=#__codelineno-12-33></a>        <span class=k>if</span> <span class=n>has_nan</span><span class=p>:</span>
</span><span id=__span-12-34><a id=__codelineno-12-34 name=__codelineno-12-34 href=#__codelineno-12-34></a>            <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;WARNING: NaN values detected!&quot;</span><span class=p>)</span>
</span><span id=__span-12-35><a id=__codelineno-12-35 name=__codelineno-12-35 href=#__codelineno-12-35></a>        <span class=k>if</span> <span class=n>has_inf</span><span class=p>:</span>
</span><span id=__span-12-36><a id=__codelineno-12-36 name=__codelineno-12-36 href=#__codelineno-12-36></a>            <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;WARNING: Inf values detected!&quot;</span><span class=p>)</span>
</span><span id=__span-12-37><a id=__codelineno-12-37 name=__codelineno-12-37 href=#__codelineno-12-37></a>
</span><span id=__span-12-38><a id=__codelineno-12-38 name=__codelineno-12-38 href=#__codelineno-12-38></a>        <span class=k>return</span> <span class=ow>not</span> <span class=p>(</span><span class=n>has_nan</span> <span class=ow>or</span> <span class=n>has_inf</span><span class=p>)</span>
</span><span id=__span-12-39><a id=__codelineno-12-39 name=__codelineno-12-39 href=#__codelineno-12-39></a>
</span><span id=__span-12-40><a id=__codelineno-12-40 name=__codelineno-12-40 href=#__codelineno-12-40></a><span class=c1># Usage in training loop</span>
</span><span id=__span-12-41><a id=__codelineno-12-41 name=__codelineno-12-41 href=#__codelineno-12-41></a><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
</span><span id=__span-12-42><a id=__codelineno-12-42 name=__codelineno-12-42 href=#__codelineno-12-42></a>    <span class=k>for</span> <span class=n>batch_idx</span><span class=p>,</span> <span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>targets</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>dataloader</span><span class=p>):</span>
</span><span id=__span-12-43><a id=__codelineno-12-43 name=__codelineno-12-43 href=#__codelineno-12-43></a>        <span class=c1># Forward pass</span>
</span><span id=__span-12-44><a id=__codelineno-12-44 name=__codelineno-12-44 href=#__codelineno-12-44></a>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span><span id=__span-12-45><a id=__codelineno-12-45 name=__codelineno-12-45 href=#__codelineno-12-45></a>        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>targets</span><span class=p>)</span>
</span><span id=__span-12-46><a id=__codelineno-12-46 name=__codelineno-12-46 href=#__codelineno-12-46></a>
</span><span id=__span-12-47><a id=__codelineno-12-47 name=__codelineno-12-47 href=#__codelineno-12-47></a>        <span class=c1># Debug information</span>
</span><span id=__span-12-48><a id=__codelineno-12-48 name=__codelineno-12-48 href=#__codelineno-12-48></a>        <span class=k>if</span> <span class=n>batch_idx</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-12-49><a id=__codelineno-12-49 name=__codelineno-12-49 href=#__codelineno-12-49></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Epoch </span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s2>, Batch </span><span class=si>{</span><span class=n>batch_idx</span><span class=si>}</span><span class=s2>:&quot;</span><span class=p>)</span>
</span><span id=__span-12-50><a id=__codelineno-12-50 name=__codelineno-12-50 href=#__codelineno-12-50></a>            <span class=n>print_tensor_info</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=s2>&quot;Input&quot;</span><span class=p>)</span>
</span><span id=__span-12-51><a id=__codelineno-12-51 name=__codelineno-12-51 href=#__codelineno-12-51></a>            <span class=n>print_tensor_info</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=s2>&quot;Output&quot;</span><span class=p>)</span> 
</span><span id=__span-12-52><a id=__codelineno-12-52 name=__codelineno-12-52 href=#__codelineno-12-52></a>            <span class=n>print_tensor_info</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=s2>&quot;Loss&quot;</span><span class=p>)</span>
</span><span id=__span-12-53><a id=__codelineno-12-53 name=__codelineno-12-53 href=#__codelineno-12-53></a>
</span><span id=__span-12-54><a id=__codelineno-12-54 name=__codelineno-12-54 href=#__codelineno-12-54></a>            <span class=c1># Check gradients after backward pass</span>
</span><span id=__span-12-55><a id=__codelineno-12-55 name=__codelineno-12-55 href=#__codelineno-12-55></a>            <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-12-56><a id=__codelineno-12-56 name=__codelineno-12-56 href=#__codelineno-12-56></a>            <span class=n>grad_norm</span> <span class=o>=</span> <span class=n>check_gradient_norms</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</span><span id=__span-12-57><a id=__codelineno-12-57 name=__codelineno-12-57 href=#__codelineno-12-57></a>
</span><span id=__span-12-58><a id=__codelineno-12-58 name=__codelineno-12-58 href=#__codelineno-12-58></a>            <span class=k>if</span> <span class=n>grad_norm</span> <span class=o>&gt;</span> <span class=mf>10.0</span><span class=p>:</span>
</span><span id=__span-12-59><a id=__codelineno-12-59 name=__codelineno-12-59 href=#__codelineno-12-59></a>                <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;WARNING: Large gradient norm detected!&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>This comprehensive guide covers all aspects of mixed precision training in Genesis, from basic usage to advanced optimization techniques and troubleshooting strategies.</p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_datetime" title="August 20, 2025 13:50:28 UTC">2025-08-20 13:50:28</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_datetime" title="August 20, 2025 13:50:28 UTC">2025-08-20 13:50:28</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../llm-training/ class="md-footer__link md-footer__link--prev" aria-label="Previous: LLM Training"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> LLM Training </div> </div> </a> <a href=../../core-components/ class="md-footer__link md-footer__link--next" aria-label="Next: Overview"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Overview </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2025 Genesis Team </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/phonism/genesis target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://pypi.org/project/genesis-dl/ target=_blank rel=noopener title=pypi.org class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <div class=md-consent data-md-component=consent id=__consent hidden> <div class=md-consent__overlay></div> <aside class=md-consent__inner> <form class="md-consent__form md-grid md-typeset" name=consent> <h4>Cookie consent</h4> <p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p> <input class=md-toggle type=checkbox id=__settings> <div class=md-consent__settings> <ul class=task-list> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=analytics checked> <span class=task-list-indicator></span> Google Analytics </label> </li> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=github checked> <span class=task-list-indicator></span> GitHub </label> </li> </ul> </div> <div class=md-consent__controls> <button class="md-button md-button--primary">Accept</button> <label class=md-button for=__settings>Manage settings</label> </div> </form> </aside> </div> <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script> <script id=__config type=application/json>{"base": "../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.path", "navigation.prune", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "toc.integrate"], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script> <script src=../../assets/javascripts/bundle.50899def.min.js></script> <script src=../../../shared/javascripts/mathjax.js></script> <script src=../../../shared/javascripts/i18n.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>