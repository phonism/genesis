<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A lightweight deep learning framework built from scratch with Python + Triton + CUDA"><meta name=author content="Genesis Team"><link href=https://phonism.github.io/genesis/en/architecture/index.zh/ rel=canonical><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.16"><title>架构概览 - Genesis Deep Learning Framework</title><link rel=stylesheet href=../../assets/stylesheets/main.7e37652d.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config",""),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#_1 class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Genesis Deep Learning Framework" class="md-header__button md-logo" aria-label="Genesis Deep Learning Framework" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Genesis Deep Learning Framework </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 架构概览 </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to system preference" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5M7 15a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/phonism/genesis title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> genesis </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../getting-started/ class=md-tabs__link> Getting Started </a> </li> <li class=md-tabs__item> <a href=../../tutorials/ class=md-tabs__link> Tutorials </a> </li> <li class=md-tabs__item> <a href=../../core-components/ class=md-tabs__link> Core Components </a> </li> <li class=md-tabs__item> <a href=../ class=md-tabs__link> Architecture </a> </li> <li class=md-tabs__item> <a href=../../models/qwen/ class=md-tabs__link> Models </a> </li> <li class=md-tabs__item> <a href=../../performance/optimization-guide/ class=md-tabs__link> Performance </a> </li> <li class=md-tabs__item> <a href=../../training/advanced-features/ class=md-tabs__link> Training </a> </li> <li class=md-tabs__item> <a href=../../api-reference/ class=md-tabs__link> API Reference </a> </li> <li class=md-tabs__item> <a href=../../contributing/ class=md-tabs__link> Contributing </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Genesis Deep Learning Framework" class="md-nav__button md-logo" aria-label="Genesis Deep Learning Framework" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> Genesis Deep Learning Framework </label> <div class=md-nav__source> <a href=https://github.com/phonism/genesis title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> genesis </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../getting-started/ class=md-nav__link> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../tutorials/ class=md-nav__link> <span class=md-ellipsis> Tutorials </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../core-components/ class=md-nav__link> <span class=md-ellipsis> Core Components </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../ class=md-nav__link> <span class=md-ellipsis> Architecture </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../models/qwen/ class=md-nav__link> <span class=md-ellipsis> Models </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../performance/optimization-guide/ class=md-nav__link> <span class=md-ellipsis> Performance </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../training/advanced-features/ class=md-nav__link> <span class=md-ellipsis> Training </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../api-reference/ class=md-nav__link> <span class=md-ellipsis> API Reference </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../contributing/ class=md-nav__link> <span class=md-ellipsis> Contributing </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/phonism/genesis/edit/main/docs/architecture/index.zh.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/phonism/genesis/raw/main/docs/architecture/index.zh.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=_1>架构概览<a class=headerlink href=#_1 title="Permanent link">&para;</a></h1> <p>Genesis深度学习框架采用了分层模块化架构设计，在保持代码清晰性的同时实现高性能计算能力。</p> <h2 id=_2>🎯 设计原则<a class=headerlink href=#_2 title="Permanent link">&para;</a></h2> <ol> <li><strong>清晰的层次分离</strong>: 每一层都有单一、明确的职责</li> <li><strong>无泄漏的抽象</strong>: 上层不了解下层实现细节</li> <li><strong>设备无关</strong>: 计算逻辑与设备特定实现分离</li> <li><strong>可扩展性</strong>: 易于添加新操作或后端实现</li> </ol> <h2 id=_3>🏗️ 分层架构<a class=headerlink href=#_3 title="Permanent link">&para;</a></h2> <h3 id=_4>四层设计<a class=headerlink href=#_4 title="Permanent link">&para;</a></h3> <ol> <li><strong>张量层</strong> (用户接口 + 自动微分)</li> <li>面向用户的API</li> <li>自动微分</li> <li> <p>计算图管理</p> </li> <li> <p><strong>函数层</strong> (梯度定义)</p> </li> <li>前向计算逻辑</li> <li>反向梯度规则</li> <li> <p>连接张量层和NDArray层</p> </li> <li> <p><strong>NDArray层</strong> (设备抽象)</p> </li> <li>设备无关的计算接口</li> <li>CPU/GPU统一操作</li> <li> <p>设备管理和切换</p> </li> <li> <p><strong>后端层</strong> (实际计算)</p> </li> <li>CPU: PyTorch张量</li> <li>GPU: CUDAStorage与Triton内核</li> </ol> <h2 id=_5>🔄 计算流程<a class=headerlink href=#_5 title="Permanent link">&para;</a></h2> <pre class=mermaid><code>graph TB
    subgraph "第1层: 用户接口"
        User["用户代码&lt;br/&gt;c = a + b"]
    end

    subgraph "第2层: 张量 (自动微分)"
        Tensor["Tensor.__add__()&lt;br/&gt;• 管理梯度&lt;br/&gt;• 构建计算图"]
    end

    subgraph "第3层: 函数层"
        Func["nn.functional.Add&lt;br/&gt;• forward(): 定义计算&lt;br/&gt;• backward(): 定义梯度"]
    end

    subgraph "第4层: NDArray"
        NDArray["NDArray.__add__()&lt;br/&gt;• 设备无关接口&lt;br/&gt;• 分发到后端"]
    end

    subgraph "第5层: 后端"
        CPU["CPU后端&lt;br/&gt;PyTorch张量"]
        GPU["GPU后端&lt;br/&gt;CUDAStorage + Triton"]
    end

    User --&gt; Tensor
    Tensor --&gt;|"调用"| Func
    Func --&gt;|"a.data + b.data"| NDArray
    NDArray --&gt;|"device.add()"| CPU
    NDArray --&gt;|"device.add()"| GPU

    style User fill:#e1f5fe
    style Tensor fill:#f3e5f5
    style Func fill:#fff3e0
    style NDArray fill:#e8f5e8
    style CPU fill:#fce4ec
    style GPU fill:#e3f2fd</code></pre> <h3 id=_6>示例: 加法操作<a class=headerlink href=#_6 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=c1># 用户代码</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=n>c</span> <span class=o>=</span> <span class=n>a</span> <span class=o>+</span> <span class=n>b</span>  <span class=c1># a, b 是张量</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=c1># 第1层: 张量</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=k>def</span><span class=w> </span><span class=fm>__add__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>other</span><span class=p>):</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a>    <span class=k>return</span> <span class=n>genesis</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>functional</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>other</span><span class=p>)</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a><span class=c1># 第2层: 函数层</span>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a><span class=k>class</span><span class=w> </span><span class=nc>Add</span><span class=p>(</span><span class=n>Function</span><span class=p>):</span>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a>    <span class=nd>@staticmethod</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=n>ctx</span><span class=p>,</span> <span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>):</span>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a>        <span class=n>ctx</span><span class=o>.</span><span class=n>save_for_backward</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a>        <span class=c1># 只使用NDArray接口，不涉及后端细节</span>
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a>        <span class=k>return</span> <span class=n>Tensor</span><span class=p>(</span><span class=n>a</span><span class=o>.</span><span class=n>data</span> <span class=o>+</span> <span class=n>b</span><span class=o>.</span><span class=n>data</span><span class=p>)</span>
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a>
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a>    <span class=nd>@staticmethod</span>
</span><span id=__span-0-17><a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a>    <span class=k>def</span><span class=w> </span><span class=nf>backward</span><span class=p>(</span><span class=n>ctx</span><span class=p>,</span> <span class=n>grad_output</span><span class=p>):</span>
</span><span id=__span-0-18><a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a>        <span class=c1># 梯度规则</span>
</span><span id=__span-0-19><a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a>        <span class=k>return</span> <span class=n>grad_output</span><span class=p>,</span> <span class=n>grad_output</span>
</span><span id=__span-0-20><a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a>
</span><span id=__span-0-21><a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a><span class=c1># 第3层: NDArray</span>
</span><span id=__span-0-22><a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a><span class=k>def</span><span class=w> </span><span class=fm>__add__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>other</span><span class=p>):</span>
</span><span id=__span-0-23><a id=__codelineno-0-23 name=__codelineno-0-23 href=#__codelineno-0-23></a>    <span class=c1># 分发到设备特定实现</span>
</span><span id=__span-0-24><a id=__codelineno-0-24 name=__codelineno-0-24 href=#__codelineno-0-24></a>    <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>other</span><span class=p>)</span>
</span><span id=__span-0-25><a id=__codelineno-0-25 name=__codelineno-0-25 href=#__codelineno-0-25></a>
</span><span id=__span-0-26><a id=__codelineno-0-26 name=__codelineno-0-26 href=#__codelineno-0-26></a><span class=c1># 第4层: 后端 (GPU示例)</span>
</span><span id=__span-0-27><a id=__codelineno-0-27 name=__codelineno-0-27 href=#__codelineno-0-27></a><span class=k>def</span><span class=w> </span><span class=nf>add</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
</span><span id=__span-0-28><a id=__codelineno-0-28 name=__codelineno-0-28 href=#__codelineno-0-28></a>    <span class=c1># 实际的Triton内核执行</span>
</span><span id=__span-0-29><a id=__codelineno-0-29 name=__codelineno-0-29 href=#__codelineno-0-29></a>    <span class=n>output</span> <span class=o>=</span> <span class=n>empty</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-0-30><a id=__codelineno-0-30 name=__codelineno-0-30 href=#__codelineno-0-30></a>    <span class=n>add_kernel</span><span class=p>[</span><span class=n>grid</span><span class=p>](</span><span class=n>x</span><span class=o>.</span><span class=n>ptr</span><span class=p>,</span> <span class=n>y</span><span class=o>.</span><span class=n>ptr</span><span class=p>,</span> <span class=n>output</span><span class=o>.</span><span class=n>ptr</span><span class=p>,</span> <span class=n>n_elements</span><span class=p>)</span>
</span><span id=__span-0-31><a id=__codelineno-0-31 name=__codelineno-0-31 href=#__codelineno-0-31></a>    <span class=k>return</span> <span class=n>output</span>
</span></code></pre></div> <h2 id=_7>🔑 关键设计原则<a class=headerlink href=#_7 title="Permanent link">&para;</a></h2> <h3 id=1>1. 清晰的抽象层次<a class=headerlink href=#1 title="Permanent link">&para;</a></h3> <p><strong>原则</strong>: 每一层只了解直接下层的信息。</p> <ul> <li><strong>张量</strong> → 了解 <strong>nn.functional</strong> (用于操作)</li> <li><strong>nn.functional</strong> → 了解 <strong>NDArray</strong> (用于计算)</li> <li><strong>NDArray</strong> → 了解 <strong>后端</strong> (用于设备特定操作)</li> <li><strong>后端</strong> → 实现实际计算</li> </ul> <p><strong>反模式</strong> (我们正在修复的): <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=c1># 错误: nn.functional不应该了解CUDAStorage</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=k>if</span> <span class=nb>hasattr</span><span class=p>(</span><span class=n>tensor</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=s1>&#39;to_numpy&#39;</span><span class=p>):</span>  <span class=c1># 触及过深层次!</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>    <span class=c1># CUDAStorage特定代码</span>
</span></code></pre></div></p> <p><strong>正确模式</strong>: <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># 正确: nn.functional只使用NDArray接口</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=n>result</span> <span class=o>=</span> <span class=n>a</span><span class=o>.</span><span class=n>data</span> <span class=o>+</span> <span class=n>b</span><span class=o>.</span><span class=n>data</span>  <span class=c1># 清晰的抽象</span>
</span></code></pre></div></p> <h3 id=2>2. 单一职责<a class=headerlink href=#2 title="Permanent link">&para;</a></h3> <ul> <li><strong>张量</strong>: 自动微分和梯度管理</li> <li><strong>nn.functional</strong>: 定义前向/后向计算规则</li> <li><strong>NDArray</strong>: 设备抽象和统一操作</li> <li><strong>后端</strong>: 实际计算实现</li> </ul> <h3 id=3>3. 双后端架构<a class=headerlink href=#3 title="Permanent link">&para;</a></h3> <ul> <li><strong>CPU后端</strong>: 利用PyTorch成熟的CPU张量实现</li> <li><strong>GPU后端</strong>: 完全独立的CUDA实现，使用CUDAStorage</li> </ul> <h2 id=_8>📊 组件职责<a class=headerlink href=#_8 title="Permanent link">&para;</a></h2> <h3 id=1-autogradpy>第1层: 张量 (<code>autograd.py</code>)<a class=headerlink href=#1-autogradpy title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=k>class</span><span class=w> </span><span class=nc>Tensor</span><span class=p>:</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>    <span class=n>data</span><span class=p>:</span> <span class=n>NDArray</span>          <span class=c1># 底层数据 (委托计算)</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a>    <span class=n>requires_grad</span><span class=p>:</span> <span class=nb>bool</span>    <span class=c1># 是否需要梯度</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>    <span class=n>grad</span><span class=p>:</span> <span class=n>Tensor</span>          <span class=c1># 累积梯度</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a>    <span class=n>creator</span><span class=p>:</span> <span class=n>Function</span>     <span class=c1># 创建此张量的操作</span>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a>    <span class=c1># 面向用户的操作</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>    <span class=k>def</span><span class=w> </span><span class=fm>__add__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>other</span><span class=p>):</span>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a>        <span class=k>return</span> <span class=n>nn</span><span class=o>.</span><span class=n>functional</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>other</span><span class=p>)</span>  <span class=c1># 委托给函数层</span>
</span></code></pre></div> <p><strong>职责</strong>: - 管理计算图 - 存储和累积梯度 - 提供用户友好的API - 委托实际计算给nn.functional</p> <h3 id=2-nnfunctional-nnfunctionalpy>第2层: nn.functional (<code>nn/functional.py</code>)<a class=headerlink href=#2-nnfunctional-nnfunctionalpy title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=k>class</span><span class=w> </span><span class=nc>Add</span><span class=p>(</span><span class=n>Function</span><span class=p>):</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a>    <span class=nd>@staticmethod</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=n>ctx</span><span class=p>,</span> <span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>):</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a>        <span class=n>ctx</span><span class=o>.</span><span class=n>save_for_backward</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a>        <span class=c1># 只使用NDArray接口</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>        <span class=k>return</span> <span class=n>Tensor</span><span class=p>(</span><span class=n>a</span><span class=o>.</span><span class=n>data</span> <span class=o>+</span> <span class=n>b</span><span class=o>.</span><span class=n>data</span><span class=p>)</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>    <span class=nd>@staticmethod</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a>    <span class=k>def</span><span class=w> </span><span class=nf>backward</span><span class=p>(</span><span class=n>ctx</span><span class=p>,</span> <span class=n>grad_output</span><span class=p>):</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a>        <span class=c1># 定义梯度规则</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a>        <span class=k>return</span> <span class=n>grad_output</span><span class=p>,</span> <span class=n>grad_output</span>
</span></code></pre></div> <p><strong>职责</strong>: - 定义前向计算逻辑 - 定义后向梯度规则 - 保存后向传播所需信息 - **不**负责实际计算实现</p> <h3 id=3-ndarray-ndarrayndarraypy>第3层: NDArray (<code>ndarray/ndarray.py</code>)<a class=headerlink href=#3-ndarray-ndarrayndarraypy title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=k>class</span><span class=w> </span><span class=nc>NDArray</span><span class=p>:</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a>    <span class=n>device</span><span class=p>:</span> <span class=n>Device</span>        <span class=c1># CPU或CUDA</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a>    <span class=n>data</span><span class=p>:</span> <span class=n>Union</span><span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>CUDAStorage</span><span class=p>]</span>  <span class=c1># 实际数据</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a>    <span class=k>def</span><span class=w> </span><span class=fm>__add__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>other</span><span class=p>):</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>        <span class=c1># 分发到设备特定实现</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>other</span><span class=p>)</span>
</span></code></pre></div> <p><strong>职责</strong>: - 提供设备无关的计算接口 - 处理设备切换 (CPU ↔ GPU) - 分发操作到正确的后端 - 数据格式转换 (numpy等)</p> <h3 id=4-ndarray_ops_cpupy-ndarray_ops_gpupy>第4层: 后端 (<code>ndarray_ops_cpu.py</code>, <code>ndarray_ops_gpu.py</code>)<a class=headerlink href=#4-ndarray_ops_cpupy-ndarray_ops_gpupy title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=c1># GPU后端示例</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=k>def</span><span class=w> </span><span class=nf>add</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>    <span class=n>output</span> <span class=o>=</span> <span class=n>empty</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a>    <span class=n>add_kernel</span><span class=p>[</span><span class=n>grid</span><span class=p>](</span><span class=n>x</span><span class=o>.</span><span class=n>ptr</span><span class=p>,</span> <span class=n>y</span><span class=o>.</span><span class=n>ptr</span><span class=p>,</span> <span class=n>output</span><span class=o>.</span><span class=n>ptr</span><span class=p>,</span> <span class=n>n_elements</span><span class=p>)</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>    <span class=k>return</span> <span class=n>output</span>
</span></code></pre></div> <p><strong>职责</strong>: - 实际计算实现 - 内存管理 - 设备特定优化 - 内核执行</p> <h2 id=_9>🔄 梯度流示例<a class=headerlink href=#_9 title="Permanent link">&para;</a></h2> <p>让我们追踪一次完整的前向和后向传播：</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=c1># 用户代码</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a><span class=n>a</span> <span class=o>=</span> <span class=n>Tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=n>b</span> <span class=o>=</span> <span class=n>Tensor</span><span class=p>([</span><span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=n>c</span> <span class=o>=</span> <span class=n>a</span> <span class=o>+</span> <span class=n>b</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=n>c</span><span class=o>.</span><span class=n>backward</span><span class=p>(</span><span class=n>Tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>]))</span>
</span></code></pre></div> <h3 id=_10>前向传播<a class=headerlink href=#_10 title="Permanent link">&para;</a></h3> <pre class=mermaid><code>sequenceDiagram
    participant User
    participant Tensor
    participant Functional
    participant NDArray
    participant Backend

    User-&gt;&gt;Tensor: c = a + b
    Tensor-&gt;&gt;Functional: functional.add(a, b)
    Functional-&gt;&gt;Functional: ctx.save_for_backward(a, b)
    Functional-&gt;&gt;NDArray: a.data + b.data
    NDArray-&gt;&gt;Backend: device.add(x, y)
    Backend--&gt;&gt;NDArray: result_data
    NDArray--&gt;&gt;Functional: result_ndarray
    Functional--&gt;&gt;Tensor: Tensor(result_ndarray)
    Tensor--&gt;&gt;User: c</code></pre> <h3 id=_11>后向传播<a class=headerlink href=#_11 title="Permanent link">&para;</a></h3> <pre class=mermaid><code>sequenceDiagram
    participant User
    participant Tensor
    participant Functional

    User-&gt;&gt;Tensor: c.backward(grad)
    Tensor-&gt;&gt;Functional: Add.backward(ctx, grad)
    Functional-&gt;&gt;Functional: 计算梯度
    Functional--&gt;&gt;Tensor: grad_a, grad_b
    Tensor-&gt;&gt;Tensor: a.grad += grad_a
    Tensor-&gt;&gt;Tensor: b.grad += grad_b</code></pre> <h2 id=_12>⚠️ 当前正在修复的问题<a class=headerlink href=#_12 title="Permanent link">&para;</a></h2> <h3 id=nnfunctional>问题: nn.functional中的抽象泄漏<a class=headerlink href=#nnfunctional title="Permanent link">&para;</a></h3> <p>当前，<code>nn.functional</code>有如下代码: <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=c1># 错误: 触及实现细节</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=k>if</span> <span class=nb>hasattr</span><span class=p>(</span><span class=n>t</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=s1>&#39;to_numpy&#39;</span><span class=p>):</span>  <span class=c1># 检查CUDAStorage</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a>    <span class=c1># 特殊GPU处理</span>
</span></code></pre></div></p> <h3 id=_13>解决方案: 清晰抽象<a class=headerlink href=#_13 title="Permanent link">&para;</a></h3> <p>我们正在重构为: <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=c1># 正确: 只使用NDArray接口</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=n>result</span> <span class=o>=</span> <span class=n>a</span><span class=o>.</span><span class=n>data</span> <span class=o>+</span> <span class=n>b</span><span class=o>.</span><span class=n>data</span>  <span class=c1># NDArray处理设备细节</span>
</span></code></pre></div></p> <p>这确保: 1. nn.functional不了解CUDAStorage 2. 每一层只了解其直接邻居 3. 易于添加新后端而不更改上层</p> <p><strong>关键特性</strong>： - 支持混合精度训练的自动类型转换 - 灵活的计算图构建和遍历 - 内置的梯度累积和清零机制</p> <h3 id=_14>张量后端系统<a class=headerlink href=#_14 title="Permanent link">&para;</a></h3> <h4 id=cpu-ndarray_ops_cpupy>CPU后端 (<code>ndarray_ops_cpu.py</code>)<a class=headerlink href=#cpu-ndarray_ops_cpupy title="Permanent link">&para;</a></h4> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=c1># 直接使用PyTorch操作</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=k>def</span><span class=w> </span><span class=nf>add</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a>    <span class=k>return</span> <span class=n>x</span> <span class=o>+</span> <span class=n>y</span>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a><span class=k>def</span><span class=w> </span><span class=nf>matmul</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a>    <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></code></pre></div> <h4 id=gpu-ndarray_ops_gpupy>GPU后端 (<code>ndarray_ops_gpu.py</code>)<a class=headerlink href=#gpu-ndarray_ops_gpupy title="Permanent link">&para;</a></h4> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=c1># 使用Triton实现的GPU内核</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a><span class=nd>@triton</span><span class=o>.</span><span class=n>jit</span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a><span class=k>def</span><span class=w> </span><span class=nf>add_kernel</span><span class=p>(</span><span class=n>x_ptr</span><span class=p>,</span> <span class=n>y_ptr</span><span class=p>,</span> <span class=n>output_ptr</span><span class=p>,</span> <span class=n>n_elements</span><span class=p>,</span> <span class=n>BLOCK_SIZE</span><span class=p>:</span> <span class=n>tl</span><span class=o>.</span><span class=n>constexpr</span><span class=p>):</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a>    <span class=n>pid</span> <span class=o>=</span> <span class=n>tl</span><span class=o>.</span><span class=n>program_id</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a>    <span class=n>block_start</span> <span class=o>=</span> <span class=n>pid</span> <span class=o>*</span> <span class=n>BLOCK_SIZE</span>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a>    <span class=n>offsets</span> <span class=o>=</span> <span class=n>block_start</span> <span class=o>+</span> <span class=n>tl</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>BLOCK_SIZE</span><span class=p>)</span>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a>    <span class=n>mask</span> <span class=o>=</span> <span class=n>offsets</span> <span class=o>&lt;</span> <span class=n>n_elements</span>
</span><span id=__span-11-8><a id=__codelineno-11-8 name=__codelineno-11-8 href=#__codelineno-11-8></a>    <span class=n>x</span> <span class=o>=</span> <span class=n>tl</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>x_ptr</span> <span class=o>+</span> <span class=n>offsets</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=n>mask</span><span class=p>)</span>
</span><span id=__span-11-9><a id=__codelineno-11-9 name=__codelineno-11-9 href=#__codelineno-11-9></a>    <span class=n>y</span> <span class=o>=</span> <span class=n>tl</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>y_ptr</span> <span class=o>+</span> <span class=n>offsets</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=n>mask</span><span class=p>)</span>
</span><span id=__span-11-10><a id=__codelineno-11-10 name=__codelineno-11-10 href=#__codelineno-11-10></a>    <span class=n>output</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=n>y</span>
</span><span id=__span-11-11><a id=__codelineno-11-11 name=__codelineno-11-11 href=#__codelineno-11-11></a>    <span class=n>tl</span><span class=o>.</span><span class=n>store</span><span class=p>(</span><span class=n>output_ptr</span> <span class=o>+</span> <span class=n>offsets</span><span class=p>,</span> <span class=n>output</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=n>mask</span><span class=p>)</span>
</span></code></pre></div> <h4 id=cuda-cuda_storagepy>CUDA内存管理 (<code>cuda_storage.py</code>)<a class=headerlink href=#cuda-cuda_storagepy title="Permanent link">&para;</a></h4> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=k>class</span><span class=w> </span><span class=nc>CUDAStorage</span><span class=p>:</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;纯CUDA实现的存储，不依赖PyTorch&quot;&quot;&quot;</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>shape</span><span class=p>,</span> <span class=n>dtype</span><span class=p>):</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a>        <span class=bp>self</span><span class=o>.</span><span class=n>_cuda_device</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>_cuda_context</span> <span class=o>=</span> <span class=n>_ensure_cuda_initialized</span><span class=p>()</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>        <span class=bp>self</span><span class=o>.</span><span class=n>_allocate_memory</span><span class=p>(</span><span class=n>shape</span><span class=p>,</span> <span class=n>dtype</span><span class=p>)</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a>
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a>    <span class=k>def</span><span class=w> </span><span class=nf>_allocate_memory</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>shape</span><span class=p>,</span> <span class=n>dtype</span><span class=p>):</span>
</span><span id=__span-12-8><a id=__codelineno-12-8 name=__codelineno-12-8 href=#__codelineno-12-8></a>        <span class=c1># 使用CUDA Python API直接分配GPU内存</span>
</span><span id=__span-12-9><a id=__codelineno-12-9 name=__codelineno-12-9 href=#__codelineno-12-9></a>        <span class=n>size_bytes</span> <span class=o>=</span> <span class=n>prod</span><span class=p>(</span><span class=n>shape</span><span class=p>)</span> <span class=o>*</span> <span class=n>dtype</span><span class=o>.</span><span class=n>itemsize</span>
</span><span id=__span-12-10><a id=__codelineno-12-10 name=__codelineno-12-10 href=#__codelineno-12-10></a>        <span class=n>result</span> <span class=o>=</span> <span class=n>cuda</span><span class=o>.</span><span class=n>cuMemAlloc</span><span class=p>(</span><span class=n>size_bytes</span><span class=p>)</span>
</span><span id=__span-12-11><a id=__codelineno-12-11 name=__codelineno-12-11 href=#__codelineno-12-11></a>        <span class=bp>self</span><span class=o>.</span><span class=n>_data_ptr</span> <span class=o>=</span> <span class=n>check_cuda_error</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span></code></pre></div> <h3 id=nnmodulespy>神经网络模块 (<code>nn/modules.py</code>)<a class=headerlink href=#nnmodulespy title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=k>class</span><span class=w> </span><span class=nc>Module</span><span class=p>:</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;神经网络模块基类&quot;&quot;&quot;</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a>    <span class=k>def</span><span class=w> </span><span class=nf>parameters</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=n>Tensor</span><span class=p>]:</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a>        <span class=c1># 递归收集所有参数</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a>        <span class=k>return</span> <span class=n>_unpack_params</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=vm>__dict__</span><span class=p>)</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a>        <span class=c1># 子类实现具体的前向传播逻辑</span>
</span><span id=__span-13-9><a id=__codelineno-13-9 name=__codelineno-13-9 href=#__codelineno-13-9></a>        <span class=k>raise</span> <span class=ne>NotImplementedError</span>
</span><span id=__span-13-10><a id=__codelineno-13-10 name=__codelineno-13-10 href=#__codelineno-13-10></a>
</span><span id=__span-13-11><a id=__codelineno-13-11 name=__codelineno-13-11 href=#__codelineno-13-11></a><span class=k>class</span><span class=w> </span><span class=nc>Linear</span><span class=p>(</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-13-12><a id=__codelineno-13-12 name=__codelineno-13-12 href=#__codelineno-13-12></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;全连接层实现&quot;&quot;&quot;</span>
</span><span id=__span-13-13><a id=__codelineno-13-13 name=__codelineno-13-13 href=#__codelineno-13-13></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>in_features</span><span class=p>,</span> <span class=n>out_features</span><span class=p>):</span>
</span><span id=__span-13-14><a id=__codelineno-13-14 name=__codelineno-13-14 href=#__codelineno-13-14></a>        <span class=bp>self</span><span class=o>.</span><span class=n>weight</span> <span class=o>=</span> <span class=n>Parameter</span><span class=p>(</span><span class=n>genesis</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>out_features</span><span class=p>,</span> <span class=n>in_features</span><span class=p>))</span>
</span><span id=__span-13-15><a id=__codelineno-13-15 name=__codelineno-13-15 href=#__codelineno-13-15></a>        <span class=bp>self</span><span class=o>.</span><span class=n>bias</span> <span class=o>=</span> <span class=n>Parameter</span><span class=p>(</span><span class=n>genesis</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>out_features</span><span class=p>))</span>
</span></code></pre></div> <h2 id=_15>🔧 关键技术实现<a class=headerlink href=#_15 title="Permanent link">&para;</a></h2> <h3 id=1_1>1. 内存管理策略<a class=headerlink href=#1_1 title="Permanent link">&para;</a></h3> <p><strong>CPU内存管理</strong>： - 依赖PyTorch的内存池和垃圾回收 - 自动处理内存对齐和缓存优化</p> <p><strong>GPU内存管理</strong>： <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=k>class</span><span class=w> </span><span class=nc>CUDAStorage</span><span class=p>:</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>shape</span><span class=p>,</span> <span class=n>dtype</span><span class=p>,</span> <span class=n>base</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a>        <span class=k>if</span> <span class=n>base</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a>            <span class=c1># 视图存储：共享内存但保持对原存储的引用</span>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a>            <span class=bp>self</span><span class=o>.</span><span class=n>base</span> <span class=o>=</span> <span class=n>base</span>
</span><span id=__span-14-6><a id=__codelineno-14-6 name=__codelineno-14-6 href=#__codelineno-14-6></a>            <span class=bp>self</span><span class=o>.</span><span class=n>_data_ptr</span> <span class=o>=</span> <span class=n>base</span><span class=o>.</span><span class=n>_data_ptr</span> <span class=o>+</span> <span class=n>offset</span>
</span><span id=__span-14-7><a id=__codelineno-14-7 name=__codelineno-14-7 href=#__codelineno-14-7></a>        <span class=k>else</span><span class=p>:</span>
</span><span id=__span-14-8><a id=__codelineno-14-8 name=__codelineno-14-8 href=#__codelineno-14-8></a>            <span class=c1># 新存储：分配独立内存</span>
</span><span id=__span-14-9><a id=__codelineno-14-9 name=__codelineno-14-9 href=#__codelineno-14-9></a>            <span class=bp>self</span><span class=o>.</span><span class=n>base</span> <span class=o>=</span> <span class=kc>None</span>
</span><span id=__span-14-10><a id=__codelineno-14-10 name=__codelineno-14-10 href=#__codelineno-14-10></a>            <span class=bp>self</span><span class=o>.</span><span class=n>_data_ptr</span> <span class=o>=</span> <span class=n>cuda</span><span class=o>.</span><span class=n>cuMemAlloc</span><span class=p>(</span><span class=n>size_bytes</span><span class=p>)</span>
</span><span id=__span-14-11><a id=__codelineno-14-11 name=__codelineno-14-11 href=#__codelineno-14-11></a>
</span><span id=__span-14-12><a id=__codelineno-14-12 name=__codelineno-14-12 href=#__codelineno-14-12></a>    <span class=k>def</span><span class=w> </span><span class=fm>__del__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-14-13><a id=__codelineno-14-13 name=__codelineno-14-13 href=#__codelineno-14-13></a>        <span class=c1># 只有基础存储才释放内存</span>
</span><span id=__span-14-14><a id=__codelineno-14-14 name=__codelineno-14-14 href=#__codelineno-14-14></a>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>base</span> <span class=ow>is</span> <span class=kc>None</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>_data_ptr</span><span class=p>:</span>
</span><span id=__span-14-15><a id=__codelineno-14-15 name=__codelineno-14-15 href=#__codelineno-14-15></a>            <span class=n>cuda</span><span class=o>.</span><span class=n>cuMemFree</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_data_ptr</span><span class=p>)</span>
</span></code></pre></div></p> <h3 id=2_1>2. 设备抽象<a class=headerlink href=#2_1 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=k>class</span><span class=w> </span><span class=nc>Device</span><span class=p>:</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>mod</span><span class=p>:</span> <span class=n>Any</span><span class=p>,</span> <span class=n>device_id</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>int</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>):</span>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a>        <span class=bp>self</span><span class=o>.</span><span class=n>name</span> <span class=o>=</span> <span class=n>name</span>        <span class=c1># &quot;cpu&quot; 或 &quot;cuda&quot;</span>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a>        <span class=bp>self</span><span class=o>.</span><span class=n>mod</span> <span class=o>=</span> <span class=n>mod</span>          <span class=c1># 对应的操作模块</span>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a>        <span class=bp>self</span><span class=o>.</span><span class=n>device_id</span> <span class=o>=</span> <span class=n>device_id</span>  <span class=c1># GPU设备ID</span>
</span><span id=__span-15-6><a id=__codelineno-15-6 name=__codelineno-15-6 href=#__codelineno-15-6></a>
</span><span id=__span-15-7><a id=__codelineno-15-7 name=__codelineno-15-7 href=#__codelineno-15-7></a>    <span class=k>def</span><span class=w> </span><span class=nf>randn</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>*</span><span class=n>shape</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>genesis</span><span class=o>.</span><span class=n>float32</span><span class=p>):</span>
</span><span id=__span-15-8><a id=__codelineno-15-8 name=__codelineno-15-8 href=#__codelineno-15-8></a>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>name</span> <span class=o>==</span> <span class=s2>&quot;cuda&quot;</span><span class=p>:</span>
</span><span id=__span-15-9><a id=__codelineno-15-9 name=__codelineno-15-9 href=#__codelineno-15-9></a>            <span class=k>return</span> <span class=n>NDArray</span><span class=p>(</span><span class=n>CUDAStorage</span><span class=p>(</span><span class=n>shape</span><span class=p>,</span> <span class=n>dtype</span><span class=p>),</span> <span class=n>device</span><span class=o>=</span><span class=bp>self</span><span class=p>)</span>
</span><span id=__span-15-10><a id=__codelineno-15-10 name=__codelineno-15-10 href=#__codelineno-15-10></a>        <span class=k>else</span><span class=p>:</span>
</span><span id=__span-15-11><a id=__codelineno-15-11 name=__codelineno-15-11 href=#__codelineno-15-11></a>            <span class=k>return</span> <span class=n>NDArray</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=o>*</span><span class=n>shape</span><span class=p>),</span> <span class=n>device</span><span class=o>=</span><span class=bp>self</span><span class=p>)</span>
</span></code></pre></div> <h3 id=3_1>3. 类型系统<a class=headerlink href=#3_1 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=c1># dtypes.py - 统一的数据类型系统</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a><span class=k>class</span><span class=w> </span><span class=nc>DType</span><span class=p>:</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>torch_dtype</span><span class=p>,</span> <span class=n>numpy_dtype</span><span class=p>,</span> <span class=n>itemsize</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a>        <span class=bp>self</span><span class=o>.</span><span class=n>name</span> <span class=o>=</span> <span class=n>name</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a>        <span class=bp>self</span><span class=o>.</span><span class=n>torch_dtype</span> <span class=o>=</span> <span class=n>torch_dtype</span>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a>        <span class=bp>self</span><span class=o>.</span><span class=n>numpy_dtype</span> <span class=o>=</span> <span class=n>numpy_dtype</span>  
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a>        <span class=bp>self</span><span class=o>.</span><span class=n>itemsize</span> <span class=o>=</span> <span class=n>itemsize</span>
</span><span id=__span-16-8><a id=__codelineno-16-8 name=__codelineno-16-8 href=#__codelineno-16-8></a>
</span><span id=__span-16-9><a id=__codelineno-16-9 name=__codelineno-16-9 href=#__codelineno-16-9></a><span class=c1># 支持的数据类型</span>
</span><span id=__span-16-10><a id=__codelineno-16-10 name=__codelineno-16-10 href=#__codelineno-16-10></a><span class=n>float32</span> <span class=o>=</span> <span class=n>DType</span><span class=p>(</span><span class=s2>&quot;float32&quot;</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
</span><span id=__span-16-11><a id=__codelineno-16-11 name=__codelineno-16-11 href=#__codelineno-16-11></a><span class=n>float16</span> <span class=o>=</span> <span class=n>DType</span><span class=p>(</span><span class=s2>&quot;float16&quot;</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>float16</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span><span id=__span-16-12><a id=__codelineno-16-12 name=__codelineno-16-12 href=#__codelineno-16-12></a><span class=n>bfloat16</span> <span class=o>=</span> <span class=n>DType</span><span class=p>(</span><span class=s2>&quot;bfloat16&quot;</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>dtype</span><span class=p>(</span><span class=s1>&#39;uint16&#39;</span><span class=p>),</span> <span class=mi>2</span><span class=p>)</span>
</span></code></pre></div> <h2 id=_16>🚀 性能优化策略<a class=headerlink href=#_16 title="Permanent link">&para;</a></h2> <h3 id=1-triton>1. Triton内核优化<a class=headerlink href=#1-triton title="Permanent link">&para;</a></h3> <p><strong>Softmax实现</strong>： <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a><span class=nd>@triton</span><span class=o>.</span><span class=n>jit</span>
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a><span class=k>def</span><span class=w> </span><span class=nf>softmax_kernel</span><span class=p>(</span><span class=n>input_ptr</span><span class=p>,</span> <span class=n>output_ptr</span><span class=p>,</span> <span class=n>input_row_stride</span><span class=p>,</span> <span class=n>output_row_stride</span><span class=p>,</span> 
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>                  <span class=n>n_cols</span><span class=p>,</span> <span class=n>BLOCK_SIZE</span><span class=p>:</span> <span class=n>tl</span><span class=o>.</span><span class=n>constexpr</span><span class=p>):</span>
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a>    <span class=c1># 高效的并行softmax实现</span>
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a>    <span class=n>row_idx</span> <span class=o>=</span> <span class=n>tl</span><span class=o>.</span><span class=n>program_id</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6 href=#__codelineno-17-6></a>    <span class=n>row_start_ptr</span> <span class=o>=</span> <span class=n>input_ptr</span> <span class=o>+</span> <span class=n>row_idx</span> <span class=o>*</span> <span class=n>input_row_stride</span>
</span><span id=__span-17-7><a id=__codelineno-17-7 name=__codelineno-17-7 href=#__codelineno-17-7></a>    <span class=n>col_offsets</span> <span class=o>=</span> <span class=n>tl</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>BLOCK_SIZE</span><span class=p>)</span>
</span><span id=__span-17-8><a id=__codelineno-17-8 name=__codelineno-17-8 href=#__codelineno-17-8></a>    <span class=n>input_ptrs</span> <span class=o>=</span> <span class=n>row_start_ptr</span> <span class=o>+</span> <span class=n>col_offsets</span>
</span><span id=__span-17-9><a id=__codelineno-17-9 name=__codelineno-17-9 href=#__codelineno-17-9></a>    <span class=n>row</span> <span class=o>=</span> <span class=n>tl</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>input_ptrs</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=n>col_offsets</span> <span class=o>&lt;</span> <span class=n>n_cols</span><span class=p>,</span> <span class=n>other</span><span class=o>=-</span><span class=nb>float</span><span class=p>(</span><span class=s1>&#39;inf&#39;</span><span class=p>))</span>
</span><span id=__span-17-10><a id=__codelineno-17-10 name=__codelineno-17-10 href=#__codelineno-17-10></a>
</span><span id=__span-17-11><a id=__codelineno-17-11 name=__codelineno-17-11 href=#__codelineno-17-11></a>    <span class=c1># 数值稳定的softmax</span>
</span><span id=__span-17-12><a id=__codelineno-17-12 name=__codelineno-17-12 href=#__codelineno-17-12></a>    <span class=n>row_minus_max</span> <span class=o>=</span> <span class=n>row</span> <span class=o>-</span> <span class=n>tl</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>row</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span><span id=__span-17-13><a id=__codelineno-17-13 name=__codelineno-17-13 href=#__codelineno-17-13></a>    <span class=n>numerator</span> <span class=o>=</span> <span class=n>tl</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>row_minus_max</span><span class=p>)</span>
</span><span id=__span-17-14><a id=__codelineno-17-14 name=__codelineno-17-14 href=#__codelineno-17-14></a>    <span class=n>denominator</span> <span class=o>=</span> <span class=n>tl</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>numerator</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span><span id=__span-17-15><a id=__codelineno-17-15 name=__codelineno-17-15 href=#__codelineno-17-15></a>    <span class=n>softmax_output</span> <span class=o>=</span> <span class=n>numerator</span> <span class=o>/</span> <span class=n>denominator</span>
</span><span id=__span-17-16><a id=__codelineno-17-16 name=__codelineno-17-16 href=#__codelineno-17-16></a>
</span><span id=__span-17-17><a id=__codelineno-17-17 name=__codelineno-17-17 href=#__codelineno-17-17></a>    <span class=n>output_row_start_ptr</span> <span class=o>=</span> <span class=n>output_ptr</span> <span class=o>+</span> <span class=n>row_idx</span> <span class=o>*</span> <span class=n>output_row_stride</span>
</span><span id=__span-17-18><a id=__codelineno-17-18 name=__codelineno-17-18 href=#__codelineno-17-18></a>    <span class=n>output_ptrs</span> <span class=o>=</span> <span class=n>output_row_start_ptr</span> <span class=o>+</span> <span class=n>col_offsets</span>
</span><span id=__span-17-19><a id=__codelineno-17-19 name=__codelineno-17-19 href=#__codelineno-17-19></a>    <span class=n>tl</span><span class=o>.</span><span class=n>store</span><span class=p>(</span><span class=n>output_ptrs</span><span class=p>,</span> <span class=n>softmax_output</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=n>col_offsets</span> <span class=o>&lt;</span> <span class=n>n_cols</span><span class=p>)</span>
</span></code></pre></div></p> <h3 id=2_2>2. 混合精度训练<a class=headerlink href=#2_2 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a><span class=c1># amp.py - 自动混合精度</span>
</span><span id=__span-18-2><a id=__codelineno-18-2 name=__codelineno-18-2 href=#__codelineno-18-2></a><span class=n>enable_autocast</span> <span class=o>=</span> <span class=kc>False</span>
</span><span id=__span-18-3><a id=__codelineno-18-3 name=__codelineno-18-3 href=#__codelineno-18-3></a>
</span><span id=__span-18-4><a id=__codelineno-18-4 name=__codelineno-18-4 href=#__codelineno-18-4></a><span class=k>def</span><span class=w> </span><span class=nf>_cast</span><span class=p>(</span><span class=n>value</span><span class=p>,</span> <span class=n>dtype</span><span class=p>):</span>
</span><span id=__span-18-5><a id=__codelineno-18-5 name=__codelineno-18-5 href=#__codelineno-18-5></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;自动类型转换&quot;&quot;&quot;</span>
</span><span id=__span-18-6><a id=__codelineno-18-6 name=__codelineno-18-6 href=#__codelineno-18-6></a>    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>value</span><span class=p>,</span> <span class=n>Tensor</span><span class=p>)</span> <span class=ow>and</span> <span class=n>value</span><span class=o>.</span><span class=n>is_floating_point</span><span class=p>():</span>
</span><span id=__span-18-7><a id=__codelineno-18-7 name=__codelineno-18-7 href=#__codelineno-18-7></a>        <span class=k>if</span> <span class=n>dtype</span> <span class=o>==</span> <span class=n>genesis</span><span class=o>.</span><span class=n>float16</span><span class=p>:</span>
</span><span id=__span-18-8><a id=__codelineno-18-8 name=__codelineno-18-8 href=#__codelineno-18-8></a>            <span class=k>return</span> <span class=n>value</span><span class=o>.</span><span class=n>half</span><span class=p>()</span>
</span><span id=__span-18-9><a id=__codelineno-18-9 name=__codelineno-18-9 href=#__codelineno-18-9></a>        <span class=k>else</span><span class=p>:</span>
</span><span id=__span-18-10><a id=__codelineno-18-10 name=__codelineno-18-10 href=#__codelineno-18-10></a>            <span class=k>return</span> <span class=n>value</span><span class=o>.</span><span class=n>float</span><span class=p>()</span>
</span><span id=__span-18-11><a id=__codelineno-18-11 name=__codelineno-18-11 href=#__codelineno-18-11></a>    <span class=k>return</span> <span class=n>value</span>
</span></code></pre></div> <h2 id=_17>🔍 架构优势<a class=headerlink href=#_17 title="Permanent link">&para;</a></h2> <h3 id=_18>教育价值<a class=headerlink href=#_18 title="Permanent link">&para;</a></h3> <ol> <li><strong>渐进式复杂度</strong>：从简单的CPU实现到复杂的GPU优化</li> <li><strong>完整实现展示</strong>：展示了深度学习框架的完整构建过程 </li> <li><strong>清晰的模块边界</strong>：每个组件职责明确，便于理解</li> </ol> <h3 id=_19>工程实践<a class=headerlink href=#_19 title="Permanent link">&para;</a></h3> <ol> <li><strong>双后端设计</strong>：CPU稳定性 + GPU高性能</li> <li><strong>内存安全</strong>：RAII模式的内存管理，防止内存泄漏</li> <li><strong>类型安全</strong>：统一的类型系统，避免类型错误</li> </ol> <h3 id=_20>性能特性<a class=headerlink href=#_20 title="Permanent link">&para;</a></h3> <ol> <li><strong>Triton优化</strong>：现代GPU内核编写方式</li> <li><strong>零拷贝视图</strong>：高效的张量视图操作</li> <li><strong>并行计算</strong>：充分利用GPU并行能力</li> </ol> <h2 id=_21>🎯 设计权衡<a class=headerlink href=#_21 title="Permanent link">&para;</a></h2> <h3 id=cpu-vs-gpu>CPU vs GPU 实现选择<a class=headerlink href=#cpu-vs-gpu title="Permanent link">&para;</a></h3> <ul> <li><strong>CPU</strong>：使用PyTorch确保稳定性和兼容性</li> <li><strong>GPU</strong>：独立实现展示完整的GPU编程栈</li> </ul> <h3 id=vs>简洁性 vs 性能<a class=headerlink href=#vs title="Permanent link">&para;</a></h3> <ul> <li>保持API简洁的同时，底层实现高度优化</li> <li>通过分层架构将复杂性隔离在底层</li> </ul> <h3 id=vs_1>教育 vs 生产<a class=headerlink href=#vs_1 title="Permanent link">&para;</a></h3> <ul> <li>代码注重可读性和教育价值</li> <li>性能仍然达到实用级别</li> </ul> <p>这种架构设计使得Genesis既是一个优秀的学习资源，也是一个功能完整的深度学习框架。</p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_datetime" title="August 15, 2025 10:04:50 UTC">2025-08-15 10:04:50</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_datetime" title="August 15, 2025 10:04:50 UTC">2025-08-15 10:04:50</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2025 Genesis Team </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/phonism/genesis target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://pypi.org/project/genesis-dl/ target=_blank rel=noopener title=pypi.org class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <div class=md-consent data-md-component=consent id=__consent hidden> <div class=md-consent__overlay></div> <aside class=md-consent__inner> <form class="md-consent__form md-grid md-typeset" name=consent> <h4>Cookie consent</h4> <p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p> <input class=md-toggle type=checkbox id=__settings> <div class=md-consent__settings> <ul class=task-list> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=analytics checked> <span class=task-list-indicator></span> Google Analytics </label> </li> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=github checked> <span class=task-list-indicator></span> GitHub </label> </li> </ul> </div> <div class=md-consent__controls> <button class="md-button md-button--primary">Accept</button> <label class=md-button for=__settings>Manage settings</label> </div> </form> </aside> </div> <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script> <script id=__config type=application/json>{"base": "../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.path", "navigation.prune", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "toc.integrate"], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script> <script src=../../assets/javascripts/bundle.50899def.min.js></script> <script src=../../javascripts/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>