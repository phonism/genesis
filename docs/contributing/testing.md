# æµ‹è¯•è§„èŒƒ

!!! warning "å¼€å‘ä¸­"
    æ­¤æ–‡æ¡£æ­£åœ¨ç¼–å†™ä¸­ï¼Œå†…å®¹å°†æŒç»­æ›´æ–°ã€‚

æœ¬æ–‡æ¡£è§„å®šäº†Genesisé¡¹ç›®çš„æµ‹è¯•æ ‡å‡†å’Œæœ€ä½³å®è·µã€‚

## ğŸ¯ æµ‹è¯•åŸåˆ™

### 1. æµ‹è¯•é‡‘å­—å¡”
- **å•å…ƒæµ‹è¯•** (70%): æµ‹è¯•å•ä¸ªå‡½æ•°å’Œç±»
- **é›†æˆæµ‹è¯•** (20%): æµ‹è¯•ç»„ä»¶é—´äº¤äº’
- **ç«¯åˆ°ç«¯æµ‹è¯•** (10%): æµ‹è¯•å®Œæ•´å·¥ä½œæµ

### 2. æµ‹è¯•è¦†ç›–ç‡
- ç›®æ ‡è¦†ç›–ç‡: 90%+
- å…³é”®æ¨¡å—è¦æ±‚: 95%+
- æ–°ä»£ç è¦æ±‚: 100%

## ğŸ“‹ æµ‹è¯•åˆ†ç±»

### å•å…ƒæµ‹è¯•
```python
def test_tensor_creation():
    """Test basic tensor creation."""
    x = genesis.randn(3, 4)
    assert x.shape == (3, 4)
    assert x.dtype == genesis.float32
```

### æ€§èƒ½æµ‹è¯•
```python
@pytest.mark.benchmark
def test_matmul_performance():
    """Benchmark matrix multiplication performance."""
    # WIP: æ€§èƒ½æµ‹è¯•å®ç°
    pass
```

### GPUæµ‹è¯•
```python
@pytest.mark.cuda
def test_cuda_operations():
    """Test CUDA-specific operations."""
    if not genesis.cuda.is_available():
        pytest.skip("CUDA not available")
    
    x = genesis.randn(10, 10, device='cuda')
    y = genesis.matmul(x, x)
    assert y.device.type == 'cuda'
```

## ğŸš€ è¿è¡Œæµ‹è¯•

```bash
# æ‰€æœ‰æµ‹è¯•
pytest tests/ -v

# ç‰¹å®šæ ‡è®°
pytest tests/ -m "not slow" -v

# è¦†ç›–ç‡æŠ¥å‘Š
pytest tests/ --cov=genesis --cov-report=html
```

## ğŸ“Š æµ‹è¯•å·¥å…·

- **pytest**: ä¸»è¦æµ‹è¯•æ¡†æ¶
- **pytest-cov**: è¦†ç›–ç‡ç»Ÿè®¡
- **pytest-benchmark**: æ€§èƒ½æµ‹è¯•
- **pytest-xdist**: å¹¶è¡Œæµ‹è¯•

---

ğŸ“˜ **æ–‡æ¡£çŠ¶æ€**: æ­£åœ¨ç¼–å†™ä¸­ï¼Œé¢„è®¡åœ¨v0.2.0ç‰ˆæœ¬å®Œæˆã€‚