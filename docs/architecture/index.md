# æ¶æ„æ¦‚è¿°

Genesisæ·±åº¦å­¦ä¹ æ¡†æ¶é‡‡ç”¨åˆ†å±‚çš„æ¨¡å—åŒ–æ¶æ„è®¾è®¡ï¼Œæ—¢ä¿æŒäº†ä»£ç çš„æ¸…æ™°æ€§ï¼Œåˆå®ç°äº†é«˜æ€§èƒ½çš„è®¡ç®—èƒ½åŠ›ã€‚

## ğŸ—ï¸ æ€»ä½“æ¶æ„

```mermaid
graph TB
    subgraph "ç”¨æˆ·APIå±‚"
        A[genesis.Tensor] --> B[genesis.nn.*]
        A --> C[genesis.optim.*]
        A --> D[genesis.functional.*]
    end
    
    subgraph "è‡ªåŠ¨å¾®åˆ†å±‚"
        E[autograd.Tensor] --> F[FunctionåŸºç±»]
        F --> G[Contextä¸Šä¸‹æ–‡]
    end
    
    subgraph "å¼ é‡ç³»ç»Ÿ"
        H[backend.py] --> I[NDArrayæ¥å£]
    end
    
    subgraph "åç«¯å®ç°"
        I --> J[CPU Backend<br/>PyTorchå¼ é‡]
        I --> K[GPU Backend<br/>CUDA + Triton]
    end
    
    subgraph "GPUç‹¬ç«‹å®ç°"
        K --> L[cuda_tensor.py<br/>çº¯CUDAå†…å­˜ç®¡ç†]
        K --> M[ndarray_ops_gpu.py<br/>Triton kernels]
        L --> N[CUDA Python API]
        M --> O[Tritonç¼–è¯‘å™¨]
    end
    
    subgraph "CPUå®ç°"
        J --> P[ndarray_ops_cpu.py<br/>PyTorchæ“ä½œ]
        P --> Q[PyTorch Backend]
    end
    
    A --> E
    B --> E
    E --> H
    
    style A fill:#e1f5fe
    style E fill:#f3e5f5
    style H fill:#fff3e0
    style K fill:#e8f5e8
    style J fill:#fce4ec
```

## ğŸ”‘ æ ¸å¿ƒè®¾è®¡ç†å¿µ

### 1. åŒåç«¯æ¶æ„

Genesisé‡‡ç”¨äº†åˆ›æ–°çš„åŒåç«¯è®¾è®¡ï¼š

- **CPUåç«¯**ï¼šåˆ©ç”¨PyTorchæˆç†Ÿçš„CPUå¼ é‡å®ç°ï¼Œç¡®ä¿ç¨³å®šæ€§å’Œå…¼å®¹æ€§
- **GPUåç«¯**ï¼šå®Œå…¨ç‹¬ç«‹çš„CUDAå®ç°ï¼Œå±•ç¤ºäº†ä»é›¶æ„å»ºGPUè®¡ç®—æ ˆçš„å®Œæ•´è¿‡ç¨‹

### 2. æ•™è‚²ä¸æ€§èƒ½å¹¶é‡

- **ä»£ç å¯è¯»æ€§**ï¼šæ¯ä¸ªæ¨¡å—éƒ½æœ‰æ¸…æ™°çš„èŒè´£åˆ†å·¥å’Œè¯¦ç»†çš„æ–‡æ¡£
- **æ€§èƒ½ä¼˜åŒ–**ï¼šGPUåç«¯ä½¿ç”¨Tritonå®ç°é«˜æ€§èƒ½kernels
- **æ¸è¿›å¼å­¦ä¹ **ï¼šä»ç®€å•çš„CPUå®ç°åˆ°å¤æ‚çš„GPUä¼˜åŒ–

### 3. æ¨¡å—åŒ–è®¾è®¡

æ¯ä¸ªç»„ä»¶éƒ½å¯ä»¥ç‹¬ç«‹ç†è§£å’Œæ‰©å±•ï¼š
- è‡ªåŠ¨å¾®åˆ†ç³»ç»Ÿç‹¬ç«‹äºå…·ä½“çš„å¼ é‡å®ç°
- ç¥ç»ç½‘ç»œæ¨¡å—åŸºäºé€šç”¨çš„å¼ é‡æ“ä½œ
- åç«¯æŠ½è±¡å…è®¸è½»æ¾åˆ‡æ¢ä¸åŒçš„å®ç°

## ğŸ“Š ä¸»è¦ç»„ä»¶è¯¦è§£

### è‡ªåŠ¨å¾®åˆ†ç³»ç»Ÿ (`autograd.py`)

```python
# æ ¸å¿ƒç±»ç»“æ„
class Tensor:
    data: NDArray          # åº•å±‚æ•°æ®å­˜å‚¨
    requires_grad: bool    # æ˜¯å¦éœ€è¦æ¢¯åº¦
    creator: Function      # åˆ›å»ºæ­¤å¼ é‡çš„æ“ä½œ
    grad: Tensor          # æ¢¯åº¦å¼ é‡
    
class Function:
    @staticmethod
    def forward(ctx, *args)    # å‰å‘ä¼ æ’­
    @staticmethod 
    def backward(ctx, grad)    # åå‘ä¼ æ’­
```

**å…³é”®ç‰¹æ€§**ï¼š
- æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒçš„è‡ªåŠ¨ç±»å‹è½¬æ¢
- çµæ´»çš„è®¡ç®—å›¾æ„å»ºå’Œéå†
- å†…ç½®çš„æ¢¯åº¦ç´¯ç§¯å’Œæ¸…é›¶æœºåˆ¶

### å¼ é‡åç«¯ç³»ç»Ÿ

#### CPUåç«¯ (`ndarray_ops_cpu.py`)
```python
# ç›´æ¥ä½¿ç”¨PyTorchæ“ä½œ
def add(x, y):
    return x + y

def matmul(x, y):
    return torch.matmul(x, y)
```

#### GPUåç«¯ (`ndarray_ops_gpu.py`)
```python
# ä½¿ç”¨Tritonå®ç°çš„GPU kernels
@triton.jit
def add_kernel(x_ptr, y_ptr, output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):
    pid = tl.program_id(axis=0)
    block_start = pid * BLOCK_SIZE
    offsets = block_start + tl.arange(0, BLOCK_SIZE)
    mask = offsets < n_elements
    x = tl.load(x_ptr + offsets, mask=mask)
    y = tl.load(y_ptr + offsets, mask=mask)
    output = x + y
    tl.store(output_ptr + offsets, output, mask=mask)
```

#### CUDAå†…å­˜ç®¡ç† (`cuda_tensor.py`)
```python
class CUDATensor:
    """çº¯CUDAå®ç°çš„å¼ é‡ï¼Œä¸ä¾èµ–PyTorch"""
    def __init__(self, shape, dtype):
        self._cuda_device, self._cuda_context = _ensure_cuda_initialized()
        self._allocate_memory(shape, dtype)
        
    def _allocate_memory(self, shape, dtype):
        # ä½¿ç”¨CUDA Python APIç›´æ¥åˆ†é…GPUå†…å­˜
        size_bytes = prod(shape) * dtype.itemsize
        result = cuda.cuMemAlloc(size_bytes)
        self._data_ptr = check_cuda_error(result)
```

### ç¥ç»ç½‘ç»œæ¨¡å— (`nn/modules.py`)

```python
class Module:
    """ç¥ç»ç½‘ç»œæ¨¡å—åŸºç±»"""
    def parameters(self) -> List[Tensor]:
        # é€’å½’æ”¶é›†æ‰€æœ‰å‚æ•°
        return _unpack_params(self.__dict__)
    
    def forward(self, *args, **kwargs):
        # å­ç±»å®ç°å…·ä½“çš„å‰å‘ä¼ æ’­é€»è¾‘
        raise NotImplementedError

class Linear(Module):
    """å…¨è¿æ¥å±‚å®ç°"""
    def __init__(self, in_features, out_features):
        self.weight = Parameter(genesis.randn(out_features, in_features))
        self.bias = Parameter(genesis.zeros(out_features))
```

## ğŸ”§ å…³é”®æŠ€æœ¯å®ç°

### 1. å†…å­˜ç®¡ç†ç­–ç•¥

**CPUå†…å­˜ç®¡ç†**ï¼š
- ä¾èµ–PyTorchçš„å†…å­˜æ± å’Œåƒåœ¾å›æ”¶
- è‡ªåŠ¨å¤„ç†å†…å­˜å¯¹é½å’Œç¼“å­˜ä¼˜åŒ–

**GPUå†…å­˜ç®¡ç†**ï¼š
```python
class CUDATensor:
    def __init__(self, shape, dtype, base=None):
        if base is not None:
            # è§†å›¾å¼ é‡ï¼šå…±äº«å†…å­˜ä½†ä¿æŒå¯¹åŸå¼ é‡çš„å¼•ç”¨
            self.base = base
            self._data_ptr = base._data_ptr + offset
        else:
            # æ–°å¼ é‡ï¼šåˆ†é…ç‹¬ç«‹å†…å­˜
            self.base = None
            self._data_ptr = cuda.cuMemAlloc(size_bytes)
    
    def __del__(self):
        # åªæœ‰åŸºç¡€å¼ é‡æ‰é‡Šæ”¾å†…å­˜
        if self.base is None and self._data_ptr:
            cuda.cuMemFree(self._data_ptr)
```

### 2. è®¾å¤‡æŠ½è±¡

```python
class Device:
    def __init__(self, name: str, mod: Any, device_id: Optional[int] = None):
        self.name = name        # "cpu" æˆ– "cuda"
        self.mod = mod          # å¯¹åº”çš„æ“ä½œæ¨¡å—
        self.device_id = device_id  # GPUè®¾å¤‡ID
        
    def randn(self, *shape, dtype=genesis.float32):
        if self.name == "cuda":
            return NDArray(CUDATensor(shape, dtype), device=self)
        else:
            return NDArray(torch.randn(*shape), device=self)
```

### 3. ç±»å‹ç³»ç»Ÿ

```python
# dtypes.py - ç»Ÿä¸€çš„æ•°æ®ç±»å‹ç³»ç»Ÿ
class DType:
    def __init__(self, name: str, torch_dtype, numpy_dtype, itemsize: int):
        self.name = name
        self.torch_dtype = torch_dtype
        self.numpy_dtype = numpy_dtype  
        self.itemsize = itemsize

# æ”¯æŒçš„æ•°æ®ç±»å‹
float32 = DType("float32", torch.float32, np.float32, 4)
float16 = DType("float16", torch.float16, np.float16, 2)
bfloat16 = DType("bfloat16", torch.bfloat16, np.dtype('uint16'), 2)
```

## ğŸš€ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. Triton Kernelä¼˜åŒ–

**Softmaxå®ç°**ï¼š
```python
@triton.jit
def softmax_kernel(input_ptr, output_ptr, input_row_stride, output_row_stride, 
                  n_cols, BLOCK_SIZE: tl.constexpr):
    # é«˜æ•ˆçš„å¹¶è¡Œsoftmaxå®ç°
    row_idx = tl.program_id(0)
    row_start_ptr = input_ptr + row_idx * input_row_stride
    col_offsets = tl.arange(0, BLOCK_SIZE)
    input_ptrs = row_start_ptr + col_offsets
    row = tl.load(input_ptrs, mask=col_offsets < n_cols, other=-float('inf'))
    
    # æ•°å€¼ç¨³å®šçš„softmax
    row_minus_max = row - tl.max(row, axis=0)
    numerator = tl.exp(row_minus_max)
    denominator = tl.sum(numerator, axis=0)
    softmax_output = numerator / denominator
    
    output_row_start_ptr = output_ptr + row_idx * output_row_stride
    output_ptrs = output_row_start_ptr + col_offsets
    tl.store(output_ptrs, softmax_output, mask=col_offsets < n_cols)
```

### 2. æ··åˆç²¾åº¦è®­ç»ƒ

```python
# amp.py - è‡ªåŠ¨æ··åˆç²¾åº¦
enable_autocast = False

def _cast(value, dtype):
    """è‡ªåŠ¨ç±»å‹è½¬æ¢"""
    if isinstance(value, Tensor) and value.is_floating_point():
        if dtype == genesis.float16:
            return value.half()
        else:
            return value.float()
    return value
```

## ğŸ” æ¶æ„ä¼˜åŠ¿

### æ•™è‚²ä»·å€¼
1. **æ¸è¿›å¼å¤æ‚åº¦**ï¼šä»ç®€å•çš„CPUå®ç°åˆ°å¤æ‚çš„GPUä¼˜åŒ–
2. **å®Œæ•´å®ç°å±•ç¤º**ï¼šå±•ç¤ºäº†æ·±åº¦å­¦ä¹ æ¡†æ¶çš„å®Œæ•´æ„å»ºè¿‡ç¨‹  
3. **æ¸…æ™°çš„æ¨¡å—è¾¹ç•Œ**ï¼šæ¯ä¸ªç»„ä»¶èŒè´£æ˜ç¡®ï¼Œä¾¿äºç†è§£

### å·¥ç¨‹å®è·µ
1. **åŒåç«¯è®¾è®¡**ï¼šCPUç¨³å®šæ€§ + GPUé«˜æ€§èƒ½
2. **å†…å­˜å®‰å…¨**ï¼šRAIIæ¨¡å¼çš„å†…å­˜ç®¡ç†ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
3. **ç±»å‹å®‰å…¨**ï¼šç»Ÿä¸€çš„ç±»å‹ç³»ç»Ÿï¼Œé¿å…ç±»å‹é”™è¯¯

### æ€§èƒ½ç‰¹æ€§
1. **Tritonä¼˜åŒ–**ï¼šç°ä»£GPU kernelç¼–å†™æ–¹å¼
2. **é›¶æ‹·è´è§†å›¾**ï¼šé«˜æ•ˆçš„å¼ é‡è§†å›¾æ“ä½œ
3. **å¹¶è¡Œè®¡ç®—**ï¼šå……åˆ†åˆ©ç”¨GPUå¹¶è¡Œèƒ½åŠ›

## ğŸ¯ è®¾è®¡æƒè¡¡

### CPU vs GPU å®ç°é€‰æ‹©
- **CPU**ï¼šä½¿ç”¨PyTorchç¡®ä¿ç¨³å®šæ€§å’Œå…¼å®¹æ€§
- **GPU**ï¼šç‹¬ç«‹å®ç°å±•ç¤ºå®Œæ•´çš„GPUç¼–ç¨‹æ ˆ

### ç®€æ´æ€§ vs æ€§èƒ½
- ä¿æŒAPIç®€æ´çš„åŒæ—¶ï¼Œåº•å±‚å®ç°é«˜åº¦ä¼˜åŒ–
- é€šè¿‡åˆ†å±‚æ¶æ„å°†å¤æ‚æ€§éš”ç¦»åœ¨åº•å±‚

### æ•™è‚² vs ç”Ÿäº§
- ä»£ç æ³¨é‡å¯è¯»æ€§å’Œæ•™è‚²ä»·å€¼
- æ€§èƒ½ä»ç„¶è¾¾åˆ°å®ç”¨çº§åˆ«

è¿™ç§æ¶æ„è®¾è®¡ä½¿å¾—Genesisæ—¢æ˜¯ä¸€ä¸ªä¼˜ç§€çš„å­¦ä¹ èµ„æºï¼Œä¹Ÿæ˜¯ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚