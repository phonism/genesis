# Optimizer API Reference

Complete reference for Genesis optimization algorithms.

## Available Optimizers

- **[Optimizers](../api/optim/optimizers.md)** - SGD, Adam, AdamW and more
- **[Learning Rate Schedulers](../api/optim/lr_scheduler.md)** - Learning rate scheduling

## Quick Reference

### Optimizers
- `optim.SGD` - Stochastic Gradient Descent
- `optim.Adam` - Adam optimizer  
- `optim.AdamW` - Adam with weight decay

### Schedulers  
- `lr_scheduler.StepLR` - Step-based decay
- `lr_scheduler.CosineAnnealingLR` - Cosine annealing

*See individual pages for detailed API documentation.*