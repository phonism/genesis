# å­˜å‚¨å±‚

Genesisçš„å­˜å‚¨å±‚æä¾›äº†ä¸€ä¸ªæŠ½è±¡æ¥å£ï¼Œç”¨äºç®¡ç†ä¸åŒè®¾å¤‡ä¸Šçš„å¼ é‡æ•°æ®å­˜å‚¨ã€‚

## ğŸ“‹ æ¦‚è¿°

å­˜å‚¨å±‚æ˜¯Genesis v2.0æ¶æ„çš„å…³é”®ç»„ä»¶ï¼Œå®ƒï¼š
- æŠ½è±¡äº†è®¾å¤‡ç‰¹å®šçš„å­˜å‚¨å®ç°
- ç®¡ç†å†…å­˜ç”Ÿå‘½å‘¨æœŸ
- æä¾›è®¾å¤‡é—´çš„é«˜æ•ˆæ•°æ®ä¼ è¾“
- æ”¯æŒå„ç§æ•°æ®ç±»å‹å’Œå†…å­˜å¸ƒå±€

## ğŸ—ï¸ æ¶æ„

```mermaid
graph TB
    subgraph "å­˜å‚¨æŠ½è±¡"
        A[Storageæ¥å£] --> B[create_storage()]
        A --> C[storage.to()]
        A --> D[storage.copy_()]
    end

    subgraph "è®¾å¤‡å®ç°"
        E[CPUStorage] --> A
        F[CUDAStorage] --> A
        G[FutureStorage] --> A
    end

    subgraph "å†…å­˜ç®¡ç†"
        H[å†…å­˜åˆ†é…] --> I[å†…å­˜æ± ]
        H --> J[å¼•ç”¨è®¡æ•°]
        H --> K[åƒåœ¾å›æ”¶]
    end

    style A fill:#e1f5fe
    style E fill:#e8f5e9
    style F fill:#ffeb3b
```

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### Storageæ¥å£
æ‰€æœ‰å­˜å‚¨å®ç°çš„åŸºç¡€æ¥å£ï¼š

```python
class Storage:
    """å¼ é‡æ•°æ®å­˜å‚¨çš„æŠ½è±¡æ¥å£ã€‚"""

    def __init__(self, shape, dtype, device):
        self.shape = shape
        self.dtype = dtype
        self.device = device
        self._data = None

    def to(self, device):
        """ä¼ è¾“å­˜å‚¨åˆ°å¦ä¸€ä¸ªè®¾å¤‡ã€‚"""
        raise NotImplementedError

    def copy_(self, other):
        """ä»å¦ä¸€ä¸ªå­˜å‚¨åŸåœ°å¤åˆ¶ã€‚"""
        raise NotImplementedError

    def clone(self):
        """åˆ›å»ºå­˜å‚¨çš„æ·±æ‹·è´ã€‚"""
        raise NotImplementedError

    @property
    def data_ptr(self):
        """è·å–åº•å±‚æ•°æ®æŒ‡é’ˆã€‚"""
        return self._data
```

### å­˜å‚¨åˆ›å»º
åˆ›å»ºé€‚åˆè®¾å¤‡çš„å­˜å‚¨ï¼š

```python
def create_storage(data, device, dtype=None):
    """ä¸ºç»™å®šè®¾å¤‡åˆ›å»ºå­˜å‚¨ã€‚"""
    if device.type == 'cpu':
        return CPUStorage(data, dtype)
    elif device.type == 'cuda':
        return CUDAStorage(data, dtype)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è®¾å¤‡ç±»å‹ï¼š{device.type}")

# ä½¿ç”¨
storage = create_storage([1, 2, 3], genesis.device("cuda"))
```

## ğŸ’» å­˜å‚¨å®ç°

### CPUå­˜å‚¨
CPUè®¾å¤‡çš„å­˜å‚¨å®ç°ï¼š

```python
class CPUStorage(Storage):
    """CPUå¼ é‡å­˜å‚¨ã€‚"""

    def __init__(self, data, dtype=None):
        # è½¬æ¢æ•°æ®ä¸ºPyTorchå¼ é‡
        if isinstance(data, torch.Tensor):
            self._data = data.cpu()
        else:
            self._data = torch.tensor(data, dtype=dtype)

        super().__init__(
            shape=self._data.shape,
            dtype=self._data.dtype,
            device=genesis.device("cpu")
        )

    def to(self, device):
        """ä¼ è¾“åˆ°å¦ä¸€ä¸ªè®¾å¤‡ã€‚"""
        if device.is_cpu:
            return self

        # ä¼ è¾“åˆ°GPU
        cuda_data = self._data.cuda(device.id)
        return CUDAStorage.from_tensor(cuda_data)

    def copy_(self, other):
        """ä»å¦ä¸€ä¸ªå­˜å‚¨å¤åˆ¶ã€‚"""
        if isinstance(other, CPUStorage):
            self._data.copy_(other._data)
        else:
            # ä»GPUå¤åˆ¶
            self._data.copy_(other.to_cpu()._data)
```

### CUDAå­˜å‚¨
GPUè®¾å¤‡çš„å­˜å‚¨å®ç°ï¼š

```python
class CUDAStorage(Storage):
    """CUDAå¼ é‡å­˜å‚¨ã€‚"""

    def __init__(self, data, dtype=None, device_id=0):
        self.device_id = device_id
        self._allocate_memory(data, dtype)

        super().__init__(
            shape=self._shape,
            dtype=self._dtype,
            device=genesis.device(f"cuda:{device_id}")
        )

    def _allocate_memory(self, data, dtype):
        """åˆ†é…CUDAå†…å­˜ã€‚"""
        # ä½¿ç”¨å†…å­˜æ± åˆ†é…
        size = self._compute_size(data, dtype)
        self._data_ptr = CUDAMemoryPool.allocate(size)

        # å¤åˆ¶æ•°æ®åˆ°GPU
        self._copy_to_gpu(data)

    def to(self, device):
        """ä¼ è¾“åˆ°å¦ä¸€ä¸ªè®¾å¤‡ã€‚"""
        if device.is_cuda and device.id == self.device_id:
            return self

        if device.is_cpu:
            # ä¼ è¾“åˆ°CPU
            cpu_data = self._copy_to_cpu()
            return CPUStorage(cpu_data)
        else:
            # ä¼ è¾“åˆ°å¦ä¸€ä¸ªGPU
            return self._transfer_to_gpu(device.id)
```

## ğŸš€ é«˜çº§ç‰¹æ€§

### å†…å­˜è§†å›¾
é«˜æ•ˆçš„å†…å­˜è§†å›¾æ— éœ€å¤åˆ¶ï¼š

```python
class StorageView(Storage):
    """åŸå§‹å­˜å‚¨çš„è§†å›¾ã€‚"""

    def __init__(self, base_storage, offset, shape, stride):
        self.base = base_storage
        self.offset = offset
        self.stride = stride

        super().__init__(
            shape=shape,
            dtype=base_storage.dtype,
            device=base_storage.device
        )

    @property
    def data_ptr(self):
        """è·å–å¸¦åç§»çš„æ•°æ®æŒ‡é’ˆã€‚"""
        return self.base.data_ptr + self.offset

    def is_contiguous(self):
        """æ£€æŸ¥è§†å›¾æ˜¯å¦è¿ç»­ã€‚"""
        expected_stride = self._compute_contiguous_stride(self.shape)
        return self.stride == expected_stride
```

### å…±äº«å†…å­˜
è¿›ç¨‹é—´å…±äº«çš„å­˜å‚¨ï¼š

```python
class SharedStorage(Storage):
    """è·¨è¿›ç¨‹å…±äº«å†…å­˜å­˜å‚¨ã€‚"""

    def __init__(self, shape, dtype, shared_memory_name=None):
        # åˆ›å»ºæˆ–è¿æ¥åˆ°å…±äº«å†…å­˜
        if shared_memory_name:
            self.shm = SharedMemory(name=shared_memory_name)
        else:
            size = self._compute_size(shape, dtype)
            self.shm = SharedMemory(create=True, size=size)

        super().__init__(shape, dtype, genesis.device("cpu"))

    def close(self):
        """å…³é—­å…±äº«å†…å­˜è¿æ¥ã€‚"""
        self.shm.close()

    def unlink(self):
        """ç§»é™¤å…±äº«å†…å­˜ã€‚"""
        self.shm.unlink()
```

### å†…å­˜æ˜ å°„å­˜å‚¨
å¤§å‹æ•°æ®é›†çš„å†…å­˜æ˜ å°„æ–‡ä»¶ï¼š

```python
class MappedStorage(Storage):
    """å†…å­˜æ˜ å°„æ–‡ä»¶å­˜å‚¨ã€‚"""

    def __init__(self, filename, shape, dtype, mode='r'):
        self.filename = filename
        self.mode = mode

        # åˆ›å»ºå†…å­˜æ˜ å°„
        self.mmap = np.memmap(
            filename,
            dtype=dtype,
            mode=mode,
            shape=shape
        )

        super().__init__(shape, dtype, genesis.device("cpu"))

    def flush(self):
        """å°†æ›´æ”¹åˆ·æ–°åˆ°ç£ç›˜ã€‚"""
        if self.mode != 'r':
            self.mmap.flush()

    def close(self):
        """å…³é—­å†…å­˜æ˜ å°„ã€‚"""
        del self.mmap
```

## ğŸ’¾ å†…å­˜ç®¡ç†

### å¼•ç”¨è®¡æ•°
è‡ªåŠ¨å†…å­˜ç®¡ç†é€šè¿‡å¼•ç”¨è®¡æ•°ï¼š

```python
class RefCountedStorage(Storage):
    """å¸¦å¼•ç”¨è®¡æ•°çš„å­˜å‚¨ã€‚"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.ref_count = 1

    def incref(self):
        """å¢åŠ å¼•ç”¨è®¡æ•°ã€‚"""
        self.ref_count += 1

    def decref(self):
        """å‡å°‘å¼•ç”¨è®¡æ•°å¹¶åœ¨éœ€è¦æ—¶é‡Šæ”¾ã€‚"""
        self.ref_count -= 1
        if self.ref_count == 0:
            self._deallocate()

    def _deallocate(self):
        """é‡Šæ”¾åº•å±‚å†…å­˜ã€‚"""
        if self.device.is_cuda:
            CUDAMemoryPool.deallocate(self.data_ptr)
        else:
            del self._data
```

### å†…å­˜æ± é›†æˆ
ä¸å†…å­˜æ± çš„é«˜æ•ˆé›†æˆï¼š

```python
class PooledStorage(Storage):
    """ä½¿ç”¨å†…å­˜æ± çš„å­˜å‚¨ã€‚"""

    def __init__(self, shape, dtype, device):
        super().__init__(shape, dtype, device)

        # ä»æ± ä¸­åˆ†é…
        size = self._compute_size()
        if device.is_cuda:
            self.pool = CUDAMemoryPool.get_instance()
        else:
            self.pool = CPUMemoryPool.get_instance()

        self._block = self.pool.allocate(size)

    def __del__(self):
        """è¿”å›å†…å­˜åˆ°æ± ã€‚"""
        if hasattr(self, '_block'):
            self.pool.deallocate(self._block)
```

## ğŸ”§ å­˜å‚¨æ“ä½œ

### æ•°æ®ç±»å‹è½¬æ¢
åœ¨å­˜å‚¨ä¹‹é—´è½¬æ¢æ•°æ®ç±»å‹ï¼š

```python
def convert_dtype(storage, target_dtype):
    """è½¬æ¢å­˜å‚¨åˆ°ä¸åŒçš„æ•°æ®ç±»å‹ã€‚"""
    if storage.dtype == target_dtype:
        return storage

    # åˆ›å»ºå…·æœ‰æ–°æ•°æ®ç±»å‹çš„æ–°å­˜å‚¨
    if storage.device.is_cuda:
        # GPUä¸Šè½¬æ¢
        converted_data = cuda_convert_dtype(
            storage.data_ptr,
            storage.dtype,
            target_dtype,
            storage.shape
        )
        return CUDAStorage.from_data(converted_data, target_dtype)
    else:
        # CPUä¸Šè½¬æ¢
        converted_data = storage._data.to(target_dtype)
        return CPUStorage(converted_data)
```

### å­˜å‚¨å¤åˆ¶
é«˜æ•ˆçš„å­˜å‚¨å¤åˆ¶æ“ä½œï¼š

```python
def copy_storage(src, dst):
    """é«˜æ•ˆå¤åˆ¶å­˜å‚¨ã€‚"""
    # åŒè®¾å¤‡å¤åˆ¶
    if src.device == dst.device:
        if src.device.is_cuda:
            cuda_copy(src.data_ptr, dst.data_ptr, src.size)
        else:
            dst._data.copy_(src._data)
    else:
        # è·¨è®¾å¤‡å¤åˆ¶
        if src.device.is_cuda and dst.device.is_cpu:
            # GPUåˆ°CPU
            cuda_to_cpu(src.data_ptr, dst._data.data_ptr(), src.size)
        elif src.device.is_cpu and dst.device.is_cuda:
            # CPUåˆ°GPU
            cpu_to_cuda(src._data.data_ptr(), dst.data_ptr, src.size)
        else:
            # GPUåˆ°GPU
            cuda_to_cuda(src.data_ptr, dst.data_ptr, src.size)
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### å†…å­˜å¯¹é½
ç¡®ä¿æœ€ä½³æ€§èƒ½çš„å†…å­˜å¯¹é½ï¼š

```python
def aligned_storage(shape, dtype, device, alignment=64):
    """åˆ›å»ºå¯¹é½çš„å­˜å‚¨ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚"""
    size = compute_size(shape, dtype)

    # å¯¹é½å¤§å°åˆ°è¾¹ç•Œ
    aligned_size = (size + alignment - 1) // alignment * alignment

    # åˆ†é…å¯¹é½çš„å†…å­˜
    if device.is_cuda:
        ptr = cuda_aligned_alloc(aligned_size, alignment)
        return CUDAStorage.from_ptr(ptr, shape, dtype)
    else:
        # ä¸ºCPUä½¿ç”¨å¯¹é½çš„åˆ†é…å™¨
        data = torch.empty(aligned_size // dtype.itemsize, dtype=dtype)
        return CPUStorage(data.view(shape))
```

### æ‰¹é‡æ“ä½œ
ä¼˜åŒ–çš„æ‰¹é‡å­˜å‚¨æ“ä½œï¼š

```python
class BatchStorage:
    """å¤šä¸ªå­˜å‚¨çš„æ‰¹é‡æ“ä½œã€‚"""

    def __init__(self, storages):
        self.storages = storages

    def batch_copy(self, targets):
        """æ‰¹é‡å¤åˆ¶åˆ°ç›®æ ‡å­˜å‚¨ã€‚"""
        if all(s.device.is_cuda for s in self.storages):
            # ä½¿ç”¨CUDAæµè¿›è¡Œå¹¶è¡Œå¤åˆ¶
            streams = [cuda.Stream() for _ in self.storages]

            for storage, target, stream in zip(self.storages, targets, streams):
                with cuda.stream(stream):
                    copy_storage(storage, target)

            # åŒæ­¥æ‰€æœ‰æµ
            for stream in streams:
                stream.synchronize()
        else:
            # é¡ºåºCPUå¤åˆ¶
            for storage, target in zip(self.storages, targets):
                copy_storage(storage, target)
```

## ğŸ” è°ƒè¯•å’Œç›‘æ§

### å­˜å‚¨æ£€æŸ¥
ç”¨äºè°ƒè¯•çš„å­˜å‚¨æ£€æŸ¥å·¥å…·ï¼š

```python
def inspect_storage(storage):
    """æ£€æŸ¥å­˜å‚¨å±æ€§ã€‚"""
    info = {
        'shape': storage.shape,
        'dtype': storage.dtype,
        'device': storage.device,
        'size_bytes': storage.size_bytes(),
        'is_contiguous': storage.is_contiguous(),
        'data_ptr': hex(storage.data_ptr) if storage.data_ptr else None,
    }

    if storage.device.is_cuda:
        info['memory_pool'] = storage.pool_info()

    return info

# ä½¿ç”¨
storage = create_storage([1, 2, 3], genesis.device("cuda"))
print(inspect_storage(storage))
```

### å†…å­˜æ³„æ¼æ£€æµ‹
æ£€æµ‹å­˜å‚¨å†…å­˜æ³„æ¼ï¼š

```python
class StorageTracker:
    """è·Ÿè¸ªå­˜å‚¨åˆ†é…å’Œé‡Šæ”¾ã€‚"""

    def __init__(self):
        self.active_storages = {}
        self.total_allocated = 0

    def register(self, storage):
        """æ³¨å†Œæ–°å­˜å‚¨ã€‚"""
        self.active_storages[id(storage)] = {
            'storage': weakref.ref(storage),
            'size': storage.size_bytes(),
            'timestamp': time.time()
        }
        self.total_allocated += storage.size_bytes()

    def unregister(self, storage):
        """æ³¨é”€å­˜å‚¨ã€‚"""
        storage_id = id(storage)
        if storage_id in self.active_storages:
            info = self.active_storages.pop(storage_id)
            self.total_allocated -= info['size']

    def check_leaks(self):
        """æ£€æŸ¥æ½œåœ¨çš„å†…å­˜æ³„æ¼ã€‚"""
        leaks = []
        for storage_id, info in self.active_storages.items():
            if info['storage']() is None:
                # å­˜å‚¨å·²è¢«åƒåœ¾å›æ”¶ä½†æœªæ³¨é”€
                leaks.append(info)
        return leaks
```

## ğŸ”— å‚è§

- [è®¾å¤‡æŠ½è±¡](device.md) - è®¾å¤‡ç®¡ç†ç³»ç»Ÿ
- [å†…å­˜ç®¡ç†](../backends/memory.md) - é«˜çº§å†…å­˜ç®¡ç†
- [åç«¯ç³»ç»Ÿ](../backends/index.md) - åç«¯å®ç°
- [å¼ é‡ç³»ç»Ÿ](tensor.md) - å¼ é‡ç±»å’Œå­˜å‚¨é›†æˆ