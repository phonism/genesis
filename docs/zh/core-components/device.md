# è®¾å¤‡æŠ½è±¡

Genesisæä¾›äº†ç»Ÿä¸€çš„è®¾å¤‡æŠ½è±¡ï¼Œå…è®¸åœ¨ä¸åŒç¡¬ä»¶åç«¯é—´æ— ç¼æ“ä½œï¼ŒåŒæ—¶ä¿æŒæœ€ä½³æ€§èƒ½ã€‚

## ğŸ“‹ æ¦‚è¿°

Genesis v2.0çš„è®¾å¤‡ç³»ç»Ÿæä¾›ï¼š
- è·¨CPUå’ŒGPUçš„ç»Ÿä¸€è®¾å¤‡æ¥å£
- è‡ªåŠ¨è®¾å¤‡æ¨æ–­å’Œç®¡ç†
- é€æ˜çš„å†…å­˜ç®¡ç†
- æ¯ç§è®¾å¤‡ç±»å‹çš„æœ€ä½³æ€§èƒ½

## ğŸ—ï¸ æ¶æ„

```mermaid
graph TB
    subgraph "è®¾å¤‡API"
        A[genesis.device] --> B[Deviceç±»]
        C[genesis.cuda] --> D[CUDAè®¾å¤‡]
        E[genesis.cpu] --> F[CPUè®¾å¤‡]
    end

    subgraph "è®¾å¤‡ç®¡ç†"
        B --> G[è®¾å¤‡å±æ€§]
        B --> H[å†…å­˜ç®¡ç†]
        B --> I[ä¸Šä¸‹æ–‡åˆ‡æ¢]
    end

    subgraph "åç«¯é›†æˆ"
        D --> J[backends/cuda.py]
        F --> K[backends/cpu.py]
        J --> L[CUDAå†…å­˜æ± ]
        K --> M[CPUå†…å­˜]
    end

    style B fill:#e1f5fe
    style G fill:#f3e5f5
    style H fill:#e8f5e8
```

## ğŸ¯ æ ¸å¿ƒç»„ä»¶

### Deviceç±»
ä¸­å¤®Deviceç±»æä¾›ç»Ÿä¸€æ¥å£ï¼š

```python
class Device:
    """ç»Ÿä¸€è®¾å¤‡æŠ½è±¡ã€‚"""

    def __init__(self, device_type, device_id=None):
        self.type = device_type  # 'cpu' æˆ– 'cuda'
        self.id = device_id or 0
        self._properties = None

    @property
    def is_cuda(self):
        """æ£€æŸ¥è®¾å¤‡æ˜¯å¦ä¸ºCUDAã€‚"""
        return self.type == 'cuda'

    @property
    def is_cpu(self):
        """æ£€æŸ¥è®¾å¤‡æ˜¯å¦ä¸ºCPUã€‚"""
        return self.type == 'cpu'

    def __str__(self):
        if self.type == 'cuda':
            return f"cuda:{self.id}"
        return self.type
```

### è®¾å¤‡åˆ›å»º
åˆ›å»ºè®¾å¤‡å¯¹è±¡çš„å¤šç§æ–¹å¼ï¼š

```python
# å­—ç¬¦ä¸²è§„èŒƒ
device = genesis.device("cuda:0")
device = genesis.device("cpu")

# ä»ç°æœ‰å¼ é‡
device = tensor.device

# é»˜è®¤è®¾å¤‡
device = genesis.get_default_device()

# è‡ªåŠ¨è®¾å¤‡é€‰æ‹©
device = genesis.device("auto")  # å¦‚æœå¯ç”¨é€‰æ‹©CUDAï¼Œå¦åˆ™CPU
```

## ğŸ’» è®¾å¤‡æ“ä½œ

### è®¾å¤‡ä¸Šä¸‹æ–‡ç®¡ç†
```python
# ä¸´æ—¶è®¾å¤‡ä¸Šä¸‹æ–‡
with genesis.device("cuda:1"):
    x = genesis.randn(3, 4)  # åœ¨cuda:1ä¸Šåˆ›å»º
    y = genesis.zeros(3, 4)  # ä¹Ÿåœ¨cuda:1ä¸Š

# è®¾å¤‡ç‰¹å®šæ“ä½œ
device = genesis.device("cuda:0")
with device:
    # æ‰€æœ‰æ“ä½œä½¿ç”¨æ­¤è®¾å¤‡
    model = MyModel()
    optimizer = genesis.optim.Adam(model.parameters())
```

### è·¨è®¾å¤‡æ“ä½œ
```python
# è‡ªåŠ¨è®¾å¤‡å¤„ç†
cpu_tensor = genesis.tensor([1, 2, 3], device="cpu")
gpu_tensor = genesis.tensor([4, 5, 6], device="cuda")

# è‡ªåŠ¨è®¾å¤‡æå‡ï¼ˆç§»åŠ¨åˆ°GPUï¼‰
result = cpu_tensor + gpu_tensor  # ç»“æœåœ¨cudaè®¾å¤‡ä¸Š

# æ˜¾å¼è®¾å¤‡ä¼ è¾“
gpu_result = cpu_tensor.to("cuda")
cpu_result = gpu_tensor.to("cpu")
```

### è®¾å¤‡å±æ€§
```python
device = genesis.device("cuda:0")

# åŸºæœ¬å±æ€§
print(f"è®¾å¤‡ç±»å‹ï¼š{device.type}")
print(f"è®¾å¤‡IDï¼š{device.id}")
print(f"æ˜¯å¦CUDAï¼š{device.is_cuda}")

# CUDAç‰¹å®šå±æ€§
if device.is_cuda:
    print(f"è®¾å¤‡åç§°ï¼š{device.name}")
    print(f"è®¡ç®—èƒ½åŠ›ï¼š{device.compute_capability}")
    print(f"æ€»å†…å­˜ï¼š{device.total_memory}")
    print(f"å¤šå¤„ç†å™¨æ•°é‡ï¼š{device.multi_processor_count}")
```

## ğŸš€ CUDAè®¾å¤‡ç‰¹æ€§

### å¤šGPUæ”¯æŒ
```python
# æ£€æŸ¥å¯ç”¨GPU
num_gpus = genesis.cuda.device_count()
print(f"å¯ç”¨GPUï¼š{num_gpus}")

# ä½¿ç”¨ç‰¹å®šGPU
device = genesis.device("cuda:1")
tensor = genesis.randn(1000, 1000, device=device)

# å¤šGPUè®¡ç®—
devices = [genesis.device(f"cuda:{i}") for i in range(num_gpus)]
tensors = [genesis.randn(100, 100, device=dev) for dev in devices]
```

### CUDAå†…å­˜ç®¡ç†
```python
device = genesis.device("cuda:0")

# å†…å­˜ä¿¡æ¯
print(f"ç©ºé—²å†…å­˜ï¼š{device.memory_free()}")
print(f"å·²ç”¨å†…å­˜ï¼š{device.memory_used()}")
print(f"æ€»å†…å­˜ï¼š{device.memory_total()}")

# å†…å­˜æ“ä½œ
genesis.cuda.empty_cache()  # æ¸…é™¤æœªä½¿ç”¨çš„ç¼“å­˜
genesis.cuda.synchronize()  # ç­‰å¾…æ“ä½œå®Œæˆ

# å†…å­˜ç»Ÿè®¡
stats = genesis.cuda.memory_stats()
print(f"å³°å€¼åˆ†é…ï¼š{stats['peak_allocated']}")
```

### CUDAæµå’Œäº‹ä»¶
```python
# CUDAæµç®¡ç†
stream = genesis.cuda.Stream()

with genesis.cuda.stream(stream):
    x = genesis.randn(1000, 1000, device="cuda")
    y = genesis.matmul(x, x)

# åŒæ­¥
stream.synchronize()

# CUDAäº‹ä»¶ç”¨äºè®¡æ—¶
start_event = genesis.cuda.Event(enable_timing=True)
end_event = genesis.cuda.Event(enable_timing=True)

start_event.record()
# ... æ“ä½œ ...
end_event.record()
genesis.cuda.synchronize()

elapsed_time = start_event.elapsed_time(end_event)
print(f"è€—æ—¶ï¼š{elapsed_time:.2f} ms")
```

## ğŸ’¾ CPUè®¾å¤‡ç‰¹æ€§

### CPUé…ç½®
```python
# CPUç‰¹å®šè®¾ç½®
genesis.cpu.set_num_threads(8)
print(f"CPUçº¿ç¨‹ï¼š{genesis.cpu.get_num_threads()}")

# å¯ç”¨/ç¦ç”¨ä¼˜åŒ–
genesis.cpu.set_optimization_level('O2')
genesis.cpu.enable_mkl(True)
```

### å†…å­˜ç®¡ç†
```python
# CPUå†…å­˜æ“ä½œ
device = genesis.device("cpu")

# é’‰ä½å†…å­˜ä»¥åŠ å¿«GPUä¼ è¾“
tensor = genesis.empty((1000, 1000), device=device, pin_memory=True)
print(f"æ˜¯å¦é’‰ä½ï¼š{tensor.is_pinned()}")

# å†…å­˜æ˜ å°„ç”¨äºå¤§å‹æ•°æ®é›†
mapped_tensor = genesis.from_file("large_dataset.dat", device="cpu", mmap=True)
```

## ğŸ”§ è®¾å¤‡é…ç½®

### é»˜è®¤è®¾å¤‡ç®¡ç†
```python
# è®¾ç½®å…¨å±€é»˜è®¤è®¾å¤‡
genesis.set_default_device("cuda:0")

# è·å–å½“å‰é»˜è®¤å€¼
device = genesis.get_default_device()
print(f"é»˜è®¤è®¾å¤‡ï¼š{device}")

# ç‰¹å®šä¸Šä¸‹æ–‡çš„é»˜è®¤å€¼
with genesis.default_device("cpu"):
    x = genesis.randn(3, 4)  # åœ¨CPUä¸Šåˆ›å»º
    print(f"è®¾å¤‡ï¼š{x.device}")  # cpu

# é‡ç½®ä¸ºç³»ç»Ÿé»˜è®¤å€¼
genesis.reset_default_device()
```

### ç¯å¢ƒå˜é‡
```python
import os

# é€šè¿‡ç¯å¢ƒè®¾ç½®è®¾å¤‡
os.environ['GENESIS_DEFAULT_DEVICE'] = 'cuda:1'
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'

# è®¾å¤‡é€‰æ‹©ä¼˜å…ˆçº§ï¼š
# 1. æ˜¾å¼è®¾å¤‡å‚æ•°
# 2. å½“å‰è®¾å¤‡ä¸Šä¸‹æ–‡
# 3. ç¯å¢ƒå˜é‡
# 4. ç³»ç»Ÿé»˜è®¤å€¼
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### è®¾å¤‡ç‰¹å®šä¼˜åŒ–
```python
def optimize_for_device(tensor):
    """åº”ç”¨è®¾å¤‡ç‰¹å®šä¼˜åŒ–ã€‚"""
    if tensor.device.is_cuda:
        # CUDAä¼˜åŒ–
        tensor = tensor.contiguous()  # ç¡®ä¿å†…å­˜å¸ƒå±€
        if tensor.numel() > 10000:
            tensor = tensor.half()    # å¤§å¼ é‡ä½¿ç”¨åŠç²¾åº¦
    else:
        # CPUä¼˜åŒ–
        tensor = tensor.float()       # CPUä½¿ç”¨float32

    return tensor

# ä½¿ç”¨
optimized_tensor = optimize_for_device(my_tensor)
```

### å†…å­˜ä¼ è¾“ä¼˜åŒ–
```python
def efficient_transfer(tensor, target_device):
    """é«˜æ•ˆä¼ è¾“å¼ é‡åˆ°ç›®æ ‡è®¾å¤‡ã€‚"""
    if tensor.device == target_device:
        return tensor  # æ— éœ€ä¼ è¾“

    # CPU->GPUä¼ è¾“ä½¿ç”¨é’‰ä½å†…å­˜
    if tensor.device.is_cpu and target_device.is_cuda:
        if not tensor.is_pinned():
            tensor = tensor.pin_memory()

    # ä½¿ç”¨æµè¿›è¡Œå¼‚æ­¥ä¼ è¾“
    if target_device.is_cuda:
        with genesis.cuda.stream(genesis.cuda.Stream()):
            return tensor.to(target_device, non_blocking=True)

    return tensor.to(target_device)
```

## ğŸ” è®¾å¤‡æ£€æµ‹å’Œèƒ½åŠ›

### ç¡¬ä»¶æ£€æµ‹
```python
def detect_hardware():
    """æ£€æµ‹å¯ç”¨ç¡¬ä»¶å’Œèƒ½åŠ›ã€‚"""
    info = {
        'cpu_count': genesis.cpu.logical_cpu_count(),
        'cpu_features': genesis.cpu.supported_features(),
        'cuda_available': genesis.cuda.is_available(),
        'cuda_version': genesis.cuda.version() if genesis.cuda.is_available() else None,
        'gpu_count': genesis.cuda.device_count() if genesis.cuda.is_available() else 0,
    }

    if info['cuda_available']:
        info['gpus'] = []
        for i in range(info['gpu_count']):
            gpu_info = genesis.cuda.get_device_properties(i)
            info['gpus'].append({
                'name': gpu_info.name,
                'memory': gpu_info.total_memory,
                'compute_capability': gpu_info.compute_capability,
            })

    return info

# ä½¿ç”¨
hw_info = detect_hardware()
print(f"ç¡¬ä»¶ä¿¡æ¯ï¼š{hw_info}")
```

### åŸºäºèƒ½åŠ›çš„é€‰æ‹©
```python
def select_optimal_device(min_memory_gb=1.0, compute_capability=None):
    """æ ¹æ®éœ€æ±‚é€‰æ‹©æœ€ä½³è®¾å¤‡ã€‚"""
    if not genesis.cuda.is_available():
        return genesis.device("cpu")

    for i in range(genesis.cuda.device_count()):
        device = genesis.device(f"cuda:{i}")
        props = genesis.cuda.get_device_properties(i)

        # æ£€æŸ¥å†…å­˜éœ€æ±‚
        if props.total_memory < min_memory_gb * 1e9:
            continue

        # æ£€æŸ¥è®¡ç®—èƒ½åŠ›
        if compute_capability and props.compute_capability < compute_capability:
            continue

        return device

    # å¦‚æœæ²¡æœ‰åˆé€‚çš„GPUåˆ™å›é€€åˆ°CPU
    return genesis.device("cpu")

# ä½¿ç”¨
device = select_optimal_device(min_memory_gb=4.0, compute_capability=7.0)
print(f"é€‰æ‹©çš„è®¾å¤‡ï¼š{device}")
```

## ğŸ”— å‚è§

- [åç«¯ç³»ç»Ÿ](../backends/index.md) - åç«¯å®ç°ç»†èŠ‚
- [å†…å­˜ç®¡ç†](../backends/memory.md) - é«˜çº§å†…å­˜ç®¡ç†
- [æ€§èƒ½æŒ‡å—](../performance/optimization-guide.md) - æ€§èƒ½ä¼˜åŒ–
- [CUDAåç«¯](../backends/cuda.md) - CUDAç‰¹å®šåŠŸèƒ½