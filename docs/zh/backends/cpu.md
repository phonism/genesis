# CPUåç«¯

CPUåç«¯é€šè¿‡åˆ©ç”¨PyTorchä¼˜åŒ–çš„CPUå†…æ ¸æä¾›é«˜æ•ˆçš„åŸºäºCPUçš„å¼ é‡æ“ä½œã€‚

## ğŸ“‹ æ¦‚è¿°

CPUåç«¯ï¼ˆ`backends/cpu.py`ï¼‰ç”¨ä½œï¼š
- CPUæ“ä½œçš„é»˜è®¤åç«¯
- æ–°åç«¯çš„å‚è€ƒå®ç°
- GPUä¸å¯ç”¨æ—¶çš„å¤‡é€‰æ–¹æ¡ˆ

## ğŸ—ï¸ æ¶æ„

```python
# backends/cpu.py ç»“æ„
class CPUStorage:
    """CPUå¼ é‡å­˜å‚¨å®ç°ã€‚"""

    def __init__(self, data):
        """ä½¿ç”¨PyTorchå¼ é‡åˆå§‹åŒ–ã€‚"""
        self.data = data  # PyTorchå¼ é‡

    def to(self, device):
        """ä¼ è¾“åˆ°å¦ä¸€ä¸ªè®¾å¤‡ã€‚"""
        ...

    def copy_(self, other):
        """ä»å¦ä¸€ä¸ªå­˜å‚¨åŸåœ°å¤åˆ¶ã€‚"""
        ...
```

## ğŸ¯ å…³é”®ç‰¹æ€§

### PyTorché›†æˆ
- åˆ©ç”¨PyTorchæˆç†Ÿçš„CPUå®ç°
- å—ç›ŠäºPyTorchä¼˜åŒ–ï¼ˆMKLã€OpenMPï¼‰
- ä¸PyTorchå¼ é‡äº’æ“ä½œå…¼å®¹

### æ“ä½œæ”¯æŒ
CPUåç«¯æ”¯æŒæ‰€æœ‰åŸºç¡€æ“ä½œï¼š

| ç±»åˆ« | æ“ä½œ |
|------|------|
| **ç®—æœ¯** | add, subtract, multiply, divide, power |
| **è§„çº¦** | sum, mean, max, min, argmax, argmin |
| **çŸ©é˜µ** | matmul, transpose, reshape, flatten |
| **æ¿€æ´»** | relu, sigmoid, tanh, softmax |
| **æ¯”è¾ƒ** | eq, ne, lt, le, gt, ge |

### å†…å­˜ç®¡ç†
- æ— éœ€æ± åŒ–çš„ç›´æ¥å†…å­˜è®¿é—®ï¼ˆç”±PyTorchå¤„ç†ï¼‰
- ä¸ºç¼“å­˜ä¼˜åŒ–è€Œè®¾è®¡çš„é«˜æ•ˆå†…å­˜å¸ƒå±€
- æ”¯æŒå„ç§æ•°æ®ç±»å‹ï¼ˆfloat32ã€float64ã€int32ç­‰ï¼‰

## ğŸ’» å®ç°ç»†èŠ‚

### å­˜å‚¨åˆ›å»º
```python
def create_cpu_storage(data, dtype=None):
    """ä»å„ç§è¾“å…¥ç±»å‹åˆ›å»ºCPUå­˜å‚¨ã€‚"""
    if isinstance(data, torch.Tensor):
        tensor = data.cpu()
    elif isinstance(data, np.ndarray):
        tensor = torch.from_numpy(data)
    else:
        tensor = torch.tensor(data)

    if dtype:
        tensor = tensor.to(dtype)

    return CPUStorage(tensor)
```

### æ“ä½œåˆ†å‘
æ“ä½œé€šè¿‡ç»Ÿä¸€çš„æ“ä½œç³»ç»Ÿåˆ†å‘ï¼š
```python
# ops/cpu/basic.py
def cpu_add(a, b):
    """åŠ æ³•çš„CPUå®ç°ã€‚"""
    return a.data + b.data

def cpu_matmul(a, b):
    """çŸ©é˜µä¹˜æ³•çš„CPUå®ç°ã€‚"""
    return torch.matmul(a.data, b.data)
```

## ğŸš€ æ€§èƒ½è€ƒè™‘

### ä¼˜åŒ–ç­–ç•¥
1. **å‘é‡åŒ–**ï¼šé€šè¿‡PyTorchåˆ©ç”¨SIMDæŒ‡ä»¤
2. **å¹¶è¡ŒåŒ–**ï¼šé€šè¿‡OpenMPåˆ©ç”¨å¤šä¸ªCPUæ ¸å¿ƒ
3. **ç¼“å­˜æ•ˆç‡**ï¼šä¼˜åŒ–å†…å­˜è®¿é—®æ¨¡å¼

### æ€§èƒ½æŠ€å·§
- ä½¿ç”¨è¿ç»­å†…å­˜å¸ƒå±€è·å¾—æ›´å¥½çš„ç¼“å­˜åˆ©ç”¨ç‡
- æ‰¹é‡æ“ä½œä»¥å‡å°‘å¼€é”€
- è€ƒè™‘å†…å­˜é’‰ä½ä»¥ä¾¿CPU-GPUä¼ è¾“

## ğŸ”§ é…ç½®

### ç¯å¢ƒå˜é‡
```bash
# æ§åˆ¶CPUçº¿ç¨‹æ•°
export OMP_NUM_THREADS=8

# å¯ç”¨MKLä¼˜åŒ–
export MKL_NUM_THREADS=8
```

### è¿è¡Œæ—¶é…ç½®
```python
import genesis

# å°†CPUåç«¯è®¾ä¸ºé»˜è®¤
genesis.set_default_device("cpu")

# åˆ›å»ºCPUå¼ é‡
x = genesis.tensor([1, 2, 3])  # ä½¿ç”¨CPUåç«¯
```

## ğŸ“Š åŸºå‡†æµ‹è¯•

ä¸çº¯PyTorchçš„ç›¸å¯¹æ€§èƒ½ï¼š

| æ“ä½œ | å¤§å° | Genesis CPU | PyTorch | æ¯”ç‡ |
|------|------|-------------|---------|-------|
| åŠ æ³• | 1M | 1.05x | 1.0x | 1.05 |
| çŸ©ä¹˜ | 1024x1024 | 0.98x | 1.0x | 0.98 |
| Softmax | 10K | 1.02x | 1.0x | 1.02 |

*æ³¨æ„ï¼šç”±äºPyTorchåç«¯ï¼Œæ€§èƒ½å‡ ä¹ç›¸åŒ*

## ğŸ” è°ƒè¯•

ä¸ºCPUæ“ä½œå¯ç”¨è°ƒè¯•æ¨¡å¼ï¼š
```python
import genesis
genesis.backends.cpu.debug_mode = True

# ç°åœ¨æ“ä½œä¼šæ‰“å°è°ƒè¯•ä¿¡æ¯
x = genesis.tensor([1, 2, 3], device="cpu")
y = x + 1  # æ‰“å°ï¼š"CPU Add: shape=(3,), dtype=float32"
```

## ğŸ”— å‚è§

- [åç«¯ç³»ç»Ÿæ¦‚è¿°](index.md)
- [CUDAåç«¯](cuda.md)
- [æ“ä½œåˆ†å‘](../ops/dispatcher.md)