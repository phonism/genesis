# å¿«é€Ÿå¼€å§‹

æ¬¢è¿ä½¿ç”¨ Genesis æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨åœ¨å‡ åˆ†é’Ÿå†…å¼€å§‹ä½¿ç”¨ Genesisã€‚

## ğŸ¯ æ¦‚è¿°

Genesis æ˜¯ä¸€ä¸ªä¸“ä¸ºå­¦ä¹ å’Œç ”ç©¶è®¾è®¡çš„è½»é‡çº§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå®ƒæä¾›äº†ï¼š

- ç®€æ´ç›´è§‚çš„APIè®¾è®¡
- é«˜æ€§èƒ½GPUåŠ é€Ÿè®¡ç®—
- å®Œæ•´çš„ç¥ç»ç½‘ç»œè®­ç»ƒåŠŸèƒ½
- ä¸PyTorchç”Ÿæ€è‰¯å¥½çš„å…¼å®¹æ€§
- æ··åˆç²¾åº¦è®­ç»ƒæ”¯æŒï¼ˆFP16/BF16ï¼‰
- å†…ç½®LLMæ¨¡å‹å¦‚Qwen

## âš¡ 5åˆ†é’Ÿå¿«é€Ÿä½“éªŒ

### 1. å®‰è£… Genesis

```bash
# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install torch triton numpy cuda-python

# å…‹éš†ä»£ç ä»“åº“
git clone https://github.com/phonism/genesis.git
cd genesis

# å®‰è£… Genesis
pip install -e .
```

### 2. ç¬¬ä¸€ä¸ªç¥ç»ç½‘ç»œ

```python
import genesis
import genesis.nn as nn

# å®šä¹‰ä¸€ä¸ªç®€å•çš„å¤šå±‚æ„ŸçŸ¥æœº
class MLP(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        self.layer1 = nn.Linear(input_dim, hidden_dim)
        self.layer2 = nn.Linear(hidden_dim, output_dim)
        self.relu = nn.ReLU()
    
    def forward(self, x):
        x = self.relu(self.layer1(x))
        return self.layer2(x)

# åˆ›å»ºæ¨¡å‹å’Œæ•°æ®
model = MLP(784, 128, 10)
x = genesis.randn(32, 784)  # æ‰¹æ¬¡å¤§å°32ï¼Œè¾“å…¥ç»´åº¦784

# å‰å‘ä¼ æ’­
output = model(x)
print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")  # torch.Size([32, 10])
```

### 3. è®­ç»ƒå¾ªç¯

```python
import genesis.optim as optim

# åˆ›å»ºä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

# æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
targets = genesis.randint(0, 10, (32,))

# è®­ç»ƒä¸€ä¸ªæ‰¹æ¬¡
optimizer.zero_grad()        # æ¸…é›¶æ¢¯åº¦
output = model(x)           # å‰å‘ä¼ æ’­
loss = criterion(output, targets)  # è®¡ç®—æŸå¤±
loss.backward()             # åå‘ä¼ æ’­
optimizer.step()            # æ›´æ–°å‚æ•°

print(f"æŸå¤±: {loss.item():.4f}")
```

## ğŸ“š æ ¸å¿ƒæ¦‚å¿µ

### å¼ é‡ (Tensor)
Genesisä¸­çš„åŸºç¡€æ•°æ®ç»“æ„ï¼Œæ”¯æŒè‡ªåŠ¨å¾®åˆ†ï¼š

```python
import genesis

# åˆ›å»ºå¼ é‡ï¼ˆè‡ªåŠ¨æ•°æ®ç±»å‹æ¨æ–­ï¼‰
x = genesis.tensor([1.0, 2.0, 3.0], requires_grad=True)  # â†’ float32
y = genesis.tensor([4, 5, 6])                           # â†’ int64
z = genesis.tensor([1, 2, 3], dtype=genesis.float32)     # æ˜¾å¼æ•°æ®ç±»å‹

# åŸºç¡€æ“ä½œ
result = x * y.float() + x.sum()  # å¹¿æ’­å’Œç±»å‹è½¬æ¢

# PyTorché£æ ¼çš„å½’çº¦æ“ä½œ
total = x.sum()                      # æ‰€æœ‰å…ƒç´ æ±‚å’Œ
mean_val = x.mean()                  # æ‰€æœ‰å…ƒç´ å¹³å‡å€¼
max_val = x.max()                    # æœ€å¤§å…ƒç´ 

# æŒ‰ç»´åº¦æ“ä½œ
data = genesis.tensor([[1, 2, 3], [4, 5, 6]])
row_sums = data.sum(dim=1)                    # æŒ‰è¡Œæ±‚å’Œ
col_means = data.mean(dim=0, keepdim=True)   # æŒ‰åˆ—æ±‚å¹³å‡å€¼ï¼Œä¿æŒç»´åº¦

# ä¹Ÿæ”¯æŒNumPyé£æ ¼ï¼ˆå…¼å®¹æ€§ï¼‰
numpy_style = data.sum(axis=0, keepdims=True)

# è®¡ç®—æ¢¯åº¦
result.backward()
print(f"xçš„æ¢¯åº¦: {x.grad}")  # å…³äºxçš„æ¢¯åº¦
```

### æ¨¡å— (Module)
ç¥ç»ç½‘ç»œç»„ä»¶çš„åŸºç±»ï¼š

```python
import genesis.nn as nn

class CustomLayer(nn.Module):
    def __init__(self, in_features, out_features):
        super().__init__()
        self.weight = genesis.randn(out_features, in_features, requires_grad=True)
        self.bias = genesis.zeros(out_features, requires_grad=True)
    
    def forward(self, x):
        return genesis.functional.linear(x, self.weight, self.bias)

# ä½¿ç”¨è‡ªå®šä¹‰å±‚
layer = CustomLayer(10, 5)
input_tensor = genesis.randn(3, 10)
output = layer(input_tensor)
```

### ä¼˜åŒ–å™¨ (Optimizer)
å‚æ•°æ›´æ–°ç®—æ³•ï¼š

```python
import genesis.optim as optim

# ä¸åŒçš„ä¼˜åŒ–å™¨é€‰æ‹©
sgd_optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
adam_optimizer = optim.Adam(model.parameters(), lr=0.001)
adamw_optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
```

## ğŸ› ï¸ ç¯å¢ƒé…ç½®

### ç¡¬ä»¶è¦æ±‚

- **CPU**: ç°ä»£å¤šæ ¸å¤„ç†å™¨
- **å†…å­˜**: æœ€å°‘8GB RAMï¼Œæ¨è16GB+
- **GPU**: NVIDIA GPU with CUDAæ”¯æŒ (æ¨è)
- **å­˜å‚¨**: è‡³å°‘2GBå¯ç”¨ç©ºé—´

### è½¯ä»¶ä¾èµ–

```bash
# Pythonç¯å¢ƒ
Python >= 3.8

# æ ¸å¿ƒä¾èµ–
torch >= 2.0.0
triton >= 2.0.0
numpy >= 1.21.0
cuda-python >= 11.8.0  # GPUæ”¯æŒ

# å¯é€‰ä¾èµ–
matplotlib >= 3.5.0  # ç”¨äºå¯è§†åŒ–
tqdm >= 4.64.0      # è¿›åº¦æ¡
wandb >= 0.13.0     # å®éªŒè·Ÿè¸ª
```

## ğŸ“– ä¸‹ä¸€æ­¥

ç°åœ¨ä½ å·²ç»äº†è§£äº†Genesisçš„åŸºç¡€ç”¨æ³•ï¼Œå¯ä»¥ç»§ç»­æ¢ç´¢ï¼š

### ğŸ“ æ·±å…¥å­¦ä¹ 
- [**å®Œæ•´å®‰è£…æŒ‡å—**](installation.md) - è¯¦ç»†çš„å®‰è£…å’Œé…ç½®æ­¥éª¤
- [**ç¬¬ä¸€ä¸ªå®Œæ•´ç¨‹åº**](first-steps.md) - æ„å»ºå®Œæ•´çš„è®­ç»ƒæµç¨‹
- [**åŸºç¡€è®­ç»ƒæ•™ç¨‹**](../tutorials/basic-training.md) - ç³»ç»Ÿæ€§çš„è®­ç»ƒæ•™ç¨‹

### ğŸ” æ¶æ„ç†è§£
- [**æ¶æ„æ¦‚è¿°**](../architecture/index.md) - äº†è§£Genesisçš„æ•´ä½“è®¾è®¡
- [**æ ¸å¿ƒç»„ä»¶**](../core-components/index.md) - æ·±å…¥ç†è§£å†…éƒ¨å®ç°
- [**APIå‚è€ƒ**](../api-reference/index.md) - å®Œæ•´çš„APIæ–‡æ¡£

### ğŸš€ é«˜çº§ç‰¹æ€§
- [**è‡ªå®šä¹‰ç®—å­**](../tutorials/custom-ops.md) - å®ç°è‡ªå®šä¹‰æ“ä½œ
- [**æ€§èƒ½ä¼˜åŒ–**](../tutorials/performance-tuning.md) - è®­ç»ƒæ€§èƒ½è°ƒä¼˜
- [**åˆ†å¸ƒå¼è®­ç»ƒ**](../neural-networks/distributed.md) - å¤šGPUè®­ç»ƒ

## â“ å¸¸è§é—®é¢˜

### Q: Genesisä¸PyTorchæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ
A: Genesisæ˜¯æ•™è‚²å¯¼å‘çš„æ¡†æ¶ï¼Œä»£ç æ›´ç®€æ´æ˜“æ‡‚ï¼Œé€‚åˆå­¦ä¹ æ·±åº¦å­¦ä¹ çš„å†…éƒ¨å®ç°ã€‚PyTorchæ›´é€‚åˆç”Ÿäº§ç¯å¢ƒä½¿ç”¨ã€‚

### Q: å¯ä»¥åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨Genesiså—ï¼Ÿ
A: Genesisä¸»è¦ç”¨äºæ•™è‚²å’Œç ”ç©¶ï¼Œè™½ç„¶åŠŸèƒ½å®Œæ•´ï¼Œä½†å»ºè®®ç”Ÿäº§ç¯å¢ƒä½¿ç”¨æ›´æˆç†Ÿçš„æ¡†æ¶å¦‚PyTorchã€‚

### Q: å¦‚ä½•è·å¾—å¸®åŠ©ï¼Ÿ
A: å¯ä»¥é€šè¿‡GitHub Issuesã€Discussionsæˆ–æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£è·å¾—å¸®åŠ©ã€‚

---

## ğŸ‰ å‡†å¤‡å¥½äº†å—ï¼Ÿ

è®©æˆ‘ä»¬å¼€å§‹æ·±å…¥äº†è§£Genesiså§ï¼

[è¯¦ç»†å®‰è£…æŒ‡å—](installation.md){ .md-button .md-button--primary }
[å®Œæ•´æ•™ç¨‹](../tutorials/index.md){ .md-button }