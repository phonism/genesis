# Your First Complete Program

After completing the installation, let's learn Genesis basics through a complete example. We will implement an image classifier to demonstrate the complete deep learning workflow.

## ğŸ¯ Project Goals

Build a handwritten digit recognizer (MNIST-like) to learn Genesis core concepts:

- Data loading and preprocessing
- Model definition and initialization
- Training loop and validation
- Model saving and loading

## ğŸ“Š Project Structure

Create the project directory structure:

```
first_project/
â”œâ”€â”€ data/                # Data directory
â”œâ”€â”€ models/              # Model save directory
â”œâ”€â”€ train.py            # Training script
â”œâ”€â”€ model.py            # Model definition
â”œâ”€â”€ dataset.py          # Data loading
â””â”€â”€ utils.py            # Utility functions
```

## ğŸ“ 1. Data Processing (`dataset.py`)

```python
"""æ•°æ®åŠ è½½å’Œé¢„å¤„ç†æ¨¡å—"""
import genesis
import numpy as np
from typing import Tuple, List
import pickle
import os

class SimpleDataset:
    """ç®€å•çš„æ•°æ®é›†ç±»"""
    
    def __init__(self, data: np.ndarray, labels: np.ndarray, transform=None):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        Args:
            data: è¾“å…¥æ•°æ® (N, H, W) æˆ– (N, D)
            labels: æ ‡ç­¾ (N,)
            transform: æ•°æ®å˜æ¢å‡½æ•°
        """
        self.data = data.astype(np.float32)
        self.labels = labels.astype(np.int64)
        self.transform = transform
    
    def __len__(self) -> int:
        return len(self.data)
    
    def __getitem__(self, idx: int) -> Tuple[genesis.Tensor, genesis.Tensor]:
        """è·å–å•ä¸ªæ ·æœ¬"""
        x = self.data[idx]
        y = self.labels[idx]
        
        if self.transform:
            x = self.transform(x)
        
        return genesis.tensor(x), genesis.tensor(y)

class DataLoader:
    """ç®€å•çš„æ•°æ®åŠ è½½å™¨"""
    
    def __init__(self, dataset: SimpleDataset, batch_size: int = 32, shuffle: bool = True):
        self.dataset = dataset
        self.batch_size = batch_size
        self.shuffle = shuffle
        self._reset_indices()
    
    def _reset_indices(self):
        """é‡ç½®ç´¢å¼•"""
        self.indices = np.arange(len(self.dataset))
        if self.shuffle:
            np.random.shuffle(self.indices)
        self.current = 0
    
    def __iter__(self):
        self._reset_indices()
        return self
    
    def __next__(self):
        if self.current >= len(self.dataset):
            raise StopIteration
        
        # è·å–å½“å‰æ‰¹æ¬¡çš„ç´¢å¼•
        end_idx = min(self.current + self.batch_size, len(self.dataset))
        batch_indices = self.indices[self.current:end_idx]
        
        # æ”¶é›†æ‰¹æ¬¡æ•°æ®
        batch_data = []
        batch_labels = []
        
        for idx in batch_indices:
            x, y = self.dataset[idx]
            batch_data.append(x)
            batch_labels.append(y)
        
        self.current = end_idx
        
        # å †å æˆæ‰¹æ¬¡
        batch_x = genesis.stack(batch_data, dim=0)
        batch_y = genesis.stack(batch_labels, dim=0)
        
        return batch_x, batch_y

def create_synthetic_data(n_samples: int = 1000, n_features: int = 784, n_classes: int = 10) -> Tuple[np.ndarray, np.ndarray]:
    """åˆ›å»ºåˆæˆæ•°æ®ç”¨äºæ¼”ç¤º"""
    np.random.seed(42)
    
    # ç”Ÿæˆéšæœºæ•°æ®
    data = np.random.randn(n_samples, n_features).astype(np.float32)
    
    # ä¸ºæ¯ä¸ªç±»åˆ«æ·»åŠ ä¸€äº›æ¨¡å¼
    labels = np.random.randint(0, n_classes, n_samples)
    for i in range(n_classes):
        mask = labels == i
        # ç»™æ¯ä¸ªç±»åˆ«æ·»åŠ ç‰¹å®šçš„åç½®
        data[mask] += np.random.randn(n_features) * 0.5
    
    return data, labels

def load_data() -> Tuple[DataLoader, DataLoader]:
    """åŠ è½½è®­ç»ƒå’ŒéªŒè¯æ•°æ®"""
    print("ğŸ”„ åŠ è½½æ•°æ®...")
    
    # åˆ›å»ºåˆæˆæ•°æ® (å®é™…é¡¹ç›®ä¸­æ›¿æ¢ä¸ºçœŸå®æ•°æ®)
    train_data, train_labels = create_synthetic_data(800, 784, 10)
    val_data, val_labels = create_synthetic_data(200, 784, 10)
    
    # æ•°æ®æ ‡å‡†åŒ–
    def normalize(x):
        return (x - x.mean()) / (x.std() + 1e-8)
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = SimpleDataset(train_data, train_labels, transform=normalize)
    val_dataset = SimpleDataset(val_data, val_labels, transform=normalize)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ - è®­ç»ƒé›†: {len(train_dataset)}, éªŒè¯é›†: {len(val_dataset)}")
    
    return train_loader, val_loader
```

## ğŸ§  2. æ¨¡å‹å®šä¹‰ (`model.py`)

```python
"""ç¥ç»ç½‘ç»œæ¨¡å‹å®šä¹‰"""
import genesis
import genesis.nn as nn
import genesis.nn.functional as F

class MLP(nn.Module):
    """å¤šå±‚æ„ŸçŸ¥æœºåˆ†ç±»å™¨"""
    
    def __init__(self, input_dim: int = 784, hidden_dims: list = None, num_classes: int = 10, dropout_rate: float = 0.2):
        """
        åˆå§‹åŒ–MLPæ¨¡å‹
        
        Args:
            input_dim: è¾“å…¥ç»´åº¦
            hidden_dims: éšè—å±‚ç»´åº¦åˆ—è¡¨
            num_classes: åˆ†ç±»æ•°é‡
            dropout_rate: Dropoutæ¯”ç‡
        """
        super().__init__()
        
        if hidden_dims is None:
            hidden_dims = [512, 256, 128]
        
        # æ„å»ºç½‘ç»œå±‚
        layers = []
        prev_dim = input_dim
        
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(dropout_rate)
            ])
            prev_dim = hidden_dim
        
        # è¾“å‡ºå±‚
        layers.append(nn.Linear(prev_dim, num_classes))
        
        self.network = nn.Sequential(*layers)
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
    
    def _init_weights(self):
        """æƒé‡åˆå§‹åŒ–"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                # Xavieråˆå§‹åŒ–
                std = (2.0 / (module.in_features + module.out_features)) ** 0.5
                module.weight.data.normal_(0, std)
                if module.bias is not None:
                    module.bias.data.zero_()
    
    def forward(self, x: genesis.Tensor) -> genesis.Tensor:
        """å‰å‘ä¼ æ’­"""
        # å±•å¹³è¾“å…¥ (å¦‚æœæ˜¯å›¾åƒæ•°æ®)
        if x.dim() > 2:
            x = x.view(x.size(0), -1)
        
        return self.network(x)

class CNN(nn.Module):
    """å·ç§¯ç¥ç»ç½‘ç»œåˆ†ç±»å™¨ (å¦‚æœéœ€è¦å¤„ç†å›¾åƒ)"""
    
    def __init__(self, num_classes: int = 10):
        super().__init__()
        
        # å·ç§¯å±‚
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        
        # æ± åŒ–å±‚
        self.pool = nn.MaxPool2d(2, 2)
        
        # å…¨è¿æ¥å±‚
        self.fc1 = nn.Linear(128 * 3 * 3, 512)  # å‡è®¾è¾“å…¥æ˜¯28x28
        self.fc2 = nn.Linear(512, num_classes)
        
        # Dropout
        self.dropout = nn.Dropout(0.5)
        
    def forward(self, x: genesis.Tensor) -> genesis.Tensor:
        # å·ç§¯ + æ± åŒ–
        x = self.pool(F.relu(self.conv1(x)))  # 28x28 -> 14x14
        x = self.pool(F.relu(self.conv2(x)))  # 14x14 -> 7x7  
        x = self.pool(F.relu(self.conv3(x)))  # 7x7 -> 3x3
        
        # å±•å¹³
        x = x.view(x.size(0), -1)
        
        # å…¨è¿æ¥å±‚
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        
        return x

def create_model(model_type: str = "mlp", **kwargs) -> nn.Module:
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºæ¨¡å‹"""
    if model_type.lower() == "mlp":
        return MLP(**kwargs)
    elif model_type.lower() == "cnn":
        return CNN(**kwargs)
    else:
        raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {model_type}")
```

## ğŸ› ï¸ 3. å·¥å…·å‡½æ•° (`utils.py`)

```python
"""å·¥å…·å‡½æ•°æ¨¡å—"""
import genesis
import time
import os
from typing import Dict, Any
import json

class AverageMeter:
    """å¹³å‡å€¼è®¡ç®—å™¨"""
    
    def __init__(self):
        self.reset()
    
    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0
    
    def update(self, val: float, n: int = 1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count

class Timer:
    """è®¡æ—¶å™¨"""
    
    def __init__(self):
        self.start_time = None
        self.end_time = None
    
    def start(self):
        self.start_time = time.time()
    
    def stop(self):
        self.end_time = time.time()
        return self.end_time - self.start_time
    
    def elapsed(self):
        if self.start_time is None:
            return 0
        return time.time() - self.start_time

def accuracy(output: genesis.Tensor, target: genesis.Tensor, topk: tuple = (1,)) -> list:
    """è®¡ç®—å‡†ç¡®ç‡"""
    with genesis.no_grad():
        maxk = max(topk)
        batch_size = target.size(0)
        
        _, pred = output.topk(maxk, 1, True, True)
        pred = pred.t()
        correct = pred.eq(target.view(1, -1).expand_as(pred))
        
        res = []
        for k in topk:
            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)
            res.append(correct_k.mul_(100.0 / batch_size))
        
        return res

def save_checkpoint(model: genesis.nn.Module, optimizer: genesis.optim.Optimizer, 
                   epoch: int, loss: float, accuracy: float, filepath: str):
    """ä¿å­˜æ£€æŸ¥ç‚¹"""
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
        'accuracy': accuracy
    }
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    
    genesis.save(checkpoint, filepath)
    print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {filepath}")

def load_checkpoint(filepath: str, model: genesis.nn.Module, optimizer: genesis.optim.Optimizer = None) -> Dict[str, Any]:
    """åŠ è½½æ£€æŸ¥ç‚¹"""
    checkpoint = genesis.load(filepath)
    
    model.load_state_dict(checkpoint['model_state_dict'])
    
    if optimizer and 'optimizer_state_dict' in checkpoint:
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    
    print(f"ğŸ“ æ£€æŸ¥ç‚¹å·²åŠ è½½: {filepath}")
    print(f"   è½®æ¬¡: {checkpoint['epoch']}, æŸå¤±: {checkpoint['loss']:.4f}, å‡†ç¡®ç‡: {checkpoint['accuracy']:.2f}%")
    
    return checkpoint

def save_training_history(history: Dict[str, list], filepath: str):
    """ä¿å­˜è®­ç»ƒå†å²"""
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    
    with open(filepath, 'w') as f:
        json.dump(history, f, indent=2)
    
    print(f"ğŸ“Š è®­ç»ƒå†å²å·²ä¿å­˜: {filepath}")

def print_model_summary(model: genesis.nn.Module, input_shape: tuple):
    """æ‰“å°æ¨¡å‹æ‘˜è¦"""
    print("ğŸ—ï¸  æ¨¡å‹æ¶æ„:")
    print("=" * 50)
    
    # è®¡ç®—å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"æ€»å‚æ•°é‡: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"è¾“å…¥å½¢çŠ¶: {input_shape}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    dummy_input = genesis.randn(*input_shape)
    try:
        with genesis.no_grad():
            output = model(dummy_input)
        print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
    except Exception as e:
        print(f"å‰å‘ä¼ æ’­æµ‹è¯•å¤±è´¥: {e}")
    
    print("=" * 50)
```

## ğŸš‚ 4. è®­ç»ƒè„šæœ¬ (`train.py`)

<function_calls>
<invoke name="TodoWrite">
<parameter name="todos">[{"id": "1", "content": "\u521b\u5efa\u6587\u6863\u76ee\u5f55\u7ed3\u6784\u548c\u914d\u7f6e\u6587\u4ef6", "status": "completed"}, {"id": "2", "content": "\u7f16\u5199\u9996\u9875\u548c\u5feb\u901f\u5f00\u59cb\u6587\u6863", "status": "completed"}, {"id": "3", "content": "\u7f16\u5199\u67b6\u6784\u8bbe\u8ba1\u6587\u6863", "status": "pending"}, {"id": "4", "content": "\u7f16\u5199\u6838\u5fc3\u7ec4\u4ef6\u6587\u6863", "status": "pending"}, {"id": "5", "content": "\u7f16\u5199\u795e\u7ecf\u7f51\u7edc\u6a21\u5757\u6587\u6863", "status": "pending"}, {"id": "6", "content": "\u7f16\u5199API\u53c2\u8003\u6587\u6863", "status": "pending"}]