# CUDA内存管理

Genesis包含了一个自定义的CUDA内存管理系统，为所有张量操作提供可靠的GPU内存分配。

## 概述

CUDA内存管理器通过直接的CUDA Driver API调用处理GPU内存分配和释放，确保稳定性和正确性优于性能优化。

## 架构

### 核心组件

#### CUDA内存管理器
主要的内存管理器类，处理：
- 使用主上下文的CUDA上下文初始化
- 通过`cuMemAlloc`进行直接内存分配
- 通过`cuMemFree`进行直接内存释放
- 基本统计跟踪

#### 关键特性

1. **主上下文使用**
   - 使用`cuDevicePrimaryCtxRetain`而不是`cuCtxCreate`
   - 避免API兼容性问题
   - 确保正确的上下文共享

2. **直接内存操作**
   - 无内存对齐或填充
   - 无缓存或内存池
   - 直接的`cuMemAlloc`/`cuMemFree`调用
   - 优先考虑正确性而非性能

3. **流管理**
   - 创建并管理默认CUDA流
   - 析构函数中的适当资源清理

## 使用方法

内存管理器在内部由CUDATensor使用，在大多数情况下不应直接调用：

```python
# 内部使用（自动处理）
from genesis.ndarray.cuda_memory_manager import allocate_memory, free_memory

# 分配GPU内存
ptr = allocate_memory(nbytes)

# 释放GPU内存  
free_memory(ptr)

# 获取统计信息
stats = memory_stats()
```

## 设计决策

### 简单性优于优化

当前实现优先考虑：
- **正确性**：所有操作都能可靠工作
- **稳定性**：没有复杂的边缘情况或竞争条件
- **可调试性**：简单、直接的操作易于追踪

### 先前的复杂版本（已弃用）

早期版本包含了高级优化：
- 具有内存池的段-块分配器
- 两级缓存（流本地+全局）
- 内存对齐和合并
- 复杂的统计和性能监控

**为什么被移除**：复杂的优化在数值计算中引入了精度错误，特别是在具有非标准维度的矩阵乘法操作中。

## 错误处理

内存管理器包含健壮的错误处理：
- CUDA API错误被捕获并用描述性消息报告
- 通过适当的析构函数清理防止内存泄漏
- 操作失败时的优雅降级

## 性能特性

虽然当前实现没有针对速度进行优化，但它提供：
- 一致的分配/释放时间
- 无内存碎片问题
- 可预测的内存使用模式
- 数值操作中零精度错误

## 未来改进

在保持正确性的同时可以添加的潜在优化：
- 具有仔细精度测试的内存池
- 大张量的异步分配
- 内存使用监控和报告
- 与CUDA内存管理API的集成

## 故障排除

### 常见问题

1. **CUDA上下文错误**
   - 确保CUDA驱动程序正确安装
   - 检查GPU是否可访问且未被其他进程使用

2. **内存分配失败**
   - 使用`nvidia-smi`监控GPU内存使用
   - 如需要，减少批量大小或张量维度

3. **性能问题**
   - 当前实现优先考虑正确性而非速度
   - 对于性能关键的应用程序，请仔细考虑优化
   - 任何内存管理更改后始终测试数值精度

### 调试技巧

- 使用`memory_stats()`监控分配模式
- 在开发版本中启用CUDA错误检查
- 首先使用较小的张量进行测试，以隔离内存与计算问题

## 集成

内存管理器与以下组件紧密集成：
- **CUDATensor**：所有张量分配都通过此系统进行
- **Triton内核**：GPU计算使用分配的内存
- **Autograd系统**：梯度张量使用相同的内存管理