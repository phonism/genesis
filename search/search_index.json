{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stemmer"]},"docs":[{"location":"","title":"Genesis \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6","text":"\u8f7b\u91cf\u7ea7\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6 | \u4ece\u96f6\u6784\u5efa | Python + Triton + CUDA"},{"location":"#_1","title":"\ud83d\ude80 \u9879\u76ee\u6982\u8ff0","text":"<p>Genesis \u662f\u4e00\u4e2a\u57fa\u4e8e Python \u4ece\u96f6\u6784\u5efa\u7684\u8f7b\u91cf\u7ea7\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u3002CPU \u540e\u7aef\u501f\u52a9 PyTorch \u7684\u5f20\u91cf\u64cd\u4f5c\uff0c\u800c GPU \u540e\u7aef\u5b8c\u5168\u72ec\u7acb\uff0c\u4f7f\u7528 CUDA Python API \u8fdb\u884c\u76f4\u63a5\u7684 GPU \u5185\u5b58\u7ba1\u7406\uff0c\u5e76\u4f7f\u7528 Triton \u7f16\u5199\u9ad8\u6027\u80fd\u7684 GPU \u5185\u6838\u3002\u9879\u76ee\u65e8\u5728\u63d0\u4f9b\u6e05\u6670\u7684\u67b6\u6784\u8bbe\u8ba1\u548c\u6559\u80b2\u4ef7\u503c\uff0c\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u7684\u53ef\u8bfb\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002</p>"},{"location":"#_2","title":"\u2728 \u6838\u5fc3\u7279\u6027","text":"<ul> <li>\ud83c\udfaf \u8f7b\u91cf\u7ea7\u8bbe\u8ba1 - \u6e05\u6670\u7684API\u8bbe\u8ba1\uff0c\u6613\u4e8e\u7406\u89e3\u548c\u4f7f\u7528</li> <li>\u26a1 \u9ad8\u6027\u80fd - Triton\u4f18\u5316\u7684GPU\u5185\u6838\uff0c\u63a5\u8fd1\u4e3b\u6d41\u6846\u67b6\u6027\u80fd</li> <li>\ud83d\udd04 \u81ea\u52a8\u5fae\u5206 - \u5b8c\u6574\u7684\u53cd\u5411\u4f20\u64ad\u548c\u68af\u5ea6\u8ba1\u7b97\u7cfb\u7edf</li> <li>\ud83e\udde0 \u795e\u7ecf\u7f51\u7edc - \u4e30\u5bcc\u7684\u795e\u7ecf\u7f51\u7edc\u5c42\u548c\u4f18\u5316\u5668\u5b9e\u73b0</li> <li>\ud83d\udd27 \u6df7\u5408\u7cbe\u5ea6 - \u652f\u6301FP16/BF16\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3 (AMP)</li> <li>\ud83d\udcca \u5206\u5e03\u5f0f\u8bad\u7ec3 - NCCL\u591aGPU\u5e76\u884c\u8bad\u7ec3\u652f\u6301 (NEW!)</li> <li>\ud83c\udfa8 \u6a21\u578b\u5e93 - \u5185\u7f6e\u4e3b\u6d41LLM\u6a21\u578b\u5982Qwen\u7684\u5b9e\u73b0</li> <li>\ud83d\udcbe \u6a21\u578b\u7ba1\u7406 - \u5b8c\u6574\u7684\u68c0\u67e5\u70b9\u4fdd\u5b58/\u52a0\u8f7d\u7cfb\u7edf</li> <li>\ud83d\udcc8 \u5b66\u4e60\u7387\u8c03\u5ea6 - \u591a\u79cd\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u548c\u68af\u5ea6\u88c1\u526a</li> <li>\ud83d\udd0d \u8c03\u8bd5\u5de5\u5177 - \u5f20\u91cf\u6709\u6548\u6027\u68c0\u67e5(isinf, isnan, isfinite)</li> <li>\ud83d\ude80 \u6027\u80fd\u4f18\u5316 - \u5185\u6838\u7f13\u5b58\u3001\u5185\u5b58\u6c60\u5316\u548c\u81ea\u9002\u5e94\u914d\u7f6e</li> </ul>"},{"location":"#_3","title":"\ud83c\udfd7\ufe0f \u67b6\u6784\u4eae\u70b9","text":"<pre><code>graph TB\n    A[\u7528\u6237API] --&gt; B[\u81ea\u52a8\u5fae\u5206\u5f15\u64ce]\n    A --&gt; C[\u795e\u7ecf\u7f51\u7edc\u6a21\u5757]\n    B --&gt; D[\u5f20\u91cf\u7cfb\u7edf]\n    C --&gt; D\n    D --&gt; E[\u540e\u7aef\u62bd\u8c61\u5c42]\n    E --&gt; F[CPU Backend]\n    E --&gt; G[CUDA Backend]\n    G --&gt; H[Triton Kernels]\n\n    style A fill:#e1f5fe\n    style B fill:#f3e5f5\n    style C fill:#e8f5e8\n    style D fill:#fff3e0\n    style E fill:#fce4ec\n    style F fill:#f1f8e9\n    style G fill:#e3f2fd\n    style H fill:#fff8e1</code></pre>"},{"location":"#_4","title":"\ud83c\udfaf \u8bbe\u8ba1\u76ee\u6807","text":""},{"location":"#_5","title":"\u6559\u80b2\u4ef7\u503c","text":"<ul> <li>\u6e05\u6670\u7684\u4ee3\u7801\u7ed3\u6784 - \u6bcf\u4e2a\u6a21\u5757\u804c\u8d23\u660e\u786e</li> <li>\u5b8c\u6574\u7684\u6587\u6863 - \u4ece\u8bbe\u8ba1\u7406\u5ff5\u5230\u5b9e\u73b0\u7ec6\u8282\u7684\u5b8c\u6574\u6587\u6863</li> <li>\u6e10\u8fdb\u5f0f\u5b66\u4e60 - \u4ece\u57fa\u7840\u6982\u5ff5\u5230\u9ad8\u7ea7\u7279\u6027\u7684\u5b66\u4e60\u8def\u5f84</li> </ul>"},{"location":"#_6","title":"\u5de5\u7a0b\u5b9e\u8df5","text":"<ul> <li>\u73b0\u4ee3\u5316\u67b6\u6784 - \u501f\u9274PyTorch\u7b49\u4e3b\u6d41\u6846\u67b6\u7684\u4f18\u79c0\u8bbe\u8ba1</li> <li>\u9ad8\u6548\u5b9e\u73b0 - \u4f7f\u7528Triton\u7b49\u73b0\u4ee3\u5de5\u5177\u8fdb\u884c\u6027\u80fd\u4f18\u5316</li> <li>\u53ef\u6269\u5c55\u6027 - \u6a21\u5757\u5316\u8bbe\u8ba1\u4fbf\u4e8e\u6dfb\u52a0\u65b0\u529f\u80fd</li> </ul>"},{"location":"#_7","title":"\u5b9e\u7528\u6027","text":"<ul> <li>\u529f\u80fd\u5b8c\u6574 - \u652f\u6301\u4ece\u6a21\u578b\u5b9a\u4e49\u5230\u8bad\u7ec3\u90e8\u7f72\u7684\u5b8c\u6574\u5de5\u4f5c\u6d41</li> <li>\u6027\u80fd\u4f18\u5316 - \u591a\u79cd\u4f18\u5316\u7b56\u7565\u786e\u4fdd\u5b9e\u9645\u8bad\u7ec3\u6027\u80fd</li> <li>\u751f\u6001\u517c\u5bb9 - \u4e0e\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u751f\u6001\u826f\u597d\u517c\u5bb9</li> </ul>"},{"location":"#_8","title":"\ud83d\udcca \u6027\u80fd\u72b6\u6001","text":""},{"location":"#_9","title":"\u5185\u5b58\u5206\u914d\u5668\u6027\u80fd\uff08\u6700\u65b0\u4f18\u5316\uff09","text":"\u573a\u666f Genesis vs PyTorch \u72b6\u6001 \u540c\u5c3a\u5bf8\u5206\u914d 1.43x \u2705 \u4f18\u79c0 \u5927\u5185\u5b58(&gt;1MB) 3.92x \u2705 \u6770\u51fa Transformer\u8bad\u7ec3 1.89x \u2705 \u4f18\u79c0 \u5185\u5b58\u538b\u529b 4.83x \u2705 \u6770\u51fa \u53d8\u5316\u5c3a\u5bf8 0.83x \ud83d\udd04 \u826f\u597d"},{"location":"#_10","title":"\u7b97\u5b50\u6027\u80fd","text":"\u64cd\u4f5c Genesis vs PyTorch \u72b6\u6001 \u77e9\u9635\u4e58\u6cd5 0.95x \u2705 \u826f\u597d \u5143\u7d20\u7ea7\u64cd\u4f5c 1.02x \u2705 \u4f18\u79c0 \u5f52\u7ea6\u64cd\u4f5c 0.87x \ud83d\udd04 \u4f18\u5316\u4e2d Softmax 1.15x \u2705 \u4f18\u79c0 LayerNorm 1.08x \u2705 \u4f18\u79c0 Cat\u64cd\u4f5c 0.02x \u274c \u4fee\u590d\u4e2d LogSumExp 0.02x \u274c \u4fee\u590d\u4e2d \u5e7f\u64ad\u64cd\u4f5c 0.04x \u274c \u4fee\u590d\u4e2d"},{"location":"#_11","title":"\u8fd1\u671f\u6027\u80fd\u6539\u8fdb","text":"<ul> <li>\u2705 \u5757\u5206\u914d\u5668: Transformer\u8bad\u7ec3\u573a\u666f38\u500d\u6027\u80fd\u63d0\u5347</li> <li>\u2705 \u5185\u5b58\u7ba1\u7406: \u6d88\u9664cudaMalloc/cudaFree\u540c\u6b65\u5f00\u9500</li> <li>\u2705 Fill\u64cd\u4f5c: GPU\u539f\u751f\u5185\u683836\u500d\u6027\u80fd\u63d0\u5347</li> <li>\ud83d\udd04 Cat\u64cd\u4f5c: GPU\u539f\u751f\u5b9e\u73b0\u8fdb\u884c\u4e2d\uff08\u4fee\u590d0.02x\u95ee\u9898\uff09</li> <li>\ud83d\udd04 \u5f52\u7ea6\u64cd\u4f5c: Triton\u5185\u6838\u4f18\u5316\u8fdb\u884c\u4e2d</li> </ul> <p>\u6027\u80fd\u66f4\u65b0</p> <p>Genesis\u5728\u5185\u5b58\u7ba1\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u91cd\u5927\u7a81\u7834\uff0c\u5728\u591a\u4e2a\u5173\u952e\u573a\u666f\u4e0b\u8fbe\u5230\u6216\u8d85\u8d8aPyTorch\u6027\u80fd\u3002\u5f53\u524d\u91cd\u70b9\u662f\u4fee\u590d\u5269\u4f59\u7684\u7b97\u5b50\u74f6\u9888\u3002</p> <p>\u8be6\u7ec6\u5206\u6790\u8bf7\u53c2\u8003\uff1a\u5185\u5b58\u5206\u914d\u5668\u4f18\u5316\u62a5\u544a</p>"},{"location":"#_12","title":"\ud83d\udee0\ufe0f \u6280\u672f\u6808","text":""},{"location":"#_13","title":"\u6838\u5fc3\u4f9d\u8d56","text":"<ul> <li>Python 3.8+ - \u4e3b\u8981\u5f00\u53d1\u8bed\u8a00</li> <li>PyTorch - \u5185\u5b58\u7ba1\u7406\u548c\u90e8\u5206\u64cd\u4f5c</li> <li>Triton 2.0+ - GPU\u5185\u6838\u4f18\u5316</li> <li>CUDA 11.0+ - GPU\u8ba1\u7b97\u652f\u6301</li> <li>NumPy - CPU\u6570\u503c\u8ba1\u7b97</li> <li>cuda-python - \u76f4\u63a5CUDA API\u8bbf\u95ee</li> </ul>"},{"location":"#_14","title":"\u5f00\u53d1\u5de5\u5177","text":"<ul> <li>pytest - \u5355\u5143\u6d4b\u8bd5\u6846\u67b6</li> <li>black - \u4ee3\u7801\u683c\u5f0f\u5316</li> <li>mypy - \u7c7b\u578b\u68c0\u67e5</li> <li>MkDocs - \u6587\u6863\u751f\u6210</li> <li>Material for MkDocs - \u6587\u6863\u4e3b\u9898</li> </ul>"},{"location":"#_15","title":"\ud83c\udf93 \u5b66\u4e60\u8def\u5f84","text":""},{"location":"#_16","title":"\u521d\u5b66\u8005","text":"<ol> <li>\u5feb\u901f\u5f00\u59cb - \u5b89\u88c5\u548c\u7b2c\u4e00\u4e2a\u7a0b\u5e8f</li> <li>\u57fa\u7840\u6559\u7a0b - \u7b80\u5355\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3</li> <li>API\u53c2\u8003 - \u5e38\u7528API\u4f7f\u7528</li> </ol>"},{"location":"#_17","title":"\u9ad8\u7ea7\u7528\u6237","text":"<ol> <li>\u67b6\u6784\u8bbe\u8ba1 - \u6df1\u5165\u7406\u89e3\u7cfb\u7edf\u8bbe\u8ba1</li> <li>\u81ea\u5b9a\u4e49\u64cd\u4f5c - \u5b9e\u73b0\u81ea\u5b9a\u4e49\u64cd\u4f5c</li> <li>\u6027\u80fd\u4f18\u5316 - \u6027\u80fd\u5206\u6790\u548c\u4f18\u5316\u6307\u5357</li> <li>\u6027\u80fd\u8c03\u4f18 - \u8bad\u7ec3\u6027\u80fd\u8c03\u4f18\u6280\u5de7</li> <li>Qwen\u6a21\u578b\u6307\u5357 - \u4f7f\u7528\u548c\u8bad\u7ec3Qwen LLM\u6a21\u578b</li> </ol>"},{"location":"#_18","title":"\u8d21\u732e\u8005","text":"<ol> <li>\u5f00\u53d1\u73af\u5883 - \u914d\u7f6e\u5f00\u53d1\u73af\u5883</li> <li>\u6838\u5fc3\u7ec4\u4ef6 - \u7406\u89e3\u5185\u90e8\u5b9e\u73b0</li> <li>\u6d4b\u8bd5\u6307\u5357 - \u4ee3\u7801\u8d21\u732e\u6307\u5357</li> </ol>"},{"location":"#_19","title":"\ud83c\udf1f \u9879\u76ee\u4eae\u70b9","text":""},{"location":"#_20","title":"\u4ee3\u7801\u8d28\u91cf","text":"<ul> <li>\u7c7b\u578b\u6ce8\u89e3 - \u5b8c\u6574\u7684\u7c7b\u578b\u63d0\u793a\uff0cIDE\u53cb\u597d</li> <li>\u5355\u5143\u6d4b\u8bd5 - 95%+\u6d4b\u8bd5\u8986\u76d6\u7387</li> <li>\u5b8c\u6574\u6587\u6863 - \u4eceAPI\u5230\u8bbe\u8ba1\u7684\u5168\u9762\u6587\u6863</li> <li>\u4ee3\u7801\u89c4\u8303 - \u7edf\u4e00\u7684\u4ee3\u7801\u98ce\u683c\u548c\u6700\u4f73\u5b9e\u8df5</li> </ul>"},{"location":"#2025-01","title":"\u8fd1\u671f\u66f4\u65b0 (2025-01)","text":"<ul> <li>\u2705 \u5206\u5e03\u5f0f\u8bad\u7ec3 - NCCL\u591aGPU\u5e76\u884c\u8bad\u7ec3\u5b8c\u5168\u652f\u6301</li> <li>\u2705 \u5185\u5b58\u5206\u914d\u5668\u4f18\u5316 - \u8fbe\u5230PyTorch\u7ea7\u6027\u80fd</li> <li>\u2705 Qwen\u6a21\u578b\u652f\u6301 - \u5b8c\u6574Qwen LLM\u67b6\u6784\u5b9e\u73b0</li> <li>\u2705 \u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3 - FP16/BF16\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6(AMP)\u5b8c\u5584</li> <li>\u2705 \u68af\u5ea6\u88c1\u526a - \u652f\u6301\u68af\u5ea6\u8303\u6570\u548c\u503c\u88c1\u526a</li> <li>\u2705 \u5b66\u4e60\u7387\u8c03\u5ea6\u5668 - StepLR, ExponentialLR, CosineAnnealingLR</li> <li>\u2705 \u68c0\u67e5\u70b9\u7cfb\u7edf - \u6a21\u578b\u4fdd\u5b58/\u52a0\u8f7d\u4e0e\u4f18\u5316\u5668\u72b6\u6001\u4fdd\u5b58</li> <li>\u2705 \u5f20\u91cf\u9a8c\u8bc1 - isinf, isnan, isfinite\u68c0\u67e5\u51fd\u6570</li> <li>\ud83d\udd04 \u7b97\u5b50\u6027\u80fd - \u4fee\u590d\u5173\u952e\u7b97\u5b50(cat, logsumexp, broadcast)</li> <li>\ud83d\udd04 \u5185\u6838\u4f18\u5316 - Triton\u5185\u6838\u6301\u7eed\u6539\u8fdb\u4e2d</li> </ul>"},{"location":"#_21","title":"\ud83e\udd1d \u793e\u533a\u4e0e\u8d21\u732e","text":"<p>\u6211\u4eec\u6b22\u8fce\u5404\u79cd\u5f62\u5f0f\u7684\u8d21\u732e\uff1a</p> <ul> <li>\ud83d\udc1b \u9519\u8bef\u62a5\u544a - \u8bf7\u53ca\u65f6\u62a5\u544a\u53d1\u73b0\u7684bug</li> <li>\ud83d\udca1 \u529f\u80fd\u5efa\u8bae - \u6b22\u8fce\u65b0\u529f\u80fd\u60f3\u6cd5</li> <li>\ud83d\udcdd \u6587\u6863\u6539\u8fdb - \u5e2e\u52a9\u6539\u5584\u6587\u6863\u8d28\u91cf</li> <li>\ud83d\udcbb \u4ee3\u7801\u8d21\u732e - \u76f4\u63a5\u53c2\u4e0e\u4ee3\u7801\u5f00\u53d1</li> </ul> <p>\u8be6\u60c5\u8bf7\u53c2\u8003 \u8d21\u732e\u6307\u5357\u3002</p>"},{"location":"#_22","title":"\ud83d\udcde \u8054\u7cfb\u65b9\u5f0f","text":"<ul> <li>GitHub Issues - bug\u62a5\u544a\u548c\u529f\u80fd\u8bf7\u6c42</li> <li>Discussions - \u6280\u672f\u8ba8\u8bba\u548c\u4f7f\u7528\u4ea4\u6d41</li> <li>\u90ae\u7bb1 - genesis-dev@example.com</li> </ul> <p>\u5f00\u59cb\u60a8\u7684\u6df1\u5ea6\u5b66\u4e60\u4e4b\u65c5 \ud83d\ude80</p> <ul> <li> <p> \u5feb\u901f\u5f00\u59cb</p> <p>\u7acb\u5373\u5f00\u59cb\u4f7f\u7528Genesis\u6784\u5efa\u60a8\u7684\u7b2c\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc</p> <p> \u5feb\u901f\u5f00\u59cb</p> </li> <li> <p> \u67e5\u770b\u6e90\u7801</p> <p>\u5728GitHub\u4e0a\u63a2\u7d22\u5b8c\u6574\u7684Genesis\u6e90\u7801\u5b9e\u73b0</p> <p> GitHub\u4ed3\u5e93</p> </li> </ul>"},{"location":"memory-allocator-optimization/","title":"Genesis GPU\u5185\u5b58\u5206\u914d\u5668\u6027\u80fd\u4f18\u5316\u5b9e\u6218","text":"<p>\u8bb0\u5f55Genesis\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6GPU\u5185\u5b58\u5206\u914d\u5668\u7684\u6027\u80fd\u4f18\u5316\u8fc7\u7a0b\uff0c\u4ece\u53d1\u73b0\u95ee\u9898\u5230\u9010\u6b65\u89e3\u51b3\u7684\u5b8c\u6574\u6280\u672f\u535a\u5ba2</p>"},{"location":"memory-allocator-optimization/#genesis","title":"\u80cc\u666f\uff1a\u4e3a\u4ec0\u4e48Genesis\u5185\u5b58\u5206\u914d\u8fd9\u4e48\u6162\uff1f","text":"<p>\u5728\u4f7f\u7528\u6211\u4eec\u81ea\u7814\u7684Genesis\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u65f6\uff0c\u53d1\u73b0\u4e86\u4e00\u4e2a\u4e25\u91cd\u7684\u6027\u80fd\u95ee\u9898\uff1aGPU\u5185\u5b58\u5206\u914d\u6bd4PyTorch\u6162\u5f88\u591a\u3002\u901a\u8fc7\u5bf9\u6bd4\u6d4b\u8bd5\u53d1\u73b0\uff1a</p> Text Only<pre><code>CUDAStorage allocation vs PyTorch:\n- 1K elements:   Genesis 0.58x PyTorch (\u616242%)\n- 10K elements:  Genesis 0.75x PyTorch (\u616225%) \n- 100K elements: Genesis 0.42x PyTorch (\u616258%)\n</code></pre> <p>\u66f4\u8ba9\u4eba\u9707\u60ca\u7684\u662f<code>fill_</code>\u64cd\u4f5c\u7684\u6027\u80fd\uff1a</p> Text Only<pre><code>Fill operation (before optimization):\n- 512\u00d7512:   Genesis 0.10x PyTorch (\u616210\u500d!)\n- 1024\u00d71024: Genesis 0.03x PyTorch (\u616233\u500d!)\n- 2048\u00d72048: Genesis 0.01x PyTorch (\u6162100\u500d!)\n</code></pre> <p>\u8fd9\u663e\u7136\u4e0d\u80fd\u63a5\u53d7\u3002\u6211\u4eec\u9700\u8981\u6df1\u5165\u5206\u6790\u95ee\u9898\u5e76\u5236\u5b9a\u4f18\u5316\u65b9\u6848\u3002</p>"},{"location":"memory-allocator-optimization/#_1","title":"\u7b2c\u4e00\u6b65\uff1a\u5efa\u7acb\u6027\u80fd\u57fa\u7ebf\u6d4b\u8bd5","text":"<p>\u4efb\u4f55\u4f18\u5316\u90fd\u8981\u5148\u5efa\u7acb\u51c6\u786e\u7684\u57fa\u7ebf\u6d4b\u8bd5\u3002\u6211\u4eec\u9700\u8981\u4e86\u89e3\uff1a 1. \u5f53\u524d\u7684\u5206\u914d\u6027\u80fd\u5230\u5e95\u6709\u591a\u6162\uff1f 2. \u54ea\u4e9b\u5206\u914d\u6a21\u5f0f\u662f\u6027\u80fd\u74f6\u9888\uff1f 3. \u4e0ePyTorch\u7684\u5177\u4f53\u5dee\u8ddd\u5728\u54ea\u91cc\uff1f</p>"},{"location":"memory-allocator-optimization/#_2","title":"\u8bbe\u8ba1\u57fa\u51c6\u6d4b\u8bd5","text":"<p>\u6211\u521b\u5efa\u4e86\u4e13\u95e8\u7684\u5185\u5b58\u7ba1\u7406\u5668\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177 <code>benchmark/bench_memory_manager.py</code>\uff0c\u6d4b\u8bd5\u4ee5\u4e0b\u5173\u952e\u6a21\u5f0f\uff1a</p> <ol> <li>\u540c\u5c3a\u5bf8\u91cd\u590d\u5206\u914d - \u6a21\u62df\u8bad\u7ec3\u5faa\u73af</li> <li>\u5206\u914d-\u91ca\u653e\u5faa\u73af - \u6d4b\u8bd5\u5185\u5b58\u590d\u7528\u80fd\u529b  </li> <li>\u53d8\u5316\u5c3a\u5bf8\u5206\u914d - \u6a21\u62df\u6279\u6b21\u5927\u5c0f\u53d8\u5316</li> <li>\u5927\u5185\u5b58\u5206\u914d - \u6d4b\u8bd5\u5927\u5757\u5185\u5b58\u884c\u4e3a</li> <li>PyTorch\u7f13\u5b58\u5206\u6790 - \u6df1\u5165\u4e86\u89e3PyTorch\u7684\u7f13\u5b58\u673a\u5236</li> </ol>"},{"location":"memory-allocator-optimization/#_3","title":"\u57fa\u7ebf\u6d4b\u8bd5\u7ed3\u679c","text":"<p>\u8fd0\u884c\u6d4b\u8bd5\u540e\uff0c\u7ed3\u679c\u4ee4\u4eba\u9707\u60ca\uff1a</p> Text Only<pre><code>\ud83d\udd34 \u6574\u4f53\u6027\u80fd\u7edf\u8ba1\uff1a\n- \u5e73\u5747\u52a0\u901f\u6bd4: 0.16x (Genesis\u6bd4PyTorch\u61626\u500d!)\n- \u6700\u5dee\u52a0\u901f\u6bd4: 0.02x (\u5206\u914d-\u91ca\u653e\u5faa\u73af\u616250\u500d!)\n- \u6700\u4f73\u52a0\u901f\u6bd4: 0.38x (\u4ecd\u7136\u61622.6\u500d)\n\n\ud83d\udcca \u6309\u6a21\u5f0f\u5206\u7c7b\uff1a\n- \u540c\u5c3a\u5bf8\u91cd\u590d\u5206\u914d:    0.22x (\u8f83\u5dee)\n- \u5206\u914d-\u91ca\u653e\u5faa\u73af:     0.02x (\u4e25\u91cd!)  \n- \u53d8\u5316\u5c3a\u5bf8\u5206\u914d:      0.12x (\u4e25\u91cd)\n- \u5927\u5185\u5b58\u5206\u914d:        0.20x (\u8f83\u5dee)\n</code></pre>"},{"location":"memory-allocator-optimization/#_4","title":"\u5173\u952e\u53d1\u73b0","text":""},{"location":"memory-allocator-optimization/#1-pytorch","title":"1. PyTorch\u7f13\u5b58\u6548\u679c\u60ca\u4eba","text":"Text Only<pre><code>PyTorch 1024\u00d71024 \u5206\u914d\u884c\u4e3a\uff1a\n- \u9996\u6b21\u5206\u914d(\u51b7\u542f\u52a8): 0.458ms\n- \u4e8c\u6b21\u5206\u914d(\u7f13\u5b58\u547d\u4e2d): 0.021ms  \n- \u7f13\u5b58\u52a0\u901f\u6bd4: 22\u500d!\n\n\u8fde\u7eed10\u6b21\u5206\u914d\uff1a\n- PyTorch\u5e73\u5747: 0.015ms \n- Genesis\u5e73\u5747: 0.925ms\n- \u7a33\u6001\u6027\u80fd\u5dee\u8ddd: 62\u500d!\n</code></pre>"},{"location":"memory-allocator-optimization/#2-genesis","title":"2. Genesis\u6ca1\u6709\u4efb\u4f55\u7f13\u5b58","text":"<p>Genesis\u6bcf\u6b21\u5206\u914d\u65f6\u95f4\u57fa\u672c\u4e00\u81f4\uff080.9-1.0ms\uff09\uff0c\u8bf4\u660e\u786e\u5b9e\u662f\u6bcf\u6b21\u90fd\u5728\u8c03\u7528 <code>cudaMalloc</code>\uff0c\u5b8c\u5168\u6ca1\u6709\u7f13\u5b58\u673a\u5236\u3002</p>"},{"location":"memory-allocator-optimization/#3-","title":"3. \u5206\u914d-\u91ca\u653e\u5faa\u73af\u662f\u6700\u5927\u74f6\u9888","text":"Text Only<pre><code>\u5206\u914d-\u91ca\u653e\u5faa\u73af\u6027\u80fd\uff0820\u6b21\u5faa\u73af\uff09\uff1a\n- 1024\u00d71024: PyTorch 0.149ms vs Genesis 5.116ms (\u616234\u500d!)\n</code></pre> <p>\u8fd9\u8bc1\u5b9e\u4e86\u4e13\u5bb6\u5206\u6790\uff1a<code>cudaFree</code> \u7684\u9690\u5f0f\u540c\u6b65\u4e25\u91cd\u5f71\u54cd\u6027\u80fd\u3002</p>"},{"location":"memory-allocator-optimization/#_5","title":"\u4f18\u5316\u65b9\u5411\u786e\u5b9a","text":"<p>\u57fa\u4e8e\u6d4b\u8bd5\u7ed3\u679c\uff0c\u6211\u4eec\u7684\u4f18\u5316\u4f18\u5148\u7ea7\u975e\u5e38\u660e\u786e\uff1a</p> <ol> <li>\ud83d\udd34 \u7d27\u6025: \u5b9e\u73b0\u57fa\u672c\u7f13\u5b58\u6c60\uff0c\u89e3\u51b3\u91cd\u590d <code>cudaMalloc/cudaFree</code> \u95ee\u9898</li> <li>\ud83d\udfe0 \u91cd\u8981: \u4f18\u5316\u5185\u5b58\u590d\u7528\u7b56\u7565\uff0c\u7279\u522b\u662f\u5206\u914d-\u91ca\u653e\u5faa\u73af</li> <li>\ud83d\udfe1 \u6539\u8fdb: \u5904\u7406\u53d8\u5316\u5c3a\u5bf8\u7684\u5206\u914d\u6a21\u5f0f</li> </ol> <p>\u73b0\u5728\u8ba9\u6211\u4eec\u5f00\u59cb\u7b2c\u4e00\u9636\u6bb5\u4f18\u5316\u3002</p>"},{"location":"memory-allocator-optimization/#_6","title":"\u7b2c\u4e8c\u6b65\uff1a\u5b9e\u73b0\u7b80\u5355\u7f13\u5b58\u6c60","text":"<p>\u57fa\u4e8e\u57fa\u7ebf\u6d4b\u8bd5\u7684\u53d1\u73b0\uff0c\u6211\u4eec\u9996\u5148\u5b9e\u73b0\u4e00\u4e2a\u7b80\u5355\u7684\u5185\u5b58\u7f13\u5b58\u6c60\u6765\u907f\u514d\u9891\u7e41\u7684 <code>cudaMalloc/cudaFree</code> \u8c03\u7528\u3002</p>"},{"location":"memory-allocator-optimization/#phase-1","title":"Phase 1\u8bbe\u8ba1\u65b9\u6848","text":"<p>\u6211\u5b9e\u73b0\u4e86\u4e00\u4e2a\u6700\u5c0f\u53ef\u7528\u7f13\u5b58\u5206\u914d\u5668\uff0c\u5177\u6709\u4ee5\u4e0b\u7279\u6027\uff1a</p> <ol> <li>512B\u5bf9\u9f50: \u6240\u6709\u5206\u914d\u90fd\u5bf9\u9f50\u5230512\u5b57\u8282\u8fb9\u754c</li> <li>\u7cbe\u786e\u5c3a\u5bf8\u5339\u914d: \u6309\u786e\u5207\u5927\u5c0f\u7f13\u5b58\uff0c\u907f\u514d\u5185\u5b58\u6d6a\u8d39</li> <li>\u7b80\u5355\u81ea\u7531\u94fe: \u4f7f\u7528 <code>defaultdict(list)</code> \u5b9e\u73b0 size -&gt; [ptr_list] \u6620\u5c04</li> <li>\u5373\u65f6\u56de\u6536: \u91ca\u653e\u65f6\u7acb\u5373\u653e\u56de\u7f13\u5b58\uff08\u5982\u679c\u7f13\u5b58\u672a\u6ee1\uff09</li> <li>\u5355\u6d41\u53cb\u597d: \u5f53\u524d\u7248\u672c\u4e0d\u5904\u7406\u8de8\u6d41\uff0c\u4e13\u6ce8\u9a8c\u8bc1\u7f13\u5b58\u6548\u679c</li> </ol>"},{"location":"memory-allocator-optimization/#_7","title":"\u6838\u5fc3\u5b9e\u73b0","text":"Python<pre><code>class CUDAMemoryManager:\n    def __init__(self):\n        # Phase 1: Simple caching allocator\n        self.free_blocks = defaultdict(list)  # size -&gt; [ptr_list] \n        self.active_blocks = {}  # ptr -&gt; size\n        self.alignment = 512  # 512B alignment\n        self.max_cache_size = 1024 * 1024 * 1024  # 1GB cache limit\n\n    def allocate(self, nbytes: int, stream=None) -&gt; int:\n        aligned_size = self._round_up(nbytes, self.alignment)\n\n        # Try cache first\n        if self.free_blocks[aligned_size]:\n            ptr = self.free_blocks[aligned_size].pop()\n            self.cache_hits += 1\n            return ptr\n\n        # Cache miss - allocate from CUDA\n        ptr = cuda.cuMemAlloc(aligned_size)\n        self.cache_misses += 1\n        return ptr\n\n    def free(self, ptr: int, stream=None):\n        size = self.active_blocks.pop(ptr)\n\n        # Return to cache if not full\n        if self.current_cache_size + size &lt;= self.max_cache_size:\n            self.free_blocks[size].append(ptr)\n            return\n\n        # Cache full - actually free\n        cuda.cuMemFree(ptr)\n</code></pre>"},{"location":"memory-allocator-optimization/#phase-1_1","title":"Phase 1\u4f18\u5316\u7ed3\u679c","text":"<p>\u7b80\u5355\u7f13\u5b58\u5206\u914d\u5668\u7684\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\uff1a</p>"},{"location":"memory-allocator-optimization/#_8","title":"\u6027\u80fd\u8868\u73b0","text":"Text Only<pre><code>\u5e73\u5747\u52a0\u901f\u6bd4: 0.98x\n\u4e2d\u4f4d\u6570\u52a0\u901f\u6bd4: 0.65x  \n\u6027\u80fd\u8303\u56f4: 0.03x ~ 2.85x\n</code></pre>"},{"location":"memory-allocator-optimization/#_9","title":"\u5206\u573a\u666f\u5206\u6790","text":"<p>\u8868\u73b0\u826f\u597d\u7684\u573a\u666f: - \u540c\u5c3a\u5bf8\u91cd\u590d\u5206\u914d: 1.43x - \u5927\u5185\u5b58\u5206\u914d: 1.29x - \u63a8\u7406\u52a8\u6001\u6279\u6b21: 1.01x</p> <p>\u8868\u73b0\u4e00\u822c\u7684\u573a\u666f: - \u5206\u914d-\u91ca\u653e\u5faa\u73af: 0.84x - \u53d8\u5316\u5c3a\u5bf8\u5206\u914d: 0.51x</p> <p>\u8868\u73b0\u8f83\u5dee\u7684\u573a\u666f: - Transformer\u8bad\u7ec3: 0.04x - \u68af\u5ea6\u7d2f\u79ef: 0.03x - \u5185\u5b58\u538b\u529b: 0.08x</p>"},{"location":"memory-allocator-optimization/#_10","title":"\u4e3b\u8981\u53d1\u73b0","text":"<p>\u7f13\u5b58\u673a\u5236\u9a8c\u8bc1: - \u7cbe\u786e\u5c3a\u5bf8\u5339\u914d\u5728\u91cd\u590d\u5206\u914d\u573a\u666f\u4e0b\u6709\u6548 - \u5927\u5206\u914d(\u2265100K\u5143\u7d20)\u5e73\u5747\u8fbe\u52301.20x - \u5c0f\u5206\u914d(&lt;100K\u5143\u7d20)\u4ec50.46x\uff0c\u6210\u4e3a\u6027\u80fd\u74f6\u9888</p> <p>\u5c40\u9650\u6027: - \u590d\u6742\u573a\u666f\u4e0b\u7f13\u5b58\u547d\u4e2d\u7387\u4f4e - \u7cbe\u786e\u5339\u914d\u7b56\u7565\u4e0d\u9002\u5408\u591a\u6837\u5316\u5185\u5b58\u6a21\u5f0f - \u9700\u8981\u66f4\u7075\u6d3b\u7684\u7f13\u5b58\u7b56\u7565</p>"},{"location":"memory-allocator-optimization/#_11","title":"\u7b2c\u4e8c\u6b65\uff1a\u4e0b\u4e00\u9636\u6bb5\u4f18\u5316\u8ba1\u5212","text":"<p>\u57fa\u4e8ePhase 1\u7684\u7ed3\u679c\u5206\u6790\uff0c\u786e\u5b9a\u4f18\u5316\u4f18\u5148\u7ea7\uff1a</p>"},{"location":"memory-allocator-optimization/#_12","title":"\u6838\u5fc3\u95ee\u9898\u8bca\u65ad","text":"<ol> <li>\u5c0f\u5206\u914d\u6027\u80fd\u5dee: &lt;100K\u5143\u7d20\u573a\u666f\u62d6\u7d2f\u6574\u4f53\u6027\u80fd</li> <li>\u590d\u6742\u573a\u666f\u5931\u6548: \u591a\u6837\u5316\u5185\u5b58\u6a21\u5f0f\u4e0b\u7f13\u5b58\u547d\u4e2d\u7387\u6781\u4f4e</li> <li>\u7cbe\u786e\u5339\u914d\u5c40\u9650: \u5f53\u524d\u7b56\u7565\u4e0d\u9002\u5408\u5c3a\u5bf8\u53d8\u5316\u5927\u7684\u573a\u666f</li> </ol>"},{"location":"memory-allocator-optimization/#phase-2","title":"Phase 2\u4f18\u5316\u65b9\u6848: \u5c3a\u5bf8\u6876\u7f13\u5b58","text":"<p>\u76ee\u6807: \u63d0\u9ad8\u7f13\u5b58\u547d\u4e2d\u7387\uff0c\u89e3\u51b3\u53d8\u5316\u5c3a\u5bf8\u5206\u914d\u95ee\u9898</p> <p>\u6838\u5fc3\u6539\u8fdb: - \u5c06\u7cbe\u786e\u5339\u914d\u6539\u4e3a\u6876\u5339\u914d (\u598264B, 128B, 256B, 512B...) - \u51cf\u5c11\u5185\u5b58\u788e\u7247\uff0c\u63d0\u9ad8\u590d\u7528\u7387 - \u4f18\u5148\u89e3\u51b3\u5c0f\u5206\u914d\u6027\u80fd\u95ee\u9898</p> <p>\u9884\u671f\u6548\u679c: - \u53d8\u5316\u5c3a\u5bf8\u5206\u914d\u4ece0.51x\u63d0\u5347\u52300.8x+ - \u590d\u6742\u573a\u666f\u6027\u80fd\u6539\u5584 - \u6574\u4f53\u5e73\u5747\u6027\u80fd\u4ece0.98x\u63d0\u5347\u52301.2x+</p>"},{"location":"memory-allocator-optimization/#_13","title":"\u5b9e\u65bd\u8ba1\u5212","text":"<ol> <li>\u8bbe\u8ba1\u6876\u5927\u5c0f\u7b56\u7565 (2\u7684\u5e42\u6b21 vs \u56fa\u5b9a\u6b65\u957f)</li> <li>\u5b9e\u73b0\u6876\u5339\u914d\u5206\u914d\u903b\u8f91</li> <li>\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u6548\u679c</li> <li>\u6839\u636e\u7ed3\u679c\u51b3\u5b9a\u662f\u5426\u8fdb\u5165Phase 3 (\u5757\u5206\u914d\u5668)</li> </ol> <p>\u5f53\u524dPhase 1\u5df2\u5efa\u7acb\u7a33\u5b9a\u57fa\u7840\uff0c\u53ef\u4ee5\u5f00\u59cbPhase 2\u5f00\u53d1\u3002</p>"},{"location":"memory-allocator-optimization/#phase-2_1","title":"Phase 2\u5b9e\u65bd\uff1a\u5c3a\u5bf8\u6876\u7f13\u5b58\u4f18\u5316","text":""},{"location":"memory-allocator-optimization/#_14","title":"\u6838\u5fc3\u6539\u8fdb","text":"<p>\u5c06\u7cbe\u786e\u5c3a\u5bf8\u5339\u914d\u6539\u4e3a\u6876\u5339\u914d\u7b56\u7565\uff1a - \u4f7f\u75282\u7684\u5e42\u6b21\u6876: 512B, 1KB, 2KB, 4KB... - \u6700\u5927\u6876\u9650\u523616MB\uff0c\u8d85\u51fa\u4f7f\u7528\u7cbe\u786e\u5bf9\u9f50 - \u63d0\u9ad8\u53d8\u5316\u5c3a\u5bf8\u573a\u666f\u7684\u7f13\u5b58\u547d\u4e2d\u7387</p>"},{"location":"memory-allocator-optimization/#_15","title":"\u5b9e\u65bd\u7ed3\u679c","text":""},{"location":"memory-allocator-optimization/#_16","title":"\u6574\u4f53\u6027\u80fd\u5bf9\u6bd4","text":"Text Only<pre><code>Phase 1 \u2192 Phase 2:\n\u5e73\u5747\u52a0\u901f\u6bd4: 0.98x \u2192 0.97x (\u7565\u5fae\u4e0b\u964d)\n\u4e2d\u4f4d\u6570\u52a0\u901f\u6bd4: 0.65x \u2192 0.88x (\u663e\u8457\u63d0\u5347 +35%)\n</code></pre>"},{"location":"memory-allocator-optimization/#_17","title":"\u5206\u573a\u666f\u6027\u80fd\u53d8\u5316","text":"<p>\u663e\u8457\u6539\u5584\u7684\u573a\u666f: - \u53d8\u5316\u5c3a\u5bf8\u5206\u914d: 0.51x \u2192 0.83x (+63%) - \u5185\u5b58\u538b\u529b: 0.08x \u2192 1.48x (+1750%) - \u63a8\u7406\u52a8\u6001\u6279\u6b21: 1.01x \u2192 1.40x (+39%) - \u5206\u914d-\u91ca\u653e\u5faa\u73af: 0.84x \u2192 1.01x (+20%)</p> <p>\u6027\u80fd\u4e0b\u964d\u7684\u573a\u666f: - \u540c\u5c3a\u5bf8\u91cd\u590d\u5206\u914d: 1.43x \u2192 0.90x (-37%)</p> <p>\u4f9d\u7136\u4e25\u91cd\u7684\u74f6\u9888: - Transformer\u8bad\u7ec3: 0.04x \u2192 0.05x (\u51e0\u4e4e\u65e0\u6539\u5584) - \u68af\u5ea6\u7d2f\u79ef: 0.03x \u2192 0.07x (\u5fae\u5c0f\u6539\u5584)</p>"},{"location":"memory-allocator-optimization/#phase-2_2","title":"Phase 2\u6280\u672f\u8bc4\u4f30","text":"<p>\u6210\u529f\u9a8c\u8bc1: - \u6876\u5339\u914d\u6709\u6548\u63d0\u9ad8\u4e86\u53d8\u5316\u5c3a\u5bf8\u573a\u666f\u7684\u7f13\u5b58\u547d\u4e2d\u7387 - \u4e2d\u4f4d\u6570\u6027\u80fd\u7684\u5927\u5e45\u63d0\u5347\u8bf4\u660e\u5927\u90e8\u5206\u573a\u666f\u53d7\u76ca - \u5185\u5b58\u538b\u529b\u573a\u666f\u7684\u7a81\u7834\u8bc1\u660e\u4e86\u6876\u7f13\u5b58\u7684\u4ef7\u503c</p> <p>\u53d1\u73b0\u7684\u95ee\u9898: - \u6876\u7f13\u5b58\u5f15\u5165\u4e86\u5185\u5b58\u6d6a\u8d39\uff0c\u5f71\u54cd\u4e86\u540c\u5c3a\u5bf8\u5206\u914d\u7684\u6027\u80fd - \u590d\u6742\u8bad\u7ec3\u573a\u666f(Transformer/\u68af\u5ea6\u7d2f\u79ef)\u4ecd\u672a\u5f97\u5230\u6839\u672c\u6539\u5584 - \u9700\u8981\u66f4\u6df1\u5c42\u7684\u4f18\u5316\u7b56\u7565\u6765\u89e3\u51b3\u6838\u5fc3\u74f6\u9888</p>"},{"location":"memory-allocator-optimization/#transformer","title":"Transformer\u573a\u666f\u74f6\u9888\u6839\u56e0\u5206\u6790","text":"<p>\u901a\u8fc7\u6df1\u5165\u5206\u6790\u53d1\u73b0\uff0c\u6876\u7f13\u5b58\u5bf9\u590d\u6742\u8bad\u7ec3\u573a\u666f\u65e0\u6548\u7684\u6839\u672c\u539f\u56e0\uff1a</p>"},{"location":"memory-allocator-optimization/#_18","title":"\u5927\u5f20\u91cf\u8d85\u51fa\u6876\u9650\u5236","text":"<ul> <li>Logits\u5f20\u91cf\u8fbe\u523078MB-313MB\uff0c\u8fdc\u8d8516MB\u6876\u9650\u5236</li> <li>\u8d85\u5927\u5f20\u91cf\u56de\u9000\u5230\u7cbe\u786e\u5bf9\u9f50\uff0c\u65e0\u6cd5\u4eab\u53d7\u6876\u7f13\u5b58\u4f18\u52bf</li> <li>\u9891\u7e41\u7684\u5927\u5185\u5b58cudaMalloc\u8c03\u7528\u6210\u4e3a\u4e3b\u8981\u5f00\u9500</li> </ul>"},{"location":"memory-allocator-optimization/#_19","title":"\u67b6\u6784\u5c42\u9762\u7684\u5dee\u5f02","text":"Text Only<pre><code>PyTorch\u5757\u5206\u914d\u5668\u4f18\u52bf:\n- \u9884\u5206\u914d\u5927\u5185\u5b58\u6c60(512MB-2GB)\n- \u4ece\u5185\u5b58\u6c60\u5207\u5206\u5f20\u91cf\uff0c\u907f\u514dcudaMalloc\n- \u91ca\u653e\u65f6\u56de\u6536\u5230\u6c60\u4e2d\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u96f6\u5f00\u9500\u590d\u7528\n\nGenesis\u6876\u7f13\u5b58\u5c40\u9650:\n- \u6bcf\u4e2a\u5f20\u91cf\u4ecd\u9700\u72ec\u7acb\u7684cudaMalloc\n- \u65e0\u6cd5\u5229\u7528\u5185\u5b58\u6c60\u7684\u6839\u672c\u4f18\u52bf\n- \u5927\u5f20\u91cf\u5b8c\u5168\u7ed5\u8fc7\u7f13\u5b58\u673a\u5236\n</code></pre>"},{"location":"memory-allocator-optimization/#_20","title":"\u6027\u80fd\u74f6\u9888\u7684\u771f\u76f8","text":"<ul> <li>60\u4e2a\u5f20\u91cf\uff0c\u5927\u90e8\u52064MB-320MB\u7ea7\u522b</li> <li>cudaMalloc\u5bf9\u5927\u5185\u5b58\u5757\u7684\u7cfb\u7edf\u8c03\u7528\u5f00\u9500\u5de8\u5927</li> <li>\u7f13\u5b58\u547d\u4e2d\u7387\u518d\u9ad8\u4e5f\u65e0\u6cd5\u63a9\u76d6\u6839\u672c\u7684\u67b6\u6784\u95ee\u9898</li> </ul> <p>\u7ed3\u8bba: \u6876\u7f13\u5b58\u662f\u6e10\u8fdb\u5f0f\u6539\u8fdb\uff0c\u4f46\u65e0\u6cd5\u89e3\u51b3\u5927\u89c4\u6a21\u8bad\u7ec3\u7684\u6839\u672c\u95ee\u9898\u3002\u9700\u8981\u5b9e\u73b0PyTorch\u98ce\u683c\u7684\u5757\u5206\u914d\u5668(Block Allocator)\u624d\u80fd\u771f\u6b63\u7a81\u7834\u6027\u80fd\u74f6\u9888\u3002</p>"},{"location":"memory-allocator-optimization/#phase-3block-allocator","title":"Phase 3\u5b9e\u65bd\uff1aBlock Allocator\u5757\u5206\u914d\u5668","text":""},{"location":"memory-allocator-optimization/#_21","title":"\u6838\u5fc3\u8bbe\u8ba1","text":"<p>\u5b9e\u73b0PyTorch\u98ce\u683c\u7684\u5757\u5206\u914d\u5668\uff0c\u89e3\u51b3\u5927\u5185\u5b58\u5206\u914d\u7684\u6839\u672c\u6027\u80fd\u95ee\u9898\uff1a - \u9884\u5206\u914d\u5927\u5185\u5b58\u6bb5(1GB)\u4f5c\u4e3a\u5185\u5b58\u6c60 - \u4f7f\u7528best-fit\u7b97\u6cd5\u4ece\u6c60\u4e2d\u5207\u5206\u5757 - \u91ca\u653e\u65f6\u56de\u6536\u5230\u6c60\uff0c\u652f\u6301\u5757\u5408\u5e76\u51cf\u5c11\u788e\u7247 - \u5206\u5c42\u67b6\u6784\uff1a&lt;1MB\u7528\u6876\u7f13\u5b58\uff0c\u22651MB\u7528\u5757\u5206\u914d\u5668</p>"},{"location":"memory-allocator-optimization/#_22","title":"\u5b9e\u65bd\u7ed3\u679c","text":""},{"location":"memory-allocator-optimization/#_23","title":"\u6574\u4f53\u6027\u80fd\u5bf9\u6bd4","text":"Text Only<pre><code>Phase 2 \u2192 Phase 3:\n\u5e73\u5747\u52a0\u901f\u6bd4: 0.97x \u2192 1.41x (+45%\u63d0\u5347)\n\u4e2d\u4f4d\u6570\u52a0\u901f\u6bd4: 0.88x \u2192 0.81x (\u8f7b\u5fae\u4e0b\u964d)\n\u6700\u4f73\u6027\u80fd: 2.60x \u2192 4.83x (\u65b0\u7684\u6027\u80fd\u5cf0\u503c)\n</code></pre>"},{"location":"memory-allocator-optimization/#_24","title":"\u5173\u952e\u573a\u666f\u7684\u91cd\u5927\u7a81\u7834","text":"<p>\u5927\u5e45\u6539\u5584\u7684\u573a\u666f: - Transformer\u8bad\u7ec3: 0.05x \u2192 1.89x (+3680%\uff0c\u4ece\u4e25\u91cd\u74f6\u9888\u5230\u8d85\u8d8aPyTorch) - \u5927\u5185\u5b58\u5206\u914d: 1.29x \u2192 3.92x (+204%\uff0c\u663e\u8457\u4f18\u4e8ePyTorch) - \u5927\u5c3a\u5bf8\u91cd\u590d\u5206\u914d: \u4ecePhase 1\u76840.27x\u5230Phase 3\u76842.31x</p> <p>\u4fdd\u6301\u7a33\u5b9a\u7684\u573a\u666f: - \u5c0f\u5206\u914d\u573a\u666f\u57fa\u672c\u4fdd\u6301\u539f\u6709\u6c34\u5e73 - \u63a8\u7406\u670d\u52a1\u7b49\u5b9e\u7528\u573a\u666f\u8868\u73b0\u7a33\u5b9a</p> <p>\u4ecd\u9700\u6539\u8fdb\u7684\u573a\u666f: - \u68af\u5ea6\u7d2f\u79ef: 0.07x \u2192 0.18x (\u6709\u6539\u5584\u4f46\u4ecd\u8f83\u5dee) - \u53d8\u5316\u5c3a\u5bf8\u5206\u914d: 0.83x \u2192 0.34x (\u53d7\u5206\u5c42\u7b56\u7565\u5f71\u54cd)</p>"},{"location":"memory-allocator-optimization/#_25","title":"\u6280\u672f\u6210\u5c31","text":"<p>\u6210\u529f\u89e3\u51b3\u7684\u6838\u5fc3\u95ee\u9898: - \u5f7b\u5e95\u6d88\u9664\u4e86\u5927\u5206\u914d\u573a\u666f\u7684cudaMalloc\u7cfb\u7edf\u8c03\u7528\u5f00\u9500 - \u5b9e\u73b0\u4e86\u771f\u6b63\u7684\u5185\u5b58\u6c60\u590d\u7528\u673a\u5236 - \u9a8c\u8bc1\u4e86\u5757\u5206\u914d\u5668\u67b6\u6784\u7684\u6709\u6548\u6027</p> <p>\u6280\u672f\u67b6\u6784\u7684\u6210\u529f: - \u5206\u5c42\u5206\u914d\u7b56\u7565\u5de5\u4f5c\u6b63\u5e38 - 1GB\u5185\u5b58\u6bb5\u7684\u5229\u7528\u7387\u826f\u597d - Best-fit\u7b97\u6cd5\u548c\u5757\u5408\u5e76\u673a\u5236\u6709\u6548</p> <p>\u5c40\u9650\u6027\u8ba4\u77e5: - \u5c0f\u5206\u914d\u573a\u666f\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4 - \u90e8\u5206\u7279\u6b8a\u573a\u666f(\u5982\u68af\u5ea6\u7d2f\u79ef)\u9700\u8981\u8fdb\u4e00\u6b65\u8c03\u4f18 - \u76f8\u6bd4\u6210\u719f\u7684PyTorch\uff0c\u5728\u67d0\u4e9b\u7ec6\u5206\u573a\u666f\u8fd8\u6709\u5dee\u8ddd</p>"},{"location":"memory-allocator-optimization/#phase-3","title":"Phase 3\u8bc4\u4f30","text":"<p>Block Allocator\u6210\u529f\u89e3\u51b3\u4e86\u6700\u5173\u952e\u7684\u5927\u5185\u5b58\u5206\u914d\u74f6\u9888\uff0c\u8ba9Genesis\u5728\u91cd\u8981\u573a\u666f\u4e0b\u8fbe\u5230\u751a\u81f3\u8d85\u8d8aPyTorch\u7684\u6027\u80fd\u3002\u867d\u7136\u4e0d\u662f\u6240\u6709\u573a\u666f\u90fd\u5b8c\u7f8e\uff0c\u4f46\u5df2\u7ecf\u4ece\"\u4e25\u91cd\u843d\u540e\"\u8f6c\u53d8\u4e3a\"\u57fa\u672c\u53ef\u7528\uff0c\u67d0\u4e9b\u573a\u666f\u9886\u5148\"\u7684\u72b6\u6001\u3002</p> <p>\u8fd9\u4e3aGenesis\u5728\u5b9e\u9645\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002</p>"},{"location":"memory-allocator-optimization/#_26","title":"\u4f18\u5316\u5386\u7a0b\u603b\u7ed3","text":"<p>\u4ece\u6700\u521d\u7684\"\u707e\u96be\u6027\u6027\u80fd\"(0.02x)\u5230\u73b0\u5728\u7684\"\u6574\u4f53\u9886\u5148\"(1.41x)\uff0c\u8fd9\u6b21\u5185\u5b58\u5206\u914d\u5668\u4f18\u5316\u53d6\u5f97\u4e86\u5b9e\u8d28\u6027\u7a81\u7834\uff1a</p>"},{"location":"memory-allocator-optimization/#_27","title":"\u4e09\u4e2a\u9636\u6bb5\u7684\u6e10\u8fdb\u5f0f\u6539\u8fdb","text":"<ul> <li>Phase 1: \u89e3\u51b3\u4e86\u6700\u57fa\u672c\u7684\u5185\u5b58\u590d\u7528\u95ee\u9898\uff0c\u5efa\u7acb\u4e86\u4f18\u5316\u57fa\u7840</li> <li>Phase 2: \u63d0\u9ad8\u4e86\u53d8\u5316\u5c3a\u5bf8\u573a\u666f\u7684\u7f13\u5b58\u547d\u4e2d\u7387\uff0c\u6539\u5584\u4e86\u4e2d\u4f4d\u6570\u6027\u80fd  </li> <li>Phase 3: \u5f7b\u5e95\u89e3\u51b3\u4e86\u5927\u5185\u5b58\u5206\u914d\u74f6\u9888\uff0c\u5b9e\u73b0\u4e86\u8d28\u7684\u98de\u8dc3</li> </ul>"},{"location":"memory-allocator-optimization/#_28","title":"\u6280\u672f\u8def\u7ebf\u7684\u6b63\u786e\u6027\u9a8c\u8bc1","text":"<p>\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u6839\u56e0\u5206\u6790\uff0c\u6211\u4eec\u51c6\u786e\u8bc6\u522b\u4e86\u6027\u80fd\u74f6\u9888\u5e76\u9009\u62e9\u4e86\u6b63\u786e\u7684\u6280\u672f\u65b9\u6848\u3002\u6bcf\u4e2a\u9636\u6bb5\u90fd\u6709\u660e\u786e\u7684\u76ee\u6807\u548c\u53ef\u8861\u91cf\u7684\u6210\u679c\u3002</p>"},{"location":"memory-allocator-optimization/#_29","title":"\u5b9e\u7528\u4ef7\u503c","text":"<p>Genesis\u73b0\u5728\u5728\u5927\u90e8\u5206\u5b9e\u9645\u573a\u666f\u4e0b\u90fd\u80fd\u63d0\u4f9b\u53ef\u63a5\u53d7\u7684\u5185\u5b58\u5206\u914d\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u8fd9\u7c7b\u5173\u952e\u573a\u666f\u4e0b\u5df2\u7ecf\u5177\u5907\u4e86\u7ade\u4e89\u529b\u3002</p> <p>\u5f53\u7136\uff0c\u8fd9\u53ea\u662f\u5185\u5b58\u7ba1\u7406\u4f18\u5316\u7684\u4e00\u4e2a\u9636\u6bb5\u6027\u6210\u679c\u3002\u672a\u6765\u8fd8\u53ef\u4ee5\u8003\u8651\u66f4\u591a\u4f18\u5316\u65b9\u5411\uff0c\u6bd4\u5982\u591a\u6d41\u5e76\u53d1\u3001NUMA\u611f\u77e5\u3001\u6216\u8005\u9488\u5bf9\u7279\u5b9a\u6a21\u578b\u7684\u4e13\u95e8\u4f18\u5316\u7b49\u3002</p>"},{"location":"api/autograd/","title":"\u81ea\u52a8\u5fae\u5206\u7cfb\u7edf (genesis.autograd)","text":""},{"location":"api/autograd/#_1","title":"\u6982\u8ff0","text":"<p>\u81ea\u52a8\u5fae\u5206\u7cfb\u7edf\u662fGenesis\u7684\u6838\u5fc3\uff0c\u63d0\u4f9b\u52a8\u6001\u8ba1\u7b97\u56fe\u6784\u5efa\u548c\u81ea\u52a8\u68af\u5ea6\u8ba1\u7b97\u3002\u5b83\u5b9e\u73b0\u4e86\u53cd\u5411\u6a21\u5f0f\u81ea\u52a8\u5fae\u5206\uff08\u53cd\u5411\u4f20\u64ad\uff09\uff0c\u652f\u6301\u590d\u6742\u7684\u8ba1\u7b97\u56fe\u3002</p>"},{"location":"api/autograd/#_2","title":"\u6838\u5fc3\u6982\u5ff5","text":""},{"location":"api/autograd/#_3","title":"\u8ba1\u7b97\u56fe","text":"<p>Genesis\u5728\u6267\u884c\u64cd\u4f5c\u65f6\u6784\u5efa\u52a8\u6001\u8ba1\u7b97\u56fe\u3002\u6bcf\u4e2a\u64cd\u4f5c\u5728\u56fe\u4e2d\u521b\u5efa\u8282\u70b9\uff0c\u7528\u4e8e\u8ffd\u8e2a\uff1a - \u8f93\u5165\u5f20\u91cf - \u6267\u884c\u7684\u64cd\u4f5c - \u8f93\u51fa\u5f20\u91cf - \u7528\u4e8e\u53cd\u5411\u4f20\u64ad\u7684\u68af\u5ea6\u51fd\u6570</p>"},{"location":"api/autograd/#_4","title":"\u68af\u5ea6\u8ba1\u7b97","text":"<p>\u68af\u5ea6\u4f7f\u7528\u94fe\u5f0f\u6cd5\u5219\u8ba1\u7b97\uff0c\u4ece\u8f93\u51fa\u5230\u8f93\u5165\u53cd\u5411\u904d\u5386\u8ba1\u7b97\u56fe\u3002</p>"},{"location":"api/autograd/#_5","title":"\u4e3b\u8981\u7c7b","text":""},{"location":"api/autograd/#genesistensor","title":"<code>genesis.Tensor</code>","text":"<p>Genesis\u4e2d\u652f\u6301\u81ea\u52a8\u5fae\u5206\u7684\u57fa\u7840\u6570\u636e\u7ed3\u6784\u3002</p> Python<pre><code>class Tensor:\n    def __init__(\n        self,\n        array: Union[list, np.ndarray, NDArray],\n        device: Optional[Device] = None,\n        dtype: Optional[DType] = None,\n        requires_grad: bool = False,\n        **kwargs\n    )\n</code></pre>"},{"location":"api/autograd/#_6","title":"\u53c2\u6570","text":"\u53c2\u6570 \u7c7b\u578b \u9ed8\u8ba4\u503c \u63cf\u8ff0 <code>array</code> array-like required \u8f93\u5165\u6570\u636e\uff08\u5217\u8868\u3001numpy\u6570\u7ec4\u6216NDArray\uff09 <code>device</code> Device <code>None</code> \u8ba1\u7b97\u8bbe\u5907\uff08cpu/cuda\uff09 <code>dtype</code> DType <code>None</code> \u6570\u636e\u7c7b\u578b\uff08\u5982\u679c\u4e3aNone\u5219\u63a8\u65ad\uff09 <code>requires_grad</code> bool <code>False</code> \u662f\u5426\u8ba1\u7b97\u68af\u5ea6 <code>**kwargs</code> dict <code>{}</code> \u989d\u5916\u7684NDArray\u53c2\u6570"},{"location":"api/autograd/#_7","title":"\u6570\u636e\u7c7b\u578b\u63a8\u65ad","text":"<p>Genesis\u81ea\u52a8\u63a8\u65ad\u6570\u636e\u7c7b\u578b\uff0c\u9075\u5faaPyTorch\u7ea6\u5b9a\uff1a</p> Python<pre><code># \u6807\u91cf\u7c7b\u578b\u63a8\u65ad\ngenesis.tensor(42)        # \u2192 genesis.int64 (Python\u6574\u6570)\ngenesis.tensor(3.14)      # \u2192 genesis.float32 (Python\u6d6e\u70b9\u6570) \ngenesis.tensor(True)      # \u2192 genesis.bool (Python\u5e03\u5c14\u503c)\n\n# \u5217\u8868/\u6570\u7ec4\u63a8\u65ad\ngenesis.tensor([1, 2, 3])           # \u2192 genesis.int64 (\u6574\u6570\u5217\u8868)\ngenesis.tensor([1.0, 2.0, 3.0])     # \u2192 genesis.float32 (\u6d6e\u70b9\u6570\u5217\u8868)\ngenesis.tensor(np.array([1, 2]))    # \u2192 \u4fdd\u6301numpy\u6570\u636e\u7c7b\u578b\uff08\u5e26\u8f6c\u6362\uff09\n\n# \u663e\u5f0f\u6570\u636e\u7c7b\u578b\u6307\u5b9a\ngenesis.tensor([1, 2, 3], dtype=genesis.float32)  # \u2192 genesis.float32\n</code></pre> <p>\u6570\u636e\u7c7b\u578b\u8f6c\u6362\u89c4\u5219\uff1a - <code>numpy.float64</code> \u2192 <code>genesis.float32</code> \uff08\u4e0ePyTorch\u9ed8\u8ba4\u503c\u4fdd\u6301\u4e00\u81f4\uff09 - \u6574\u6570\u7c7b\u578b\u88ab\u4fdd\u7559\uff1a<code>np.int32</code> \u2192 <code>genesis.int32</code>\u7b49 - \u5e03\u5c14\u7c7b\u578b\u88ab\u4fdd\u7559\uff1a<code>np.bool_</code> \u2192 <code>genesis.bool</code></p>"},{"location":"api/autograd/#_8","title":"\u5c5e\u6027","text":""},{"location":"api/autograd/#_9","title":"\u5f62\u72b6\u548c\u7c7b\u578b\u4fe1\u606f","text":"Python<pre><code>@property\ndef shape(self) -&gt; Tuple[int, ...]:\n    \"\"\"\u8fd4\u56de\u5f20\u91cf\u7684\u5f62\u72b6\u3002\"\"\"\n\n@property\ndef dtype(self) -&gt; DType:\n    \"\"\"\u8fd4\u56de\u6570\u636e\u7c7b\u578b\u3002\"\"\"\n\n@property\ndef device(self) -&gt; Device:\n    \"\"\"\u8fd4\u56de\u8bbe\u5907\u3002\"\"\"\n\n@property\ndef ndim(self) -&gt; int:\n    \"\"\"\u8fd4\u56de\u7ef4\u5ea6\u6570\u91cf\u3002\"\"\"\n\n@property\ndef size(self) -&gt; int:\n    \"\"\"\u8fd4\u56de\u5143\u7d20\u603b\u6570\u3002\"\"\"\n</code></pre>"},{"location":"api/autograd/#_10","title":"\u68af\u5ea6\u5c5e\u6027","text":"Python<pre><code>@property\ndef requires_grad(self) -&gt; bool:\n    \"\"\"\u6b64\u5f20\u91cf\u662f\u5426\u9700\u8981\u68af\u5ea6\u8ba1\u7b97\u3002\"\"\"\n\n@property\ndef grad(self) -&gt; Optional[Tensor]:\n    \"\"\"\u8bbf\u95ee\u68af\u5ea6\u5f20\u91cf\u3002\"\"\"\n\n@property\ndef is_leaf(self) -&gt; bool:\n    \"\"\"\u662f\u5426\u662f\u53f6\u8282\u70b9\uff08\u7528\u6237\u521b\u5efa\u7684\u5f20\u91cf\uff09\u3002\"\"\"\n\n@property\ndef grad_fn(self) -&gt; Optional[Function]:\n    \"\"\"\u521b\u5efa\u6b64\u5f20\u91cf\u7684\u51fd\u6570\u3002\"\"\"\n</code></pre>"},{"location":"api/autograd/#_11","title":"\u6838\u5fc3\u65b9\u6cd5","text":""},{"location":"api/autograd/#_12","title":"\u68af\u5ea6\u64cd\u4f5c","text":"Python<pre><code>def backward(self, gradient: Optional[Tensor] = None) -&gt; None:\n    \"\"\"\n    \u901a\u8fc7\u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\u68af\u5ea6\u3002\n\n    \u53c2\u6570:\n        gradient: \u8f93\u51fa\u68af\u5ea6\u3002\u5bf9\u4e8e\u6807\u91cf\u9ed8\u8ba4\u4e3atensor([1.0])\u3002\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.tensor([1., 2., 3.], requires_grad=True)\n        &gt;&gt;&gt; y = (x ** 2).sum()\n        &gt;&gt;&gt; y.backward()\n        &gt;&gt;&gt; print(x.grad)  # tensor([2., 4., 6.])\n    \"\"\"\n\ndef detach(self) -&gt; Tensor:\n    \"\"\"\n    \u8fd4\u56de\u4ece\u8ba1\u7b97\u56fe\u5206\u79bb\u7684\u65b0\u5f20\u91cf\u3002\n\n    \u8fd4\u56de:\n        requires_grad=False\u7684\u5f20\u91cf\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.tensor([1., 2.], requires_grad=True)\n        &gt;&gt;&gt; y = x.detach()\n        &gt;&gt;&gt; print(y.requires_grad)  # False\n    \"\"\"\n\ndef retain_grad(self) -&gt; None:\n    \"\"\"\n    \u4e3a\u975e\u53f6\u5f20\u91cf\u542f\u7528\u68af\u5ea6\u4fdd\u6301\u3002\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.tensor([1., 2.], requires_grad=True)\n        &gt;&gt;&gt; y = x * 2  # \u975e\u53f6\u5f20\u91cf\n        &gt;&gt;&gt; y.retain_grad()\n        &gt;&gt;&gt; z = y.sum()\n        &gt;&gt;&gt; z.backward()\n        &gt;&gt;&gt; print(y.grad)  # tensor([1., 1.])\n    \"\"\"\n\ndef zero_grad(self) -&gt; None:\n    \"\"\"\n    \u5c06\u68af\u5ea6\u5f20\u91cf\u6e05\u96f6\u3002\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.tensor([1., 2.], requires_grad=True)\n        &gt;&gt;&gt; y = x.sum()\n        &gt;&gt;&gt; y.backward()\n        &gt;&gt;&gt; x.zero_grad()\n        &gt;&gt;&gt; print(x.grad)  # None\n    \"\"\"\n</code></pre>"},{"location":"api/autograd/#_13","title":"\u5f20\u91cf\u64cd\u4f5c","text":"<p>\u6240\u6709\u6807\u51c6\u6570\u5b66\u64cd\u4f5c\u90fd\u88ab\u652f\u6301\u5e76\u81ea\u52a8\u8ffd\u8e2a\u68af\u5ea6\u8ba1\u7b97\uff1a</p> Python<pre><code># \u7b97\u672f\u64cd\u4f5c\nz = x + y          # \u52a0\u6cd5\nz = x - y          # \u51cf\u6cd5\nz = x * y          # \u4e58\u6cd5\nz = x / y          # \u9664\u6cd5\nz = x ** y         # \u5e42\u8fd0\u7b97\nz = x @ y          # \u77e9\u9635\u4e58\u6cd5\n\n# \u4e00\u5143\u64cd\u4f5c\nz = -x             # \u53d6\u8d1f\nz = x.abs()        # \u7edd\u5bf9\u503c\nz = x.exp()        # \u6307\u6570\nz = x.log()        # \u81ea\u7136\u5bf9\u6570\nz = x.sqrt()       # \u5e73\u65b9\u6839\nz = x.sin()        # \u6b63\u5f26\nz = x.cos()        # \u4f59\u5f26\nz = x.tanh()       # \u53cc\u66f2\u6b63\u5207\n\n# \u5f52\u7ea6\u64cd\u4f5c\uff08PyTorch\u98ce\u683c\u63a5\u53e3\uff09\nz = x.sum()              # \u5bf9\u6240\u6709\u5143\u7d20\u6c42\u548c\nz = x.sum(dim=0)         # \u6cbf\u7b2c0\u7ef4\u6c42\u548c\nz = x.sum(dim=1, keepdim=True)  # \u6cbf\u7b2c1\u7ef4\u6c42\u548c\uff0c\u4fdd\u6301\u7ef4\u5ea6\n\nz = x.mean()             # \u6240\u6709\u5143\u7d20\u7684\u5e73\u5747\u503c\nz = x.mean(dim=0)        # \u6cbf\u7b2c0\u7ef4\u6c42\u5e73\u5747\u503c\nz = x.mean(dim=1, keepdim=True) # \u6cbf\u7b2c1\u7ef4\u6c42\u5e73\u5747\u503c\uff0c\u4fdd\u6301\u7ef4\u5ea6\n\nz = x.max()              # \u6700\u5927\u5143\u7d20\nz = x.max(dim=0)         # \u6cbf\u7b2c0\u7ef4\u6c42\u6700\u5927\u503c\nz = x.max(dim=1, keepdim=True)  # \u6cbf\u7b2c1\u7ef4\u6c42\u6700\u5927\u503c\uff0c\u4fdd\u6301\u7ef4\u5ea6\n\n# \u4e5f\u652f\u6301NumPy\u98ce\u683c\u53c2\u6570\uff08\u517c\u5bb9\u6027\uff09\nz = x.sum(axis=0, keepdims=True)    # NumPy\u98ce\u683c\uff08axis, keepdims\uff09\nz = x.mean(axis=1, keepdims=False)  # NumPy\u98ce\u683c\u63a5\u53e3\n\n# \u5f62\u72b6\u64cd\u4f5c\nz = x.reshape(shape)      # \u91cd\u5851\nz = x.transpose(dims)     # \u8f6c\u7f6e\nz = x.squeeze()           # \u79fb\u9664\u5355\u7ef4\u5ea6\nz = x.unsqueeze(dim)      # \u6dfb\u52a0\u5355\u7ef4\u5ea6\nz = x.view(shape)         # \u4ee5\u4e0d\u540c\u5f62\u72b6\u67e5\u770b\n</code></pre>"},{"location":"api/autograd/#genesisfunction","title":"<code>genesis.Function</code>","text":"<p>\u6240\u6709\u53ef\u5fae\u5206\u64cd\u4f5c\u7684\u57fa\u7c7b\u3002</p> Python<pre><code>class Function:\n    \"\"\"\n    \u5b9e\u73b0\u81ea\u5b9a\u4e49\u53ef\u5fae\u5206\u64cd\u4f5c\u7684\u57fa\u7c7b\u3002\n    \"\"\"\n\n    @staticmethod\n    def forward(ctx: Context, *args, **kwargs) -&gt; Tensor:\n        \"\"\"\n        \u524d\u5411\u4f20\u64ad\u5b9e\u73b0\u3002\n\n        \u53c2\u6570:\n            ctx: \u7528\u4e8e\u4e3a\u540e\u5411\u4f20\u64ad\u4fdd\u5b58\u4fe1\u606f\u7684\u4e0a\u4e0b\u6587\u5bf9\u8c61\n            *args: \u8f93\u5165\u5f20\u91cf\n            **kwargs: \u989d\u5916\u53c2\u6570\n\n        \u8fd4\u56de:\n            \u8f93\u51fa\u5f20\u91cf\n        \"\"\"\n        raise NotImplementedError\n\n    @staticmethod\n    def backward(ctx: Context, *grad_outputs) -&gt; Tuple[Optional[Tensor], ...]:\n        \"\"\"\n        \u540e\u5411\u4f20\u64ad\u5b9e\u73b0\u3002\n\n        \u53c2\u6570:\n            ctx: \u5305\u542b\u4fdd\u5b58\u4fe1\u606f\u7684\u4e0a\u4e0b\u6587\u5bf9\u8c61\n            *grad_outputs: \u76f8\u5bf9\u4e8e\u8f93\u51fa\u7684\u68af\u5ea6\n\n        \u8fd4\u56de:\n            \u76f8\u5bf9\u4e8e\u8f93\u5165\u7684\u68af\u5ea6\uff08\u5bf9\u4e8e\u4e0d\u53ef\u5fae\u5206\u8f93\u5165\u4e3aNone\uff09\n        \"\"\"\n        raise NotImplementedError\n\n    @classmethod\n    def apply(cls, *args, **kwargs) -&gt; Tensor:\n        \"\"\"\n        \u5e94\u7528\u51fd\u6570\u5e76\u5728\u8ba1\u7b97\u56fe\u4e2d\u6ce8\u518c\u3002\n        \"\"\"\n</code></pre>"},{"location":"api/autograd/#_14","title":"\u81ea\u5b9a\u4e49\u51fd\u6570\u793a\u4f8b","text":"Python<pre><code>import genesis\nfrom genesis import Function\n\nclass Exp(Function):\n    @staticmethod\n    def forward(ctx, x):\n        # \u4e3a\u540e\u5411\u4f20\u64ad\u4fdd\u5b58\u8f93\u5165\n        ctx.save_for_backward(x)\n        return genesis.tensor(x.data.exp(), requires_grad=x.requires_grad)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        # \u68c0\u7d22\u4fdd\u5b58\u7684\u5f20\u91cf\n        x, = ctx.saved_tensors\n        # exp(x)\u7684\u68af\u5ea6\u662fexp(x)\n        return grad_output * x.exp()\n\n# \u4f7f\u7528\nexp = Exp.apply\nx = genesis.tensor([1., 2., 3.], requires_grad=True)\ny = exp(x)\ny.sum().backward()\nprint(x.grad)  # \u901a\u8fc7\u81ea\u5b9a\u4e49\u51fd\u6570\u8ba1\u7b97\u7684\u68af\u5ea6\n</code></pre>"},{"location":"api/autograd/#_15","title":"\u4e0a\u4e0b\u6587\u7ba1\u7406","text":""},{"location":"api/autograd/#genesisno_grad","title":"<code>genesis.no_grad()</code>","text":"<p>\u5728\u63a8\u7406\u65f6\u7981\u7528\u68af\u5ea6\u8ba1\u7b97\u4ee5\u63d0\u9ad8\u6548\u7387\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u3002</p> Python<pre><code>with genesis.no_grad():\n    # \u8fd9\u91cc\u7684\u64cd\u4f5c\u4e0d\u4f1a\u6784\u5efa\u8ba1\u7b97\u56fe\n    y = model(x)  # \u4e0d\u8ba1\u7b97\u68af\u5ea6\n</code></pre>"},{"location":"api/autograd/#genesisenable_grad","title":"<code>genesis.enable_grad()</code>","text":"<p>\u542f\u7528\u68af\u5ea6\u8ba1\u7b97\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\uff08\u5728no_grad\u4e0a\u4e0b\u6587\u4e2d\u6709\u7528\uff09\u3002</p> Python<pre><code>with genesis.no_grad():\n    # \u5927\u591a\u6570\u64cd\u4f5c\u4e0d\u9700\u8981\u68af\u5ea6\n    y = model(x)\n\n    with genesis.enable_grad():\n        # \u8fd9\u4e2a\u7279\u5b9a\u64cd\u4f5c\u9700\u8981\u68af\u5ea6\n        z = y.sum()\n        z.backward()\n</code></pre>"},{"location":"api/autograd/#genesisset_grad_enabledmode-bool","title":"<code>genesis.set_grad_enabled(mode: bool)</code>","text":"<p>\u5168\u5c40\u542f\u7528\u6216\u7981\u7528\u68af\u5ea6\u8ba1\u7b97\u3002</p> Python<pre><code>genesis.set_grad_enabled(False)  # \u5168\u5c40\u7981\u7528\ny = x * 2  # \u65e0\u68af\u5ea6\n\ngenesis.set_grad_enabled(True)   # \u5168\u5c40\u542f\u7528\nz = x * 2  # \u8ba1\u7b97\u68af\u5ea6\n</code></pre>"},{"location":"api/autograd/#_16","title":"\u68af\u5ea6\u94a9\u5b50","text":""},{"location":"api/autograd/#_17","title":"\u524d\u7f6e\u548c\u540e\u7f6e\u94a9\u5b50","text":"<p>\u6ce8\u518c\u5728\u540e\u5411\u4f20\u64ad\u671f\u95f4\u8c03\u7528\u7684\u51fd\u6570\uff1a</p> Python<pre><code>def print_grad(grad):\n    print(f\"\u68af\u5ea6: {grad}\")\n    return grad  # \u53ef\u4ee5\u5728\u8fd9\u91cc\u4fee\u6539\u68af\u5ea6\n\nx = genesis.tensor([1., 2., 3.], requires_grad=True)\nx.register_hook(print_grad)\ny = (x ** 2).sum()\ny.backward()  # \u5728\u540e\u5411\u4f20\u64ad\u671f\u95f4\u6253\u5370\u68af\u5ea6\n</code></pre>"},{"location":"api/autograd/#_18","title":"\u5185\u5b58\u7ba1\u7406","text":""},{"location":"api/autograd/#_19","title":"\u68af\u5ea6\u7d2f\u79ef","text":"<p>\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u68af\u5ea6\u4f1a\u5728\u591a\u6b21\u540e\u5411\u4f20\u64ad\u4e2d\u7d2f\u79ef\uff1a</p> Python<pre><code>x = genesis.tensor([1., 2.], requires_grad=True)\n\ny1 = x.sum()\ny1.backward()\nprint(x.grad)  # tensor([1., 1.])\n\ny2 = (x * 2).sum()\ny2.backward()\nprint(x.grad)  # tensor([3., 3.]) - \u7d2f\u79ef\u4e86\uff01\n</code></pre>"},{"location":"api/autograd/#_20","title":"\u6e05\u9664\u68af\u5ea6","text":"Python<pre><code># \u5728\u65b0\u8ba1\u7b97\u524d\u6e05\u9664\u68af\u5ea6\nx.grad = None  # \u6216 x.zero_grad()\n</code></pre>"},{"location":"api/autograd/#_21","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"api/autograd/#1","title":"1. \u9ad8\u6548\u63a8\u7406","text":"<p>\u5728\u63a8\u7406\u65f6\u59cb\u7ec8\u4f7f\u7528<code>no_grad()</code>\u4e0a\u4e0b\u6587\uff1a</p> Python<pre><code>model.eval()\nwith genesis.no_grad():\n    predictions = model(test_data)\n</code></pre>"},{"location":"api/autograd/#2","title":"2. \u5185\u5b58\u4f18\u5316","text":"<p>\u5f53\u4e0d\u9700\u8981\u68af\u5ea6\u65f6\uff0c\u5206\u79bb\u4e2d\u95f4\u7ed3\u679c\uff1a</p> Python<pre><code># \u4e0d\u9700\u8981running_mean\u7684\u68af\u5ea6\nrunning_mean = (alpha * running_mean.detach() + \n                (1 - alpha) * batch_mean)\n</code></pre>"},{"location":"api/autograd/#3","title":"3. \u68af\u5ea6\u88c1\u526a","text":"<p>\u9632\u6b62\u68af\u5ea6\u7206\u70b8\uff1a</p> Python<pre><code>genesis.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n</code></pre>"},{"location":"api/autograd/#4","title":"4. \u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3","text":"<p>\u4f7f\u7528\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6\u52a0\u901f\u8bad\u7ec3\uff1a</p> Python<pre><code>genesis.enable_autocast = True\nwith genesis.autocast():\n    output = model(input)\n    loss = criterion(output, target)\n</code></pre>"},{"location":"api/autograd/#_22","title":"\u5e38\u89c1\u6a21\u5f0f","text":""},{"location":"api/autograd/#_23","title":"\u8bad\u7ec3\u5faa\u73af","text":"Python<pre><code>model = MyModel()\noptimizer = genesis.optim.Adam(model.parameters())\n\nfor epoch in range(num_epochs):\n    for batch in dataloader:\n        # \u524d\u5411\u4f20\u64ad\n        outputs = model(batch.inputs)\n        loss = criterion(outputs, batch.targets)\n\n        # \u540e\u5411\u4f20\u64ad\n        optimizer.zero_grad()\n        loss.backward()\n\n        # \u66f4\u65b0\u6743\u91cd\n        optimizer.step()\n</code></pre>"},{"location":"api/autograd/#_24","title":"\u68af\u5ea6\u68c0\u67e5\u70b9","text":"<p>\u901a\u8fc7\u91cd\u8ba1\u7b97\u6fc0\u6d3b\u8282\u7701\u5185\u5b58\uff1a</p> Python<pre><code># \u672a\u6765\u7248\u672c\u4e2d\u63d0\u4f9b\nfrom genesis.utils.checkpoint import checkpoint\n\ndef forward(self, x):\n    # \u68c0\u67e5\u70b9\u4e2d\u95f4\u8ba1\u7b97\n    x = checkpoint(self.layer1, x)\n    x = checkpoint(self.layer2, x)\n    return self.layer3(x)\n</code></pre>"},{"location":"api/autograd/#_25","title":"\u8c03\u8bd5","text":""},{"location":"api/autograd/#_26","title":"\u68af\u5ea6\u68c0\u67e5","text":"<p>\u4f7f\u7528\u6570\u503c\u5fae\u5206\u9a8c\u8bc1\u68af\u5ea6\uff1a</p> Python<pre><code>from genesis.autograd import gradcheck\n\ndef func(x):\n    return (x ** 2).sum()\n\nx = genesis.tensor([1., 2., 3.], requires_grad=True)\ngradcheck(func, x, eps=1e-6)  # \u5982\u679c\u68af\u5ea6\u6b63\u786e\u8fd4\u56deTrue\n</code></pre>"},{"location":"api/autograd/#_27","title":"\u68c0\u67e5\u8ba1\u7b97\u56fe","text":"Python<pre><code># \u6253\u5370\u8ba1\u7b97\u56fe\u7ed3\u6784\ny = x * 2 + 3\nprint(y.grad_fn)  # &lt;AddBackward&gt;\nprint(y.grad_fn.next_functions)  # \u8fde\u63a5\u7684\u64cd\u4f5c\n</code></pre>"},{"location":"api/autograd/#_28","title":"\u6027\u80fd\u63d0\u793a","text":"<ol> <li>\u91cd\u7528\u5f20\u91cf: \u907f\u514d\u4e0d\u5fc5\u8981\u5730\u521b\u5efa\u65b0\u5f20\u91cf</li> <li>\u539f\u5730\u64cd\u4f5c: \u5c3d\u53ef\u80fd\u4f7f\u7528\uff08\u5982<code>x.add_(y)</code>\uff09</li> <li>\u6279\u91cf\u64cd\u4f5c: \u540c\u65f6\u5904\u7406\u591a\u4e2a\u6837\u672c</li> <li>\u7981\u7528\u68af\u5ea6: \u63a8\u7406\u65f6\u4f7f\u7528<code>no_grad()</code></li> <li>\u6e05\u9664\u68af\u5ea6: \u6bcf\u6b21\u540e\u5411\u4f20\u64ad\u524d\u5c06\u68af\u5ea6\u6e05\u96f6</li> </ol>"},{"location":"api/autograd/#_29","title":"\u53e6\u8bf7\u53c2\u9605","text":"<ul> <li>\u795e\u7ecf\u7f51\u7edc\u6a21\u5757 - \u4f7f\u7528Genesis\u6784\u5efa\u6a21\u578b</li> <li>\u4f18\u5316\u5668 - \u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u8bad\u7ec3</li> <li>\u5f20\u91cf\u64cd\u4f5c - \u4f4e\u7ea7\u5f20\u91cf\u64cd\u4f5c</li> <li>\u793a\u4f8b - \u5b8c\u6574\u5de5\u4f5c\u793a\u4f8b</li> </ul>"},{"location":"api/serialization/","title":"\u6a21\u578b\u5e8f\u5217\u5316\u4e0e\u68c0\u67e5\u70b9","text":"<p>Genesis\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u6a21\u578b\u5e8f\u5217\u5316\u548c\u68c0\u67e5\u70b9\u529f\u80fd\uff0c\u7528\u4e8e\u4fdd\u5b58\u548c\u52a0\u8f7d\u6a21\u578b\u72b6\u6001\u3001\u4f18\u5316\u5668\u72b6\u6001\u548c\u8bad\u7ec3\u8fdb\u5ea6\u3002\u8fd9\u5bf9\u4e8e\u957f\u65f6\u95f4\u8bad\u7ec3\u3001\u6a21\u578b\u90e8\u7f72\u548c\u5b9e\u9a8c\u53ef\u91cd\u73b0\u6027\u81f3\u5173\u91cd\u8981\u3002</p>"},{"location":"api/serialization/#_2","title":"\u6982\u8ff0","text":"<p>Genesis\u4e2d\u7684\u5e8f\u5217\u5316\u7cfb\u7edf\u5904\u7406\uff1a - \u6a21\u578b\u72b6\u6001\u5b57\u5178\uff08\u53c2\u6570\u548c\u7f13\u51b2\u533a\uff09 - \u4f18\u5316\u5668\u72b6\u6001\uff08\u52a8\u91cf\u3001\u8fd0\u884c\u5e73\u5747\u503c\u7b49\uff09 - \u8bad\u7ec3\u5143\u6570\u636e\uff08epoch\u3001\u635f\u5931\u3001\u6307\u6807\uff09 - \u539f\u5b50\u5199\u64cd\u4f5c\u548c\u5b89\u5168\u5907\u4efd</p>"},{"location":"api/serialization/#_3","title":"\u6838\u5fc3\u51fd\u6570","text":""},{"location":"api/serialization/#save","title":"save()","text":"Python<pre><code>import genesis\n\ndef save(state_dict, file_path):\n    \"\"\"\n    \u5c06\u72b6\u6001\u5b57\u5178\u4fdd\u5b58\u5230\u6587\u4ef6\uff0c\u4f7f\u7528\u539f\u5b50\u5199\u64cd\u4f5c\u3002\n\n    Args:\n        state_dict (dict): \u5305\u542b\u8981\u4fdd\u5b58\u72b6\u6001\u7684\u5b57\u5178\n        file_path (str): \u4fdd\u5b58\u6587\u4ef6\u7684\u8def\u5f84\n\n    Features:\n        - \u539f\u5b50\u5199\u64cd\u4f5c\u4e0e\u5907\u4efd\n        - \u6210\u529f\u65f6\u81ea\u52a8\u6e05\u7406\n        - \u5931\u8d25\u65f6\u56de\u6eda\n        - \u4fdd\u5b58\u540e\u5185\u5b58\u6e05\u7406\n    \"\"\"\n</code></pre>"},{"location":"api/serialization/#load","title":"load()","text":"Python<pre><code>def load(file_path):\n    \"\"\"\n    \u4ece\u6587\u4ef6\u52a0\u8f7d\u72b6\u6001\u5b57\u5178\u3002\n\n    Args:\n        file_path (str): \u4fdd\u5b58\u6587\u4ef6\u7684\u8def\u5f84\n\n    Returns:\n        dict: \u52a0\u8f7d\u7684\u72b6\u6001\u5b57\u5178\n\n    Raises:\n        FileNotFoundError: \u5982\u679c\u6587\u4ef6\u4e0d\u5b58\u5728\n        pickle.UnpicklingError: \u5982\u679c\u6587\u4ef6\u635f\u574f\n    \"\"\"\n</code></pre>"},{"location":"api/serialization/#save_checkpoint","title":"save_checkpoint()","text":"Python<pre><code>def save_checkpoint(model_state_dict, optimizer_state_dict, file_path):\n    \"\"\"\n    \u4fdd\u5b58\u6a21\u578b\u548c\u4f18\u5316\u5668\u68c0\u67e5\u70b9\u3002\n\n    Args:\n        model_state_dict (dict): \u6a21\u578b\u72b6\u6001\u5b57\u5178\n        optimizer_state_dict (dict): \u4f18\u5316\u5668\u72b6\u6001\u5b57\u5178\n        file_path (str): \u4fdd\u5b58\u68c0\u67e5\u70b9\u7684\u8def\u5f84\n\n    \u521b\u5efa\u5305\u542b\u4ee5\u4e0b\u5185\u5bb9\u7684\u68c0\u67e5\u70b9\uff1a\n        - model_state_dict: \u6a21\u578b\u53c2\u6570\u548c\u7f13\u51b2\u533a\n        - optimizer_state_dict: \u4f18\u5316\u5668\u72b6\u6001\n    \"\"\"\n</code></pre>"},{"location":"api/serialization/#load_checkpoint","title":"load_checkpoint()","text":"Python<pre><code>def load_checkpoint(file_path):\n    \"\"\"\n    \u52a0\u8f7d\u6a21\u578b\u548c\u4f18\u5316\u5668\u68c0\u67e5\u70b9\u3002\n\n    Args:\n        file_path (str): \u68c0\u67e5\u70b9\u6587\u4ef6\u8def\u5f84\n\n    Returns:\n        tuple: (model_state_dict, optimizer_state_dict)\n\n    Example:\n        &gt;&gt;&gt; model_state, optimizer_state = genesis.load_checkpoint('checkpoint.pth')\n        &gt;&gt;&gt; model.load_state_dict(model_state)\n        &gt;&gt;&gt; optimizer.load_state_dict(optimizer_state)\n    \"\"\"\n</code></pre>"},{"location":"api/serialization/#_4","title":"\u57fa\u672c\u7528\u6cd5","text":""},{"location":"api/serialization/#_5","title":"\u4fdd\u5b58\u7b80\u5355\u6a21\u578b","text":"Python<pre><code>import genesis\nimport genesis.nn as nn\n\n# \u521b\u5efa\u548c\u8bad\u7ec3\u6a21\u578b\nmodel = nn.Linear(784, 10)\n\n# \u4fdd\u5b58\u6a21\u578b\u72b6\u6001\ngenesis.save(model.state_dict(), 'model.pth')\n\n# \u52a0\u8f7d\u6a21\u578b\u72b6\u6001\nstate_dict = genesis.load('model.pth')\nmodel.load_state_dict(state_dict)\n</code></pre>"},{"location":"api/serialization/#_6","title":"\u8bad\u7ec3\u68c0\u67e5\u70b9","text":"Python<pre><code>import genesis\nimport genesis.nn as nn\nimport genesis.optim as optim\n\n# \u8bbe\u7f6e\u6a21\u578b\u548c\u4f18\u5316\u5668\nmodel = nn.Sequential(\n    nn.Linear(784, 256),\n    nn.ReLU(),\n    nn.Linear(256, 10)\n)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# \u5e26\u68c0\u67e5\u70b9\u7684\u8bad\u7ec3\u5faa\u73af\nfor epoch in range(100):\n    # \u8bad\u7ec3\u4ee3\u7801...\n    train_loss = train_one_epoch(model, train_loader, optimizer)\n\n    # \u6bcf10\u4e2aepoch\u4fdd\u5b58\u68c0\u67e5\u70b9\n    if epoch % 10 == 0:\n        genesis.save_checkpoint(\n            model.state_dict(),\n            optimizer.state_dict(), \n            f'checkpoint_epoch_{epoch}.pth'\n        )\n        print(f\"\u68c0\u67e5\u70b9\u5df2\u4fdd\u5b58\u5728epoch {epoch}\")\n\n# \u52a0\u8f7d\u68c0\u67e5\u70b9\u6062\u590d\u8bad\u7ec3\nmodel_state, optimizer_state = genesis.load_checkpoint('checkpoint_epoch_90.pth')\nmodel.load_state_dict(model_state)\noptimizer.load_state_dict(optimizer_state)\n</code></pre>"},{"location":"api/serialization/#_7","title":"\u9ad8\u7ea7\u68c0\u67e5\u70b9","text":""},{"location":"api/serialization/#_8","title":"\u5b8c\u6574\u8bad\u7ec3\u72b6\u6001","text":"Python<pre><code>import genesis\n\ndef save_training_checkpoint(model, optimizer, scheduler, epoch, loss, metrics, file_path):\n    \"\"\"\u4fdd\u5b58\u5b8c\u6574\u8bad\u7ec3\u72b6\u6001\u3002\"\"\"\n    checkpoint = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n        'loss': loss,\n        'metrics': metrics,\n        'model_config': {\n            'input_size': model.input_size,\n            'hidden_size': model.hidden_size,\n            'num_classes': model.num_classes\n        }\n    }\n    genesis.save(checkpoint, file_path)\n\ndef load_training_checkpoint(file_path):\n    \"\"\"\u52a0\u8f7d\u5b8c\u6574\u8bad\u7ec3\u72b6\u6001\u3002\"\"\"\n    return genesis.load(file_path)\n\n# \u7528\u6cd5\nsave_training_checkpoint(\n    model, optimizer, scheduler, \n    epoch=50, loss=0.234, \n    metrics={'accuracy': 0.94, 'f1': 0.91},\n    file_path='complete_checkpoint.pth'\n)\n\n# \u6062\u590d\u8bad\u7ec3\ncheckpoint = load_training_checkpoint('complete_checkpoint.pth')\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nif checkpoint['scheduler_state_dict']:\n    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n\nstart_epoch = checkpoint['epoch'] + 1\nprint(f\"\u4eceepoch {start_epoch}\u6062\u590d\u8bad\u7ec3\uff0c\u635f\u5931: {checkpoint['loss']}\")\n</code></pre>"},{"location":"api/serialization/#_9","title":"\u6700\u4f73\u6a21\u578b\u8ddf\u8e2a","text":"Python<pre><code>import genesis\n\nclass ModelCheckpointer:\n    def __init__(self, save_dir='checkpoints'):\n        self.save_dir = save_dir\n        self.best_loss = float('inf')\n        self.best_accuracy = 0.0\n\n    def save_checkpoint(self, model, optimizer, epoch, loss, accuracy, is_best=False):\n        \"\"\"\u4fdd\u5b58\u68c0\u67e5\u70b9\u5e76\u8ddf\u8e2a\u6700\u4f73\u6a21\u578b\u3002\"\"\"\n        checkpoint = {\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': loss,\n            'accuracy': accuracy\n        }\n\n        # \u4fdd\u5b58\u5e38\u89c4\u68c0\u67e5\u70b9\n        checkpoint_path = f'{self.save_dir}/checkpoint_epoch_{epoch}.pth'\n        genesis.save(checkpoint, checkpoint_path)\n\n        # \u57fa\u4e8e\u635f\u5931\u4fdd\u5b58\u6700\u4f73\u6a21\u578b\n        if loss &lt; self.best_loss:\n            self.best_loss = loss\n            best_loss_path = f'{self.save_dir}/best_loss_model.pth'\n            genesis.save(checkpoint, best_loss_path)\n            print(f\"\u65b0\u7684\u6700\u4f73\u635f\u5931: {loss:.4f}\")\n\n        # \u57fa\u4e8e\u51c6\u786e\u7387\u4fdd\u5b58\u6700\u4f73\u6a21\u578b\n        if accuracy &gt; self.best_accuracy:\n            self.best_accuracy = accuracy\n            best_acc_path = f'{self.save_dir}/best_accuracy_model.pth'\n            genesis.save(checkpoint, best_acc_path)\n            print(f\"\u65b0\u7684\u6700\u4f73\u51c6\u786e\u7387: {accuracy:.4f}\")\n\n    def load_best_model(self, model, metric='loss'):\n        \"\"\"\u52a0\u8f7d\u6700\u4f73\u6a21\u578b\u3002\"\"\"\n        if metric == 'loss':\n            path = f'{self.save_dir}/best_loss_model.pth'\n        elif metric == 'accuracy':\n            path = f'{self.save_dir}/best_accuracy_model.pth'\n        else:\n            raise ValueError(\"metric\u5fc5\u987b\u662f'loss'\u6216'accuracy'\")\n\n        checkpoint = genesis.load(path)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        return checkpoint\n\n# \u7528\u6cd5\ncheckpointer = ModelCheckpointer()\n\nfor epoch in range(100):\n    train_loss = train_one_epoch(model, train_loader, optimizer)\n    val_loss, val_accuracy = validate(model, val_loader)\n\n    checkpointer.save_checkpoint(\n        model, optimizer, epoch, val_loss, val_accuracy\n    )\n</code></pre>"},{"location":"api/serialization/#_10","title":"\u6a21\u578b\u90e8\u7f72","text":""},{"location":"api/serialization/#_11","title":"\u63a8\u7406\u6a21\u578b\u4fdd\u5b58","text":"Python<pre><code>import genesis\n\ndef save_for_inference(model, file_path, model_config=None):\n    \"\"\"\u4fdd\u5b58\u4f18\u5316\u7684\u63a8\u7406\u6a21\u578b\u3002\"\"\"\n    model.eval()  # \u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f\n\n    inference_state = {\n        'model_state_dict': model.state_dict(),\n        'model_config': model_config,\n        'genesis_version': genesis.__version__,\n        'inference_only': True\n    }\n\n    genesis.save(inference_state, file_path)\n\ndef load_for_inference(file_path, model_class):\n    \"\"\"\u52a0\u8f7d\u63a8\u7406\u6a21\u578b\u3002\"\"\"\n    checkpoint = genesis.load(file_path)\n\n    # \u521b\u5efa\u6a21\u578b\u5b9e\u4f8b\n    if 'model_config' in checkpoint and checkpoint['model_config']:\n        model = model_class(**checkpoint['model_config'])\n    else:\n        model = model_class()\n\n    # \u52a0\u8f7d\u72b6\u6001\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.eval()\n\n    return model\n\n# \u4fdd\u5b58\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u7528\u4e8e\u90e8\u7f72\nmodel_config = {\n    'input_size': 784,\n    'hidden_size': 256, \n    'num_classes': 10\n}\n\nsave_for_inference(model, 'deployed_model.pth', model_config)\n\n# \u5728\u751f\u4ea7\u73af\u5883\u4e2d\u52a0\u8f7d\ndeployed_model = load_for_inference('deployed_model.pth', MyModelClass)\n</code></pre>"},{"location":"api/serialization/#_12","title":"\u6a21\u578b\u7248\u672c\u7ba1\u7406","text":"Python<pre><code>import genesis\nimport time\nfrom datetime import datetime\n\nclass VersionedCheckpoint:\n    def __init__(self, base_path='models'):\n        self.base_path = base_path\n\n    def save_version(self, model, optimizer, epoch, metrics, version_name=None):\n        \"\"\"\u4fdd\u5b58\u5e26\u6709\u7248\u672c\u4fe1\u606f\u7684\u6a21\u578b\u3002\"\"\"\n        if version_name is None:\n            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            version_name = f\"v_{timestamp}\"\n\n        checkpoint = {\n            'version': version_name,\n            'timestamp': time.time(),\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'metrics': metrics,\n            'genesis_version': genesis.__version__\n        }\n\n        file_path = f'{self.base_path}/{version_name}.pth'\n        genesis.save(checkpoint, file_path)\n\n        # \u66f4\u65b0\u6700\u65b0\u7248\u672c\u94fe\u63a5\n        latest_path = f'{self.base_path}/latest.pth'\n        genesis.save(checkpoint, latest_path)\n\n        return version_name\n\n    def load_version(self, version_name='latest'):\n        \"\"\"\u52a0\u8f7d\u7279\u5b9a\u7248\u672c\u7684\u6a21\u578b\u3002\"\"\"\n        file_path = f'{self.base_path}/{version_name}.pth'\n        return genesis.load(file_path)\n\n    def list_versions(self):\n        \"\"\"\u5217\u51fa\u53ef\u7528\u7684\u6a21\u578b\u7248\u672c\u3002\"\"\"\n        import os\n        versions = []\n        for file in os.listdir(self.base_path):\n            if file.endswith('.pth') and file != 'latest.pth':\n                versions.append(file[:-4])  # \u79fb\u9664.pth\u6269\u5c55\u540d\n        return sorted(versions)\n\n# \u7528\u6cd5\nversioner = VersionedCheckpoint()\n\n# \u4fdd\u5b58\u65b0\u7248\u672c\nversion = versioner.save_version(\n    model, optimizer, epoch=100, \n    metrics={'accuracy': 0.95, 'loss': 0.15},\n    version_name='model_v1.2'\n)\n\n# \u52a0\u8f7d\u7279\u5b9a\u7248\u672c\ncheckpoint = versioner.load_version('model_v1.2')\n\n# \u52a0\u8f7d\u6700\u65b0\u7248\u672c\nlatest = versioner.load_version('latest')\n</code></pre>"},{"location":"api/serialization/#_13","title":"\u9519\u8bef\u5904\u7406\u548c\u5b89\u5168\u6027","text":""},{"location":"api/serialization/#_14","title":"\u7a33\u5065\u7684\u68c0\u67e5\u70b9\u52a0\u8f7d","text":"Python<pre><code>import genesis\nimport os\n\ndef safe_load_checkpoint(file_path, model, optimizer=None):\n    \"\"\"\u5b89\u5168\u52a0\u8f7d\u68c0\u67e5\u70b9\uff0c\u5e26\u9519\u8bef\u5904\u7406\u3002\"\"\"\n    try:\n        if not os.path.exists(file_path):\n            print(f\"\u8b66\u544a: \u68c0\u67e5\u70b9 {file_path} \u672a\u627e\u5230\")\n            return False\n\n        checkpoint = genesis.load(file_path)\n\n        # \u9a8c\u8bc1\u68c0\u67e5\u70b9\u7ed3\u6784\n        required_keys = ['model_state_dict']\n        for key in required_keys:\n            if key not in checkpoint:\n                print(f\"\u9519\u8bef: \u68c0\u67e5\u70b9\u4e2d\u7f3a\u5c11\u952e '{key}'\")\n                return False\n\n        # \u52a0\u8f7d\u6a21\u578b\u72b6\u6001\n        try:\n            model.load_state_dict(checkpoint['model_state_dict'])\n            print(\"\u6a21\u578b\u72b6\u6001\u52a0\u8f7d\u6210\u529f\")\n        except Exception as e:\n            print(f\"\u52a0\u8f7d\u6a21\u578b\u72b6\u6001\u65f6\u51fa\u9519: {e}\")\n            return False\n\n        # \u5982\u679c\u63d0\u4f9b\u4e86\u4f18\u5316\u5668\uff0c\u5219\u52a0\u8f7d\u4f18\u5316\u5668\u72b6\u6001\n        if optimizer and 'optimizer_state_dict' in checkpoint:\n            try:\n                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n                print(\"\u4f18\u5316\u5668\u72b6\u6001\u52a0\u8f7d\u6210\u529f\")\n            except Exception as e:\n                print(f\"\u8b66\u544a: \u65e0\u6cd5\u52a0\u8f7d\u4f18\u5316\u5668\u72b6\u6001: {e}\")\n\n        # \u8fd4\u56de\u9644\u52a0\u4fe1\u606f\n        epoch = checkpoint.get('epoch', 0)\n        loss = checkpoint.get('loss', 'unknown')\n        print(f\"\u4eceepoch {epoch}\u52a0\u8f7d\u68c0\u67e5\u70b9\uff0c\u635f\u5931: {loss}\")\n\n        return True\n\n    except Exception as e:\n        print(f\"\u52a0\u8f7d\u68c0\u67e5\u70b9\u65f6\u51fa\u9519: {e}\")\n        return False\n\n# \u7528\u6cd5\nsuccess = safe_load_checkpoint('checkpoint.pth', model, optimizer)\nif success:\n    print(\"\u68c0\u67e5\u70b9\u52a0\u8f7d\u6210\u529f\")\nelse:\n    print(\"\u52a0\u8f7d\u68c0\u67e5\u70b9\u5931\u8d25\uff0c\u4ece\u5934\u5f00\u59cb\")\n</code></pre>"},{"location":"api/serialization/#_15","title":"\u68c0\u67e5\u70b9\u9a8c\u8bc1","text":"Python<pre><code>import genesis\n\ndef validate_checkpoint(file_path):\n    \"\"\"\u9a8c\u8bc1\u68c0\u67e5\u70b9\u6587\u4ef6\u5b8c\u6574\u6027\u3002\"\"\"\n    try:\n        checkpoint = genesis.load(file_path)\n\n        # \u57fa\u672c\u7ed3\u6784\u9a8c\u8bc1\n        if not isinstance(checkpoint, dict):\n            return False, \"\u68c0\u67e5\u70b9\u4e0d\u662f\u5b57\u5178\u7c7b\u578b\"\n\n        if 'model_state_dict' not in checkpoint:\n            return False, \"\u7f3a\u5c11model_state_dict\"\n\n        # \u68c0\u67e5\u6a21\u578b\u72b6\u6001\u7ed3\u6784\n        model_state = checkpoint['model_state_dict']\n        if not isinstance(model_state, dict):\n            return False, \"model_state_dict\u4e0d\u662f\u5b57\u5178\u7c7b\u578b\"\n\n        # \u68c0\u67e5\u7a7a\u72b6\u6001\n        if len(model_state) == 0:\n            return False, \"model_state_dict\u4e3a\u7a7a\"\n\n        # \u9a8c\u8bc1\u5f20\u91cf\u5f62\u72b6\uff08\u57fa\u672c\u68c0\u67e5\uff09\n        for key, tensor in model_state.items():\n            if not hasattr(tensor, 'shape'):\n                return False, f\"\u952e '{key}' \u7684\u5f20\u91cf\u65e0\u6548\"\n\n        return True, \"\u68c0\u67e5\u70b9\u6709\u6548\"\n\n    except Exception as e:\n        return False, f\"\u9a8c\u8bc1\u68c0\u67e5\u70b9\u65f6\u51fa\u9519: {e}\"\n\n# \u7528\u6cd5\nis_valid, message = validate_checkpoint('checkpoint.pth')\nprint(f\"\u68c0\u67e5\u70b9\u9a8c\u8bc1: {message}\")\n</code></pre>"},{"location":"api/serialization/#_16","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"api/serialization/#1","title":"1. \u68c0\u67e5\u70b9\u7b56\u7565","text":"<ul> <li>\u5b9a\u671f\u4fdd\u5b58\u68c0\u67e5\u70b9\uff08\u6bcfN\u4e2aepoch\uff09</li> <li>\u4fdd\u7559\u591a\u4e2a\u6700\u8fd1\u7684\u68c0\u67e5\u70b9</li> <li>\u5355\u72ec\u4fdd\u5b58\u6700\u4f73\u6a21\u578b</li> <li>\u5305\u542b\u8bad\u7ec3\u5143\u6570\u636e</li> </ul>"},{"location":"api/serialization/#2","title":"2. \u6587\u4ef6\u7ec4\u7ec7","text":"Python<pre><code># \u63a8\u8350\u7684\u76ee\u5f55\u7ed3\u6784\ncheckpoints/\n\u251c\u2500\u2500 latest.pth                    # \u6700\u65b0\u68c0\u67e5\u70b9\n\u251c\u2500\u2500 best_model.pth               # \u6700\u4f73\u6027\u80fd\u6a21\u578b\n\u251c\u2500\u2500 epoch_000010.pth            # \u5e38\u89c4\u68c0\u67e5\u70b9\n\u251c\u2500\u2500 epoch_000020.pth\n\u2514\u2500\u2500 deployed/\n    \u2514\u2500\u2500 production_model.pth     # \u751f\u4ea7\u5c31\u7eea\u6a21\u578b\n</code></pre>"},{"location":"api/serialization/#3","title":"3. \u5185\u5b58\u7ba1\u7406","text":"Python<pre><code>import genesis\nimport gc\n\ndef efficient_checkpoint_save(model, optimizer, file_path):\n    \"\"\"\u5e26\u5185\u5b58\u4f18\u5316\u7684\u68c0\u67e5\u70b9\u4fdd\u5b58\u3002\"\"\"\n    # \u521b\u5efa\u68c0\u67e5\u70b9\u5b57\u5178\n    checkpoint = {\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict()\n    }\n\n    # \u4fdd\u5b58\u68c0\u67e5\u70b9\n    genesis.save(checkpoint, file_path)\n\n    # \u4ece\u5185\u5b58\u4e2d\u6e05\u9664\u68c0\u67e5\u70b9\u5b57\u5178\n    del checkpoint\n    gc.collect()\n\n    print(f\"\u68c0\u67e5\u70b9\u5df2\u4fdd\u5b58\u5230 {file_path}\")\n</code></pre>"},{"location":"api/serialization/#4","title":"4. \u8de8\u8bbe\u5907\u517c\u5bb9\u6027","text":"Python<pre><code>def save_device_agnostic(model, file_path):\n    \"\"\"\u4fdd\u5b58\u53ef\u5728\u4efb\u4f55\u8bbe\u5907\u4e0a\u52a0\u8f7d\u7684\u6a21\u578b\u3002\"\"\"\n    # \u4fdd\u5b58\u524d\u79fb\u52a8\u5230CPU\n    model.cpu()\n    genesis.save(model.state_dict(), file_path)\n\ndef load_to_device(file_path, model, device):\n    \"\"\"\u5c06\u68c0\u67e5\u70b9\u52a0\u8f7d\u5230\u6307\u5b9a\u8bbe\u5907\u3002\"\"\"\n    # \u52a0\u8f7d\u68c0\u67e5\u70b9\n    state_dict = genesis.load(file_path)\n\n    # \u52a0\u8f7d\u5230\u6a21\u578b\n    model.load_state_dict(state_dict)\n\n    # \u79fb\u52a8\u5230\u76ee\u6807\u8bbe\u5907\n    model.to(device)\n</code></pre>"},{"location":"api/serialization/#_17","title":"\u8fc1\u79fb\u548c\u517c\u5bb9\u6027","text":""},{"location":"api/serialization/#pytorch","title":"\u4ecePyTorch\u8fc1\u79fb","text":"Python<pre><code>import genesis\nimport torch\n\ndef convert_pytorch_checkpoint(pytorch_file, genesis_file):\n    \"\"\"\u5c06PyTorch\u68c0\u67e5\u70b9\u8f6c\u6362\u4e3aGenesis\u683c\u5f0f\u3002\"\"\"\n    # \u52a0\u8f7dPyTorch\u68c0\u67e5\u70b9\n    torch_checkpoint = torch.load(pytorch_file, map_location='cpu')\n\n    # \u8f6c\u6362\u4e3aGenesis\u683c\u5f0f\uff08\u5982\u9700\u8981\uff09\n    genesis_checkpoint = {\n        'model_state_dict': torch_checkpoint['model_state_dict'],\n        'optimizer_state_dict': torch_checkpoint.get('optimizer_state_dict', {}),\n        'epoch': torch_checkpoint.get('epoch', 0),\n        'converted_from_pytorch': True\n    }\n\n    # \u4ee5Genesis\u683c\u5f0f\u4fdd\u5b58\n    genesis.save(genesis_checkpoint, genesis_file)\n    print(f\"\u5df2\u8f6c\u6362 {pytorch_file} -&gt; {genesis_file}\")\n</code></pre> <p>Genesis\u5e8f\u5217\u5316\u7cfb\u7edf\u4e3a\u751f\u4ea7\u7ea7\u6df1\u5ea6\u5b66\u4e60\u5de5\u4f5c\u6d41\u7a0b\u63d0\u4f9b\u4e86\u5f3a\u5927\u3001\u9ad8\u6548\u548c\u5b89\u5168\u7684\u6a21\u578b\u68c0\u67e5\u70b9\u529f\u80fd\u3002</p>"},{"location":"api/ndarray/","title":"NDArray\u7cfb\u7edf (genesis.ndarray)","text":""},{"location":"api/ndarray/#_1","title":"\u6982\u8ff0","text":"<p><code>genesis.ndarray</code>\u6a21\u5757\u63d0\u4f9b\u4f4e\u7ea7\u5f20\u91cf\u64cd\u4f5c\u548c\u8bbe\u5907\u62bd\u8c61\u5c42\uff0c\u4e3aGenesis\u63d0\u4f9b\u652f\u6301\u3002\u5b83\u5b9e\u73b0\u4e86\u53cc\u540e\u7aef\u67b6\u6784\uff0c\u4e3aCPU\u548cGPU\u6267\u884c\u63d0\u4f9b\u4e86\u4f18\u5316\u64cd\u4f5c\u3002</p>"},{"location":"api/ndarray/#_2","title":"\u6838\u5fc3\u6982\u5ff5","text":""},{"location":"api/ndarray/#_3","title":"\u53cc\u540e\u7aef\u67b6\u6784","text":"<p>Genesis\u4f7f\u7528\u72ec\u7279\u7684\u53cc\u540e\u7aef\u65b9\u6cd5\uff1a - CPU\u540e\u7aef: \u5229\u7528PyTorch\u8fdb\u884cCPU\u64cd\u4f5c\uff0c\u5177\u6709\u5b8c\u5168\u517c\u5bb9\u6027 - GPU\u540e\u7aef: \u7eafCUDA/Triton\u5b9e\u73b0\uff0c\u5b9e\u73b0\u6700\u5927\u6027\u80fd\u63a7\u5236</p>"},{"location":"api/ndarray/#_4","title":"\u8bbe\u5907\u62bd\u8c61","text":"<p>\u6240\u6709\u8ba1\u7b97\u901a\u8fc7<code>Device</code>\u62bd\u8c61\u5b9e\u73b0\u8bbe\u5907\u65e0\u5173\uff1a - \u81ea\u52a8\u8bbe\u5907\u9009\u62e9\u548c\u5185\u5b58\u7ba1\u7406 - CPU\u548cGPU\u6267\u884c\u4e4b\u95f4\u7684\u65e0\u7f1d\u5207\u6362 - \u4f18\u5316\u7684\u5185\u5b58\u5206\u914d\u6a21\u5f0f</p>"},{"location":"api/ndarray/#_5","title":"\u6027\u80fd\u4f18\u5316","text":"<p>ndarray\u7cfb\u7edf\u5305\u62ec\u51e0\u4e2a\u6027\u80fd\u4f18\u5316\uff1a - \u5185\u6838\u7f13\u5b58: \u7f16\u8bd1\u7684Triton\u5185\u6838\u88ab\u7f13\u5b58\u4ee5\u4f9b\u91cd\u7528 - \u81ea\u9002\u5e94\u914d\u7f6e: \u5757\u5927\u5c0f\u6839\u636e\u5f20\u91cf\u7ef4\u5ea6\u81ea\u52a8\u8c03\u6574 - \u5185\u5b58\u89c6\u56fe: \u65e0\u9700\u6570\u636e\u590d\u5236\u7684\u9ad8\u6548\u5f20\u91cf\u89c6\u56fe - \u5e7f\u64ad\u4f18\u5316: \u5143\u7d20\u7ea7\u64cd\u4f5c\u7684\u667a\u80fd\u5e7f\u64ad</p>"},{"location":"api/ndarray/#_6","title":"\u4e3b\u8981\u7c7b","text":""},{"location":"api/ndarray/#ndarray","title":"<code>NDArray</code>","text":"<p>Genesis\u4e2d\u7684\u57fa\u7840\u6570\u7ec4\u7c7b\u578b\uff0c\u63d0\u4f9b\u8bbe\u5907\u65e0\u5173\u7684\u5f20\u91cf\u64cd\u4f5c\u3002</p> Python<pre><code>class NDArray:\n    \"\"\"\n    \u652f\u6301\u8bbe\u5907\u7684N\u7ef4\u6570\u7ec4\u3002\n\n    \u53c2\u6570:\n        data: \u8f93\u5165\u6570\u636e\uff08numpy\u6570\u7ec4\u3001\u5217\u8868\u6216\u5f20\u91cf\uff09\n        device: \u76ee\u6807\u8bbe\u5907\uff08cpu\u6216cuda\uff09\n        dtype: \u6570\u7ec4\u7684\u6570\u636e\u7c7b\u578b\n\n    \u5c5e\u6027:\n        shape: \u6570\u7ec4\u7ef4\u5ea6\u7684\u5143\u7ec4\n        dtype: \u5143\u7d20\u7684\u6570\u636e\u7c7b\u578b\n        device: \u6570\u7ec4\u5b58\u50a8\u7684\u8bbe\u5907\n        data: \u5e95\u5c42\u5f20\u91cf\u6570\u636e\n    \"\"\"\n\n    def __init__(\n        self, \n        data, \n        device: Optional[Device] = None, \n        dtype: Optional[DType] = None\n    ):\n</code></pre>"},{"location":"api/ndarray/#_7","title":"\u521b\u5efa\u65b9\u6cd5","text":"Python<pre><code>@staticmethod\ndef make(\n    shape: Tuple[int, ...], \n    device: Optional[Device] = None, \n    dtype: DType = genesis.float32\n) -&gt; NDArray:\n    \"\"\"\n    \u521b\u5efa\u6307\u5b9a\u5f62\u72b6\u7684\u672a\u521d\u59cb\u5316\u6570\u7ec4\u3002\n\n    \u53c2\u6570:\n        shape: \u6570\u7ec4\u7684\u7ef4\u5ea6\n        device: \u76ee\u6807\u8bbe\u5907\n        dtype: \u5143\u7d20\u6570\u636e\u7c7b\u578b\n\n    \u8fd4\u56de:\n        \u65b0\u7684NDArray\u5b9e\u4f8b\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; arr = NDArray.make((10, 20), device=genesis.cuda(), dtype=genesis.float32)\n        &gt;&gt;&gt; print(arr.shape)  # (10, 20)\n    \"\"\"\n</code></pre>"},{"location":"api/ndarray/#_8","title":"\u5c5e\u6027\u548c\u65b9\u6cd5","text":"Python<pre><code>@property\ndef shape(self) -&gt; Tuple[int, ...]:\n    \"\"\"\u6570\u7ec4\u7ef4\u5ea6\u3002\"\"\"\n\n@property\ndef dtype(self) -&gt; DType:\n    \"\"\"\u5143\u7d20\u6570\u636e\u7c7b\u578b\u3002\"\"\"\n\n@property\ndef device(self) -&gt; Device:\n    \"\"\"\u6570\u7ec4\u5b58\u50a8\u7684\u8bbe\u5907\u3002\"\"\"\n\ndef numel(self) -&gt; int:\n    \"\"\"\n    \u5143\u7d20\u603b\u6570\u3002\n\n    \u8fd4\u56de:\n        \u6240\u6709\u7ef4\u5ea6\u7684\u4e58\u79ef\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; arr = NDArray.make((3, 4, 5))\n        &gt;&gt;&gt; print(arr.numel())  # 60\n    \"\"\"\n\ndef is_contiguous(self) -&gt; bool:\n    \"\"\"\n    \u68c0\u67e5\u6570\u7ec4\u662f\u5426\u5177\u6709\u8fde\u7eed\u7684\u5185\u5b58\u5e03\u5c40\u3002\n\n    \u8fd4\u56de:\n        \u5982\u679c\u5185\u5b58\u8fde\u7eed\u5219\u4e3aTrue\n    \"\"\"\n\ndef fill(self, value: float) -&gt; None:\n    \"\"\"\n    \u7528\u5e38\u6570\u503c\u539f\u5730\u586b\u5145\u6570\u7ec4\u3002\n\n    \u53c2\u6570:\n        value: \u586b\u5145\u503c\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; arr = NDArray.make((5, 5))\n        &gt;&gt;&gt; arr.fill(0.0)\n        &gt;&gt;&gt; # \u6570\u7ec4\u73b0\u5728\u5305\u542b\u5168\u96f6\n    \"\"\"\n\ndef numpy(self) -&gt; np.ndarray:\n    \"\"\"\n    \u8f6c\u6362\u4e3aNumPy\u6570\u7ec4\u3002\n\n    \u8fd4\u56de:\n        \u590d\u5236\u6570\u636e\u7684NumPy\u6570\u7ec4\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; arr = NDArray([1, 2, 3], device=genesis.cuda())\n        &gt;&gt;&gt; np_arr = arr.numpy()  # \u4eceGPU\u590d\u5236\u5230CPU\n    \"\"\"\n\ndef cpu(self):\n    \"\"\"\n    \u5c06\u6570\u7ec4\u4f20\u8f93\u5230CPU\u3002\n\n    \u8fd4\u56de:\n        \u6570\u7ec4\u6570\u636e\u7684CPU\u7248\u672c\n    \"\"\"\n</code></pre>"},{"location":"api/ndarray/#device","title":"<code>Device</code>","text":"<p>\u652f\u6301CPU\u548cCUDA\u6267\u884c\u7684\u62bd\u8c61\u8bbe\u5907\u63a5\u53e3\u3002</p> Python<pre><code>class Device:\n    \"\"\"\n    \u8ba1\u7b97\u540e\u7aef\u7684\u8bbe\u5907\u62bd\u8c61\u3002\n\n    \u53c2\u6570:\n        name: \u8bbe\u5907\u540d\u79f0\uff08'cpu'\u6216'cuda'\uff09\n        mod: \u64cd\u4f5c\u7684\u540e\u7aef\u6a21\u5757\n        device_id: GPU\u8bbe\u5907\u7d22\u5f15\uff08\u7528\u4e8eCUDA\u8bbe\u5907\uff09\n    \"\"\"\n\n    def __init__(\n        self, \n        name: str, \n        mod: Any, \n        device_id: Optional[int] = None\n    ):\n\n    def enabled(self) -&gt; bool:\n        \"\"\"\n        \u68c0\u67e5\u8bbe\u5907\u662f\u5426\u53ef\u7528\u3002\n\n        \u8fd4\u56de:\n            \u5982\u679c\u8bbe\u5907\u53ef\u4ee5\u4f7f\u7528\u5219\u4e3aTrue\n        \"\"\"\n</code></pre>"},{"location":"api/ndarray/#_9","title":"\u5f20\u91cf\u521b\u5efa","text":"Python<pre><code>def randn(\n    self, \n    *shape: int, \n    dtype: Optional[DType] = genesis.float32\n) -&gt; NDArray:\n    \"\"\"\n    \u4ece\u6b63\u6001\u5206\u5e03\u521b\u5efa\u968f\u673a\u6570\u7ec4\u3002\n\n    \u53c2\u6570:\n        *shape: \u6570\u7ec4\u7ef4\u5ea6\n        dtype: \u5143\u7d20\u6570\u636e\u7c7b\u578b\n\n    \u8fd4\u56de:\n        \u5177\u6709\u968f\u673a\u503c\u7684NDArray\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; device = genesis.cuda()\n        &gt;&gt;&gt; arr = device.randn(10, 10)  # 10x10\u968f\u673a\u6570\u7ec4\n    \"\"\"\n\ndef rand(\n    self, \n    *shape: int, \n    dtype: Optional[DType] = genesis.float32\n) -&gt; NDArray:\n    \"\"\"\n    \u4ece\u5747\u5300\u5206\u5e03[0, 1)\u521b\u5efa\u968f\u673a\u6570\u7ec4\u3002\n\n    \u53c2\u6570:\n        *shape: \u6570\u7ec4\u7ef4\u5ea6\n        dtype: \u5143\u7d20\u6570\u636e\u7c7b\u578b\n\n    \u8fd4\u56de:\n        \u5177\u6709\u5747\u5300\u968f\u673a\u503c\u7684NDArray\n    \"\"\"\n\ndef empty(\n    self, \n    shape: Tuple[int, ...], \n    dtype: Optional[DType] = genesis.float32\n) -&gt; NDArray:\n    \"\"\"\n    \u521b\u5efa\u672a\u521d\u59cb\u5316\u6570\u7ec4\u3002\n\n    \u53c2\u6570:\n        shape: \u6570\u7ec4\u7ef4\u5ea6\n        dtype: \u5143\u7d20\u6570\u636e\u7c7b\u578b\n\n    \u8fd4\u56de:\n        \u672a\u521d\u59cb\u5316\u7684NDArray\n    \"\"\"\n\ndef full(\n    self, \n    shape: Tuple[int, ...], \n    fill_value: float, \n    dtype: Optional[DType] = genesis.float32\n) -&gt; NDArray:\n    \"\"\"\n    \u521b\u5efa\u7528\u6307\u5b9a\u503c\u586b\u5145\u7684\u6570\u7ec4\u3002\n\n    \u53c2\u6570:\n        shape: \u6570\u7ec4\u7ef4\u5ea6\n        fill_value: \u586b\u5145\u6570\u7ec4\u7684\u503c\n        dtype: \u5143\u7d20\u6570\u636e\u7c7b\u578b\n\n    \u8fd4\u56de:\n        \u7528fill_value\u586b\u5145\u7684NDArray\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; device = genesis.cpu()\n        &gt;&gt;&gt; ones = device.full((5, 5), 1.0)  # 5x5\u51681\u6570\u7ec4\n    \"\"\"\n\ndef one_hot(\n    self, \n    n: int, \n    i: NDArray, \n    dtype: Optional[DType] = genesis.float32\n) -&gt; NDArray:\n    \"\"\"\n    \u521b\u5efa\u72ec\u70ed\u7f16\u7801\u6570\u7ec4\u3002\n\n    \u53c2\u6570:\n        n: \u7c7b\u522b\u6570\u91cf\n        i: \u7d22\u5f15\u6570\u7ec4\n        dtype: \u5143\u7d20\u6570\u636e\u7c7b\u578b\n\n    \u8fd4\u56de:\n        \u72ec\u70ed\u7f16\u7801\u7684NDArray\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; device = genesis.cpu()\n        &gt;&gt;&gt; indices = NDArray([0, 2, 1], device=device)\n        &gt;&gt;&gt; one_hot = device.one_hot(3, indices)\n        &gt;&gt;&gt; # \u5f62\u72b6: (3, 3) \u72ec\u70ed\u7f16\u7801\n    \"\"\"\n</code></pre>"},{"location":"api/ndarray/#_10","title":"\u8bbe\u5907\u51fd\u6570","text":""},{"location":"api/ndarray/#_11","title":"\u8bbe\u5907\u521b\u5efa","text":"Python<pre><code>def cpu() -&gt; Device:\n    \"\"\"\n    \u521b\u5efaCPU\u8bbe\u5907\u3002\n\n    \u8fd4\u56de:\n        CPU\u8bbe\u5907\u5b9e\u4f8b\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; cpu_device = genesis.cpu()\n        &gt;&gt;&gt; arr = NDArray([1, 2, 3], device=cpu_device)\n    \"\"\"\n\ndef cuda(index: int = 0) -&gt; Device:\n    \"\"\"\n    \u521b\u5efaCUDA\u8bbe\u5907\u3002\n\n    \u53c2\u6570:\n        index: GPU\u8bbe\u5907\u7d22\u5f15\n\n    \u8fd4\u56de:\n        CUDA\u8bbe\u5907\u5b9e\u4f8b\uff0c\u5982\u679cCUDA\u4e0d\u53ef\u7528\u5219\u4e3aNone\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; gpu_device = genesis.cuda(0)  # \u7b2c\u4e00\u4e2aGPU\n        &gt;&gt;&gt; if gpu_device.enabled():\n        ...     arr = NDArray([1, 2, 3], device=gpu_device)\n    \"\"\"\n\ndef device(device_name: Union[str, int]) -&gt; Device:\n    \"\"\"\n    \u901a\u8fc7\u540d\u79f0\u6216\u7d22\u5f15\u521b\u5efa\u8bbe\u5907\u3002\n\n    \u53c2\u6570:\n        device_name: 'cpu', 'cuda', 'cuda:N', \u6216GPU\u7d22\u5f15\n\n    \u8fd4\u56de:\n        \u8bbe\u5907\u5b9e\u4f8b\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; dev1 = genesis.device('cuda:1')  # \u7b2c\u4e8c\u4e2aGPU\n        &gt;&gt;&gt; dev2 = genesis.device(1)         # \u540c\u4e0a\n        &gt;&gt;&gt; dev3 = genesis.device('cpu')     # CPU\u8bbe\u5907\n    \"\"\"\n\ndef default_device() -&gt; Device:\n    \"\"\"\n    \u83b7\u53d6\u9ed8\u8ba4\u8bbe\u5907\uff08CPU\uff09\u3002\n\n    \u8fd4\u56de:\n        \u9ed8\u8ba4\u8bbe\u5907\u5b9e\u4f8b\n    \"\"\"\n\ndef all_devices() -&gt; List[Device]:\n    \"\"\"\n    \u83b7\u53d6\u6240\u6709\u53ef\u7528\u8bbe\u5907\u7684\u5217\u8868\u3002\n\n    \u8fd4\u56de:\n        \u8bbe\u5907\u5b9e\u4f8b\u5217\u8868\n    \"\"\"\n</code></pre>"},{"location":"api/ndarray/#_12","title":"\u64cd\u4f5c","text":"<p>ndarray\u7cfb\u7edf\u901a\u8fc7\u540e\u7aef\u6a21\u5757\u652f\u6301\u4e00\u5957\u5b8c\u6574\u7684\u64cd\u4f5c\u3002</p>"},{"location":"api/ndarray/#_13","title":"\u7b97\u672f\u64cd\u4f5c","text":"Python<pre><code># \u4e8c\u5143\u64cd\u4f5c\nadd(x, y)           # \u5143\u7d20\u7ea7\u52a0\u6cd5\nsub(x, y)           # \u5143\u7d20\u7ea7\u51cf\u6cd5  \nmul(x, y)           # \u5143\u7d20\u7ea7\u4e58\u6cd5\ntruediv(x, y)       # \u5143\u7d20\u7ea7\u9664\u6cd5\npow(x, scalar)      # \u5143\u7d20\u7ea7\u5e42\u8fd0\u7b97\n\n# \u4e00\u5143\u64cd\u4f5c\nlog(x)              # \u81ea\u7136\u5bf9\u6570\nexp(x)              # \u6307\u6570\nsin(x)              # \u6b63\u5f26\ncos(x)              # \u4f59\u5f26\nsqrt(x)             # \u5e73\u65b9\u6839\n</code></pre>"},{"location":"api/ndarray/#_14","title":"\u5f52\u7ea6\u64cd\u4f5c","text":"Python<pre><code>reduce_sum(x, axis=None, keepdims=False)    # \u6c42\u548c\u5f52\u7ea6\nreduce_max(x, axis=None, keepdims=False)    # \u6700\u5927\u503c\u5f52\u7ea6\nreduce_min(x, axis=None, keepdims=False)    # \u6700\u5c0f\u503c\u5f52\u7ea6\n</code></pre>"},{"location":"api/ndarray/#_15","title":"\u6bd4\u8f83\u64cd\u4f5c","text":"Python<pre><code>maximum(x, y)       # \u5143\u7d20\u7ea7\u6700\u5927\u503c\nminimum(x, y)       # \u5143\u7d20\u7ea7\u6700\u5c0f\u503c\n</code></pre>"},{"location":"api/ndarray/#_16","title":"\u77e9\u9635\u64cd\u4f5c","text":"Python<pre><code>matmul(x, y)        # \u77e9\u9635\u4e58\u6cd5\ntranspose(x, axes)  # \u5f20\u91cf\u8f6c\u7f6e\n</code></pre>"},{"location":"api/ndarray/#_17","title":"\u6027\u80fd\u4f18\u5316","text":""},{"location":"api/ndarray/#_18","title":"\u5185\u6838\u7f13\u5b58","text":"<p>Triton\u5185\u6838\u81ea\u52a8\u7f13\u5b58\u4ee5\u4f9b\u91cd\u7528\uff1a</p> Python<pre><code>from genesis.ndarray.kernel_cache import cached_kernel_call\n\n# \u5185\u6838\u6309\u51fd\u6570\u7b7e\u540d\u548c\u53c2\u6570\u7f13\u5b58\ncached_kernel_call(kernel_func, grid_func, *args, **kwargs)\n</code></pre>"},{"location":"api/ndarray/#_19","title":"\u81ea\u9002\u5e94\u914d\u7f6e","text":"<p>\u5757\u5927\u5c0f\u81ea\u52a8\u9002\u5e94\u5f20\u91cf\u7ef4\u5ea6\uff1a</p> Python<pre><code>from genesis.ndarray.adaptive_config import AdaptiveConfig\n\n# \u4e3a\u5f20\u91cf\u5f62\u72b6\u83b7\u53d6\u4f18\u5316\u914d\u7f6e\nconfig = AdaptiveConfig.get_elementwise_config(shape)\nblock_size = config['BLOCK_SIZE']\ngrid = config['grid']\n</code></pre>"},{"location":"api/ndarray/#_20","title":"\u5185\u5b58\u7ba1\u7406","text":"<p>\u9ad8\u6548\u7684\u5185\u5b58\u5206\u914d\u6a21\u5f0f\uff1a - \u5c3d\u53ef\u80fd\u8fde\u7eed\u7684\u5185\u5b58\u5e03\u5c40 - \u57fa\u4e8e\u89c6\u56fe\u7684\u64cd\u4f5c\u907f\u514d\u590d\u5236 - \u81ea\u52a8\u5185\u5b58\u6e05\u7406</p>"},{"location":"api/ndarray/#gpucudatriton","title":"GPU\u540e\u7aef\uff08CUDA/Triton\uff09","text":""},{"location":"api/ndarray/#gpu","title":"GPU\u64cd\u4f5c","text":"<p>\u7eafCUDA/Triton\u5b9e\u73b0\uff0c\u9488\u5bf9GPU\u64cd\u4f5c\u8fdb\u884c\u6027\u80fd\u4f18\u5316\u3002</p>"},{"location":"api/ndarray/#triton","title":"Triton\u5185\u6838","text":"<p>\u4e3a\u6700\u5927\u6027\u80fd\u624b\u5de5\u4f18\u5316\u7684Triton\u5185\u6838\uff1a - \u5177\u6709\u5e7f\u64ad\u7684\u5143\u7d20\u7ea7\u64cd\u4f5c - \u5177\u6709\u5de5\u4f5c\u9ad8\u6548\u7b97\u6cd5\u7684\u5f52\u7ea6\u64cd\u4f5c - \u5177\u6709\u5206\u5757\u7684\u77e9\u9635\u4e58\u6cd5 - \u5185\u5b58\u4f18\u5316\u8bbf\u95ee\u6a21\u5f0f</p>"},{"location":"api/ndarray/#_21","title":"\u4f7f\u7528\u793a\u4f8b","text":""},{"location":"api/ndarray/#_22","title":"\u57fa\u672c\u6570\u7ec4\u521b\u5efa","text":"Python<pre><code>import genesis\n\n# \u5728\u4e0d\u540c\u8bbe\u5907\u4e0a\u521b\u5efa\u6570\u7ec4\ncpu_arr = genesis.NDArray([1, 2, 3, 4], device=genesis.cpu())\ngpu_arr = genesis.NDArray([1, 2, 3, 4], device=genesis.cuda())\n\n# \u521b\u5efa\u7279\u5b9a\u5f62\u72b6\nzeros = genesis.NDArray.make((100, 100), device=genesis.cuda())\nzeros.fill(0.0)\n</code></pre>"},{"location":"api/ndarray/#_23","title":"\u8bbe\u5907\u64cd\u4f5c","text":"Python<pre><code># \u968f\u673a\u6570\u7ec4\ndevice = genesis.cuda(0)\nrandom_normal = device.randn(1000, 1000)\nrandom_uniform = device.rand(1000, 1000)\n\n# \u72ec\u70ed\u7f16\u7801\nindices = genesis.NDArray([0, 2, 1, 3], device=device)\none_hot = device.one_hot(4, indices)\n</code></pre>"},{"location":"api/ndarray/#_24","title":"\u5185\u5b58\u4f20\u8f93","text":"Python<pre><code># GPU\u5230CPU\u4f20\u8f93\ngpu_data = genesis.NDArray([1, 2, 3], device=genesis.cuda())\ncpu_data = gpu_data.cpu()\nnumpy_data = gpu_data.numpy()\n\n# CPU\u5230GPU\u4f20\u8f93  \ncpu_data = genesis.NDArray([1, 2, 3], device=genesis.cpu())\ngpu_data = genesis.NDArray(cpu_data, device=genesis.cuda())\n</code></pre>"},{"location":"api/ndarray/#_25","title":"\u6027\u80fd\u76d1\u63a7","text":"Python<pre><code>import time\n\n# \u8ba1\u65f6\u64cd\u4f5c\nstart = time.time()\nresult = genesis.ndarray.add(x, y)\nend = time.time()\nprint(f\"\u64cd\u4f5c\u7528\u65f6 {(end - start) * 1000:.2f}ms\")\n</code></pre>"},{"location":"api/ndarray/#_26","title":"\u540e\u7aef\u9009\u62e9","text":"<p>Genesis\u81ea\u52a8\u9009\u62e9\u5408\u9002\u7684\u540e\u7aef\uff1a</p> Python<pre><code># CPU\u64cd\u4f5c\u4f7f\u7528PyTorch\u540e\u7aef\ncpu_device = genesis.cpu()\nx = genesis.NDArray([1, 2, 3], device=cpu_device)\n\n# GPU\u64cd\u4f5c\u4f7f\u7528Triton/CUDA\u540e\u7aef\ngpu_device = genesis.cuda()\nif gpu_device.enabled():\n    x = genesis.NDArray([1, 2, 3], device=gpu_device)\n    # \u4f7f\u7528\u4f18\u5316\u7684Triton\u5185\u6838\n</code></pre>"},{"location":"api/ndarray/#_27","title":"\u9519\u8bef\u5904\u7406","text":"<p>ndarray\u7cfb\u7edf\u63d0\u4f9b\u5168\u9762\u7684\u9519\u8bef\u5904\u7406\uff1a</p> Python<pre><code>try:\n    # \u5c1d\u8bd5GPU\u64cd\u4f5c\n    gpu_device = genesis.cuda()\n    if not gpu_device.enabled():\n        raise RuntimeError(\"CUDA\u4e0d\u53ef\u7528\")\n\n    arr = genesis.NDArray([1, 2, 3], device=gpu_device)\nexcept RuntimeError as e:\n    # \u56de\u9000\u5230CPU\n    print(f\"GPU\u9519\u8bef: {e}\uff0c\u4f7f\u7528CPU\")\n    cpu_device = genesis.cpu()\n    arr = genesis.NDArray([1, 2, 3], device=cpu_device)\n</code></pre>"},{"location":"api/ndarray/#_28","title":"\u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u8bbe\u5907\u9009\u62e9: \u4f7f\u7528\u524d\u68c0\u67e5\u8bbe\u5907\u53ef\u7528\u6027</li> <li>\u5185\u5b58\u7ba1\u7406: \u8c28\u614e\u5730\u5728\u8bbe\u5907\u95f4\u4f20\u8f93  </li> <li>\u6279\u91cf\u64cd\u4f5c: \u5c3d\u53ef\u80fd\u540c\u65f6\u5904\u7406\u591a\u4e2a\u5f20\u91cf</li> <li>\u8fde\u7eed\u5185\u5b58: \u786e\u4fdd\u6570\u7ec4\u8fde\u7eed\u4ee5\u83b7\u5f97\u6700\u4f73\u6027\u80fd</li> <li>\u9519\u8bef\u5904\u7406: \u59cb\u7ec8\u4f18\u96c5\u5730\u5904\u7406CUDA\u53ef\u7528\u6027</li> </ol>"},{"location":"api/ndarray/#_29","title":"\u6027\u80fd\u63d0\u793a","text":"<ol> <li>\u4f7f\u7528\u9002\u5f53\u7684\u5757\u5927\u5c0f \u7528\u4e8eGPU\u5185\u6838</li> <li>\u6700\u5c0f\u5316\u8bbe\u5907\u4f20\u8f93 \u5728CPU\u548cGPU\u4e4b\u95f4</li> <li>\u5229\u7528\u5185\u6838\u7f13\u5b58 \u901a\u8fc7\u91cd\u7528\u76f8\u4f3c\u64cd\u4f5c</li> <li>\u4f7f\u7528\u89c6\u56fe\u800c\u4e0d\u662f\u526f\u672c \u5c3d\u53ef\u80fd</li> <li>\u6279\u91cf\u76f8\u4f3c\u64cd\u4f5c \u644a\u9500\u5185\u6838\u542f\u52a8\u5f00\u9500</li> </ol>"},{"location":"api/ndarray/#_30","title":"\u53e6\u8bf7\u53c2\u9605","text":"<ul> <li>\u5f20\u91cf\u64cd\u4f5c - \u9ad8\u7ea7\u5f20\u91cf\u63a5\u53e3</li> <li>\u795e\u7ecf\u7f51\u7edc\u6a21\u5757 - \u5728ndarray\u57fa\u7840\u4e0a\u6784\u5efa</li> <li>\u6027\u80fd\u6307\u5357 - \u4f18\u5316\u6280\u672f</li> <li>CUDA\u5b58\u50a8 - \u4f4e\u7ea7CUDA\u5b9e\u73b0</li> </ul>"},{"location":"api/nn/functional/","title":"\u51fd\u6570\u5f0f\u64cd\u4f5c\u63a5\u53e3 (genesis.nn.functional)","text":"<p>Genesis\u7684\u51fd\u6570\u5f0f\u63a5\u53e3\u63d0\u4f9b\u4e86\u65e0\u72b6\u6001\u7684\u5f20\u91cf\u64cd\u4f5c\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u5728\u5f20\u91cf\u4e0a\u8c03\u7528\u800c\u65e0\u9700\u521b\u5efa\u6a21\u5757\u5b9e\u4f8b\u3002</p>"},{"location":"api/nn/functional/#_1","title":"\u6a21\u5757\u6982\u8ff0","text":"<p><code>genesis.nn.functional</code>\uff08\u901a\u5e38\u5bfc\u5165\u4e3a<code>F</code>\uff09\u5305\u542b\uff1a - \u57fa\u7840\u7b97\u672f\u8fd0\u7b97\uff08\u52a0\u3001\u51cf\u3001\u4e58\u3001\u9664\uff09 - \u6570\u5b66\u51fd\u6570\uff08sin\u3001cos\u3001log\u3001exp\u3001sqrt\u3001power\uff09 - \u5f20\u91cf\u5f62\u72b6\u64cd\u4f5c\uff08transpose\u3001reshape\u3001expand\u3001view\u3001flatten\uff09 - \u5f20\u91cf\u7d22\u5f15\u548c\u5207\u7247\uff08getitem\u3001setitem\u3001broadcast_to\uff09 - \u805a\u5408\u64cd\u4f5c\uff08sum\u3001max\u3001logsumexp\uff09 - \u77e9\u9635\u64cd\u4f5c\uff08matmul\u3001stack\u3001cat\u3001squeeze\u3001unsqueeze\uff09 - \u57fa\u7840\u6fc0\u6d3b\u51fd\u6570\uff08relu\uff09 - \u9ad8\u7ea7\u64cd\u4f5c\uff08softmax\u3001dropout\u6765\u81eatriton_ops\uff09</p>"},{"location":"api/nn/functional/#_2","title":"\u57fa\u7840\u7b97\u672f\u8fd0\u7b97","text":""},{"location":"api/nn/functional/#add","title":"add","text":"Python<pre><code>def add(a: Tensor, b: Tensor) -&gt; Tensor:\n    \"\"\"\n    \u4e24\u4e2a\u5f20\u91cf\u7684\u9010\u5143\u7d20\u52a0\u6cd5\u3002\n\n    \u53c2\u6570:\n        a: Tensor - \u7b2c\u4e00\u4e2a\u8f93\u5165\u5f20\u91cf\n        b: Tensor - \u7b2c\u4e8c\u4e2a\u8f93\u5165\u5f20\u91cf\n\n    \u8fd4\u56de:\n        Tensor - \u9010\u5143\u7d20\u548c a + b\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.tensor([[1.0, 2.0], [3.0, 4.0]])\n        &gt;&gt;&gt; y = genesis.tensor([[2.0, 1.0], [1.0, 2.0]])\n        &gt;&gt;&gt; z = F.add(x, y)\n        &gt;&gt;&gt; # \u7ed3\u679c: [[3.0, 3.0], [4.0, 6.0]]\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#sub","title":"sub","text":"Python<pre><code>def sub(a: Tensor, b: Tensor) -&gt; Tensor:\n    \"\"\"\n    \u4e24\u4e2a\u5f20\u91cf\u7684\u9010\u5143\u7d20\u51cf\u6cd5\u3002\n\n    \u53c2\u6570:\n        a: Tensor - \u7b2c\u4e00\u4e2a\u8f93\u5165\u5f20\u91cf\uff08\u88ab\u51cf\u6570\uff09\n        b: Tensor - \u7b2c\u4e8c\u4e2a\u8f93\u5165\u5f20\u91cf\uff08\u51cf\u6570\uff09\n\n    \u8fd4\u56de:\n        Tensor - \u9010\u5143\u7d20\u5dee a - b\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.tensor([5.0, 3.0, 8.0])\n        &gt;&gt;&gt; y = genesis.tensor([2.0, 1.0, 3.0])\n        &gt;&gt;&gt; z = F.sub(x, y)\n        &gt;&gt;&gt; # \u7ed3\u679c: [3.0, 2.0, 5.0]\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#multiply","title":"multiply","text":"Python<pre><code>def multiply(a: Tensor, b: Tensor) -&gt; Tensor:\n    \"\"\"\n    \u4e24\u4e2a\u5f20\u91cf\u7684\u9010\u5143\u7d20\u4e58\u6cd5\u3002\n\n    \u53c2\u6570:\n        a: Tensor - \u7b2c\u4e00\u4e2a\u8f93\u5165\u5f20\u91cf\n        b: Tensor - \u7b2c\u4e8c\u4e2a\u8f93\u5165\u5f20\u91cf\n\n    \u8fd4\u56de:\n        Tensor - \u9010\u5143\u7d20\u79ef a * b\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.tensor([2.0, 3.0, 4.0])\n        &gt;&gt;&gt; y = genesis.tensor([1.5, 2.0, 0.5])\n        &gt;&gt;&gt; z = F.multiply(x, y)\n        &gt;&gt;&gt; # \u7ed3\u679c: [3.0, 6.0, 2.0]\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#divide","title":"divide","text":"Python<pre><code>def divide(a: Tensor, b: Tensor) -&gt; Tensor:\n    \"\"\"\n    \u4e24\u4e2a\u5f20\u91cf\u7684\u9010\u5143\u7d20\u9664\u6cd5\u3002\n\n    \u53c2\u6570:\n        a: Tensor - \u88ab\u9664\u6570\u5f20\u91cf\n        b: Tensor - \u9664\u6570\u5f20\u91cf\n\n    \u8fd4\u56de:\n        Tensor - \u9010\u5143\u7d20\u5546 a / b\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.tensor([6.0, 8.0, 9.0])\n        &gt;&gt;&gt; y = genesis.tensor([2.0, 4.0, 3.0])\n        &gt;&gt;&gt; z = F.divide(x, y)\n        &gt;&gt;&gt; # \u7ed3\u679c: [3.0, 2.0, 3.0]\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#_3","title":"\u6807\u91cf\u8fd0\u7b97","text":""},{"location":"api/nn/functional/#add_scalar-mul_scalar-divide_scalar-pow_scalar","title":"add_scalar, mul_scalar, divide_scalar, pow_scalar","text":"Python<pre><code>def add_scalar(a: Tensor, scalar: float) -&gt; Tensor:\ndef mul_scalar(a: Tensor, scalar: float) -&gt; Tensor:\ndef divide_scalar(a: Tensor, scalar: float, reverse: bool = False) -&gt; Tensor:\ndef pow_scalar(a: Tensor, scalar: float, reverse: bool = False) -&gt; Tensor:\n    \"\"\"\n    \u5f20\u91cf\u4e0e\u6807\u91cf\u4e4b\u95f4\u7684\u9010\u5143\u7d20\u8fd0\u7b97\u3002\n\n    \u53c2\u6570:\n        a: Tensor - \u8f93\u5165\u5f20\u91cf\n        scalar: float - \u6807\u91cf\u503c\n        reverse: bool - \u5982\u679c\u4e3aTrue\uff0c\u5219\u6267\u884c scalar op tensor\uff08\u7528\u4e8edivide/pow\uff09\n\n    \u8fd4\u56de:\n        Tensor - \u5f20\u91cf-\u6807\u91cf\u8fd0\u7b97\u7ed3\u679c\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.tensor([1.0, 2.0, 3.0])\n        &gt;&gt;&gt; y1 = F.add_scalar(x, 5.0)      # [6.0, 7.0, 8.0]\n        &gt;&gt;&gt; y2 = F.mul_scalar(x, 2.0)      # [2.0, 4.0, 6.0]\n        &gt;&gt;&gt; y3 = F.pow_scalar(x, 2.0)      # [1.0, 4.0, 9.0]\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#_4","title":"\u6570\u5b66\u51fd\u6570","text":""},{"location":"api/nn/functional/#sin-cos-log-exp-sqrt","title":"sin, cos, log, exp, sqrt","text":"Python<pre><code>def sin(a: Tensor) -&gt; Tensor:\ndef cos(a: Tensor) -&gt; Tensor:\ndef log(a: Tensor) -&gt; Tensor:\ndef exp(a: Tensor) -&gt; Tensor:\ndef sqrt(a: Tensor) -&gt; Tensor:\n    \"\"\"\n    \u9010\u5143\u7d20\u6570\u5b66\u51fd\u6570\u3002\n\n    \u53c2\u6570:\n        a: Tensor - \u8f93\u5165\u5f20\u91cf\n\n    \u8fd4\u56de:\n        Tensor - \u6570\u5b66\u51fd\u6570\u7ed3\u679c\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.tensor([0.0, 1.0, 2.0])\n        &gt;&gt;&gt; y1 = F.sin(x)   # [0.0, 0.841, 0.909]\n        &gt;&gt;&gt; y2 = F.exp(x)   # [1.0, 2.718, 7.389]\n        &gt;&gt;&gt; y3 = F.sqrt(genesis.tensor([4.0, 9.0, 16.0]))  # [2.0, 3.0, 4.0]\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#negate","title":"negate","text":"Python<pre><code>def negate(a: Tensor) -&gt; Tensor:\n    \"\"\"\n    \u9010\u5143\u7d20\u53d6\u8d1f: -a\n\n    \u53c2\u6570:\n        a: Tensor - \u8f93\u5165\u5f20\u91cf\n\n    \u8fd4\u56de:\n        Tensor - \u53d6\u8d1f\u540e\u7684\u5f20\u91cf\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.tensor([1.0, -2.0, 3.0])\n        &gt;&gt;&gt; y = F.negate(x)\n        &gt;&gt;&gt; # \u7ed3\u679c: [-1.0, 2.0, -3.0]\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#_5","title":"\u5f62\u72b6\u64cd\u4f5c","text":""},{"location":"api/nn/functional/#transpose","title":"transpose","text":"Python<pre><code>def transpose(a: Tensor, axis: tuple = None) -&gt; Tensor:\n    \"\"\"\n    \u8f6c\u7f6e\u5f20\u91cf\u7ef4\u5ea6\u3002\n\n    \u53c2\u6570:\n        a: Tensor - \u8f93\u5165\u5f20\u91cf\n        axis: tuple - \u8981\u4ea4\u6362\u7684\u7ef4\u5ea6\u5bf9\uff08\u9ed8\u8ba4\uff1a\u6700\u540e\u4e24\u4e2a\u7ef4\u5ea6\uff09\n\n    \u8fd4\u56de:\n        Tensor - \u8f6c\u7f6e\u540e\u7684\u5f20\u91cf\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.randn(3, 4, 5)\n        &gt;&gt;&gt; y1 = F.transpose(x)           # \u4ea4\u6362\u6700\u540e\u4e24\u4e2a\u7ef4\u5ea6: (3, 5, 4)\n        &gt;&gt;&gt; y2 = F.transpose(x, (0, 2))   # \u4ea4\u6362\u7ef4\u5ea60,2: (5, 4, 3)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#reshape","title":"reshape","text":"Python<pre><code>def reshape(a: Tensor, shape: tuple) -&gt; Tensor:\n    \"\"\"\n    \u91cd\u65b0\u5851\u5f62\u5f20\u91cf\u3002\n\n    \u53c2\u6570:\n        a: Tensor - \u8f93\u5165\u5f20\u91cf\n        shape: tuple - \u65b0\u5f62\u72b6\uff08\u603b\u5143\u7d20\u6570\u5fc5\u987b\u76f8\u540c\uff09\n\n    \u8fd4\u56de:\n        Tensor - \u91cd\u5851\u5f62\u540e\u7684\u5f20\u91cf\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.randn(2, 6)\n        &gt;&gt;&gt; y = F.reshape(x, (3, 4))\n        &gt;&gt;&gt; # \u5f62\u72b6\u4ece (2, 6) \u53d8\u4e3a (3, 4)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#view-expand-flatten","title":"view, expand, flatten","text":"Python<pre><code>def view(a: Tensor, shape: tuple) -&gt; Tensor:\ndef expand(a: Tensor, shape: tuple) -&gt; Tensor:\ndef flatten(a: Tensor, start_dim: int = 0, end_dim: int = None) -&gt; Tensor:\n    \"\"\"\n    \u5f20\u91cf\u89c6\u56fe\u548c\u5f62\u72b6\u64cd\u4f5c\u3002\n\n    \u53c2\u6570:\n        a: Tensor - \u8f93\u5165\u5f20\u91cf\n        shape: tuple - \u76ee\u6807\u5f62\u72b6\n        start_dim, end_dim: int - \u8981\u5c55\u5e73\u7684\u7ef4\u5ea6\n\n    \u8fd4\u56de:\n        Tensor - \u53d8\u6362\u540e\u7684\u5f20\u91cf\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.randn(2, 3, 4)\n        &gt;&gt;&gt; y1 = F.view(x, (6, 4))         # \u89c6\u56fe\u4e3a (6, 4)\n        &gt;&gt;&gt; y2 = F.expand(x, (2, 3, 4, 5)) # \u6269\u5c55\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\n        &gt;&gt;&gt; y3 = F.flatten(x, 1)           # \u4ece\u7ef4\u5ea61\u5f00\u59cb\u5c55\u5e73: (2, 12)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#_6","title":"\u5f20\u91cf\u64cd\u4f5c","text":""},{"location":"api/nn/functional/#matmul","title":"matmul","text":"Python<pre><code>def matmul(a: Tensor, b: Tensor) -&gt; Tensor:\n    \"\"\"\n    \u77e9\u9635\u4e58\u6cd5\u3002\n\n    \u53c2\u6570:\n        a: Tensor - \u5de6\u77e9\u9635\n        b: Tensor - \u53f3\u77e9\u9635\n\n    \u8fd4\u56de:\n        Tensor - \u77e9\u9635\u4e58\u79ef\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.randn(3, 4)\n        &gt;&gt;&gt; y = genesis.randn(4, 5)\n        &gt;&gt;&gt; z = F.matmul(x, y)  # \u5f62\u72b6: (3, 5)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#stack-cat","title":"stack, cat","text":"Python<pre><code>def stack(tensors: list, dim: int = 0) -&gt; Tensor:\ndef cat(tensors: list, dim: int = 0) -&gt; Tensor:\n    \"\"\"\n    \u6cbf\u6307\u5b9a\u7ef4\u5ea6\u5806\u53e0\u6216\u8fde\u63a5\u5f20\u91cf\u3002\n\n    \u53c2\u6570:\n        tensors: list - \u8981\u7ec4\u5408\u7684\u5f20\u91cf\u5217\u8868\n        dim: int - \u5806\u53e0/\u8fde\u63a5\u7684\u7ef4\u5ea6\n\n    \u8fd4\u56de:\n        Tensor - \u7ec4\u5408\u540e\u7684\u5f20\u91cf\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.randn(2, 3)\n        &gt;&gt;&gt; y = genesis.randn(2, 3)\n        &gt;&gt;&gt; z1 = F.stack([x, y], dim=0)  # \u5f62\u72b6: (2, 2, 3)\n        &gt;&gt;&gt; z2 = F.cat([x, y], dim=0)    # \u5f62\u72b6: (4, 3)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#squeeze-unsqueeze","title":"squeeze, unsqueeze","text":"Python<pre><code>def squeeze(tensor: Tensor, dim: int) -&gt; Tensor:\ndef unsqueeze(tensor: Tensor, dim: int) -&gt; Tensor:\n    \"\"\"\n    \u79fb\u9664\u6216\u6dfb\u52a0\u5355\u4e00\u7ef4\u5ea6\u3002\n\n    \u53c2\u6570:\n        tensor: Tensor - \u8f93\u5165\u5f20\u91cf\n        dim: int - \u8981squeeze/unsqueeze\u7684\u7ef4\u5ea6\n\n    \u8fd4\u56de:\n        Tensor - \u4fee\u6539\u7ef4\u5ea6\u540e\u7684\u5f20\u91cf\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.randn(1, 3, 1, 4)\n        &gt;&gt;&gt; y1 = F.squeeze(x, 0)    # \u5f62\u72b6: (3, 1, 4)\n        &gt;&gt;&gt; y2 = F.unsqueeze(x, 2)  # \u5f62\u72b6: (1, 3, 1, 1, 4)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#_7","title":"\u805a\u5408\u64cd\u4f5c","text":""},{"location":"api/nn/functional/#sum","title":"sum","text":"Python<pre><code>def sum(a: Tensor, axis: int = None, keepdims: bool = False) -&gt; Tensor:\n    \"\"\"\n    \u6cbf\u6307\u5b9a\u7ef4\u5ea6\u6c42\u548c\u5f20\u91cf\u5143\u7d20\u3002\n\n    \u53c2\u6570:\n        a: Tensor - \u8f93\u5165\u5f20\u91cf\n        axis: int - \u6c42\u548c\u7684\u7ef4\u5ea6\uff08None\u8868\u793a\u6240\u6709\u7ef4\u5ea6\uff09\n        keepdims: bool - \u662f\u5426\u4fdd\u6301\u7f29\u51cf\u7684\u7ef4\u5ea6\n\n    \u8fd4\u56de:\n        Tensor - \u6c42\u548c\u540e\u7684\u5f20\u91cf\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.randn(3, 4)\n        &gt;&gt;&gt; y1 = F.sum(x)           # \u6c42\u6240\u6709\u5143\u7d20\u7684\u548c\uff1a\u6807\u91cf\n        &gt;&gt;&gt; y2 = F.sum(x, axis=0)   # \u6cbf\u884c\u6c42\u548c\uff1a\u5f62\u72b6 (4,)\n        &gt;&gt;&gt; y3 = F.sum(x, axis=1, keepdims=True)  # \u5f62\u72b6: (3, 1)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#max-logsumexp","title":"max, logsumexp","text":"Python<pre><code>def max(a: Tensor, axis: int = None, keepdims: bool = False) -&gt; Tensor:\ndef logsumexp(a: Tensor, axis: int = None) -&gt; Tensor:\n    \"\"\"\n    \u6700\u5927\u503c\u548clog-sum-exp\u64cd\u4f5c\u3002\n\n    \u53c2\u6570:\n        a: Tensor - \u8f93\u5165\u5f20\u91cf\n        axis: int - \u7f29\u51cf\u7684\u7ef4\u5ea6\n        keepdims: bool - \u662f\u5426\u4fdd\u6301\u7f29\u51cf\u7684\u7ef4\u5ea6\n\n    \u8fd4\u56de:\n        Tensor - \u7ed3\u679c\u5f20\u91cf\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.randn(3, 4)\n        &gt;&gt;&gt; y1 = F.max(x, axis=1)      # \u6cbf\u884c\u6c42\u6700\u5927\u503c\n        &gt;&gt;&gt; y2 = F.logsumexp(x, axis=0) # \u6cbf\u5217LogSumExp\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#_8","title":"\u6fc0\u6d3b\u51fd\u6570","text":""},{"location":"api/nn/functional/#relu","title":"relu","text":"Python<pre><code>def relu(a: Tensor) -&gt; Tensor:\n    \"\"\"\n    ReLU\u6fc0\u6d3b\u51fd\u6570: f(x) = max(0, x)\n\n    \u53c2\u6570:\n        a: Tensor - \u8f93\u5165\u5f20\u91cf\n\n    \u8fd4\u56de:\n        Tensor - ReLU\u6fc0\u6d3b\u540e\u7684\u5f20\u91cf\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.tensor([-2.0, -1.0, 0.0, 1.0, 2.0])\n        &gt;&gt;&gt; y = F.relu(x)\n        &gt;&gt;&gt; # \u7ed3\u679c: [0.0, 0.0, 0.0, 1.0, 2.0]\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#triton_ops","title":"\u9ad8\u7ea7\u64cd\u4f5c\uff08\u6765\u81eatriton_ops\uff09","text":""},{"location":"api/nn/functional/#softmax","title":"softmax","text":"Python<pre><code># \u4ece genesis.nn.triton_ops \u5bfc\u5165\nfrom genesis.nn.triton_ops import softmax\n\ndef softmax(x: Tensor, dim: int = -1) -&gt; Tensor:\n    \"\"\"\n    \u4f7f\u7528\u4f18\u5316\u7684Triton\u5185\u6838\u7684Softmax\u51fd\u6570\u3002\n\n    \u53c2\u6570:\n        x: Tensor - \u8f93\u5165\u5f20\u91cf\n        dim: int - \u5e94\u7528softmax\u7684\u7ef4\u5ea6\n\n    \u8fd4\u56de:\n        Tensor - Softmax\u8f93\u51fa\uff08\u6cbfdim\u7ef4\u5ea6\u548c\u4e3a1\uff09\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.randn(2, 3)\n        &gt;&gt;&gt; y = softmax(x, dim=1)\n        &gt;&gt;&gt; # \u6bcf\u884c\u548c\u4e3a1\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#dropout","title":"dropout","text":"Python<pre><code># \u4ece genesis.nn.triton_ops \u5bfc\u5165\nfrom genesis.nn.triton_ops import dropout\n\ndef dropout(x: Tensor, p: float = 0.5, training: bool = True) -&gt; Tensor:\n    \"\"\"\n    \u4f7f\u7528Triton\u5185\u6838\u7684Dropout\u6b63\u5219\u5316\u3002\n\n    \u53c2\u6570:\n        x: Tensor - \u8f93\u5165\u5f20\u91cf\n        p: float - Dropout\u6982\u7387\n        training: bool - \u662f\u5426\u5904\u4e8e\u8bad\u7ec3\u6a21\u5f0f\n\n    \u8fd4\u56de:\n        Tensor - \u5e94\u7528dropout\u540e\u7684\u5f20\u91cf\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.randn(100, 50)\n        &gt;&gt;&gt; y = dropout(x, p=0.2, training=True)\n        &gt;&gt;&gt; # 20%\u7684\u5143\u7d20\u8bbe\u4e3a0\uff0c\u5176\u4ed6\u5143\u7d20\u63091/(1-p)\u7f29\u653e\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#_9","title":"\u7d22\u5f15\u548c\u5e7f\u64ad","text":""},{"location":"api/nn/functional/#getitem-setitem-broadcast_to","title":"getitem, setitem, broadcast_to","text":"Python<pre><code>def getitem(a: Tensor, index) -&gt; Tensor:\ndef setitem(a: Tensor, index, value) -&gt; Tensor:\ndef broadcast_to(a: Tensor, shape: tuple) -&gt; Tensor:\n    \"\"\"\n    \u5f20\u91cf\u7d22\u5f15\u548c\u5e7f\u64ad\u64cd\u4f5c\u3002\n\n    \u53c2\u6570:\n        a: Tensor - \u8f93\u5165\u5f20\u91cf\n        index: Various - \u7d22\u5f15\uff08int\u3001slice\u3001list\u3001Tensor\uff09\n        value: Tensor/scalar - \u8981\u8bbe\u7f6e\u7684\u503c\n        shape: tuple - \u76ee\u6807\u5e7f\u64ad\u5f62\u72b6\n\n    \u8fd4\u56de:\n        Tensor - \u7d22\u5f15/\u5e7f\u64ad\u540e\u7684\u5f20\u91cf\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; x = genesis.randn(3, 4)\n        &gt;&gt;&gt; y1 = F.getitem(x, [0, 2])      # \u9009\u62e9\u7b2c0\u548c\u7b2c2\u884c\n        &gt;&gt;&gt; y2 = F.broadcast_to(x, (2, 3, 4))  # \u5e7f\u64ad\u5230 (2, 3, 4)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/functional/#_10","title":"\u6027\u80fd\u8bf4\u660e","text":"<ul> <li>GPU\u52a0\u901f\uff1a\u5f53\u5f20\u91cf\u5728CUDA\u8bbe\u5907\u4e0a\u65f6\uff0c\u64cd\u4f5c\u81ea\u52a8\u4f7f\u7528GPU</li> <li>Triton\u4f18\u5316\uff1aSoftmax\u548cdropout\u4f7f\u7528\u4f18\u5316\u7684Triton\u5185\u6838</li> <li>\u5185\u5b58\u6548\u7387\uff1aview\u64cd\u4f5c\u5728\u53ef\u80fd\u65f6\u5171\u4eab\u5185\u5b58</li> <li>\u6df7\u5408\u7cbe\u5ea6\uff1a\u542f\u7528\u65f6\u51fd\u6570\u652f\u6301\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6</li> </ul>"},{"location":"api/nn/functional/#_11","title":"\u5e38\u7528\u6a21\u5f0f","text":"Python<pre><code>import genesis\nimport genesis.nn.functional as F\n\n# \u57fa\u7840\u64cd\u4f5c\nx = genesis.randn(100, 784)\ny = F.relu(F.matmul(x, weights) + bias)\n\n# \u5f62\u72b6\u64cd\u4f5c\nx = genesis.randn(32, 3, 224, 224)\nx_flat = F.flatten(x, start_dim=1)  # (32, 150528)\n\n# \u805a\u5408\nlogits = genesis.randn(32, 10)\nprobs = F.softmax(logits, dim=1)\nmax_vals = F.max(logits, axis=1)\n\n# \u9ad8\u7ea7\u7d22\u5f15\nindices = genesis.tensor([0, 2, 4])\nselected = F.getitem(x, indices)\n</code></pre>"},{"location":"api/nn/functional/#_12","title":"\u672a\u6765\u529f\u80fd\uff08\u8def\u7ebf\u56fe\uff09","text":"<p>\u4ee5\u4e0b\u51fd\u6570\u8ba1\u5212\u5728\u672a\u6765\u7248\u672c\u4e2d\u5b9e\u73b0\uff1a - \u9ad8\u7ea7\u6fc0\u6d3b\u51fd\u6570\uff08gelu\u3001silu\u3001swish\uff09 - \u635f\u5931\u51fd\u6570\uff08cross_entropy\u3001mse_loss\u3001l1_loss\uff09 - \u5f52\u4e00\u5316\u51fd\u6570\uff08layer_norm\u3001batch_norm\uff09 - \u5377\u79ef\u64cd\u4f5c\uff08conv1d\u3001conv2d\uff09 - \u6ce8\u610f\u529b\u673a\u5236\uff08scaled_dot_product_attention\uff09</p> <p>\u8981\u8ddf\u8e2a\u8fd9\u4e9b\u529f\u80fd\u7684\u8fdb\u5c55\uff0c\u8bf7\u67e5\u770bGitHub\u4e0a\u7684\u9879\u76ee\u8def\u7ebf\u56fe\u3002</p>"},{"location":"api/nn/modules/","title":"\u795e\u7ecf\u7f51\u7edc\u6a21\u5757 (genesis.nn)","text":""},{"location":"api/nn/modules/#_1","title":"\u6982\u8ff0","text":"<p><code>genesis.nn</code>\u6a21\u5757\u63d0\u4f9b\u4e86\u521b\u5efa\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6240\u9700\u7684\u6240\u6709\u6784\u5efa\u5757\u3002\u5b83\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u901a\u8fc7\u7ec4\u5408\u66f4\u7b80\u5355\u7684\u7ec4\u4ef6\u6765\u6784\u5efa\u590d\u6742\u6a21\u578b\u3002</p>"},{"location":"api/nn/modules/#_2","title":"\u6838\u5fc3\u6982\u5ff5","text":""},{"location":"api/nn/modules/#_3","title":"\u6a21\u5757\u7cfb\u7edf","text":"<p>\u6240\u6709\u795e\u7ecf\u7f51\u7edc\u7ec4\u4ef6\u90fd\u7ee7\u627f\u81ea<code>nn.Module</code>\uff0c\u5b83\u63d0\u4f9b\uff1a - \u53c2\u6570\u7ba1\u7406 - \u8bbe\u5907\u548cdtype\u5904\u7406 - \u72b6\u6001\u5e8f\u5217\u5316 - \u524d\u5411\u4f20\u64ad\u5b9a\u4e49</p>"},{"location":"api/nn/modules/#_4","title":"\u53c2\u6570","text":"<p>\u53c2\u6570\u662f\u81ea\u52a8\u8ddf\u8e2a\u5e76\u5728\u8bad\u7ec3\u671f\u95f4\u66f4\u65b0\u7684\u5f20\u91cf\uff1a - \u5206\u914d\u4e3a\u6a21\u5757\u5c5e\u6027\u65f6\u81ea\u52a8\u6ce8\u518c - \u5305\u542b\u5728<code>module.parameters()</code>\u4e2d\u4f9b\u4f18\u5316\u5668\u4f7f\u7528 - \u4e0e\u6a21\u578b\u72b6\u6001\u4e00\u8d77\u4fdd\u5b58/\u52a0\u8f7d</p>"},{"location":"api/nn/modules/#_5","title":"\u57fa\u7c7b","text":""},{"location":"api/nn/modules/#nnmodule","title":"<code>nn.Module</code>","text":"<p>\u6240\u6709\u795e\u7ecf\u7f51\u7edc\u6a21\u5757\u7684\u57fa\u7c7b\u3002</p> Python<pre><code>class Module:\n    \"\"\"\u6240\u6709\u795e\u7ecf\u7f51\u7edc\u6a21\u5757\u7684\u57fa\u7c7b\u3002\"\"\"\n\n    def __init__(self):\n        \"\"\"\u521d\u59cb\u5316\u6a21\u5757\u3002\"\"\"\n        self._modules = {}\n        self._parameters = {}\n        self._buffers = {}\n        self.training = True\n</code></pre>"},{"location":"api/nn/modules/#_6","title":"\u6838\u5fc3\u65b9\u6cd5","text":""},{"location":"api/nn/modules/#_7","title":"\u524d\u5411\u4f20\u64ad","text":"Python<pre><code>def forward(self, *args, **kwargs) -&gt; Tensor:\n    \"\"\"\n    \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8ba1\u7b97\u3002\n    \u5fc5\u987b\u7531\u5b50\u7c7b\u91cd\u5199\u3002\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; class MyModule(nn.Module):\n        ...     def forward(self, x):\n        ...         return x * 2\n    \"\"\"\n    raise NotImplementedError\n\ndef __call__(self, *args, **kwargs) -&gt; Tensor:\n    \"\"\"\n    \u4f7f\u6a21\u5757\u53ef\u8c03\u7528\u3002\u5185\u90e8\u8c03\u7528forward()\u3002\n\n    \u6ce8\u610f: \u59cb\u7ec8\u4f7f\u7528module(input)\u800c\u4e0d\u662fmodule.forward(input)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_8","title":"\u53c2\u6570\u7ba1\u7406","text":"Python<pre><code>def parameters(self) -&gt; List[Tensor]:\n    \"\"\"\n    \u8fd4\u56de\u6a21\u5757\u4e2d\u7684\u6240\u6709\u53c2\u6570\u3002\n\n    \u8fd4\u56de:\n        \u53c2\u6570\u5f20\u91cf\u5217\u8868\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; model = nn.Linear(10, 5)\n        &gt;&gt;&gt; params = model.parameters()\n        &gt;&gt;&gt; print(len(params))  # 2 (\u6743\u91cd\u548c\u504f\u7f6e)\n    \"\"\"\n\ndef named_parameters(self) -&gt; List[Tuple[str, Tensor]]:\n    \"\"\"\n    \u8fd4\u56de\u5e26\u540d\u79f0\u7684\u53c2\u6570\u3002\n\n    \u8fd4\u56de:\n        (\u540d\u79f0, \u53c2\u6570)\u5143\u7ec4\u5217\u8868\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; for name, param in model.named_parameters():\n        ...     print(f\"{name}: {param.shape}\")\n    \"\"\"\n\ndef zero_grad(self) -&gt; None:\n    \"\"\"\n    \u5c06\u6240\u6709\u53c2\u6570\u7684\u68af\u5ea6\u6e05\u96f6\u3002\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; model.zero_grad()  # \u6e05\u9664\u6240\u6709\u68af\u5ea6\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_9","title":"\u6a21\u5757\u5c42\u6b21\u7ed3\u6784","text":"Python<pre><code>def add_module(self, name: str, module: Optional[Module]) -&gt; None:\n    \"\"\"\n    \u6dfb\u52a0\u5b50\u6a21\u5757\u3002\n\n    \u53c2\u6570:\n        name: \u5b50\u6a21\u5757\u7684\u540d\u79f0\n        module: \u8981\u6dfb\u52a0\u7684\u6a21\u5757\u5b9e\u4f8b\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; model = nn.Module()\n        &gt;&gt;&gt; model.add_module('fc', nn.Linear(10, 5))\n    \"\"\"\n\ndef modules(self) -&gt; Iterator[Module]:\n    \"\"\"\u8fd4\u56de\u6240\u6709\u6a21\u5757\uff08\u5305\u62ec\u81ea\u8eab\uff09\u7684\u8fed\u4ee3\u5668\u3002\"\"\"\n\ndef children(self) -&gt; Iterator[Module]:\n    \"\"\"\u8fd4\u56de\u76f4\u63a5\u5b50\u6a21\u5757\u7684\u8fed\u4ee3\u5668\u3002\"\"\"\n\ndef named_modules(self) -&gt; Iterator[Tuple[str, Module]]:\n    \"\"\"\u8fd4\u56de\u6240\u6709\u6a21\u5757\u53ca\u5176\u540d\u79f0\u7684\u8fed\u4ee3\u5668\u3002\"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_10","title":"\u8bad\u7ec3\u6a21\u5f0f","text":"Python<pre><code>def train(self, mode: bool = True) -&gt; Module:\n    \"\"\"\n    \u5c06\u6a21\u5757\u8bbe\u7f6e\u4e3a\u8bad\u7ec3\u6a21\u5f0f\u3002\n\n    \u53c2\u6570:\n        mode: \u662f\u5426\u542f\u7528\u8bad\u7ec3\u6a21\u5f0f\n\n    \u8fd4\u56de:\n        self\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; model.train()  # \u542f\u7528\u8bad\u7ec3\u6a21\u5f0f\n        &gt;&gt;&gt; model.train(False)  # \u7b49\u4ef7\u4e8emodel.eval()\n    \"\"\"\n\ndef eval(self) -&gt; Module:\n    \"\"\"\n    \u5c06\u6a21\u5757\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f\u3002\n\n    \u8fd4\u56de:\n        self\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; model.eval()  # \u7981\u7528dropout\uff0c\u4f7f\u7528BN\u7684\u8fd0\u884c\u7edf\u8ba1\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_11","title":"\u72b6\u6001\u7ba1\u7406","text":"Python<pre><code>def state_dict(self) -&gt; Dict[str, Tensor]:\n    \"\"\"\n    \u8fd4\u56de\u5305\u542b\u6240\u6709\u53c2\u6570\u548c\u7f13\u51b2\u533a\u7684\u72b6\u6001\u5b57\u5178\u3002\n\n    \u8fd4\u56de:\n        \u53c2\u6570\u540d\u79f0\u5230\u5f20\u91cf\u7684\u6620\u5c04\u5b57\u5178\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; state = model.state_dict()\n        &gt;&gt;&gt; genesis.save(state, 'model.pth')\n    \"\"\"\n\ndef load_state_dict(self, state_dict: Dict[str, Tensor]) -&gt; None:\n    \"\"\"\n    \u4ece\u72b6\u6001\u5b57\u5178\u52a0\u8f7d\u53c2\u6570\u3002\n\n    \u53c2\u6570:\n        state_dict: \u53c2\u6570\u5b57\u5178\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; state = genesis.load('model.pth')\n        &gt;&gt;&gt; model.load_state_dict(state)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#nnparameter","title":"<code>nn.Parameter</code>","text":"<p>\u81ea\u52a8\u6ce8\u518c\u4e3a\u6a21\u5757\u53c2\u6570\u7684\u7279\u6b8a\u5f20\u91cf\u3002</p> Python<pre><code>class Parameter(Tensor):\n    \"\"\"\n    \u81ea\u52a8\u6ce8\u518c\u4e3a\u6a21\u5757\u53c2\u6570\u7684\u5f20\u91cf\u3002\n\n    \u53c2\u6570:\n        data: \u5f20\u91cf\u6570\u636e\n        requires_grad: \u662f\u5426\u8ba1\u7b97\u68af\u5ea6\uff08\u9ed8\u8ba4: True\uff09\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; class MyModule(nn.Module):\n        ...     def __init__(self):\n        ...         super().__init__()\n        ...         self.weight = nn.Parameter(genesis.randn(10, 5))\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_12","title":"\u5c42\u7c7b\u578b","text":""},{"location":"api/nn/modules/#_13","title":"\u7ebf\u6027\u5c42","text":""},{"location":"api/nn/modules/#nnlinear","title":"<code>nn.Linear</code>","text":"<p>\u6267\u884c\u7ebf\u6027\u53d8\u6362\u7684\u5168\u8fde\u63a5\u5c42\u3002</p> Python<pre><code>class Linear(Module):\n    \"\"\"\n    \u7ebf\u6027\u53d8\u6362: y = xW^T + b\n\n    \u53c2\u6570:\n        in_features: \u8f93\u5165\u7279\u5f81\u5927\u5c0f\n        out_features: \u8f93\u51fa\u7279\u5f81\u5927\u5c0f\n        bias: \u662f\u5426\u5305\u542b\u504f\u7f6e\u9879\uff08\u9ed8\u8ba4: True\uff09\n\n    \u5f62\u72b6:\n        - \u8f93\u5165: (*, in_features)\n        - \u8f93\u51fa: (*, out_features)\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; layer = nn.Linear(20, 30)\n        &gt;&gt;&gt; x = genesis.randn(128, 20)\n        &gt;&gt;&gt; output = layer(x)  # \u5f62\u72b6: (128, 30)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_14","title":"\u5377\u79ef\u5c42","text":""},{"location":"api/nn/modules/#nnconv2d","title":"<code>nn.Conv2d</code>","text":"<p>\u7528\u4e8e\u56fe\u50cf\u5904\u7406\u76842D\u5377\u79ef\u5c42\u3002</p> Python<pre><code>class Conv2d(Module):\n    \"\"\"\n    \u8f93\u5165\u4fe1\u53f7\u76842D\u5377\u79ef\u3002\n\n    \u53c2\u6570:\n        in_channels: \u8f93\u5165\u901a\u9053\u6570\n        out_channels: \u8f93\u51fa\u901a\u9053\u6570\n        kernel_size: \u5377\u79ef\u6838\u5927\u5c0f\n        stride: \u5377\u79ef\u6b65\u957f\uff08\u9ed8\u8ba4: 1\uff09\n        padding: \u4e24\u4fa7\u6dfb\u52a0\u7684\u96f6\u586b\u5145\uff08\u9ed8\u8ba4: 0\uff09\n        bias: \u662f\u5426\u6dfb\u52a0\u504f\u7f6e\uff08\u9ed8\u8ba4: True\uff09\n\n    \u5f62\u72b6:\n        - \u8f93\u5165: (N, C_in, H, W)\n        - \u8f93\u51fa: (N, C_out, H_out, W_out)\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; conv = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n        &gt;&gt;&gt; x = genesis.randn(32, 3, 224, 224)\n        &gt;&gt;&gt; output = conv(x)  # \u5f62\u72b6: (32, 64, 224, 224)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_15","title":"\u6fc0\u6d3b\u51fd\u6570","text":""},{"location":"api/nn/modules/#nnrelu","title":"<code>nn.ReLU</code>","text":"<p>\u4fee\u6b63\u7ebf\u6027\u5355\u5143\u6fc0\u6d3b\u3002</p> Python<pre><code>class ReLU(Module):\n    \"\"\"\n    ReLU\u6fc0\u6d3b: f(x) = max(0, x)\n\n    \u53c2\u6570:\n        inplace: \u662f\u5426\u539f\u5730\u4fee\u6539\u8f93\u5165\uff08\u9ed8\u8ba4: False\uff09\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; relu = nn.ReLU()\n        &gt;&gt;&gt; x = genesis.randn(10)\n        &gt;&gt;&gt; output = relu(x)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#nnsigmoid","title":"<code>nn.Sigmoid</code>","text":"<p>Sigmoid\u6fc0\u6d3b\u51fd\u6570\u3002</p> Python<pre><code>class Sigmoid(Module):\n    \"\"\"\n    Sigmoid\u6fc0\u6d3b: f(x) = 1 / (1 + exp(-x))\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; sigmoid = nn.Sigmoid()\n        &gt;&gt;&gt; x = genesis.randn(10)\n        &gt;&gt;&gt; output = sigmoid(x)  # \u503c\u5728(0, 1)\u8303\u56f4\u5185\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#nntanh","title":"<code>nn.Tanh</code>","text":"<p>\u53cc\u66f2\u6b63\u5207\u6fc0\u6d3b\u3002</p> Python<pre><code>class Tanh(Module):\n    \"\"\"\n    Tanh\u6fc0\u6d3b: f(x) = tanh(x)\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; tanh = nn.Tanh()\n        &gt;&gt;&gt; x = genesis.randn(10)\n        &gt;&gt;&gt; output = tanh(x)  # \u503c\u5728(-1, 1)\u8303\u56f4\u5185\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#nnsilu-swish","title":"<code>nn.SiLU</code> (Swish)","text":"<p>Sigmoid\u7ebf\u6027\u5355\u5143\u6fc0\u6d3b\u3002</p> Python<pre><code>class SiLU(Module):\n    \"\"\"\n    SiLU/Swish\u6fc0\u6d3b: f(x) = x * sigmoid(x)\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; silu = nn.SiLU()\n        &gt;&gt;&gt; x = genesis.randn(10)\n        &gt;&gt;&gt; output = silu(x)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#nngelu","title":"<code>nn.GELU</code>","text":"<p>\u9ad8\u65af\u8bef\u5dee\u7ebf\u6027\u5355\u5143\u6fc0\u6d3b\u3002</p> Python<pre><code>class GELU(Module):\n    \"\"\"\n    GELU\u6fc0\u6d3b: f(x) = x * \u03a6(x)\n    \u5176\u4e2d\u03a6(x)\u662f\u6807\u51c6\u9ad8\u65af\u5206\u5e03\u7684\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u3002\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; gelu = nn.GELU()\n        &gt;&gt;&gt; x = genesis.randn(10)\n        &gt;&gt;&gt; output = gelu(x)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#nnsoftmax","title":"<code>nn.Softmax</code>","text":"<p>\u591a\u7c7b\u5206\u7c7b\u7684Softmax\u6fc0\u6d3b\u3002</p> Python<pre><code>class Softmax(Module):\n    \"\"\"\n    Softmax\u6fc0\u6d3b: softmax(x_i) = exp(x_i) / \u03a3 exp(x_j)\n\n    \u53c2\u6570:\n        dim: \u5e94\u7528softmax\u7684\u7ef4\u5ea6\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; softmax = nn.Softmax(dim=-1)\n        &gt;&gt;&gt; x = genesis.randn(10, 5)\n        &gt;&gt;&gt; output = softmax(x)  # \u6bcf\u884c\u548c\u4e3a1\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_16","title":"\u5f52\u4e00\u5316\u5c42","text":""},{"location":"api/nn/modules/#nnbatchnorm1d","title":"<code>nn.BatchNorm1d</code>","text":"<p>1D\u62162D\u8f93\u5165\u7684\u6279\u91cf\u5f52\u4e00\u5316\u3002</p> Python<pre><code>class BatchNorm1d(Module):\n    \"\"\"\n    2D\u62163D\u8f93\u5165\u7684\u6279\u91cf\u5f52\u4e00\u5316\u3002\n\n    \u53c2\u6570:\n        num_features: \u7279\u5f81\u6570\u91cf\uff08[N, C]\u6216[N, C, L]\u4e2d\u7684C\uff09\n        eps: \u6570\u503c\u7a33\u5b9a\u6027\u7684\u5c0f\u503c\uff08\u9ed8\u8ba4: 1e-5\uff09\n        momentum: \u8fd0\u884c\u7edf\u8ba1\u7684\u52a8\u91cf\uff08\u9ed8\u8ba4: 0.1\uff09\n\n    \u5f62\u72b6:\n        - \u8f93\u5165: (N, C)\u6216(N, C, L)\n        - \u8f93\u51fa: \u4e0e\u8f93\u5165\u76f8\u540c\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; bn = nn.BatchNorm1d(100)\n        &gt;&gt;&gt; x = genesis.randn(20, 100)\n        &gt;&gt;&gt; output = bn(x)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#nnlayernorm","title":"<code>nn.LayerNorm</code>","text":"<p>\u5c42\u5f52\u4e00\u5316\u3002</p> Python<pre><code>class LayerNorm(Module):\n    \"\"\"\n    \u6700\u540e\u7ef4\u5ea6\u7684\u5c42\u5f52\u4e00\u5316\u3002\n\n    \u53c2\u6570:\n        normalized_shape: \u8981\u5f52\u4e00\u5316\u7684\u7ef4\u5ea6\u5f62\u72b6\n        eps: \u6570\u503c\u7a33\u5b9a\u6027\u7684\u5c0f\u503c\uff08\u9ed8\u8ba4: 1e-5\uff09\n\n    \u5f62\u72b6:\n        - \u8f93\u5165: (*, normalized_shape)\n        - \u8f93\u51fa: \u4e0e\u8f93\u5165\u76f8\u540c\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; ln = nn.LayerNorm([768])\n        &gt;&gt;&gt; x = genesis.randn(32, 100, 768)\n        &gt;&gt;&gt; output = ln(x)  # \u5728\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u5f52\u4e00\u5316\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#dropout","title":"Dropout\u5c42","text":""},{"location":"api/nn/modules/#nndropout","title":"<code>nn.Dropout</code>","text":"<p>\u6b63\u5219\u5316\u7684Dropout\u3002</p> Python<pre><code>class Dropout(Module):\n    \"\"\"\n    \u968f\u673a\u5c06\u5143\u7d20\u7f6e\u96f6\u8fdb\u884c\u6b63\u5219\u5316\u3002\n\n    \u53c2\u6570:\n        p: \u5c06\u5143\u7d20\u7f6e\u96f6\u7684\u6982\u7387\uff08\u9ed8\u8ba4: 0.5\uff09\n        inplace: \u662f\u5426\u539f\u5730\u4fee\u6539\u8f93\u5165\uff08\u9ed8\u8ba4: False\uff09\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; dropout = nn.Dropout(p=0.2)\n        &gt;&gt;&gt; x = genesis.randn(20, 16)\n        &gt;&gt;&gt; output = dropout(x)  # \u8bad\u7ec3\u6a21\u5f0f\uff1a\u968f\u673a\u5c0620%\u7684\u5143\u7d20\u7f6e\u96f6\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_17","title":"\u6c60\u5316\u5c42","text":""},{"location":"api/nn/modules/#nnmaxpool2d","title":"<code>nn.MaxPool2d</code>","text":"<p>2D\u6700\u5927\u6c60\u5316\u3002</p> Python<pre><code>class MaxPool2d(Module):\n    \"\"\"\n    2D\u8f93\u5165\u7684\u6700\u5927\u6c60\u5316\u3002\n\n    \u53c2\u6570:\n        kernel_size: \u6c60\u5316\u7a97\u53e3\u5927\u5c0f\n        stride: \u6c60\u5316\u6b65\u957f\uff08\u9ed8\u8ba4: kernel_size\uff09\n        padding: \u96f6\u586b\u5145\uff08\u9ed8\u8ba4: 0\uff09\n\n    \u5f62\u72b6:\n        - \u8f93\u5165: (N, C, H, W)\n        - \u8f93\u51fa: (N, C, H_out, W_out)\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        &gt;&gt;&gt; x = genesis.randn(1, 16, 32, 32)\n        &gt;&gt;&gt; output = pool(x)  # \u5f62\u72b6: (1, 16, 16, 16)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#nnavgpool2d","title":"<code>nn.AvgPool2d</code>","text":"<p>2D\u5e73\u5747\u6c60\u5316\u3002</p> Python<pre><code>class AvgPool2d(Module):\n    \"\"\"\n    2D\u8f93\u5165\u7684\u5e73\u5747\u6c60\u5316\u3002\n\n    \u53c2\u6570:\n        kernel_size: \u6c60\u5316\u7a97\u53e3\u5927\u5c0f\n        stride: \u6c60\u5316\u6b65\u957f\uff08\u9ed8\u8ba4: kernel_size\uff09\n        padding: \u96f6\u586b\u5145\uff08\u9ed8\u8ba4: 0\uff09\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; pool = nn.AvgPool2d(kernel_size=2, stride=2)\n        &gt;&gt;&gt; x = genesis.randn(1, 16, 32, 32)\n        &gt;&gt;&gt; output = pool(x)  # \u5f62\u72b6: (1, 16, 16, 16)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_18","title":"\u5d4c\u5165\u5c42","text":""},{"location":"api/nn/modules/#nnembedding","title":"<code>nn.Embedding</code>","text":"<p>\u5d4c\u5165\u67e5\u627e\u8868\u3002</p> Python<pre><code>class Embedding(Module):\n    \"\"\"\n    \u5d4c\u5165\u67e5\u627e\u8868\u3002\n\n    \u53c2\u6570:\n        num_embeddings: \u8bcd\u6c47\u5927\u5c0f\n        embedding_dim: \u5d4c\u5165\u7ef4\u5ea6\n\n    \u5f62\u72b6:\n        - \u8f93\u5165: (*)\u5305\u542b\u7d22\u5f15\n        - \u8f93\u51fa: (*, embedding_dim)\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; embed = nn.Embedding(10000, 300)  # 10k\u8bcd\u6c47\uff0c300\u7ef4\u5d4c\u5165\n        &gt;&gt;&gt; indices = genesis.tensor([1, 2, 3, 4])\n        &gt;&gt;&gt; output = embed(indices)  # \u5f62\u72b6: (4, 300)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_19","title":"\u6ce8\u610f\u529b\u5c42","text":""},{"location":"api/nn/modules/#nnmultiheadattention","title":"<code>nn.MultiheadAttention</code>","text":"<p>\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u3002</p> Python<pre><code>class MultiheadAttention(Module):\n    \"\"\"\n    \u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u3002\n\n    \u53c2\u6570:\n        embed_dim: \u5d4c\u5165\u7ef4\u5ea6\n        num_heads: \u6ce8\u610f\u529b\u5934\u6570\n        dropout: Dropout\u6982\u7387\uff08\u9ed8\u8ba4: 0.0\uff09\n        bias: \u662f\u5426\u6dfb\u52a0\u504f\u7f6e\uff08\u9ed8\u8ba4: True\uff09\n\n    \u5f62\u72b6:\n        - Query: (L, N, E)\u6216(N, L, E)\n        - Key: (S, N, E)\u6216(N, S, E)\n        - Value: (S, N, E)\u6216(N, S, E)\n        - Output: (L, N, E)\u6216(N, L, E)\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; attn = nn.MultiheadAttention(embed_dim=512, num_heads=8)\n        &gt;&gt;&gt; x = genesis.randn(10, 32, 512)  # (seq_len, batch, embed_dim)\n        &gt;&gt;&gt; output, weights = attn(x, x, x)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_20","title":"\u5bb9\u5668\u6a21\u5757","text":""},{"location":"api/nn/modules/#nnsequential","title":"<code>nn.Sequential</code>","text":"<p>\u6a21\u5757\u7684\u5e8f\u5217\u5bb9\u5668\u3002</p> Python<pre><code>class Sequential(Module):\n    \"\"\"\n    \u6309\u987a\u5e8f\u8fd0\u884c\u6a21\u5757\u7684\u5e8f\u5217\u5bb9\u5668\u3002\n\n    \u53c2\u6570:\n        *modules: \u8981\u5e94\u7528\u7684\u6a21\u5757\u5e8f\u5217\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; model = nn.Sequential(\n        ...     nn.Linear(784, 256),\n        ...     nn.ReLU(),\n        ...     nn.Linear(256, 10)\n        ... )\n        &gt;&gt;&gt; x = genesis.randn(32, 784)\n        &gt;&gt;&gt; output = model(x)  # \u5f62\u72b6: (32, 10)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#nnmodulelist","title":"<code>nn.ModuleList</code>","text":"<p>\u6a21\u5757\u7684\u5217\u8868\u5bb9\u5668\u3002</p> Python<pre><code>class ModuleList(Module):\n    \"\"\"\n    \u6b63\u786e\u6ce8\u518c\u7684\u6a21\u5757\u5217\u8868\u3002\n\n    \u53c2\u6570:\n        modules: \u53ef\u9009\u7684\u6a21\u5757\u5217\u8868\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; layers = nn.ModuleList([\n        ...     nn.Linear(10, 10) for _ in range(5)\n        ... ])\n        &gt;&gt;&gt; x = genesis.randn(32, 10)\n        &gt;&gt;&gt; for layer in layers:\n        ...     x = layer(x)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#nnmoduledict","title":"<code>nn.ModuleDict</code>","text":"<p>\u6a21\u5757\u7684\u5b57\u5178\u5bb9\u5668\u3002</p> Python<pre><code>class ModuleDict(Module):\n    \"\"\"\n    \u5e26\u5b57\u7b26\u4e32\u952e\u7684\u6a21\u5757\u5b57\u5178\u3002\n\n    \u53c2\u6570:\n        modules: \u53ef\u9009\u7684\u6a21\u5757\u5b57\u5178\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; layers = nn.ModuleDict({\n        ...     'fc1': nn.Linear(10, 20),\n        ...     'fc2': nn.Linear(20, 10)\n        ... })\n        &gt;&gt;&gt; x = genesis.randn(32, 10)\n        &gt;&gt;&gt; x = layers['fc1'](x)\n        &gt;&gt;&gt; x = layers['fc2'](x)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_21","title":"\u635f\u5931\u51fd\u6570","text":""},{"location":"api/nn/modules/#nnmseloss","title":"<code>nn.MSELoss</code>","text":"<p>\u5747\u65b9\u8bef\u5dee\u635f\u5931\u3002</p> Python<pre><code>class MSELoss(Module):\n    \"\"\"\n    \u5747\u65b9\u8bef\u5dee\u635f\u5931: L = mean((y_pred - y_true)^2)\n\n    \u53c2\u6570:\n        reduction: 'mean', 'sum', \u6216 'none'\uff08\u9ed8\u8ba4: 'mean'\uff09\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; loss_fn = nn.MSELoss()\n        &gt;&gt;&gt; pred = genesis.randn(32, 10)\n        &gt;&gt;&gt; target = genesis.randn(32, 10)\n        &gt;&gt;&gt; loss = loss_fn(pred, target)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#nncrossentropyloss","title":"<code>nn.CrossEntropyLoss</code>","text":"<p>\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u3002</p> Python<pre><code>class CrossEntropyLoss(Module):\n    \"\"\"\n    \u591a\u7c7b\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u3002\n\n    \u53c2\u6570:\n        weight: \u6bcf\u4e2a\u7c7b\u7684\u624b\u52a8\u91cd\u7f29\u653e\u6743\u91cd\n        reduction: 'mean', 'sum', \u6216 'none'\uff08\u9ed8\u8ba4: 'mean'\uff09\n\n    \u5f62\u72b6:\n        - \u8f93\u5165: (N, C) \u5176\u4e2dC\u662f\u7c7b\u522b\u6570\n        - \u76ee\u6807: (N,) \u5305\u542b\u7c7b\u522b\u7d22\u5f15\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; loss_fn = nn.CrossEntropyLoss()\n        &gt;&gt;&gt; logits = genesis.randn(32, 10)  # 32\u4e2a\u6837\u672c\uff0c10\u4e2a\u7c7b\u522b\n        &gt;&gt;&gt; targets = genesis.randint(0, 10, (32,))\n        &gt;&gt;&gt; loss = loss_fn(logits, targets)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#nnbceloss","title":"<code>nn.BCELoss</code>","text":"<p>\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u3002</p> Python<pre><code>class BCELoss(Module):\n    \"\"\"\n    \u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u3002\n\n    \u53c2\u6570:\n        reduction: 'mean', 'sum', \u6216 'none'\uff08\u9ed8\u8ba4: 'mean'\uff09\n\n    \u5f62\u72b6:\n        - \u8f93\u5165: (N, *) \u5176\u4e2d*\u8868\u793a\u4efb\u610f\u6570\u91cf\u7684\u7ef4\u5ea6\n        - \u76ee\u6807: \u4e0e\u8f93\u5165\u76f8\u540c\u5f62\u72b6\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; loss_fn = nn.BCELoss()\n        &gt;&gt;&gt; pred = genesis.sigmoid(genesis.randn(32, 1))\n        &gt;&gt;&gt; target = genesis.randint(0, 2, (32, 1)).float()\n        &gt;&gt;&gt; loss = loss_fn(pred, target)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_22","title":"\u5de5\u5177","text":""},{"location":"api/nn/modules/#_23","title":"\u6743\u91cd\u521d\u59cb\u5316","text":"Python<pre><code>def init_weights(module: Module, init_type: str = 'xavier'):\n    \"\"\"\n    \u521d\u59cb\u5316\u6a21\u5757\u6743\u91cd\u3002\n\n    \u53c2\u6570:\n        module: \u8981\u521d\u59cb\u5316\u7684\u6a21\u5757\n        init_type: 'xavier', 'kaiming', 'normal', 'uniform'\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; model = nn.Linear(10, 5)\n        &gt;&gt;&gt; init_weights(model, 'xavier')\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_24","title":"\u68af\u5ea6\u88c1\u526a","text":"Python<pre><code>def clip_grad_norm_(parameters, max_norm: float, norm_type: float = 2.0):\n    \"\"\"\n    \u6309\u8303\u6570\u88c1\u526a\u68af\u5ea6\u3002\n\n    \u53c2\u6570:\n        parameters: \u53c2\u6570\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\n        max_norm: \u6700\u5927\u8303\u6570\u503c\n        norm_type: \u8303\u6570\u7c7b\u578b\uff08\u9ed8\u8ba4: 2.0\uff09\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n    \"\"\"\n\ndef clip_grad_value_(parameters, clip_value: float):\n    \"\"\"\n    \u6309\u503c\u88c1\u526a\u68af\u5ea6\u3002\n\n    \u53c2\u6570:\n        parameters: \u53c2\u6570\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\n        clip_value: \u6700\u5927\u7edd\u5bf9\u503c\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; nn.utils.clip_grad_value_(model.parameters(), clip_value=0.5)\n    \"\"\"\n</code></pre>"},{"location":"api/nn/modules/#_25","title":"\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u5757","text":""},{"location":"api/nn/modules/#_26","title":"\u793a\u4f8b\uff1a\u81ea\u5b9a\u4e49\u5c42","text":"Python<pre><code>class CustomLayer(nn.Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        # \u53c2\u6570\u81ea\u52a8\u8ddf\u8e2a\n        self.weight = nn.Parameter(genesis.randn(out_features, in_features))\n        self.bias = nn.Parameter(genesis.zeros(out_features))\n\n        # \u5b50\u6a21\u5757\u81ea\u52a8\u8ddf\u8e2a\n        self.activation = nn.ReLU()\n\n    def forward(self, x):\n        # \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\n        x = genesis.matmul(x, self.weight.T) + self.bias\n        x = self.activation(x)\n        return x\n\n# \u4f7f\u7528\nlayer = CustomLayer(10, 5)\nx = genesis.randn(32, 10)\noutput = layer(x)\n</code></pre>"},{"location":"api/nn/modules/#_27","title":"\u793a\u4f8b\uff1a\u81ea\u5b9a\u4e49\u6a21\u578b","text":"Python<pre><code>class ResidualBlock(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(channels)\n        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(channels)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        residual = x\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.bn2(self.conv2(x))\n        x = x + residual  # \u8df3\u8dc3\u8fde\u63a5\n        x = self.relu(x)\n        return x\n\nclass ResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 64, 7, stride=2, padding=3)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n\n        # \u6b8b\u5dee\u5757\n        self.layer1 = nn.Sequential(*[ResidualBlock(64) for _ in range(3)])\n        self.layer2 = nn.Sequential(*[ResidualBlock(64) for _ in range(4)])\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(64, num_classes)\n\n    def forward(self, x):\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n</code></pre>"},{"location":"api/nn/modules/#_28","title":"\u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u59cb\u7ec8\u91cd\u5199<code>forward()</code>: \u5728forward\u65b9\u6cd5\u4e2d\u5b9a\u4e49\u8ba1\u7b97</li> <li>\u4f7f\u7528<code>module(input)</code>: \u7edd\u4e0d\u76f4\u63a5\u8c03\u7528forward()</li> <li>\u6ce8\u518c\u53c2\u6570: \u5bf9\u53ef\u5b66\u4e60\u53c2\u6570\u4f7f\u7528nn.Parameter</li> <li>\u8ddf\u8e2a\u5b50\u6a21\u5757: \u5c06\u6a21\u5757\u5206\u914d\u4e3a\u5c5e\u6027\u4ee5\u81ea\u52a8\u8ddf\u8e2a</li> <li>\u5904\u7406\u8bad\u7ec3/\u8bc4\u4f30: \u5728\u8bad\u7ec3\u548c\u8bc4\u4f30\u4e2d\u4f7f\u7528\u4e0d\u540c\u884c\u4e3a</li> <li>\u521d\u59cb\u5316\u6743\u91cd: \u9002\u5f53\u7684\u521d\u59cb\u5316\u6539\u5584\u6536\u655b</li> </ol>"},{"location":"api/nn/modules/#_29","title":"\u53e6\u8bf7\u53c2\u9605","text":"<ul> <li>\u51fd\u6570\u5f0fAPI - \u51fd\u6570\u5f0f\u64cd\u4f5c</li> <li>\u4f18\u5316\u5668 - \u8bad\u7ec3\u4f18\u5316\u5668</li> <li>\u81ea\u52a8\u5fae\u5206 - \u81ea\u52a8\u5fae\u5206</li> <li>\u793a\u4f8b - \u5b8c\u6574\u793a\u4f8b</li> </ul>"},{"location":"api/optim/lr_scheduler/","title":"\u5b66\u4e60\u7387\u8c03\u5ea6\u5668","text":"<p>Genesis\u63d0\u4f9b\u4e86\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u6765\u8c03\u6574\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5b66\u4e60\u7387\uff0c\u8fd9\u5bf9\u4e8e\u5728\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u5b9e\u73b0\u6700\u4f73\u6536\u655b\u81f3\u5173\u91cd\u8981\u3002</p>"},{"location":"api/optim/lr_scheduler/#_2","title":"\u6982\u8ff0","text":"<p>\u5b66\u4e60\u7387\u8c03\u5ea6\u662f\u4e00\u79cd\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8c03\u6574\u5b66\u4e60\u7387\u7684\u6280\u672f\u3002Genesis\u63d0\u4f9b\u4e86\u4e0ePyTorch\u517c\u5bb9\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\uff0c\u53ef\u4ee5\u663e\u8457\u6539\u5584\u6a21\u578b\u6536\u655b\u3002</p>"},{"location":"api/optim/lr_scheduler/#_3","title":"\u53ef\u7528\u8c03\u5ea6\u5668","text":""},{"location":"api/optim/lr_scheduler/#lambdalr","title":"LambdaLR","text":"<p><code>LambdaLR</code>\u8c03\u5ea6\u5668\u5141\u8bb8\u4f60\u5b9a\u4e49\u81ea\u5b9a\u4e49\u51fd\u6570\u6765\u4fee\u6539\u6bcf\u4e2a\u8f6e\u6b21\u7684\u5b66\u4e60\u7387\u3002</p> Python<pre><code>import genesis.optim as optim\n\nclass LambdaLR:\n    def __init__(self, optimizer, lr_lambda, last_epoch=-1, verbose=False):\n        \"\"\"\n        \u901a\u8fc7lr_lambda\u51fd\u6570\u7ed9\u51fa\u7684\u56e0\u5b50\u4e58\u4ee5\u5b66\u4e60\u7387\u3002\n\n        Args:\n            optimizer: \u5305\u88c5\u7684\u4f18\u5316\u5668\n            lr_lambda: \u8ba1\u7b97\u4e58\u6cd5\u56e0\u5b50\u7684\u51fd\u6570\u6216\u51fd\u6570\u5217\u8868\n            last_epoch: \u6700\u540e\u4e00\u4e2a\u8f6e\u6b21\u7684\u7d22\u5f15\n            verbose: \u5982\u679c\u4e3aTrue\uff0c\u4e3a\u6bcf\u6b21\u66f4\u65b0\u6253\u5370\u6d88\u606f\n        \"\"\"\n</code></pre> <p>\u4f7f\u7528\u793a\u4f8b\uff1a Python<pre><code>import genesis\nimport genesis.nn as nn\nimport genesis.optim as optim\n\n# \u521b\u5efa\u6a21\u578b\u548c\u4f18\u5316\u5668\nmodel = nn.Linear(10, 1)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# \u5b9a\u4e49\u5b66\u4e60\u7387\u8c03\u5ea6\u51fd\u6570\ndef lr_lambda(epoch):\n    # \u6bcf10\u4e2a\u8f6e\u6b21\u5c06\u5b66\u4e60\u7387\u8870\u51cf0.95\u500d\n    return 0.95 ** (epoch // 10)\n\n# \u521b\u5efa\u8c03\u5ea6\u5668\nscheduler = optim.LambdaLR(optimizer, lr_lambda=lr_lambda)\n\n# \u8bad\u7ec3\u5faa\u73af\nfor epoch in range(100):\n    # \u8fd9\u91cc\u662f\u8bad\u7ec3\u4ee3\u7801\n    loss = train_one_epoch(model, dataloader, optimizer)\n\n    # \u8c03\u5ea6\u5668\u6b65\u8fdb\n    scheduler.step()\n    print(f\"\u8f6e\u6b21 {epoch}: lr={scheduler.get_last_lr()}\")\n</code></pre></p>"},{"location":"api/optim/lr_scheduler/#_4","title":"\u4f59\u5f26\u9000\u706b\u4e0e\u9884\u70ed","text":"<p><code>get_cosine_schedule_with_warmup</code>\u51fd\u6570\u521b\u5efa\u4e00\u4e2a\u5e26\u6709\u7ebf\u6027\u9884\u70ed\u7684\u4f59\u5f26\u9000\u706b\u8c03\u5ea6\u3002</p> Python<pre><code>def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n    \"\"\"\n    \u521b\u5efa\u5177\u6709\u7ebf\u6027\u9884\u70ed\u548c\u4f59\u5f26\u8870\u51cf\u7684\u8c03\u5ea6\u3002\n\n    Args:\n        optimizer: \u5305\u88c5\u7684\u4f18\u5316\u5668\n        num_warmup_steps: \u9884\u70ed\u9636\u6bb5\u7684\u6b65\u6570\n        num_training_steps: \u603b\u8bad\u7ec3\u6b65\u6570\n\n    Returns:\n        LambdaLR\u8c03\u5ea6\u5668\u5bf9\u8c61\n    \"\"\"\n</code></pre> <p>\u4f7f\u7528\u793a\u4f8b\uff1a Python<pre><code>import genesis.optim as optim\n\n# \u8bad\u7ec3\u914d\u7f6e\nnum_epochs = 100\nsteps_per_epoch = 1000\ntotal_steps = num_epochs * steps_per_epoch\nwarmup_steps = total_steps // 10  # 10%\u9884\u70ed\n\n# \u521b\u5efa\u4f18\u5316\u5668\u548c\u8c03\u5ea6\u5668\noptimizer = optim.AdamW(model.parameters(), lr=5e-4)\nscheduler = optim.get_cosine_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=warmup_steps,\n    num_training_steps=total_steps\n)\n\n# \u9010\u6b65\u8c03\u5ea6\u7684\u8bad\u7ec3\u5faa\u73af\nstep = 0\nfor epoch in range(num_epochs):\n    for batch in dataloader:\n        # \u524d\u5411\u4f20\u64ad\u548c\u4f18\u5316\n        loss = model(batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # \u6bcf\u4e2a\u6279\u6b21\u8c03\u5ea6\u5668\u6b65\u8fdb\n        scheduler.step()\n        step += 1\n\n        if step % 100 == 0:\n            print(f\"\u6b65\u9aa4 {step}: lr={scheduler.get_last_lr():.6f}\")\n</code></pre></p>"},{"location":"api/optim/lr_scheduler/#_5","title":"\u8c03\u5ea6\u5668\u65b9\u6cd5","text":"<p>\u6240\u6709\u8c03\u5ea6\u5668\u63d0\u4f9b\u4ee5\u4e0b\u65b9\u6cd5\uff1a</p>"},{"location":"api/optim/lr_scheduler/#step","title":"step()","text":"Python<pre><code>def step(self, epoch=None):\n    \"\"\"\n    \u6839\u636e\u8c03\u5ea6\u66f4\u65b0\u5b66\u4e60\u7387\u3002\n\n    Args:\n        epoch: \u5f53\u524d\u8f6e\u6b21\uff08\u53ef\u9009\uff0c\u5982\u679c\u4e3aNone\u4f7f\u7528\u5185\u90e8\u8ba1\u6570\u5668\uff09\n    \"\"\"\n</code></pre>"},{"location":"api/optim/lr_scheduler/#get_last_lr","title":"get_last_lr()","text":"Python<pre><code>def get_last_lr(self):\n    \"\"\"\n    \u8fd4\u56de\u6700\u540e\u8ba1\u7b97\u7684\u5b66\u4e60\u7387\u3002\n\n    Returns:\n        \u5f53\u524d\u5b66\u4e60\u7387\u503c\n    \"\"\"\n</code></pre>"},{"location":"api/optim/lr_scheduler/#state_dict","title":"state_dict()","text":"Python<pre><code>def state_dict(self):\n    \"\"\"\n    \u5c06\u8c03\u5ea6\u5668\u7684\u72b6\u6001\u4f5c\u4e3a\u5b57\u5178\u8fd4\u56de\u3002\n\n    Returns:\n        \u5305\u542b\u8c03\u5ea6\u5668\u72b6\u6001\u7684\u5b57\u5178\n    \"\"\"\n</code></pre>"},{"location":"api/optim/lr_scheduler/#load_state_dict","title":"load_state_dict()","text":"Python<pre><code>def load_state_dict(self, state_dict):\n    \"\"\"\n    \u4ece\u5b57\u5178\u52a0\u8f7d\u8c03\u5ea6\u5668\u72b6\u6001\u3002\n\n    Args:\n        state_dict: \u5305\u542b\u8c03\u5ea6\u5668\u72b6\u6001\u7684\u5b57\u5178\n    \"\"\"\n</code></pre>"},{"location":"api/optim/lr_scheduler/#_6","title":"\u5e38\u89c1\u6a21\u5f0f","text":""},{"location":"api/optim/lr_scheduler/#_7","title":"\u6307\u6570\u8870\u51cf","text":"Python<pre><code># \u6bcf\u4e2a\u8f6e\u6b21\u5b66\u4e60\u7387\u8870\u51cf0.95\nscheduler = optim.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)\n</code></pre>"},{"location":"api/optim/lr_scheduler/#_8","title":"\u9636\u68af\u8870\u51cf","text":"Python<pre><code># \u6bcf30\u4e2a\u8f6e\u6b21\u5c06\u5b66\u4e60\u7387\u51cf\u534a\ndef step_decay(epoch):\n    return 0.5 ** (epoch // 30)\n\nscheduler = optim.LambdaLR(optimizer, lr_lambda=step_decay)\n</code></pre>"},{"location":"api/optim/lr_scheduler/#_9","title":"\u591a\u9879\u5f0f\u8870\u51cf","text":"Python<pre><code># \u591a\u9879\u5f0f\u8870\u51cf\u5230\u96f6\ndef poly_decay(epoch, total_epochs=100, power=0.9):\n    return (1 - epoch / total_epochs) ** power\n\nscheduler = optim.LambdaLR(optimizer, lr_lambda=lambda epoch: poly_decay(epoch))\n</code></pre>"},{"location":"api/optim/lr_scheduler/#_10","title":"\u4f59\u5f26\u91cd\u542f","text":"Python<pre><code>import math\n\ndef cosine_restart(epoch, restart_period=50):\n    epoch_in_cycle = epoch % restart_period\n    return 0.5 * (1 + math.cos(math.pi * epoch_in_cycle / restart_period))\n\nscheduler = optim.LambdaLR(optimizer, lr_lambda=cosine_restart)\n</code></pre>"},{"location":"api/optim/lr_scheduler/#_11","title":"\u4e0e\u8bad\u7ec3\u96c6\u6210","text":""},{"location":"api/optim/lr_scheduler/#_12","title":"\u57fa\u7840\u8bad\u7ec3\u5faa\u73af","text":"Python<pre><code>import genesis\nimport genesis.nn as nn\nimport genesis.optim as optim\n\n# \u8bbe\u7f6e\nmodel = nn.Sequential(\n    nn.Linear(784, 256),\n    nn.ReLU(),\n    nn.Linear(256, 10)\n)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = optim.get_cosine_schedule_with_warmup(\n    optimizer, num_warmup_steps=1000, num_training_steps=10000\n)\n\n# \u8bad\u7ec3\u5faa\u73af\nfor epoch in range(num_epochs):\n    model.train()\n    for batch_idx, (data, targets) in enumerate(train_loader):\n        # \u524d\u5411\u4f20\u64ad\n        outputs = model(data)\n        loss = nn.CrossEntropyLoss()(outputs, targets)\n\n        # \u53cd\u5411\u4f20\u64ad\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()  # \u66f4\u65b0\u5b66\u4e60\u7387\n\n        # \u65e5\u5fd7\u8bb0\u5f55\n        if batch_idx % 100 == 0:\n            current_lr = scheduler.get_last_lr()\n            print(f'\u8f6e\u6b21: {epoch}, \u6279\u6b21: {batch_idx}, LR: {current_lr:.6f}, \u635f\u5931: {loss.item():.4f}')\n</code></pre>"},{"location":"api/optim/lr_scheduler/#_13","title":"\u68c0\u67e5\u70b9\u96c6\u6210","text":"Python<pre><code>import genesis\n\n# \u4fdd\u5b58\u8c03\u5ea6\u5668\u72b6\u6001\u4e0e\u6a21\u578b\u68c0\u67e5\u70b9\ncheckpoint = {\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'scheduler_state_dict': scheduler.state_dict(),\n    'epoch': epoch,\n    'loss': loss\n}\ngenesis.save_checkpoint(checkpoint, 'checkpoint.pth')\n\n# \u52a0\u8f7d\u8c03\u5ea6\u5668\u72b6\u6001\ncheckpoint = genesis.load_checkpoint('checkpoint.pth')\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nscheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n</code></pre>"},{"location":"api/optim/lr_scheduler/#_14","title":"\u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u9009\u62e9\u6b63\u786e\u7684\u8c03\u5ea6\uff1a</li> <li>\u5927\u591a\u6570\u5e94\u7528\u4f7f\u7528\u4f59\u5f26\u9000\u706b</li> <li>\u4e3atransformer\u6a21\u578b\u6dfb\u52a0\u9884\u70ed</li> <li> <p>\u5fae\u8c03\u65f6\u4f7f\u7528\u9636\u68af\u8870\u51cf</p> </li> <li> <p>\u9884\u70ed\u9636\u6bb5\uff1a</p> </li> <li>\u5bf9\u5927\u6279\u91cf\u5927\u5c0f\u81f3\u5173\u91cd\u8981</li> <li>\u5efa\u8bae\u7528\u4e8etransformer\u67b6\u6784</li> <li> <p>\u901a\u5e38\u4e3a\u603b\u8bad\u7ec3\u6b65\u6570\u76845-10%</p> </li> <li> <p>\u76d1\u63a7\uff1a</p> </li> <li>\u8bb0\u5f55\u5b66\u4e60\u7387\u503c</li> <li>\u7ed8\u5236\u5b66\u4e60\u7387\u8c03\u5ea6</li> <li> <p>\u8bad\u7ec3\u671f\u95f4\u76d1\u63a7\u9a8c\u8bc1\u635f\u5931</p> </li> <li> <p>\u68c0\u67e5\u70b9\u4fdd\u5b58\uff1a</p> </li> <li>\u59cb\u7ec8\u4fdd\u5b58\u8c03\u5ea6\u5668\u72b6\u6001</li> <li>\u4ee5\u6b63\u786e\u7684\u5b66\u4e60\u7387\u6062\u590d\u8bad\u7ec3</li> <li>\u5bf9\u957f\u65f6\u95f4\u8bad\u7ec3\u8fd0\u884c\u81f3\u5173\u91cd\u8981</li> </ol>"},{"location":"api/optim/lr_scheduler/#_15","title":"\u793a\u4f8b","text":""},{"location":"api/optim/lr_scheduler/#transformer","title":"Transformer\u8bad\u7ec3\u8c03\u5ea6","text":"Python<pre><code># \u5178\u578b\u7684transformer\u8bad\u7ec3\u8c03\u5ea6\ndef get_transformer_schedule(optimizer, d_model=512, warmup_steps=4000):\n    def lr_lambda(step):\n        if step == 0:\n            return 0\n        return min(step ** -0.5, step * warmup_steps ** -1.5) * (d_model ** -0.5)\n\n    return optim.LambdaLR(optimizer, lr_lambda=lr_lambda)\n\nscheduler = get_transformer_schedule(optimizer, d_model=512, warmup_steps=4000)\n</code></pre>"},{"location":"api/optim/lr_scheduler/#_16","title":"\u5b66\u4e60\u7387\u8303\u56f4\u6d4b\u8bd5","text":"Python<pre><code># \u627e\u5230\u6700\u4f73\u5b66\u4e60\u7387\u8303\u56f4\ndef lr_range_test(model, optimizer, start_lr=1e-7, end_lr=10, num_it=100):\n    lrs = []\n    losses = []\n\n    lr_lambda = lambda step: (end_lr / start_lr) ** (step / num_it)\n    scheduler = optim.LambdaLR(optimizer, lr_lambda=lr_lambda)\n\n    for i in range(num_it):\n        # \u8bad\u7ec3\u6b65\u9aa4\n        loss = train_step(model, batch)\n        losses.append(loss)\n        lrs.append(scheduler.get_last_lr())\n\n        scheduler.step()\n\n        if loss &gt; 4 * min(losses):  # \u5982\u679c\u635f\u5931\u7206\u70b8\u5219\u505c\u6b62\n            break\n\n    return lrs, losses\n</code></pre>"},{"location":"api/optim/lr_scheduler/#pytorch","title":"\u4ecePyTorch\u8fc1\u79fb","text":"<p>Genesis\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u8bbe\u8ba1\u4e3aPyTorch\u8c03\u5ea6\u5668\u7684\u76f4\u63a5\u66ff\u4ee3\uff1a</p> Python<pre><code># PyTorch\u4ee3\u7801\nimport torch.optim as optim\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n\n# Genesis\u7b49\u6548\u4ee3\u7801\nimport genesis.optim as optim\nscheduler = optim.LambdaLR(\n    optimizer, \n    lr_lambda=lambda epoch: 0.5 * (1 + math.cos(math.pi * epoch / 100))\n)\n</code></pre> <p>API\u517c\u5bb9\uff0c\u4f7f\u5f97\u5c06\u73b0\u6709PyTorch\u8bad\u7ec3\u811a\u672c\u8fc1\u79fb\u5230Genesis\u53d8\u5f97\u5bb9\u6613\u3002</p>"},{"location":"api/optim/optimizers/","title":"\u4f18\u5316\u5668 (genesis.optim)","text":""},{"location":"api/optim/optimizers/#_1","title":"\u6982\u8ff0","text":"<p><code>genesis.optim</code>\u6a21\u5757\u4e3a\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4f18\u5316\u5668\u3002\u5b83\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u652f\u6301\u53c2\u6570\u7ec4\u3001\u68af\u5ea6\u88c1\u526a\u548c\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u3002</p>"},{"location":"api/optim/optimizers/#_2","title":"\u6838\u5fc3\u6982\u5ff5","text":""},{"location":"api/optim/optimizers/#_3","title":"\u4f18\u5316\u8fc7\u7a0b","text":"<p>\u4f18\u5316\u5668\u4f7f\u7528\u5404\u79cd\u7b97\u6cd5\u57fa\u4e8e\u8ba1\u7b97\u7684\u68af\u5ea6\u66f4\u65b0\u6a21\u578b\u53c2\u6570\uff1a 1. \u68af\u5ea6\u4e0b\u964d: \u4f7f\u7528\u68af\u5ea6\u8fdb\u884c\u57fa\u672c\u53c2\u6570\u66f4\u65b0 2. \u52a8\u91cf: \u4f7f\u7528\u79fb\u52a8\u5e73\u5747\u52a0\u901f\u6536\u655b 3. \u81ea\u9002\u5e94\u5b66\u4e60\u7387: \u6bcf\u4e2a\u53c2\u6570\u7684\u4e0d\u540c\u5b66\u4e60\u7387 4. \u6b63\u5219\u5316: \u6743\u91cd\u8870\u51cf\u548c\u68af\u5ea6\u88c1\u526a</p>"},{"location":"api/optim/optimizers/#_4","title":"\u53c2\u6570\u7ec4","text":"<p>\u53c2\u6570\u53ef\u4ee5\u7ec4\u7ec7\u6210\u5177\u6709\u4e0d\u540c\u8d85\u53c2\u6570\u7684\u7ec4\uff1a - \u4e0d\u540c\u5c42\u7684\u4e0d\u540c\u5b66\u4e60\u7387 - \u9009\u62e9\u6027\u6743\u91cd\u8870\u51cf\u5e94\u7528 - \u5c42\u7279\u5b9a\u7684\u4f18\u5316\u8bbe\u7f6e</p>"},{"location":"api/optim/optimizers/#_5","title":"\u57fa\u7c7b","text":""},{"location":"api/optim/optimizers/#optimoptimizer","title":"<code>optim.Optimizer</code>","text":"<p>\u6240\u6709\u4f18\u5316\u5668\u7684\u62bd\u8c61\u57fa\u7c7b\u3002</p> Python<pre><code>class Optimizer:\n    \"\"\"\n    \u6240\u6709\u4f18\u5316\u5668\u7684\u57fa\u7c7b\u3002\n\n    \u53c2\u6570:\n        params: \u53c2\u6570\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\u6216\u5b9a\u4e49\u53c2\u6570\u7ec4\u7684\u5b57\u5178\n        defaults: \u5305\u542b\u4f18\u5316\u9009\u9879\u9ed8\u8ba4\u503c\u7684\u5b57\u5178\n    \"\"\"\n\n    def __init__(self, params, defaults: dict):\n        \"\"\"\n        \u521d\u59cb\u5316\u4f18\u5316\u5668\u3002\n\n        \u53c2\u6570:\n            params: \u6a21\u578b\u53c2\u6570\u6216\u53c2\u6570\u7ec4\n            defaults: \u9ed8\u8ba4\u8d85\u53c2\u6570\u503c\n        \"\"\"\n</code></pre>"},{"location":"api/optim/optimizers/#_6","title":"\u6838\u5fc3\u65b9\u6cd5","text":""},{"location":"api/optim/optimizers/#_7","title":"\u4f18\u5316\u6b65\u9aa4","text":"Python<pre><code>def step(self, closure: Optional[Callable] = None) -&gt; Optional[float]:\n    \"\"\"\n    \u6267\u884c\u5355\u4e2a\u4f18\u5316\u6b65\u9aa4\u3002\n\n    \u53c2\u6570:\n        closure: \u91cd\u65b0\u8bc4\u4f30\u6a21\u578b\u5e76\u8fd4\u56de\u635f\u5931\u7684\u53ef\u9009\u51fd\u6570\n\n    \u8fd4\u56de:\n        \u5982\u679c\u63d0\u4f9bclosure\u5219\u8fd4\u56de\u635f\u5931\u503c\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; optimizer.zero_grad()\n        &gt;&gt;&gt; loss = criterion(output, target)\n        &gt;&gt;&gt; loss.backward()\n        &gt;&gt;&gt; optimizer.step()\n    \"\"\"\n\ndef zero_grad(self, set_to_none: bool = True) -&gt; None:\n    \"\"\"\n    \u6e05\u9664\u6240\u6709\u4f18\u5316\u53c2\u6570\u7684\u68af\u5ea6\u3002\n\n    \u53c2\u6570:\n        set_to_none: \u5982\u679c\u4e3aTrue\uff0c\u5c06\u68af\u5ea6\u8bbe\u7f6e\u4e3aNone\u800c\u4e0d\u662f\u96f6\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; # \u6bcf\u4e2a\u8bad\u7ec3\u6b65\u9aa4\u524d\u6e05\u9664\u68af\u5ea6\n        &gt;&gt;&gt; optimizer.zero_grad()\n        &gt;&gt;&gt; loss.backward()\n        &gt;&gt;&gt; optimizer.step()\n    \"\"\"\n</code></pre>"},{"location":"api/optim/optimizers/#_8","title":"\u72b6\u6001\u7ba1\u7406","text":"Python<pre><code>def state_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    \u5c06\u4f18\u5316\u5668\u72b6\u6001\u8fd4\u56de\u4e3a\u5b57\u5178\u3002\n\n    \u8fd4\u56de:\n        \u5305\u542b\u4f18\u5316\u5668\u72b6\u6001\u548c\u53c2\u6570\u7ec4\u7684\u5b57\u5178\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; # \u4fdd\u5b58\u4f18\u5316\u5668\u72b6\u6001\n        &gt;&gt;&gt; state = optimizer.state_dict()\n        &gt;&gt;&gt; genesis.save(state, 'optimizer_checkpoint.pth')\n    \"\"\"\n\ndef load_state_dict(self, state_dict: Dict[str, Any]) -&gt; None:\n    \"\"\"\n    \u4ece\u5b57\u5178\u52a0\u8f7d\u4f18\u5316\u5668\u72b6\u6001\u3002\n\n    \u53c2\u6570:\n        state_dict: \u4f18\u5316\u5668\u72b6\u6001\u5b57\u5178\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; # \u6062\u590d\u4f18\u5316\u5668\u72b6\u6001\n        &gt;&gt;&gt; state = genesis.load('optimizer_checkpoint.pth')\n        &gt;&gt;&gt; optimizer.load_state_dict(state)\n    \"\"\"\n</code></pre>"},{"location":"api/optim/optimizers/#_9","title":"\u53c2\u6570\u7ec4","text":"Python<pre><code>def add_param_group(self, param_group: Dict[str, Any]) -&gt; None:\n    \"\"\"\n    \u5411\u4f18\u5316\u5668\u6dfb\u52a0\u53c2\u6570\u7ec4\u3002\n\n    \u53c2\u6570:\n        param_group: \u6307\u5b9a\u53c2\u6570\u53ca\u5176\u9009\u9879\u7684\u5b57\u5178\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; # \u6dfb\u52a0\u5177\u6709\u4e0d\u540c\u5b66\u4e60\u7387\u7684\u65b0\u5c42\n        &gt;&gt;&gt; optimizer.add_param_group({\n        ...     'params': new_layer.parameters(),\n        ...     'lr': 0.001\n        ... })\n    \"\"\"\n\n@property\ndef param_groups(self) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    \u8bbf\u95ee\u53c2\u6570\u7ec4\u3002\n\n    \u8fd4\u56de:\n        \u53c2\u6570\u7ec4\u5b57\u5178\u7684\u5217\u8868\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; # \u624b\u52a8\u8c03\u6574\u5b66\u4e60\u7387\n        &gt;&gt;&gt; for group in optimizer.param_groups:\n        ...     group['lr'] *= 0.9\n    \"\"\"\n</code></pre>"},{"location":"api/optim/optimizers/#_10","title":"\u4f18\u5316\u5668","text":""},{"location":"api/optim/optimizers/#optimsgd","title":"<code>optim.SGD</code>","text":"<p>\u5e26\u52a8\u91cf\u548c\u6743\u91cd\u8870\u51cf\u7684\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u5668\u3002</p> Python<pre><code>class SGD(Optimizer):\n    \"\"\"\n    \u968f\u673a\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u5668\u3002\n\n    \u53c2\u6570:\n        params: \u8981\u4f18\u5316\u7684\u53c2\u6570\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\n        lr: \u5b66\u4e60\u7387\uff08\u5fc5\u9700\uff09\n        momentum: \u52a8\u91cf\u56e0\u5b50\uff08\u9ed8\u8ba4: 0\uff09\n        dampening: \u52a8\u91cf\u7684\u963b\u5c3c\uff08\u9ed8\u8ba4: 0\uff09\n        weight_decay: \u6743\u91cd\u8870\u51cf\u7cfb\u6570\uff08\u9ed8\u8ba4: 0\uff09\n        nesterov: \u662f\u5426\u4f7f\u7528Nesterov\u52a8\u91cf\uff08\u9ed8\u8ba4: False\uff09\n\n    \u7b97\u6cd5:\n        v_t = momentum * v_{t-1} + g_t\n        p_t = p_{t-1} - lr * v_t\n\n    \u5176\u4e2d:\n        g_t: \u65f6\u523bt\u7684\u68af\u5ea6\n        v_t: \u65f6\u523bt\u7684\u901f\u5ea6\n        p_t: \u65f6\u523bt\u7684\u53c2\u6570\n    \"\"\"\n\n    def __init__(\n        self,\n        params,\n        lr: float,\n        momentum: float = 0,\n        dampening: float = 0,\n        weight_decay: float = 0,\n        nesterov: bool = False\n    ):\n</code></pre>"},{"location":"api/optim/optimizers/#_11","title":"\u4f7f\u7528\u793a\u4f8b","text":"Python<pre><code>import genesis.optim as optim\n\n# \u57fa\u672cSGD\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\n# \u5e26\u52a8\u91cf\u7684SGD\uff08\u5927\u591a\u6570\u4efb\u52a1\u63a8\u8350\uff09\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n\n# \u5e26\u6743\u91cd\u8870\u51cf\u7684SGD\noptimizer = optim.SGD(model.parameters(), lr=0.01, \n                     momentum=0.9, weight_decay=1e-4)\n\n# Nesterov\u52a0\u901f\u68af\u5ea6\noptimizer = optim.SGD(model.parameters(), lr=0.01,\n                     momentum=0.9, nesterov=True)\n\n# \u4e0d\u540c\u5c42\u7684\u4e0d\u540c\u5b66\u4e60\u7387\noptimizer = optim.SGD([\n    {'params': model.features.parameters(), 'lr': 0.001},\n    {'params': model.classifier.parameters(), 'lr': 0.01}\n], momentum=0.9)\n</code></pre>"},{"location":"api/optim/optimizers/#optimadam","title":"<code>optim.Adam</code>","text":"<p>\u7ed3\u5408RMSprop\u548c\u52a8\u91cf\u7684\u81ea\u9002\u5e94\u77e9\u4f30\u8ba1\u4f18\u5316\u5668\u3002</p> Python<pre><code>class Adam(Optimizer):\n    \"\"\"\n    Adam\u4f18\u5316\u5668\u3002\n\n    \u53c2\u6570:\n        params: \u8981\u4f18\u5316\u7684\u53c2\u6570\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\n        lr: \u5b66\u4e60\u7387\uff08\u9ed8\u8ba4: 1e-3\uff09\n        betas: \u8ba1\u7b97\u68af\u5ea6\u53ca\u5176\u5e73\u65b9\u7684\u8fd0\u884c\u5e73\u5747\u7684\u7cfb\u6570\n               \uff08\u9ed8\u8ba4: (0.9, 0.999)\uff09\n        eps: \u6dfb\u52a0\u5230\u5206\u6bcd\u4ee5\u63d0\u9ad8\u6570\u503c\u7a33\u5b9a\u6027\u7684\u9879\uff08\u9ed8\u8ba4: 1e-8\uff09\n        weight_decay: \u6743\u91cd\u8870\u51cf\u7cfb\u6570\uff08\u9ed8\u8ba4: 0\uff09\n        amsgrad: \u662f\u5426\u4f7f\u7528AMSGrad\u53d8\u4f53\uff08\u9ed8\u8ba4: False\uff09\n\n    \u7b97\u6cd5:\n        m_t = \u03b2\u2081 * m_{t-1} + (1 - \u03b2\u2081) * g_t\n        v_t = \u03b2\u2082 * v_{t-1} + (1 - \u03b2\u2082) * g_t\u00b2\n        m\u0302_t = m_t / (1 - \u03b2\u2081\u1d57)\n        v\u0302_t = v_t / (1 - \u03b2\u2082\u1d57)\n        p_t = p_{t-1} - lr * m\u0302_t / (\u221av\u0302_t + \u03b5)\n\n    \u5176\u4e2d:\n        g_t: \u68af\u5ea6\n        m_t: \u4e00\u9636\u77e9\u4f30\u8ba1\uff08\u52a8\u91cf\uff09\n        v_t: \u4e8c\u9636\u77e9\u4f30\u8ba1\uff08\u81ea\u9002\u5e94\u5b66\u4e60\u7387\uff09\n        m\u0302_t, v\u0302_t: \u504f\u5dee\u4fee\u6b63\u7684\u77e9\u4f30\u8ba1\n    \"\"\"\n\n    def __init__(\n        self,\n        params,\n        lr: float = 1e-3,\n        betas: Tuple[float, float] = (0.9, 0.999),\n        eps: float = 1e-8,\n        weight_decay: float = 0,\n        amsgrad: bool = False\n    ):\n</code></pre>"},{"location":"api/optim/optimizers/#_12","title":"\u72b6\u6001\u53d8\u91cf","text":"<p>\u6bcf\u4e2a\u53c2\u6570\u7ef4\u62a4\u4ee5\u4e0b\u72b6\u6001\uff1a - <code>step</code>: \u5df2\u6267\u884c\u7684\u4f18\u5316\u6b65\u6570 - <code>exp_avg</code>: \u68af\u5ea6\u503c\u7684\u6307\u6570\u79fb\u52a8\u5e73\u5747\uff08\u52a8\u91cf\uff09 - <code>exp_avg_sq</code>: \u5e73\u65b9\u68af\u5ea6\u503c\u7684\u6307\u6570\u79fb\u52a8\u5e73\u5747 - <code>max_exp_avg_sq</code>: exp_avg_sq\u7684\u6700\u5927\u503c\uff08\u4ec5AMSGrad\uff09</p>"},{"location":"api/optim/optimizers/#_13","title":"\u4f7f\u7528\u793a\u4f8b","text":"Python<pre><code># \u9ed8\u8ba4Adam\uff08\u6700\u5e38\u89c1\uff09\noptimizer = optim.Adam(model.parameters())\n\n# \u81ea\u5b9a\u4e49\u5b66\u4e60\u7387\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Transformer\u6a21\u578b\u8bbe\u7f6e\noptimizer = optim.Adam(model.parameters(), lr=0.0001,\n                      betas=(0.9, 0.98), eps=1e-9)\n\n# \u5e26\u6743\u91cd\u8870\u51cf\noptimizer = optim.Adam(model.parameters(), lr=0.001,\n                      weight_decay=1e-5)\n\n# \u4e0d\u540c\u5b66\u4e60\u7387\u7684\u5fae\u8c03\noptimizer = optim.Adam([\n    {'params': model.encoder.parameters(), 'lr': 1e-5},\n    {'params': model.decoder.parameters(), 'lr': 1e-4},\n    {'params': model.head.parameters(), 'lr': 1e-3}\n])\n\n# \u4f7f\u7528AMSGrad\u53d8\u4f53\noptimizer = optim.Adam(model.parameters(), lr=0.001, amsgrad=True)\n</code></pre>"},{"location":"api/optim/optimizers/#optimadamw","title":"<code>optim.AdamW</code>","text":"<p>\u5e26\u89e3\u8026\u6743\u91cd\u8870\u51cf\u7684Adam\u4f18\u5316\u5668\u3002</p> Python<pre><code>class AdamW(Optimizer):\n    \"\"\"\n    AdamW\u4f18\u5316\u5668\uff08\u5e26\u89e3\u8026\u6743\u91cd\u8870\u51cf\u7684Adam\uff09\u3002\n\n    \u53c2\u6570:\n        params: \u8981\u4f18\u5316\u7684\u53c2\u6570\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\n        lr: \u5b66\u4e60\u7387\uff08\u9ed8\u8ba4: 1e-3\uff09\n        betas: \u8ba1\u7b97\u8fd0\u884c\u5e73\u5747\u7684\u7cfb\u6570\uff08\u9ed8\u8ba4: (0.9, 0.999)\uff09\n        eps: \u6570\u503c\u7a33\u5b9a\u6027\u9879\uff08\u9ed8\u8ba4: 1e-8\uff09\n        weight_decay: \u6743\u91cd\u8870\u51cf\u7cfb\u6570\uff08\u9ed8\u8ba4: 0.01\uff09\n        amsgrad: \u662f\u5426\u4f7f\u7528AMSGrad\u53d8\u4f53\uff08\u9ed8\u8ba4: False\uff09\n\n    \u4e0eAdam\u7684\u533a\u522b:\n        Adam: p_t = p_{t-1} - lr * (m\u0302_t / (\u221av\u0302_t + \u03b5) + wd * p_{t-1})\n        AdamW: p_t = p_{t-1} * (1 - lr * wd) - lr * m\u0302_t / (\u221av\u0302_t + \u03b5)\n\n    AdamW\u5c06\u6743\u91cd\u8870\u51cf\u4ece\u68af\u5ea6\u8ba1\u7b97\u4e2d\u89e3\u8026\uff0c\u76f4\u63a5\u5e94\u7528\u5230\u53c2\u6570\u4e0a\n    \u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u6b63\u5219\u5316\u3002\n    \"\"\"\n\n    def __init__(\n        self,\n        params,\n        lr: float = 1e-3,\n        betas: Tuple[float, float] = (0.9, 0.999),\n        eps: float = 1e-8,\n        weight_decay: float = 0.01,\n        amsgrad: bool = False\n    ):\n</code></pre>"},{"location":"api/optim/optimizers/#_14","title":"\u4f7f\u7528\u793a\u4f8b","text":"Python<pre><code># \u9ed8\u8ba4AdamW\uff08Transformers\u63a8\u8350\uff09\noptimizer = optim.AdamW(model.parameters())\n\n# BERT/GPT\u6807\u51c6\u8bbe\u7f6e\noptimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n\n# \u5927\u6a21\u578b\u8bad\u7ec3\noptimizer = optim.AdamW(model.parameters(), lr=1e-4,\n                       betas=(0.9, 0.95), weight_decay=0.1)\n\n# \u4ece\u6743\u91cd\u8870\u51cf\u4e2d\u6392\u9664\u504f\u7f6e\u548c\u5f52\u4e00\u5316\ndecay_params = []\nno_decay_params = []\nfor name, param in model.named_parameters():\n    if any(nd in name for nd in ['bias', 'norm', 'ln']):\n        no_decay_params.append(param)\n    else:\n        decay_params.append(param)\n\noptimizer = optim.AdamW([\n    {'params': decay_params, 'weight_decay': 0.01},\n    {'params': no_decay_params, 'weight_decay': 0.0}\n], lr=1e-4)\n</code></pre>"},{"location":"api/optim/optimizers/#optimrmsprop","title":"<code>optim.RMSprop</code>","text":"<p>\u5747\u65b9\u6839\u4f20\u64ad\u4f18\u5316\u5668\u3002</p> Python<pre><code>class RMSprop(Optimizer):\n    \"\"\"\n    RMSprop\u4f18\u5316\u5668\u3002\n\n    \u53c2\u6570:\n        params: \u8981\u4f18\u5316\u7684\u53c2\u6570\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\n        lr: \u5b66\u4e60\u7387\uff08\u9ed8\u8ba4: 1e-2\uff09\n        alpha: \u5e73\u6ed1\u5e38\u6570\uff08\u9ed8\u8ba4: 0.99\uff09\n        eps: \u6570\u503c\u7a33\u5b9a\u6027\u9879\uff08\u9ed8\u8ba4: 1e-8\uff09\n        weight_decay: \u6743\u91cd\u8870\u51cf\u7cfb\u6570\uff08\u9ed8\u8ba4: 0\uff09\n        momentum: \u52a8\u91cf\u56e0\u5b50\uff08\u9ed8\u8ba4: 0\uff09\n        centered: \u662f\u5426\u6309\u4e2d\u5fc3\u5316\u7684\u4e8c\u9636\u77e9\u5f52\u4e00\u5316\uff08\u9ed8\u8ba4: False\uff09\n    \"\"\"\n</code></pre>"},{"location":"api/optim/optimizers/#_15","title":"\u68af\u5ea6\u88c1\u526a","text":"<p>\u9632\u6b62\u68af\u5ea6\u7206\u70b8\u7684\u5b9e\u7528\u5de5\u5177\u3002</p> Python<pre><code>def clip_grad_norm_(\n    parameters: Iterable[Tensor],\n    max_norm: float,\n    norm_type: float = 2.0,\n    error_if_nonfinite: bool = False\n) -&gt; float:\n    \"\"\"\n    \u6309\u5168\u5c40\u8303\u6570\u88c1\u526a\u68af\u5ea6\u3002\n\n    \u53c2\u6570:\n        parameters: \u6709\u68af\u5ea6\u7684\u53c2\u6570\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\n        max_norm: \u6700\u5927\u68af\u5ea6\u8303\u6570\n        norm_type: \u8303\u6570\u7c7b\u578b\uff081, 2, \u6216 inf\uff09\n        error_if_nonfinite: \u5982\u679c\u603b\u8303\u6570\u975e\u6709\u9650\u5219\u62a5\u9519\n\n    \u8fd4\u56de:\n        \u88c1\u526a\u524d\u68af\u5ea6\u7684\u603b\u8303\u6570\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; loss.backward()\n        &gt;&gt;&gt; # \u88c1\u526a\u68af\u5ea6\u4ee5\u9632\u6b62\u7206\u70b8\n        &gt;&gt;&gt; genesis.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        &gt;&gt;&gt; optimizer.step()\n    \"\"\"\n\ndef clip_grad_value_(\n    parameters: Iterable[Tensor],\n    clip_value: float\n) -&gt; None:\n    \"\"\"\n    \u6309\u503c\u88c1\u526a\u68af\u5ea6\u3002\n\n    \u53c2\u6570:\n        parameters: \u6709\u68af\u5ea6\u7684\u53c2\u6570\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\n        clip_value: \u88c1\u526a\u9608\u503c\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; loss.backward()\n        &gt;&gt;&gt; # \u5c06\u68af\u5ea6\u9650\u5236\u5728[-1, 1]\u8303\u56f4\u5185\n        &gt;&gt;&gt; genesis.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n        &gt;&gt;&gt; optimizer.step()\n    \"\"\"\n</code></pre>"},{"location":"api/optim/optimizers/#_16","title":"\u8bad\u7ec3\u793a\u4f8b","text":""},{"location":"api/optim/optimizers/#_17","title":"\u57fa\u672c\u8bad\u7ec3\u5faa\u73af","text":"Python<pre><code>import genesis\nimport genesis.nn as nn\nimport genesis.optim as optim\n\n# \u6a21\u578b\u548c\u4f18\u5316\u5668\u8bbe\u7f6e\nmodel = MyModel()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\n# \u8bad\u7ec3\u5faa\u73af\nfor epoch in range(num_epochs):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        # \u68af\u5ea6\u6e05\u96f6\n        optimizer.zero_grad()\n\n        # \u524d\u5411\u4f20\u64ad\n        output = model(data)\n        loss = criterion(output, target)\n\n        # \u540e\u5411\u4f20\u64ad\n        loss.backward()\n\n        # \u68af\u5ea6\u88c1\u526a\uff08\u53ef\u9009\uff09\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n        # \u66f4\u65b0\u53c2\u6570\n        optimizer.step()\n\n        if batch_idx % 100 == 0:\n            print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n</code></pre>"},{"location":"api/optim/optimizers/#_18","title":"\u6df7\u5408\u7cbe\u5ea6\u7684\u9ad8\u7ea7\u8bad\u7ec3","text":"Python<pre><code>import genesis\nimport genesis.nn as nn\nimport genesis.optim as optim\n\n# \u542f\u7528\u6df7\u5408\u7cbe\u5ea6\ngenesis.enable_autocast = True\n\n# \u6a21\u578b\u8bbe\u7f6e\nmodel = TransformerModel()\noptimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n\nfor epoch in range(num_epochs):\n    for batch in train_loader:\n        optimizer.zero_grad()\n\n        # \u4f7f\u7528autocast\u8fdb\u884c\u6df7\u5408\u7cbe\u5ea6\n        with genesis.autocast():\n            outputs = model(batch['input'])\n            loss = criterion(outputs, batch['target'])\n\n        # \u540e\u5411\u4f20\u64ad\n        loss.backward()\n\n        # \u68af\u5ea6\u88c1\u526a\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n        # \u4f18\u5316\u5668\u6b65\u9aa4\n        optimizer.step()\n</code></pre>"},{"location":"api/optim/optimizers/#_19","title":"\u5b66\u4e60\u7387\u8c03\u5ea6","text":"Python<pre><code>from genesis.optim.lr_scheduler import CosineAnnealingLR\n\n# \u4f18\u5316\u5668\u548c\u8c03\u5ea6\u5668\noptimizer = optim.AdamW(model.parameters(), lr=1e-3)\nscheduler = CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6)\n\nfor epoch in range(num_epochs):\n    # \u8bad\u7ec3\n    for batch in train_loader:\n        optimizer.zero_grad()\n        loss = compute_loss(model, batch)\n        loss.backward()\n        optimizer.step()\n\n    # \u66f4\u65b0\u5b66\u4e60\u7387\n    scheduler.step()\n    print(f'Epoch {epoch}, LR: {scheduler.get_last_lr()[0]:.6f}')\n</code></pre>"},{"location":"api/optim/optimizers/#_20","title":"\u68af\u5ea6\u7d2f\u79ef","text":"Python<pre><code># \u901a\u8fc7\u7d2f\u79ef\u6a21\u62df\u66f4\u5927\u7684\u6279\u5927\u5c0f\naccumulation_steps = 4\noptimizer.zero_grad()\n\nfor i, batch in enumerate(train_loader):\n    # \u524d\u5411\u4f20\u64ad\n    outputs = model(batch['input'])\n    loss = criterion(outputs, batch['target'])\n\n    # \u6309\u7d2f\u79ef\u6b65\u6570\u5f52\u4e00\u5316\u635f\u5931\n    loss = loss / accumulation_steps\n    loss.backward()\n\n    # \u6bcfaccumulation_steps\u66f4\u65b0\u6743\u91cd\n    if (i + 1) % accumulation_steps == 0:\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        optimizer.zero_grad()\n</code></pre>"},{"location":"api/optim/optimizers/#_21","title":"\u4f18\u5316\u5668\u9009\u62e9\u6307\u5357","text":""},{"location":"api/optim/optimizers/#sgd","title":"SGD","text":"<ul> <li>\u4f18\u70b9: \u7b80\u5355\u3001\u5185\u5b58\u9ad8\u6548\u3001\u6cdb\u5316\u6027\u597d</li> <li>\u7f3a\u70b9: \u6536\u655b\u6162\u3001\u5bf9\u5b66\u4e60\u7387\u654f\u611f</li> <li>\u9002\u7528\u4e8e:</li> <li>\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\uff08ResNet\u3001VGG\uff09</li> <li>\u5185\u5b58\u53d7\u9650\u73af\u5883</li> <li>\u9700\u8981\u6700\u4f73\u6cdb\u5316\u65f6</li> <li>\u63a8\u8350\u8bbe\u7f6e: <code>lr=0.1, momentum=0.9, weight_decay=1e-4</code></li> </ul>"},{"location":"api/optim/optimizers/#adam","title":"Adam","text":"<ul> <li>\u4f18\u70b9: \u6536\u655b\u5feb\u3001\u81ea\u9002\u5e94\u3001\u5bf9\u8d85\u53c2\u6570\u4e0d\u654f\u611f</li> <li>\u7f3a\u70b9: \u5185\u5b58\u4f7f\u7528\u8f83\u9ad8\u3001\u53ef\u80fd\u8fc7\u62df\u5408</li> <li>\u9002\u7528\u4e8e:</li> <li>NLP\u4efb\u52a1</li> <li>\u5feb\u901f\u539f\u578b\u5236\u4f5c</li> <li>\u7a00\u758f\u68af\u5ea6</li> <li>\u63a8\u8350\u8bbe\u7f6e: <code>lr=1e-3, betas=(0.9, 0.999)</code></li> </ul>"},{"location":"api/optim/optimizers/#adamw","title":"AdamW","text":"<ul> <li>\u4f18\u70b9: \u6bd4Adam\u6cdb\u5316\u6027\u66f4\u597d\u3001\u5bf9\u5927\u6a21\u578b\u4f18\u79c0</li> <li>\u7f3a\u70b9: \u5185\u5b58\u4f7f\u7528\u8f83\u9ad8</li> <li>\u9002\u7528\u4e8e:</li> <li>Transformer\u6a21\u578b\uff08BERT\u3001GPT\uff09</li> <li>\u5927\u89c4\u6a21\u9884\u8bad\u7ec3</li> <li>\u9700\u8981\u5f3a\u6b63\u5219\u5316\u65f6</li> <li>\u63a8\u8350\u8bbe\u7f6e: <code>lr=5e-5, weight_decay=0.01</code></li> </ul>"},{"location":"api/optim/optimizers/#rmsprop","title":"RMSprop","text":"<ul> <li>\u4f18\u70b9: \u5bf9\u975e\u5e73\u7a33\u76ee\u6807\u51fd\u6570\u597d</li> <li>\u7f3a\u70b9: \u9ad8\u5b66\u4e60\u7387\u65f6\u53ef\u80fd\u4e0d\u7a33\u5b9a</li> <li>\u9002\u7528\u4e8e:</li> <li>RNN\u8bad\u7ec3</li> <li>\u5f3a\u5316\u5b66\u4e60</li> <li>\u975e\u5e73\u7a33\u95ee\u9898</li> </ul>"},{"location":"api/optim/optimizers/#_22","title":"\u6027\u80fd\u63d0\u793a","text":"<ol> <li>\u68af\u5ea6\u7d2f\u79ef: \u5185\u5b58\u6709\u9650\u65f6\u6a21\u62df\u66f4\u5927\u6279\u5927\u5c0f</li> <li>\u68af\u5ea6\u88c1\u526a: \u5bf9RNN\u548cTransformers\u5fc5\u4e0d\u53ef\u5c11</li> <li>\u53c2\u6570\u7ec4: \u5bf9\u4e0d\u540c\u5c42\u4f7f\u7528\u4e0d\u540c\u5b66\u4e60\u7387</li> <li>\u6743\u91cd\u8870\u51cf: AdamW\u901a\u5e38\u6bd4Adam + L2\u6b63\u5219\u5316\u8868\u73b0\u66f4\u597d</li> <li>\u5b66\u4e60\u7387\u9884\u70ed: \u5927\u6279\u91cf\u8bad\u7ec3\u65f6\u4f7f\u7528\u9884\u70ed</li> <li>\u6df7\u5408\u7cbe\u5ea6: \u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u5e76\u52a0\u901f\u8bad\u7ec3</li> </ol>"},{"location":"api/optim/optimizers/#_23","title":"\u5185\u5b58\u8003\u8651","text":"<ul> <li>\u4f18\u5316\u5668\u7ef4\u62a4\u6bcf\u4e2a\u53c2\u6570\u7684\u72b6\u6001\uff08Adam/AdamW\u4f7f\u75282\u500d\u53c2\u6570\u5185\u5b58\uff09</li> <li>\u4f7f\u7528<code>zero_grad(set_to_none=True)</code>\u51cf\u5c11\u5185\u5b58\u788e\u7247</li> <li>\u5728\u8bbe\u5907\u95f4\u79fb\u52a8\u6a21\u578b\u65f6\u8003\u8651\u4f18\u5316\u5668\u72b6\u6001</li> <li>\u5728\u68c0\u67e5\u70b9\u4e2d\u4fdd\u5b58\u4f18\u5316\u5668\u72b6\u6001\u4ee5\u6062\u590d\u8bad\u7ec3</li> </ul>"},{"location":"api/optim/optimizers/#_24","title":"\u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u59cb\u7ec8\u6e05\u9664\u68af\u5ea6 \u5728\u540e\u5411\u4f20\u64ad\u524d</li> <li>\u4f7f\u7528\u68af\u5ea6\u88c1\u526a \u5bf9RNN\u548cTransformers</li> <li>\u76d1\u63a7\u5b66\u4e60\u7387 \u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b</li> <li>\u4fdd\u5b58\u4f18\u5316\u5668\u72b6\u6001 \u5728\u68c0\u67e5\u70b9\u4e2d</li> <li>\u4e3a\u6a21\u578b\u7c7b\u578b\u4f7f\u7528\u9002\u5f53\u7684\u6743\u91cd\u8870\u51cf</li> <li>\u4e3a\u5927\u6a21\u578b\u8003\u8651\u6df7\u5408\u7cbe\u5ea6</li> </ol>"},{"location":"api/optim/optimizers/#_25","title":"\u53e6\u8bf7\u53c2\u9605","text":"<ul> <li>\u5b66\u4e60\u7387\u8c03\u5ea6\u5668 - \u52a8\u6001\u5b66\u4e60\u7387\u8c03\u6574</li> <li>\u795e\u7ecf\u7f51\u7edc\u6a21\u5757 - \u6784\u5efa\u6a21\u578b</li> <li>\u81ea\u52a8\u5fae\u5206 - \u81ea\u52a8\u5fae\u5206</li> <li>\u793a\u4f8b - \u5b8c\u6574\u8bad\u7ec3\u793a\u4f8b</li> </ul>"},{"location":"api/utils/","title":"\u5b9e\u7528\u5de5\u5177 (genesis.utils)","text":""},{"location":"api/utils/#_1","title":"\u6982\u8ff0","text":"<p><code>genesis.utils</code>\u6a21\u5757\u4e3a\u5f00\u53d1\u3001\u8c03\u8bd5\u548c\u6570\u636e\u5904\u7406\u63d0\u4f9b\u5fc5\u8981\u7684\u5b9e\u7528\u5de5\u5177\u3002\u5b83\u5305\u62ec\u6027\u80fd\u5206\u6790\u5de5\u5177\u3001\u6570\u636e\u52a0\u8f7d\u5b9e\u7528\u7a0b\u5e8f\u548c\u5e2e\u52a9\u51fd\u6570\uff0c\u4ee5\u7b80\u5316\u6df1\u5ea6\u5b66\u4e60\u5de5\u4f5c\u6d41\u7a0b\u3002</p>"},{"location":"api/utils/#_2","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"api/utils/#_3","title":"\u6027\u80fd\u5206\u6790","text":"<ul> <li>\u51fd\u6570\u548c\u65b9\u6cd5\u6267\u884c\u65f6\u95f4\u8ddf\u8e2a</li> <li>\u88c5\u9970\u5668\u81ea\u52a8\u5206\u6790</li> <li>\u6027\u80fd\u5206\u6790\u548c\u62a5\u544a</li> </ul>"},{"location":"api/utils/#_4","title":"\u6570\u636e\u52a0\u8f7d","text":"<ul> <li>\u8bad\u7ec3\u6570\u636e\u7684\u6570\u636e\u96c6\u62bd\u8c61</li> <li>\u5177\u6709\u6279\u5904\u7406\u548c\u6d17\u724c\u7684DataLoader</li> <li>\u652f\u6301\u6620\u5c04\u5f0f\u548c\u53ef\u8fed\u4ee3\u6570\u636e\u96c6</li> </ul>"},{"location":"api/utils/#_5","title":"\u6027\u80fd\u5206\u6790\u5de5\u5177","text":""},{"location":"api/utils/#profile","title":"<code>@profile</code> \u88c5\u9970\u5668","text":"<p>\u51fd\u6570\u548c\u7c7b\u7684\u81ea\u52a8\u6027\u80fd\u5206\u6790\u3002</p> Python<pre><code>from genesis.utils import profile\n\n@profile\ndef expensive_function(x):\n    \"\"\"\n    \u5206\u6790\u6b64\u51fd\u6570\u7684\u6267\u884c\u65f6\u95f4\u548c\u8c03\u7528\u6b21\u6570\u3002\n    \"\"\"\n    # \u4f60\u7684\u8ba1\u7b97\u5728\u8fd9\u91cc\n    return x * 2\n\n@profile\nclass MyModel:\n    \"\"\"\n    \u5206\u6790\u6b64\u7c7b\u4e2d\u7684\u6240\u6709\u65b9\u6cd5\u3002\n    \"\"\"\n    def forward(self, x):\n        return x + 1\n\n    def backward(self, grad):\n        return grad\n</code></pre> <p>\u5206\u6790\u5668\u81ea\u52a8\u8ddf\u8e2a\uff1a - \u8c03\u7528\u6b21\u6570: \u6bcf\u4e2a\u51fd\u6570\u88ab\u8c03\u7528\u7684\u6b21\u6570 - \u603b\u65f6\u95f4: \u7d2f\u79ef\u6267\u884c\u65f6\u95f4 - \u5e73\u5747\u65f6\u95f4: \u6bcf\u6b21\u8c03\u7528\u7684\u5e73\u5747\u6267\u884c\u65f6\u95f4</p>"},{"location":"api/utils/#_6","title":"\u4f7f\u7528\u793a\u4f8b","text":"Python<pre><code>import genesis.utils as utils\nimport time\n\n# \u5206\u6790\u51fd\u6570\n@utils.profile\ndef matrix_multiply(a, b):\n    \"\"\"\u865a\u62df\u77e9\u9635\u4e58\u6cd5\u3002\"\"\"\n    time.sleep(0.01)  # \u6a21\u62df\u8ba1\u7b97\n    return a @ b\n\n# \u5206\u6790\u7c7b\n@utils.profile\nclass NeuralNetwork:\n    def __init__(self):\n        pass\n\n    def forward(self, x):\n        time.sleep(0.005)  # \u6a21\u62df\u524d\u5411\u4f20\u64ad\n        return x * 2\n\n    def backward(self, grad):\n        time.sleep(0.003)  # \u6a21\u62df\u540e\u5411\u4f20\u64ad\n        return grad\n\n# \u4f7f\u7528\u88ab\u5206\u6790\u7684\u51fd\u6570\nmodel = NeuralNetwork()\nfor i in range(100):\n    x = matrix_multiply([[1, 2]], [[3], [4]])\n    y = model.forward(x)\n    model.backward([1, 1])\n\n# \u5206\u6790\u6570\u636e\u5728\u7a0b\u5e8f\u9000\u51fa\u65f6\u81ea\u52a8\u6253\u5370\n</code></pre>"},{"location":"api/utils/#_7","title":"\u5206\u6790\u6570\u636e\u683c\u5f0f","text":"<p>\u7a0b\u5e8f\u9000\u51fa\u65f6\uff0c\u5206\u6790\u6570\u636e\u81ea\u52a8\u6253\u5370\uff1a</p> Text Only<pre><code>\u7a0b\u5e8f\u82b1\u8d39\u4e86 2.1456 \u79d2!\n__main__.matrix_multiply: 100\u6b21\u8c03\u7528, 1.0234\u603b\u79d2\u6570\n__main__.NeuralNetwork.forward: 100\u6b21\u8c03\u7528, 0.5123\u603b\u79d2\u6570\n__main__.NeuralNetwork.backward: 100\u6b21\u8c03\u7528, 0.3089\u603b\u79d2\u6570\n</code></pre>"},{"location":"api/utils/#_8","title":"\u624b\u52a8\u5206\u6790","text":"<p>\u4e3a\u4e86\u66f4\u7cbe\u7ec6\u7684\u63a7\u5236\uff0c\u4f60\u53ef\u4ee5\u7f16\u7a0b\u5f0f\u5730\u8bbf\u95ee\u5206\u6790\u6570\u636e\uff1a</p> Python<pre><code>from genesis.utils.profile import profile_data, print_profile_data\n\n# \u83b7\u53d6\u5f53\u524d\u5206\u6790\u6570\u636e\ncurrent_data = profile_data.copy()\nprint(f\"\u5230\u76ee\u524d\u4e3a\u6b62\u7684\u51fd\u6570\u8c03\u7528: {sum(data['calls'] for data in current_data.values())}\")\n\n# \u624b\u52a8\u6253\u5370\u5206\u6790\u6458\u8981\nprint_profile_data()\n</code></pre>"},{"location":"api/utils/#_9","title":"\u6570\u636e\u52a0\u8f7d","text":""},{"location":"api/utils/#dataset","title":"<code>Dataset</code>","text":"<p>\u6240\u6709\u6570\u636e\u96c6\u7684\u62bd\u8c61\u57fa\u7c7b\u3002</p> Python<pre><code>from genesis.utils.data import Dataset\n\nclass Dataset:\n    \"\"\"\n    \u62bd\u8c61\u6570\u636e\u96c6\u7c7b\u3002\n\n    \u6240\u6709\u5b50\u7c7b\u5fc5\u987b\u5b9e\u73b0 __len__ \u548c __getitem__\u3002\n    \"\"\"\n\n    def __len__(self) -&gt; int:\n        \"\"\"\n        \u8fd4\u56de\u6570\u636e\u96c6\u7684\u5927\u5c0f\u3002\n\n        \u8fd4\u56de:\n            \u6570\u636e\u96c6\u4e2d\u6837\u672c\u7684\u6570\u91cf\n        \"\"\"\n        raise NotImplementedError\n\n    def __getitem__(self, idx: int):\n        \"\"\"\n        \u6309\u7d22\u5f15\u68c0\u7d22\u6837\u672c\u3002\n\n        \u53c2\u6570:\n            idx: \u6837\u672c\u7d22\u5f15\n\n        \u8fd4\u56de:\n            \u7ed9\u5b9a\u7d22\u5f15\u5904\u7684\u6570\u636e\u6837\u672c\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"api/utils/#_10","title":"\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u793a\u4f8b","text":"Python<pre><code>import numpy as np\nfrom genesis.utils.data import Dataset\n\nclass MNIST(Dataset):\n    \"\"\"MNIST\u6570\u636e\u96c6\u5b9e\u73b0\u793a\u4f8b\u3002\"\"\"\n\n    def __init__(self, data_path, transform=None):\n        \"\"\"\n        \u521d\u59cb\u5316MNIST\u6570\u636e\u96c6\u3002\n\n        \u53c2\u6570:\n            data_path: MNIST\u6570\u636e\u6587\u4ef6\u8def\u5f84\n            transform: \u53ef\u9009\u7684\u6570\u636e\u53d8\u6362\u51fd\u6570\n        \"\"\"\n        self.data = self._load_data(data_path)\n        self.labels = self._load_labels(data_path)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image = self.data[idx]\n        label = self.labels[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n    def _load_data(self, path):\n        # \u5728\u8fd9\u91cc\u52a0\u8f7d\u4f60\u7684\u6570\u636e\n        return np.random.randn(10000, 28, 28)  # \u865a\u62df\u6570\u636e\n\n    def _load_labels(self, path):\n        # \u5728\u8fd9\u91cc\u52a0\u8f7d\u4f60\u7684\u6807\u7b7e\n        return np.random.randint(0, 10, 10000)  # \u865a\u62df\u6807\u7b7e\n</code></pre>"},{"location":"api/utils/#iterabledataset","title":"<code>IterableDataset</code>","text":"<p>\u53ef\u8fed\u4ee3\u5f0f\u6570\u636e\u96c6\u7684\u57fa\u7c7b\u3002</p> Python<pre><code>from genesis.utils.data import IterableDataset\n\nclass IterableDataset(Dataset):\n    \"\"\"\n    \u53ef\u8fed\u4ee3\u6570\u636e\u96c6\u7684\u57fa\u7c7b\u3002\n\n    \u5bf9\u4e8e\u6d41\u5f0f\u6570\u636e\u6216\u968f\u673a\u8bbf\u95ee\u4e0d\u53ef\u884c\u65f6\u5f88\u6709\u7528\u3002\n    \"\"\"\n\n    def __iter__(self):\n        \"\"\"\n        \u8fd4\u56de\u6570\u636e\u96c6\u7684\u8fed\u4ee3\u5668\u3002\n\n        \u8fd4\u56de:\n            \u4ea7\u751f\u6570\u636e\u6837\u672c\u7684\u8fed\u4ee3\u5668\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"api/utils/#_11","title":"\u53ef\u8fed\u4ee3\u6570\u636e\u96c6\u793a\u4f8b","text":"Python<pre><code>import random\nfrom genesis.utils.data import IterableDataset\n\nclass RandomDataStream(IterableDataset):\n    \"\"\"\u6d41\u5f0f\u6570\u636e\u96c6\u793a\u4f8b\u3002\"\"\"\n\n    def __init__(self, num_samples, feature_dim):\n        \"\"\"\n        \u521d\u59cb\u5316\u6d41\u5f0f\u6570\u636e\u96c6\u3002\n\n        \u53c2\u6570:\n            num_samples: \u8981\u751f\u6210\u7684\u6837\u672c\u6570\n            feature_dim: \u6bcf\u4e2a\u6837\u672c\u7684\u7ef4\u5ea6\n        \"\"\"\n        self.num_samples = num_samples\n        self.feature_dim = feature_dim\n\n    def __iter__(self):\n        \"\"\"\u5373\u65f6\u751f\u6210\u968f\u673a\u6837\u672c\u3002\"\"\"\n        for _ in range(self.num_samples):\n            # \u751f\u6210\u968f\u673a\u6570\u636e\n            data = [random.random() for _ in range(self.feature_dim)]\n            label = random.randint(0, 9)\n            yield data, label\n</code></pre>"},{"location":"api/utils/#dataloader","title":"<code>DataLoader</code>","text":"<p>\u5177\u6709\u6279\u5904\u7406\u548c\u6d17\u724c\u7684\u9ad8\u6548\u6570\u636e\u52a0\u8f7d\u3002</p> Python<pre><code>from genesis.utils.data import DataLoader\n\nclass DataLoader:\n    \"\"\"\n    \u7528\u4e8e\u6279\u5904\u7406\u548c\u6d17\u724c\u6570\u636e\u96c6\u7684\u6570\u636e\u52a0\u8f7d\u5668\u3002\n\n    \u53c2\u6570:\n        dataset: \u6570\u636e\u96c6\u5b9e\u4f8b\uff08Dataset\u6216IterableDataset\uff09\n        batch_size: \u6bcf\u6279\u6837\u672c\u6570\uff08\u9ed8\u8ba4: 1\uff09\n        shuffle: \u662f\u5426\u5728\u6bcf\u4e2aepoch\u6d17\u724c\u6570\u636e\uff08\u9ed8\u8ba4: False\uff09\n    \"\"\"\n\n    def __init__(\n        self, \n        dataset, \n        batch_size: int = 1, \n        shuffle: bool = False\n    ):\n</code></pre>"},{"location":"api/utils/#dataloader_1","title":"DataLoader\u793a\u4f8b","text":"Python<pre><code>from genesis.utils.data import Dataset, DataLoader\nimport numpy as np\n\n# \u521b\u5efa\u7b80\u5355\u6570\u636e\u96c6\nclass SimpleDataset(Dataset):\n    def __init__(self, size):\n        self.data = np.random.randn(size, 10)\n        self.labels = np.random.randint(0, 2, size)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx], self.labels[idx]\n\n# \u521b\u5efa\u6570\u636e\u96c6\u548c\u6570\u636e\u52a0\u8f7d\u5668\ndataset = SimpleDataset(1000)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n# \u8bad\u7ec3\u5faa\u73af\nfor epoch in range(5):\n    print(f\"Epoch {epoch + 1}\")\n    for batch_idx, batch in enumerate(dataloader):\n        # batch\u662f(data, label)\u5143\u7ec4\u7684\u5217\u8868\n        batch_data = [item[0] for item in batch]\n        batch_labels = [item[1] for item in batch]\n\n        # \u5982\u9700\u8981\u8f6c\u6362\u4e3a\u6570\u7ec4\n        batch_data = np.array(batch_data)\n        batch_labels = np.array(batch_labels)\n\n        print(f\"  Batch {batch_idx}: data shape {batch_data.shape}\")\n\n        # \u4f60\u7684\u8bad\u7ec3\u4ee3\u7801\u5728\u8fd9\u91cc\n        pass\n</code></pre>"},{"location":"api/utils/#dataloader_2","title":"\u9ad8\u7ea7DataLoader\u4f7f\u7528","text":"Python<pre><code># \u5e26\u6d17\u724c\u7684\u5927\u6570\u636e\u96c6\nlarge_dataset = SimpleDataset(50000)\ntrain_loader = DataLoader(large_dataset, batch_size=128, shuffle=True)\n\n# \u53ef\u8fed\u4ee3\u6570\u636e\u96c6\nstream_dataset = RandomDataStream(1000, 20)\nstream_loader = DataLoader(stream_dataset, batch_size=16)\n\n# \u8c03\u8bd5\u7528\u5c0f\u6279\u91cf\ndebug_loader = DataLoader(dataset, batch_size=4, shuffle=False)\n\n# \u591a\u6570\u636e\u52a0\u8f7d\u5668\u7684\u8bad\u7ec3\u5faa\u73af\ndef train_model(model, train_loader, val_loader):\n    for epoch in range(num_epochs):\n        # \u8bad\u7ec3\u9636\u6bb5\n        model.train()\n        for batch in train_loader:\n            # \u8bad\u7ec3\u4ee3\u7801\n            pass\n\n        # \u9a8c\u8bc1\u9636\u6bb5\n        model.eval()\n        for batch in val_loader:\n            # \u9a8c\u8bc1\u4ee3\u7801\n            pass\n</code></pre>"},{"location":"api/utils/#genesis","title":"\u4e0eGenesis\u8bad\u7ec3\u7684\u96c6\u6210","text":""},{"location":"api/utils/#_12","title":"\u5b8c\u6574\u8bad\u7ec3\u793a\u4f8b","text":"Python<pre><code>import genesis\nimport genesis.nn as nn\nimport genesis.optim as optim\nfrom genesis.utils.data import Dataset, DataLoader\nfrom genesis.utils import profile\nimport numpy as np\n\n# \u81ea\u5b9a\u4e49\u6570\u636e\u96c6\nclass TrainingDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\n# \u88ab\u5206\u6790\u7684\u6a21\u578b\n@profile\nclass SimpleModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x\n\n# \u751f\u6210\u865a\u62df\u6570\u636e\nX = np.random.randn(1000, 20).astype(np.float32)\ny = np.random.randint(0, 3, 1000)\n\n# \u521b\u5efa\u6570\u636e\u96c6\u548c\u6570\u636e\u52a0\u8f7d\u5668\ndataset = TrainingDataset(X, y)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n# \u6a21\u578b\u548c\u4f18\u5316\u5668\nmodel = SimpleModel(20, 64, 3)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\n# \u5e26\u5206\u6790\u7684\u8bad\u7ec3\u5faa\u73af\n@profile\ndef train_epoch(model, dataloader, optimizer, criterion):\n    \"\"\"\u8bad\u7ec3\u4e00\u4e2aepoch\u3002\"\"\"\n    total_loss = 0.0\n    for batch in dataloader:\n        # \u63d0\u53d6\u6279\u6570\u636e\n        batch_x = [item[0] for item in batch]\n        batch_y = [item[1] for item in batch]\n\n        # \u8f6c\u6362\u4e3aGenesis\u5f20\u91cf\n        x = genesis.tensor(batch_x)\n        y = genesis.tensor(batch_y)\n\n        # \u524d\u5411\u4f20\u64ad\n        optimizer.zero_grad()\n        outputs = model(x)\n        loss = criterion(outputs, y)\n\n        # \u540e\u5411\u4f20\u64ad\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader)\n\n# \u8bad\u7ec3\u6a21\u578b\nfor epoch in range(10):\n    avg_loss = train_epoch(model, dataloader, optimizer, criterion)\n    print(f\"Epoch {epoch + 1}, \u5e73\u5747\u635f\u5931: {avg_loss:.4f}\")\n\n# \u5206\u6790\u6570\u636e\u5c06\u5728\u7a0b\u5e8f\u9000\u51fa\u65f6\u81ea\u52a8\u6253\u5370\n</code></pre>"},{"location":"api/utils/#_13","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"api/utils/#_14","title":"\u5206\u6790\u6307\u5357","text":"<ol> <li>\u7528\u4e8e\u5f00\u53d1: \u5728\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u542f\u7528\u5206\u6790\u4ee5\u8bc6\u522b\u74f6\u9888</li> <li>\u751f\u4ea7\u73af\u5883\u7981\u7528: \u5728\u751f\u4ea7\u4ee3\u7801\u4e2d\u5220\u9664\u5206\u6790\u88c5\u9970\u5668</li> <li>\u9009\u62e9\u6027\u5206\u6790: \u53ea\u5206\u6790\u4f60\u6000\u7591\u6162\u7684\u51fd\u6570</li> <li>\u6279\u91cf\u5206\u6790: \u5206\u6790\u6574\u4e2a\u8bad\u7ec3\u5faa\u73af\u800c\u4e0d\u662f\u5355\u4e2a\u64cd\u4f5c</li> </ol>"},{"location":"api/utils/#_15","title":"\u6570\u636e\u52a0\u8f7d\u6307\u5357","text":"<ol> <li>\u9002\u5f53\u7684\u6279\u5927\u5c0f: \u5e73\u8861\u5185\u5b58\u4f7f\u7528\u548c\u8bad\u7ec3\u6548\u7387</li> <li>\u6d17\u724c\u8bad\u7ec3\u6570\u636e: \u5728epochs\u4e4b\u95f4\u59cb\u7ec8\u6d17\u724c\u8bad\u7ec3\u6570\u636e</li> <li>\u4e0d\u6d17\u724c\u9a8c\u8bc1: \u4fdd\u6301\u9a8c\u8bc1\u6570\u636e\u4e00\u81f4\u7684\u987a\u5e8f</li> <li>\u5185\u5b58\u8003\u8651: \u5bf9\u975e\u5e38\u5927\u7684\u6570\u636e\u96c6\u4f7f\u7528\u53ef\u8fed\u4ee3\u6570\u636e\u96c6</li> <li>\u6570\u636e\u9884\u5904\u7406: \u5728\u6570\u636e\u96c6\u7684<code>__getitem__</code>\u65b9\u6cd5\u4e2d\u5e94\u7528\u53d8\u6362</li> </ol>"},{"location":"api/utils/#_16","title":"\u6027\u80fd\u63d0\u793a","text":""},{"location":"api/utils/#_17","title":"\u9ad8\u6548\u6570\u636e\u52a0\u8f7d","text":"Python<pre><code># \u597d\uff1a\u9ad8\u6548\u6279\u5904\u7406\nclass EfficientDataset(Dataset):\n    def __init__(self, data):\n        # \u9884\u5904\u7406\u6570\u636e\u4e00\u6b21\n        self.data = self._preprocess(data)\n\n    def _preprocess(self, data):\n        # \u6602\u8d35\u7684\u9884\u5904\u7406\u53ea\u505a\u4e00\u6b21\n        return data * 2 + 1\n\n    def __getitem__(self, idx):\n        # \u5feb\u901f\u8bbf\u95ee\n        return self.data[idx]\n\n# \u597d\uff1a\u5c3d\u53ef\u80fd\u4f7f\u7528\u5927\u6279\u5927\u5c0f\ntrain_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n\n# \u597d\uff1a\u4f7f\u7528\u9002\u5f53\u7684\u6570\u636e\u7c7b\u578b\ndata = np.array(data, dtype=np.float32)  # \u4f7f\u7528float32\u800c\u4e0d\u662ffloat64\n</code></pre>"},{"location":"api/utils/#_18","title":"\u5185\u5b58\u7ba1\u7406","text":"Python<pre><code># \u597d\uff1a\u5b8c\u6210\u540e\u5220\u9664\u5927\u5bf9\u8c61\ndel large_dataset\ndel temporary_data\n\n# \u597d\uff1a\u5bf9\u5927\u6570\u636e\u96c6\u4f7f\u7528\u751f\u6210\u5668\ndef data_generator():\n    for file in file_list:\n        data = load_file(file)\n        yield data\n\n# \u597d\uff1a\u5982\u9700\u8981\u7528\u8f83\u5c0f\u6279\u91cf\u9650\u5236\u5185\u5b58\u4f7f\u7528\nsmall_batch_loader = DataLoader(dataset, batch_size=16)\n</code></pre>"},{"location":"api/utils/#_19","title":"\u53e6\u8bf7\u53c2\u9605","text":"<ul> <li>\u795e\u7ecf\u7f51\u7edc\u6a21\u5757 - \u6784\u5efa\u6a21\u578b</li> <li>\u4f18\u5316\u5668 - \u8bad\u7ec3\u7b97\u6cd5  </li> <li>\u81ea\u52a8\u5fae\u5206 - \u81ea\u52a8\u5fae\u5206</li> <li>\u6027\u80fd\u6307\u5357 - \u4f18\u5316\u6280\u672f</li> </ul>"},{"location":"api-reference/","title":"API \u53c2\u8003\u6587\u6863","text":"<p>Genesis\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684API\u63a5\u53e3\uff0c\u672c\u8282\u63d0\u4f9b\u8be6\u7ec6\u7684\u4ee3\u7801\u7ea7\u6587\u6863\u548c\u4f7f\u7528\u793a\u4f8b\u3002</p>"},{"location":"api-reference/#_1","title":"\u6838\u5fc3\u6a21\u5757\u7ed3\u6784","text":""},{"location":"api-reference/#_2","title":"\u4e3b\u8981\u547d\u540d\u7a7a\u95f4","text":"<ul> <li><code>genesis</code>: \u6838\u5fc3\u5f20\u91cf\u548c\u81ea\u52a8\u5fae\u5206\u7cfb\u7edf</li> <li><code>genesis.nn</code>: \u795e\u7ecf\u7f51\u7edc\u6a21\u5757\u548c\u5c42</li> <li><code>genesis.optim</code>: \u4f18\u5316\u5668\u548c\u5b66\u4e60\u7387\u8c03\u5ea6\u5668</li> <li><code>genesis.functional</code>: \u51fd\u6570\u5f0f\u64cd\u4f5c\u63a5\u53e3</li> <li><code>genesis.utils</code>: \u5de5\u5177\u51fd\u6570\u548c\u8f85\u52a9\u7c7b</li> </ul>"},{"location":"api-reference/#_3","title":"\u5feb\u901f\u5bfc\u822a","text":"\u6a21\u5757 \u63cf\u8ff0 \u4e3b\u8981\u7c7b/\u51fd\u6570 genesis \u6838\u5fc3\u5f20\u91cf\u7cfb\u7edf <code>Tensor</code>, <code>autocast</code>, <code>no_grad</code> nn \u795e\u7ecf\u7f51\u7edc\u5c42 <code>Module</code>, <code>Linear</code>, <code>MultiHeadAttention</code> optim \u4f18\u5316\u5668 <code>SGD</code>, <code>Adam</code>, <code>AdamW</code> functional \u51fd\u6570\u5f0f\u64cd\u4f5c <code>relu</code>, <code>softmax</code>, <code>matmul</code> utils \u5de5\u5177\u51fd\u6570 <code>profile</code>, <code>DataLoader</code>"},{"location":"api-reference/#_4","title":"\u4ee3\u7801\u7ea6\u5b9a","text":""},{"location":"api-reference/#_5","title":"\u5bfc\u5165\u89c4\u8303","text":"Python<pre><code>import genesis\nimport genesis.nn as nn\nimport genesis.optim as optim\nimport genesis.nn.functional as F\n</code></pre>"},{"location":"api-reference/#_6","title":"\u8bbe\u5907\u7ba1\u7406","text":"Python<pre><code># \u8bbe\u7f6e\u9ed8\u8ba4\u8bbe\u5907\ngenesis.set_default_device(genesis.cuda())\n\n# \u68c0\u67e5CUDA\u53ef\u7528\u6027\nif genesis.cuda.is_available():\n    device = genesis.cuda()\nelse:\n    device = genesis.cpu()\n</code></pre>"},{"location":"api-reference/#_7","title":"\u6570\u636e\u7c7b\u578b","text":"Python<pre><code># \u652f\u6301\u7684\u6570\u636e\u7c7b\u578b\ngenesis.float32  # \u9ed8\u8ba4\u6d6e\u70b9\u7c7b\u578b\ngenesis.float16  # \u534a\u7cbe\u5ea6\u6d6e\u70b9\ngenesis.int32    # 32\u4f4d\u6574\u6570\ngenesis.bool     # \u5e03\u5c14\u7c7b\u578b\n</code></pre>"},{"location":"api-reference/#_8","title":"\u5feb\u901f\u793a\u4f8b","text":""},{"location":"api-reference/#_9","title":"\u57fa\u7840\u5f20\u91cf\u64cd\u4f5c","text":"Python<pre><code>import genesis\n\n# \u521b\u5efa\u5f20\u91cf\nx = genesis.tensor([[1, 2], [3, 4]], dtype=genesis.float32)\ny = genesis.randn(2, 2)\n\n# \u57fa\u7840\u8fd0\u7b97\nz = x + y\nresult = genesis.matmul(x, y.T)\n\n# \u68af\u5ea6\u8ba1\u7b97\nx.requires_grad_(True)\nloss = (x ** 2).sum()\nloss.backward()\nprint(x.grad)  # \u6253\u5370\u68af\u5ea6\n</code></pre>"},{"location":"api-reference/#_10","title":"\u795e\u7ecf\u7f51\u7edc\u6a21\u578b","text":"Python<pre><code>import genesis.nn as nn\n\nclass MLP(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.relu(self.fc1(x))\n        return self.fc2(x)\n\n# \u4f7f\u7528\u6a21\u578b\nmodel = MLP(784, 256, 10)\nx = genesis.randn(32, 784)\noutput = model(x)\n</code></pre>"},{"location":"api-reference/#_11","title":"\u8bad\u7ec3\u5faa\u73af","text":"Python<pre><code>import genesis.optim as optim\n\n# \u521d\u59cb\u5316\nmodel = MLP(784, 256, 10)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\n# \u8bad\u7ec3\u6b65\u9aa4\nfor epoch in range(100):\n    for batch_idx, (data, target) in enumerate(dataloader):\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n</code></pre>"},{"location":"api-reference/#_12","title":"\u6027\u80fd\u4f18\u5316\u63d0\u793a","text":""},{"location":"api-reference/#_13","title":"\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3","text":"Python<pre><code># \u542f\u7528\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6\ngenesis.enable_autocast = True\n\nwith genesis.autocast():\n    output = model(input_tensor)\n    loss = criterion(output, target)\n</code></pre>"},{"location":"api-reference/#gpu","title":"GPU\u5185\u5b58\u4f18\u5316","text":"Python<pre><code># \u4f7f\u7528inplace\u64cd\u4f5c\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\nx.relu_()  # inplace ReLU\nx.add_(y)  # inplace \u52a0\u6cd5\n\n# \u91ca\u653e\u4e0d\u9700\u8981\u7684\u68af\u5ea6\nwith genesis.no_grad():\n    inference_result = model(data)\n</code></pre>"},{"location":"api-reference/#_14","title":"\u6279\u91cf\u64cd\u4f5c\u4f18\u5316","text":"Python<pre><code># \u6279\u91cf\u77e9\u9635\u4e58\u6cd5\nbatch_result = genesis.bmm(batch_a, batch_b)\n\n# \u5411\u91cf\u5316\u64cd\u4f5c\u66ff\u4ee3\u5faa\u73af\nresult = genesis.sum(tensor, dim=1, keepdim=True)\n</code></pre>"},{"location":"api-reference/functional/","title":"\u51fd\u6570\u5f0fAPI\u53c2\u8003","text":"<p>Genesis\u64cd\u4f5c\u7684\u51fd\u6570\u5f0f\u63a5\u53e3 - \u795e\u7ecf\u7f51\u7edc\u64cd\u4f5c\u7684\u65e0\u72b6\u6001\u51fd\u6570\u3002</p>"},{"location":"api-reference/functional/#_1","title":"\u6838\u5fc3\u51fd\u6570","text":""},{"location":"api-reference/functional/#_2","title":"\u6fc0\u6d3b\u51fd\u6570","text":"<ul> <li><code>F.relu(x)</code> - ReLU\u6fc0\u6d3b</li> <li><code>F.softmax(x, dim=-1)</code> - Softmax</li> <li><code>F.gelu(x)</code> - GELU\u6fc0\u6d3b</li> </ul>"},{"location":"api-reference/functional/#_3","title":"\u635f\u5931\u51fd\u6570","text":"<ul> <li><code>F.mse_loss(input, target)</code> - \u5747\u65b9\u8bef\u5dee</li> <li><code>F.cross_entropy(input, target)</code> - \u4ea4\u53c9\u71b5\u635f\u5931</li> </ul>"},{"location":"api-reference/functional/#_4","title":"\u5377\u79ef\u64cd\u4f5c","text":"<ul> <li><code>F.conv2d(input, weight, bias)</code> - 2D\u5377\u79ef</li> <li><code>F.linear(input, weight, bias)</code> - \u7ebf\u6027\u53d8\u6362</li> </ul>"},{"location":"api-reference/functional/#_5","title":"\u5f20\u91cf\u64cd\u4f5c\u51fd\u6570","text":""},{"location":"api-reference/functional/#sortinput-dim-1-descendingfalse-stablefalse","title":"<code>sort(input, dim=-1, descending=False, stable=False)</code>","text":"<p>\u6cbf\u7ef4\u5ea6\u6392\u5e8f\u5143\u7d20\u3002</p> Python<pre><code>values, indices = genesis.sort(tensor, dim=1, descending=False)\n</code></pre> <p>\u53c2\u6570: - <code>input</code>: \u8f93\u5165\u5f20\u91cf - <code>dim</code>: \u6392\u5e8f\u7684\u7ef4\u5ea6 - <code>descending</code>: \u5982\u679c\u4e3aTrue\uff0c\u964d\u5e8f\u6392\u5e8f - <code>stable</code>: \u5982\u679c\u4e3aTrue\uff0c\u7a33\u5b9a\u6392\u5e8f\uff08\u4fdd\u6301\u76f8\u7b49\u5143\u7d20\u7684\u987a\u5e8f\uff09</p> <p>\u8fd4\u56de: (\u503c, \u7d22\u5f15) \u5f20\u91cf\u5143\u7ec4</p>"},{"location":"api-reference/functional/#topkinput-k-dim-1-largesttrue-sortedtrue","title":"<code>topk(input, k, dim=-1, largest=True, sorted=True)</code>","text":"<p>\u8fd4\u56de\u6cbf\u7ef4\u5ea6\u7684k\u4e2a\u6700\u5927/\u6700\u5c0f\u5143\u7d20\u3002</p> Python<pre><code>values, indices = genesis.topk(tensor, k=3, dim=1, largest=True)\n</code></pre> <p>\u53c2\u6570: - <code>input</code>: \u8f93\u5165\u5f20\u91cf - <code>k</code>: \u8fd4\u56de\u7684top\u503c\u6570\u91cf - <code>dim</code>: \u67e5\u627etop-k\u503c\u7684\u7ef4\u5ea6 - <code>largest</code>: \u5982\u679c\u4e3aTrue\uff0c\u8fd4\u56de\u6700\u5927\u503c\uff1b\u5982\u679c\u4e3aFalse\uff0c\u8fd4\u56de\u6700\u5c0f\u503c - <code>sorted</code>: \u5982\u679c\u4e3aTrue\uff0c\u8fd4\u56de\u6392\u5e8f\u540e\u7684\u503c</p> <p>\u8fd4\u56de: (\u503c, \u7d22\u5f15) \u5f20\u91cf\u5143\u7ec4</p>"},{"location":"api-reference/functional/#argsortinput-dim-1-descendingfalse","title":"<code>argsort(input, dim=-1, descending=False)</code>","text":"<p>\u8fd4\u56de\u6cbf\u7ef4\u5ea6\u6392\u5e8f\u5f20\u91cf\u7684\u7d22\u5f15\u3002</p> Python<pre><code>indices = genesis.argsort(tensor, dim=1, descending=False)\n</code></pre> <p>\u53c2\u6570: - <code>input</code>: \u8f93\u5165\u5f20\u91cf - <code>dim</code>: \u6392\u5e8f\u7684\u7ef4\u5ea6 - <code>descending</code>: \u5982\u679c\u4e3aTrue\uff0c\u964d\u5e8f\u6392\u5e8f</p> <p>\u8fd4\u56de: \u7d22\u5f15\u5f20\u91cf</p>"},{"location":"api-reference/functional/#gatherinput-dim-index","title":"<code>gather(input, dim, index)</code>","text":"<p>\u6cbf\u7531index\u6307\u5b9a\u7684\u8f74\u6536\u96c6\u503c\u3002</p> Python<pre><code>output = genesis.gather(tensor, dim=1, index=indices)\n</code></pre> <p>\u53c2\u6570: - <code>input</code>: \u8f93\u5165\u5f20\u91cf - <code>dim</code>: \u6536\u96c6\u7684\u7ef4\u5ea6 - <code>index</code>: \u4e0e\u8f93\u5165\u5177\u6709\u76f8\u540c\u7ef4\u6570\u7684\u7d22\u5f15\u5f20\u91cf</p> <p>\u8fd4\u56de: \u5305\u542b\u6536\u96c6\u503c\u7684\u5f20\u91cf</p>"},{"location":"api-reference/functional/#scatter_addinput-dim-index-src","title":"<code>scatter_add(input, dim, index, src)</code>","text":"<p>\u5c06src\u4e2d\u7684\u503c\u6dfb\u52a0\u5230input\u5728index\u6307\u5b9a\u4f4d\u7f6e\u5904\u3002</p> Python<pre><code>genesis.scatter_add(tensor, dim=1, index=indices, src=values)\n</code></pre> <p>\u53c2\u6570: - <code>input</code>: \u8f93\u5165\u5f20\u91cf\uff08\u5c31\u5730\u4fee\u6539\uff09 - <code>dim</code>: \u6563\u5e03\u7684\u7ef4\u5ea6 - <code>index</code>: \u7d22\u5f15\u5f20\u91cf - <code>src</code>: \u5305\u542b\u8981\u6dfb\u52a0\u503c\u7684\u6e90\u5f20\u91cf</p> <p>\u8fd4\u56de: \u4fee\u6539\u540e\u7684\u8f93\u5165\u5f20\u91cf</p>"},{"location":"api-reference/functional/#bincountinput-weightsnone-minlength0","title":"<code>bincount(input, weights=None, minlength=0)</code>","text":"<p>\u7edf\u8ba1\u6574\u6570\u5f20\u91cf\u4e2d\u6bcf\u4e2a\u503c\u7684\u51fa\u73b0\u6b21\u6570\u3002</p> Python<pre><code>counts = genesis.bincount(tensor, minlength=10)\n</code></pre> <p>\u53c2\u6570: - <code>input</code>: 1D\u6574\u6570\u5f20\u91cf - <code>weights</code>: \u53ef\u9009\u7684\u6743\u91cd\u5f20\u91cf - <code>minlength</code>: \u8f93\u51fa\u7684\u6700\u5c0f\u957f\u5ea6</p> <p>\u8fd4\u56de: \u5305\u542b\u8ba1\u6570\u7684\u5f20\u91cf</p>"},{"location":"api-reference/functional/#_6","title":"\u5b9e\u7528\u51fd\u6570","text":""},{"location":"api-reference/functional/#allcloseinput-other-rtol1e-05-atol1e-08-equal_nanfalse","title":"<code>allclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False)</code>","text":"<p>\u6d4b\u8bd5\u8f93\u5165\u548c\u5176\u4ed6\u5f20\u91cf\u7684\u6240\u6709\u5143\u7d20\u662f\u5426\u63a5\u8fd1\u3002</p> Python<pre><code>result = genesis.allclose(tensor1, tensor2, rtol=1e-5, atol=1e-8)\n</code></pre> <p>\u53c2\u6570: - <code>input</code>: \u7b2c\u4e00\u4e2a\u5f20\u91cf - <code>other</code>: \u7b2c\u4e8c\u4e2a\u5f20\u91cf - <code>rtol</code>: \u76f8\u5bf9\u5bb9\u5dee - <code>atol</code>: \u7edd\u5bf9\u5bb9\u5dee - <code>equal_nan</code>: \u662f\u5426\u5c06NaN\u503c\u89c6\u4e3a\u76f8\u7b49</p> <p>\u8fd4\u56de: \u5e03\u5c14\u6807\u91cf\u5f20\u91cf</p>"},{"location":"api-reference/functional/#_7","title":"\u5f20\u91cf\u9a8c\u8bc1\u51fd\u6570","text":""},{"location":"api-reference/functional/#isinfinput","title":"<code>isinf(input)</code>","text":"<p>\u6d4b\u8bd5\u6bcf\u4e2a\u5143\u7d20\u662f\u5426\u4e3a\u65e0\u7a77\u5927\uff08\u6b63\u65e0\u7a77\u6216\u8d1f\u65e0\u7a77\uff09\u3002</p> Python<pre><code>inf_mask = genesis.isinf(tensor)\n</code></pre> <p>\u53c2\u6570: - <code>input</code>: \u8f93\u5165\u5f20\u91cf</p> <p>\u8fd4\u56de: \u4e0e\u8f93\u5165\u5f62\u72b6\u76f8\u540c\u7684\u5e03\u5c14\u5f20\u91cf</p>"},{"location":"api-reference/functional/#isnaninput","title":"<code>isnan(input)</code>","text":"<p>\u6d4b\u8bd5\u6bcf\u4e2a\u5143\u7d20\u662f\u5426\u4e3aNaN\uff08\u975e\u6570\u503c\uff09\u3002</p> Python<pre><code>nan_mask = genesis.isnan(tensor)\n</code></pre> <p>\u53c2\u6570: - <code>input</code>: \u8f93\u5165\u5f20\u91cf</p> <p>\u8fd4\u56de: \u4e0e\u8f93\u5165\u5f62\u72b6\u76f8\u540c\u7684\u5e03\u5c14\u5f20\u91cf</p>"},{"location":"api-reference/functional/#isfiniteinput","title":"<code>isfinite(input)</code>","text":"<p>\u6d4b\u8bd5\u6bcf\u4e2a\u5143\u7d20\u662f\u5426\u4e3a\u6709\u9650\u503c\uff08\u975e\u65e0\u7a77\u4e14\u975eNaN\uff09\u3002</p> Python<pre><code>finite_mask = genesis.isfinite(tensor)\n</code></pre> <p>\u53c2\u6570: - <code>input</code>: \u8f93\u5165\u5f20\u91cf</p> <p>\u8fd4\u56de: \u4e0e\u8f93\u5165\u5f62\u72b6\u76f8\u540c\u7684\u5e03\u5c14\u5f20\u91cf</p>"},{"location":"api-reference/functional/#_8","title":"\u5206\u5e03\u5f0f\u8bad\u7ec3\u51fd\u6570","text":""},{"location":"api-reference/functional/#genesisdistributedinit_process_groupbackend-world_size-rank","title":"<code>genesis.distributed.init_process_group(backend, world_size, rank)</code>","text":"<p>\u521d\u59cb\u5316\u5206\u5e03\u5f0f\u8fdb\u7a0b\u7ec4\u3002</p> Python<pre><code>import genesis.distributed as dist\ndist.init_process_group(backend='nccl', world_size=2, rank=0)\n</code></pre> <p>\u53c2\u6570: - <code>backend</code>: \u901a\u4fe1\u540e\u7aef\uff08'nccl' \u7528\u4e8eGPU\uff09 - <code>world_size</code>: \u8fdb\u7a0b\u603b\u6570 - <code>rank</code>: \u5f53\u524d\u8fdb\u7a0b\u7684rank</p>"},{"location":"api-reference/functional/#genesisdistributeddistributeddataparallelmodel-device_idsnone","title":"<code>genesis.distributed.DistributedDataParallel(model, device_ids=None)</code>","text":"<p>\u5206\u5e03\u5f0f\u6570\u636e\u5e76\u884c\u5305\u88c5\u5668\u3002</p> Python<pre><code>ddp_model = dist.DistributedDataParallel(model, device_ids=[0])\n</code></pre> <p>\u53c2\u6570: - <code>model</code>: \u8981\u5305\u88c5\u7684\u6a21\u578b - <code>device_ids</code>: GPU\u8bbe\u5907ID\u5217\u8868</p> <p>\u8fd4\u56de: DDP\u5305\u88c5\u7684\u6a21\u578b</p>"},{"location":"api-reference/functional/#_9","title":"\u521b\u5efa\u51fd\u6570","text":""},{"location":"api-reference/functional/#eyen-mnone-devicenone-dtypegenesisfloat32","title":"<code>eye(n, m=None, device=None, dtype=genesis.float32)</code>","text":"<p>\u751f\u6210\u5355\u4f4d\u77e9\u9635\u3002</p> Python<pre><code>identity = genesis.eye(5)  # 5x5\u5355\u4f4d\u77e9\u9635\nrect_matrix = genesis.eye(3, 5)  # 3x5\u77e9\u9635\n</code></pre>"},{"location":"api-reference/functional/#ones_liketensor-dtypenone-devicenone","title":"<code>ones_like(tensor, dtype=None, device=None)</code>","text":"<p>\u751f\u6210\u4e0e\u8f93\u5165\u5f62\u72b6\u76f8\u540c\u7684\u51681\u5f20\u91cf\u3002</p> Python<pre><code>ones_tensor = genesis.ones_like(input_tensor)\n</code></pre>"},{"location":"api-reference/functional/#from_numpyarray-devicenone-dtypenone","title":"<code>from_numpy(array, device=None, dtype=None)</code>","text":"<p>\u4ecenumpy\u6570\u7ec4\u521b\u5efa\u5f20\u91cf\u3002</p> Python<pre><code>np_array = np.array([1, 2, 3])\ntensor = genesis.from_numpy(np_array)\n</code></pre> <p>\u6b64\u53c2\u8003\u6db5\u76d6\u4e86\u4e3b\u8981\u7684\u51fd\u6570\u5f0f\u64cd\u4f5c\u3002\u5b8c\u6574\u7684API\u8be6\u60c5\u8bf7\u53c2\u9605\u6e90\u7801\u6587\u6863\u3002</p>"},{"location":"api-reference/genesis/","title":"Genesis API Reference","text":"<p>This is the main API reference for the Genesis deep learning framework.</p>"},{"location":"api-reference/genesis/#core-functions","title":"Core Functions","text":"<p>Please refer to the specific module documentation for detailed information:</p> <ul> <li>Autograd - Automatic differentiation</li> <li>NDArray - Tensor operations  </li> <li>Neural Networks - Neural network layers</li> <li>Optimizers - Optimization algorithms</li> <li>Utilities - Helper functions</li> </ul> <p>This page is under construction. More detailed API documentation will be added soon.</p>"},{"location":"api-reference/nn/","title":"Neural Network API Reference","text":"<p>Complete reference for Genesis neural network modules and functions.</p>"},{"location":"api-reference/nn/#available-modules","title":"Available Modules","text":"<ul> <li>Modules - Neural network layers and building blocks</li> <li>Functional - Functional interface for operations</li> </ul>"},{"location":"api-reference/nn/#quick-reference","title":"Quick Reference","text":""},{"location":"api-reference/nn/#common-layers","title":"Common Layers","text":"<ul> <li><code>nn.Linear</code> - Fully connected layer</li> <li><code>nn.Conv2d</code> - 2D convolution</li> <li><code>nn.ReLU</code> - ReLU activation</li> <li><code>nn.LayerNorm</code> - Layer normalization</li> </ul> <p>Detailed documentation for each module is available in the respective pages.</p>"},{"location":"api-reference/optim/","title":"Optimizer API Reference","text":"<p>Complete reference for Genesis optimization algorithms.</p>"},{"location":"api-reference/optim/#available-optimizers","title":"Available Optimizers","text":"<ul> <li>Optimizers - SGD, Adam, AdamW and more</li> <li>Learning Rate Schedulers - Learning rate scheduling</li> </ul>"},{"location":"api-reference/optim/#quick-reference","title":"Quick Reference","text":""},{"location":"api-reference/optim/#optimizers","title":"Optimizers","text":"<ul> <li><code>optim.SGD</code> - Stochastic Gradient Descent</li> <li><code>optim.Adam</code> - Adam optimizer  </li> <li><code>optim.AdamW</code> - Adam with weight decay</li> </ul>"},{"location":"api-reference/optim/#schedulers","title":"Schedulers","text":"<ul> <li><code>lr_scheduler.StepLR</code> - Step-based decay</li> <li><code>lr_scheduler.CosineAnnealingLR</code> - Cosine annealing</li> </ul> <p>See individual pages for detailed API documentation.</p>"},{"location":"api-reference/utils/","title":"Utilities API Reference","text":"<p>Utility functions and helpers for Genesis framework.</p>"},{"location":"api-reference/utils/#available-utilities","title":"Available Utilities","text":"<p>See Utils for the main utilities documentation.</p>"},{"location":"api-reference/utils/#categories","title":"Categories","text":""},{"location":"api-reference/utils/#data-utilities","title":"Data Utilities","text":"<ul> <li>Data loading helpers</li> <li>Preprocessing functions</li> <li>Dataset utilities</li> </ul>"},{"location":"api-reference/utils/#training-utilities","title":"Training Utilities","text":"<ul> <li>Checkpoint management</li> <li>Logging and monitoring</li> <li>Performance profiling</li> </ul>"},{"location":"api-reference/utils/#system-utilities","title":"System Utilities","text":"<ul> <li>CUDA utilities</li> <li>Memory management</li> <li>Device management</li> </ul> <p>Detailed documentation is available in the main utils documentation.</p>"},{"location":"architecture/","title":"\u67b6\u6784\u6982\u89c8","text":"<p>Genesis\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u91c7\u7528\u4e86\u5206\u5c42\u6a21\u5757\u5316\u67b6\u6784\u8bbe\u8ba1\uff0c\u5728\u4fdd\u6301\u4ee3\u7801\u6e05\u6670\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6027\u80fd\u8ba1\u7b97\u80fd\u529b\u3002</p>"},{"location":"architecture/#_2","title":"\ud83c\udfaf \u8bbe\u8ba1\u539f\u5219","text":"<ol> <li>\u6e05\u6670\u7684\u5c42\u6b21\u5206\u79bb: \u6bcf\u4e00\u5c42\u90fd\u6709\u5355\u4e00\u3001\u660e\u786e\u7684\u804c\u8d23</li> <li>\u65e0\u6cc4\u6f0f\u7684\u62bd\u8c61: \u4e0a\u5c42\u4e0d\u4e86\u89e3\u4e0b\u5c42\u5b9e\u73b0\u7ec6\u8282</li> <li>\u8bbe\u5907\u65e0\u5173: \u8ba1\u7b97\u903b\u8f91\u4e0e\u8bbe\u5907\u7279\u5b9a\u5b9e\u73b0\u5206\u79bb</li> <li>\u53ef\u6269\u5c55\u6027: \u6613\u4e8e\u6dfb\u52a0\u65b0\u64cd\u4f5c\u6216\u540e\u7aef\u5b9e\u73b0</li> </ol>"},{"location":"architecture/#_3","title":"\ud83c\udfd7\ufe0f \u5206\u5c42\u67b6\u6784","text":""},{"location":"architecture/#_4","title":"\u56db\u5c42\u8bbe\u8ba1","text":"<ol> <li>\u5f20\u91cf\u5c42 (\u7528\u6237\u63a5\u53e3 + \u81ea\u52a8\u5fae\u5206)</li> <li>\u9762\u5411\u7528\u6237\u7684API</li> <li>\u81ea\u52a8\u5fae\u5206</li> <li> <p>\u8ba1\u7b97\u56fe\u7ba1\u7406</p> </li> <li> <p>\u51fd\u6570\u5c42 (\u68af\u5ea6\u5b9a\u4e49)</p> </li> <li>\u524d\u5411\u8ba1\u7b97\u903b\u8f91</li> <li>\u53cd\u5411\u68af\u5ea6\u89c4\u5219</li> <li> <p>\u8fde\u63a5\u5f20\u91cf\u5c42\u548cNDArray\u5c42</p> </li> <li> <p>NDArray\u5c42 (\u8bbe\u5907\u62bd\u8c61)</p> </li> <li>\u8bbe\u5907\u65e0\u5173\u7684\u8ba1\u7b97\u63a5\u53e3</li> <li>CPU/GPU\u7edf\u4e00\u64cd\u4f5c</li> <li> <p>\u8bbe\u5907\u7ba1\u7406\u548c\u5207\u6362</p> </li> <li> <p>\u540e\u7aef\u5c42 (\u5b9e\u9645\u8ba1\u7b97)</p> </li> <li>CPU: PyTorch\u5f20\u91cf</li> <li>GPU: CUDAStorage\u4e0eTriton\u5185\u6838</li> </ol>"},{"location":"architecture/#_5","title":"\ud83d\udd04 \u8ba1\u7b97\u6d41\u7a0b","text":"<pre><code>graph TB\n    subgraph \"\u7b2c1\u5c42: \u7528\u6237\u63a5\u53e3\"\n        User[\"\u7528\u6237\u4ee3\u7801&lt;br/&gt;c = a + b\"]\n    end\n\n    subgraph \"\u7b2c2\u5c42: \u5f20\u91cf (\u81ea\u52a8\u5fae\u5206)\"\n        Tensor[\"Tensor.__add__()&lt;br/&gt;\u2022 \u7ba1\u7406\u68af\u5ea6&lt;br/&gt;\u2022 \u6784\u5efa\u8ba1\u7b97\u56fe\"]\n    end\n\n    subgraph \"\u7b2c3\u5c42: \u51fd\u6570\u5c42\"\n        Func[\"nn.functional.Add&lt;br/&gt;\u2022 forward(): \u5b9a\u4e49\u8ba1\u7b97&lt;br/&gt;\u2022 backward(): \u5b9a\u4e49\u68af\u5ea6\"]\n    end\n\n    subgraph \"\u7b2c4\u5c42: NDArray\"\n        NDArray[\"NDArray.__add__()&lt;br/&gt;\u2022 \u8bbe\u5907\u65e0\u5173\u63a5\u53e3&lt;br/&gt;\u2022 \u5206\u53d1\u5230\u540e\u7aef\"]\n    end\n\n    subgraph \"\u7b2c5\u5c42: \u540e\u7aef\"\n        CPU[\"CPU\u540e\u7aef&lt;br/&gt;PyTorch\u5f20\u91cf\"]\n        GPU[\"GPU\u540e\u7aef&lt;br/&gt;CUDAStorage + Triton\"]\n    end\n\n    User --&gt; Tensor\n    Tensor --&gt;|\"\u8c03\u7528\"| Func\n    Func --&gt;|\"a.data + b.data\"| NDArray\n    NDArray --&gt;|\"device.add()\"| CPU\n    NDArray --&gt;|\"device.add()\"| GPU\n\n    style User fill:#e1f5fe\n    style Tensor fill:#f3e5f5\n    style Func fill:#fff3e0\n    style NDArray fill:#e8f5e8\n    style CPU fill:#fce4ec\n    style GPU fill:#e3f2fd</code></pre>"},{"location":"architecture/#_6","title":"\u793a\u4f8b: \u52a0\u6cd5\u64cd\u4f5c","text":"Python<pre><code># \u7528\u6237\u4ee3\u7801\nc = a + b  # a, b \u662f\u5f20\u91cf\n\n# \u7b2c1\u5c42: \u5f20\u91cf\ndef __add__(self, other):\n    return genesis.nn.functional.add(self, other)\n\n# \u7b2c2\u5c42: \u51fd\u6570\u5c42\nclass Add(Function):\n    @staticmethod\n    def forward(ctx, a, b):\n        ctx.save_for_backward(a, b)\n        # \u53ea\u4f7f\u7528NDArray\u63a5\u53e3\uff0c\u4e0d\u6d89\u53ca\u540e\u7aef\u7ec6\u8282\n        return Tensor(a.data + b.data)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        # \u68af\u5ea6\u89c4\u5219\n        return grad_output, grad_output\n\n# \u7b2c3\u5c42: NDArray\ndef __add__(self, other):\n    # \u5206\u53d1\u5230\u8bbe\u5907\u7279\u5b9a\u5b9e\u73b0\n    return self.device.add(self, other)\n\n# \u7b2c4\u5c42: \u540e\u7aef (GPU\u793a\u4f8b)\ndef add(x, y):\n    # \u5b9e\u9645\u7684Triton\u5185\u6838\u6267\u884c\n    output = empty(x.shape)\n    add_kernel[grid](x.ptr, y.ptr, output.ptr, n_elements)\n    return output\n</code></pre>"},{"location":"architecture/#_7","title":"\ud83d\udd11 \u5173\u952e\u8bbe\u8ba1\u539f\u5219","text":""},{"location":"architecture/#1","title":"1. \u6e05\u6670\u7684\u62bd\u8c61\u5c42\u6b21","text":"<p>\u539f\u5219: \u6bcf\u4e00\u5c42\u53ea\u4e86\u89e3\u76f4\u63a5\u4e0b\u5c42\u7684\u4fe1\u606f\u3002</p> <ul> <li>\u5f20\u91cf \u2192 \u4e86\u89e3 nn.functional (\u7528\u4e8e\u64cd\u4f5c)</li> <li>nn.functional \u2192 \u4e86\u89e3 NDArray (\u7528\u4e8e\u8ba1\u7b97)</li> <li>NDArray \u2192 \u4e86\u89e3 \u540e\u7aef (\u7528\u4e8e\u8bbe\u5907\u7279\u5b9a\u64cd\u4f5c)</li> <li>\u540e\u7aef \u2192 \u5b9e\u73b0\u5b9e\u9645\u8ba1\u7b97</li> </ul> <p>\u53cd\u6a21\u5f0f (\u6211\u4eec\u6b63\u5728\u4fee\u590d\u7684): Python<pre><code># \u9519\u8bef: nn.functional\u4e0d\u5e94\u8be5\u4e86\u89e3CUDAStorage\nif hasattr(tensor.data.data, 'to_numpy'):  # \u89e6\u53ca\u8fc7\u6df1\u5c42\u6b21!\n    # CUDAStorage\u7279\u5b9a\u4ee3\u7801\n</code></pre></p> <p>\u6b63\u786e\u6a21\u5f0f: Python<pre><code># \u6b63\u786e: nn.functional\u53ea\u4f7f\u7528NDArray\u63a5\u53e3\nresult = a.data + b.data  # \u6e05\u6670\u7684\u62bd\u8c61\n</code></pre></p>"},{"location":"architecture/#2","title":"2. \u5355\u4e00\u804c\u8d23","text":"<ul> <li>\u5f20\u91cf: \u81ea\u52a8\u5fae\u5206\u548c\u68af\u5ea6\u7ba1\u7406</li> <li>nn.functional: \u5b9a\u4e49\u524d\u5411/\u540e\u5411\u8ba1\u7b97\u89c4\u5219</li> <li>NDArray: \u8bbe\u5907\u62bd\u8c61\u548c\u7edf\u4e00\u64cd\u4f5c</li> <li>\u540e\u7aef: \u5b9e\u9645\u8ba1\u7b97\u5b9e\u73b0</li> </ul>"},{"location":"architecture/#3","title":"3. \u53cc\u540e\u7aef\u67b6\u6784","text":"<ul> <li>CPU\u540e\u7aef: \u5229\u7528PyTorch\u6210\u719f\u7684CPU\u5f20\u91cf\u5b9e\u73b0</li> <li>GPU\u540e\u7aef: \u5b8c\u5168\u72ec\u7acb\u7684CUDA\u5b9e\u73b0\uff0c\u4f7f\u7528CUDAStorage</li> </ul>"},{"location":"architecture/#_8","title":"\ud83d\udcca \u7ec4\u4ef6\u804c\u8d23","text":""},{"location":"architecture/#1-autogradpy","title":"\u7b2c1\u5c42: \u5f20\u91cf (<code>autograd.py</code>)","text":"Python<pre><code>class Tensor:\n    data: NDArray          # \u5e95\u5c42\u6570\u636e (\u59d4\u6258\u8ba1\u7b97)\n    requires_grad: bool    # \u662f\u5426\u9700\u8981\u68af\u5ea6\n    grad: Tensor          # \u7d2f\u79ef\u68af\u5ea6\n    creator: Function     # \u521b\u5efa\u6b64\u5f20\u91cf\u7684\u64cd\u4f5c\n\n    # \u9762\u5411\u7528\u6237\u7684\u64cd\u4f5c\n    def __add__(self, other):\n        return nn.functional.add(self, other)  # \u59d4\u6258\u7ed9\u51fd\u6570\u5c42\n</code></pre> <p>\u804c\u8d23: - \u7ba1\u7406\u8ba1\u7b97\u56fe - \u5b58\u50a8\u548c\u7d2f\u79ef\u68af\u5ea6 - \u63d0\u4f9b\u7528\u6237\u53cb\u597d\u7684API - \u59d4\u6258\u5b9e\u9645\u8ba1\u7b97\u7ed9nn.functional</p>"},{"location":"architecture/#2-nnfunctional-nnfunctionalpy","title":"\u7b2c2\u5c42: nn.functional (<code>nn/functional.py</code>)","text":"Python<pre><code>class Add(Function):\n    @staticmethod\n    def forward(ctx, a, b):\n        ctx.save_for_backward(a, b)\n        # \u53ea\u4f7f\u7528NDArray\u63a5\u53e3\n        return Tensor(a.data + b.data)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        # \u5b9a\u4e49\u68af\u5ea6\u89c4\u5219\n        return grad_output, grad_output\n</code></pre> <p>\u804c\u8d23: - \u5b9a\u4e49\u524d\u5411\u8ba1\u7b97\u903b\u8f91 - \u5b9a\u4e49\u540e\u5411\u68af\u5ea6\u89c4\u5219 - \u4fdd\u5b58\u540e\u5411\u4f20\u64ad\u6240\u9700\u4fe1\u606f - **\u4e0d**\u8d1f\u8d23\u5b9e\u9645\u8ba1\u7b97\u5b9e\u73b0</p>"},{"location":"architecture/#3-ndarray-ndarrayndarraypy","title":"\u7b2c3\u5c42: NDArray (<code>ndarray/ndarray.py</code>)","text":"Python<pre><code>class NDArray:\n    device: Device        # CPU\u6216CUDA\n    data: Union[torch.Tensor, CUDAStorage]  # \u5b9e\u9645\u6570\u636e\n\n    def __add__(self, other):\n        # \u5206\u53d1\u5230\u8bbe\u5907\u7279\u5b9a\u5b9e\u73b0\n        return self.device.add(self, other)\n</code></pre> <p>\u804c\u8d23: - \u63d0\u4f9b\u8bbe\u5907\u65e0\u5173\u7684\u8ba1\u7b97\u63a5\u53e3 - \u5904\u7406\u8bbe\u5907\u5207\u6362 (CPU \u2194 GPU) - \u5206\u53d1\u64cd\u4f5c\u5230\u6b63\u786e\u7684\u540e\u7aef - \u6570\u636e\u683c\u5f0f\u8f6c\u6362 (numpy\u7b49)</p>"},{"location":"architecture/#4-ndarray_ops_cpupy-ndarray_ops_gpupy","title":"\u7b2c4\u5c42: \u540e\u7aef (<code>ndarray_ops_cpu.py</code>, <code>ndarray_ops_gpu.py</code>)","text":"Python<pre><code># GPU\u540e\u7aef\u793a\u4f8b\ndef add(x, y):\n    output = empty(x.shape)\n    add_kernel[grid](x.ptr, y.ptr, output.ptr, n_elements)\n    return output\n</code></pre> <p>\u804c\u8d23: - \u5b9e\u9645\u8ba1\u7b97\u5b9e\u73b0 - \u5185\u5b58\u7ba1\u7406 - \u8bbe\u5907\u7279\u5b9a\u4f18\u5316 - \u5185\u6838\u6267\u884c</p>"},{"location":"architecture/#_9","title":"\ud83d\udd04 \u68af\u5ea6\u6d41\u793a\u4f8b","text":"<p>\u8ba9\u6211\u4eec\u8ffd\u8e2a\u4e00\u6b21\u5b8c\u6574\u7684\u524d\u5411\u548c\u540e\u5411\u4f20\u64ad\uff1a</p> Python<pre><code># \u7528\u6237\u4ee3\u7801\na = Tensor([1, 2, 3], requires_grad=True)\nb = Tensor([4, 5, 6], requires_grad=True)\nc = a + b\nc.backward(Tensor([1, 1, 1]))\n</code></pre>"},{"location":"architecture/#_10","title":"\u524d\u5411\u4f20\u64ad","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Tensor\n    participant Functional\n    participant NDArray\n    participant Backend\n\n    User-&gt;&gt;Tensor: c = a + b\n    Tensor-&gt;&gt;Functional: functional.add(a, b)\n    Functional-&gt;&gt;Functional: ctx.save_for_backward(a, b)\n    Functional-&gt;&gt;NDArray: a.data + b.data\n    NDArray-&gt;&gt;Backend: device.add(x, y)\n    Backend--&gt;&gt;NDArray: result_data\n    NDArray--&gt;&gt;Functional: result_ndarray\n    Functional--&gt;&gt;Tensor: Tensor(result_ndarray)\n    Tensor--&gt;&gt;User: c</code></pre>"},{"location":"architecture/#_11","title":"\u540e\u5411\u4f20\u64ad","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Tensor\n    participant Functional\n\n    User-&gt;&gt;Tensor: c.backward(grad)\n    Tensor-&gt;&gt;Functional: Add.backward(ctx, grad)\n    Functional-&gt;&gt;Functional: \u8ba1\u7b97\u68af\u5ea6\n    Functional--&gt;&gt;Tensor: grad_a, grad_b\n    Tensor-&gt;&gt;Tensor: a.grad += grad_a\n    Tensor-&gt;&gt;Tensor: b.grad += grad_b</code></pre>"},{"location":"architecture/#_12","title":"\u26a0\ufe0f \u5f53\u524d\u6b63\u5728\u4fee\u590d\u7684\u95ee\u9898","text":""},{"location":"architecture/#nnfunctional","title":"\u95ee\u9898: nn.functional\u4e2d\u7684\u62bd\u8c61\u6cc4\u6f0f","text":"<p>\u5f53\u524d\uff0c<code>nn.functional</code>\u6709\u5982\u4e0b\u4ee3\u7801: Python<pre><code># \u9519\u8bef: \u89e6\u53ca\u5b9e\u73b0\u7ec6\u8282\nif hasattr(t.data.data, 'to_numpy'):  # \u68c0\u67e5CUDAStorage\n    # \u7279\u6b8aGPU\u5904\u7406\n</code></pre></p>"},{"location":"architecture/#_13","title":"\u89e3\u51b3\u65b9\u6848: \u6e05\u6670\u62bd\u8c61","text":"<p>\u6211\u4eec\u6b63\u5728\u91cd\u6784\u4e3a: Python<pre><code># \u6b63\u786e: \u53ea\u4f7f\u7528NDArray\u63a5\u53e3\nresult = a.data + b.data  # NDArray\u5904\u7406\u8bbe\u5907\u7ec6\u8282\n</code></pre></p> <p>\u8fd9\u786e\u4fdd: 1. nn.functional\u4e0d\u4e86\u89e3CUDAStorage 2. \u6bcf\u4e00\u5c42\u53ea\u4e86\u89e3\u5176\u76f4\u63a5\u90bb\u5c45 3. \u6613\u4e8e\u6dfb\u52a0\u65b0\u540e\u7aef\u800c\u4e0d\u66f4\u6539\u4e0a\u5c42</p> <p>\u5173\u952e\u7279\u6027\uff1a - \u652f\u6301\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u7684\u81ea\u52a8\u7c7b\u578b\u8f6c\u6362 - \u7075\u6d3b\u7684\u8ba1\u7b97\u56fe\u6784\u5efa\u548c\u904d\u5386 - \u5185\u7f6e\u7684\u68af\u5ea6\u7d2f\u79ef\u548c\u6e05\u96f6\u673a\u5236</p>"},{"location":"architecture/#_14","title":"\u5f20\u91cf\u540e\u7aef\u7cfb\u7edf","text":""},{"location":"architecture/#cpu-ndarray_ops_cpupy","title":"CPU\u540e\u7aef (<code>ndarray_ops_cpu.py</code>)","text":"Python<pre><code># \u76f4\u63a5\u4f7f\u7528PyTorch\u64cd\u4f5c\ndef add(x, y):\n    return x + y\n\ndef matmul(x, y):\n    return torch.matmul(x, y)\n</code></pre>"},{"location":"architecture/#gpu-ndarray_ops_gpupy","title":"GPU\u540e\u7aef (<code>ndarray_ops_gpu.py</code>)","text":"Python<pre><code># \u4f7f\u7528Triton\u5b9e\u73b0\u7684GPU\u5185\u6838\n@triton.jit\ndef add_kernel(x_ptr, y_ptr, output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets &lt; n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    y = tl.load(y_ptr + offsets, mask=mask)\n    output = x + y\n    tl.store(output_ptr + offsets, output, mask=mask)\n</code></pre>"},{"location":"architecture/#cuda-cuda_storagepy","title":"CUDA\u5185\u5b58\u7ba1\u7406 (<code>cuda_storage.py</code>)","text":"Python<pre><code>class CUDAStorage:\n    \"\"\"\u7eafCUDA\u5b9e\u73b0\u7684\u5b58\u50a8\uff0c\u4e0d\u4f9d\u8d56PyTorch\"\"\"\n    def __init__(self, shape, dtype):\n        self._cuda_device, self._cuda_context = _ensure_cuda_initialized()\n        self._allocate_memory(shape, dtype)\n\n    def _allocate_memory(self, shape, dtype):\n        # \u4f7f\u7528CUDA Python API\u76f4\u63a5\u5206\u914dGPU\u5185\u5b58\n        size_bytes = prod(shape) * dtype.itemsize\n        result = cuda.cuMemAlloc(size_bytes)\n        self._data_ptr = check_cuda_error(result)\n</code></pre>"},{"location":"architecture/#nnmodules","title":"\u795e\u7ecf\u7f51\u7edc\u6a21\u5757 (<code>nn/modules/</code>)","text":"<p>Genesis\u91c7\u7528\u4e0ePyTorch\u7c7b\u4f3c\u7684\u6a21\u5757\u5316\u67b6\u6784\uff0c\u4fbf\u4e8e\u4ee3\u7801\u7ec4\u7ec7\uff1a</p> Text Only<pre><code>nn/modules/\n\u251c\u2500\u2500 module.py          # Module\u57fa\u7c7b\u548cParameter\u7c7b\n\u251c\u2500\u2500 linear.py          # Linear\u3001Flatten\u5c42\n\u251c\u2500\u2500 activation.py      # ReLU\u3001Softmax\u3001SiLU\u6fc0\u6d3b\u51fd\u6570\n\u251c\u2500\u2500 normalization.py   # BatchNorm\u3001LayerNorm\u3001RMSNorm\n\u251c\u2500\u2500 loss.py           # CrossEntropyLoss\u3001MSELoss\u3001BCELoss\n\u251c\u2500\u2500 container.py      # Sequential\u3001ModuleList\u5bb9\u5668\n\u251c\u2500\u2500 dropout.py        # Dropout\u6b63\u5219\u5316\n\u251c\u2500\u2500 sparse.py         # Embedding\u3001RotaryEmbedding\n\u2514\u2500\u2500 transformer.py    # MultiheadAttention\u3001FeedForwardSwiGLU\n</code></pre> <p>\u6838\u5fc3\u5b9e\u73b0\uff1a</p> Python<pre><code># modules/module.py\nclass Module:\n    \"\"\"\u795e\u7ecf\u7f51\u7edc\u6a21\u5757\u57fa\u7c7b\"\"\"\n    def parameters(self) -&gt; List[Tensor]:\n        # \u9012\u5f52\u6536\u96c6\u6240\u6709\u53c2\u6570\n        return _unpack_params(self.__dict__)\n\n    def forward(self, *args, **kwargs):\n        # \u5b50\u7c7b\u5b9e\u73b0\u5177\u4f53\u7684\u524d\u5411\u4f20\u64ad\u903b\u8f91\n        raise NotImplementedError\n\n# modules/linear.py  \nclass Linear(Module):\n    \"\"\"\u5168\u8fde\u63a5\u5c42\u5b9e\u73b0\"\"\"\n    def __init__(self, in_features, out_features):\n        self.weight = Parameter(genesis.randn(out_features, in_features))\n        self.bias = Parameter(genesis.zeros(out_features))\n\n# modules/loss.py\nclass CrossEntropyLoss(Module):\n    \"\"\"\u5206\u7c7b\u4efb\u52a1\u7684\u4ea4\u53c9\u71b5\u635f\u5931\"\"\"\n    def forward(self, input: Tensor, target: Tensor) -&gt; Tensor:\n        log_prob = F.log_softmax(input, dim=1)\n        # ... \u5b9e\u73b0\u7ec6\u8282\n</code></pre>"},{"location":"architecture/#_15","title":"\ud83d\udd27 \u5173\u952e\u6280\u672f\u5b9e\u73b0","text":""},{"location":"architecture/#1_1","title":"1. \u5185\u5b58\u7ba1\u7406\u7b56\u7565","text":"<p>CPU\u5185\u5b58\u7ba1\u7406\uff1a - \u4f9d\u8d56PyTorch\u7684\u5185\u5b58\u6c60\u548c\u5783\u573e\u56de\u6536 - \u81ea\u52a8\u5904\u7406\u5185\u5b58\u5bf9\u9f50\u548c\u7f13\u5b58\u4f18\u5316</p> <p>GPU\u5185\u5b58\u7ba1\u7406\uff1a Python<pre><code>class CUDAStorage:\n    def __init__(self, shape, dtype, base=None):\n        if base is not None:\n            # \u89c6\u56fe\u5b58\u50a8\uff1a\u5171\u4eab\u5185\u5b58\u4f46\u4fdd\u6301\u5bf9\u539f\u5b58\u50a8\u7684\u5f15\u7528\n            self.base = base\n            self._data_ptr = base._data_ptr + offset\n        else:\n            # \u65b0\u5b58\u50a8\uff1a\u5206\u914d\u72ec\u7acb\u5185\u5b58\n            self.base = None\n            self._data_ptr = cuda.cuMemAlloc(size_bytes)\n\n    def __del__(self):\n        # \u53ea\u6709\u57fa\u7840\u5b58\u50a8\u624d\u91ca\u653e\u5185\u5b58\n        if self.base is None and self._data_ptr:\n            cuda.cuMemFree(self._data_ptr)\n</code></pre></p>"},{"location":"architecture/#2_1","title":"2. \u8bbe\u5907\u62bd\u8c61","text":"Python<pre><code>class Device:\n    def __init__(self, name: str, mod: Any, device_id: Optional[int] = None):\n        self.name = name        # \"cpu\" \u6216 \"cuda\"\n        self.mod = mod          # \u5bf9\u5e94\u7684\u64cd\u4f5c\u6a21\u5757\n        self.device_id = device_id  # GPU\u8bbe\u5907ID\n\n    def randn(self, *shape, dtype=genesis.float32):\n        if self.name == \"cuda\":\n            return NDArray(CUDAStorage(shape, dtype), device=self)\n        else:\n            return NDArray(torch.randn(*shape), device=self)\n</code></pre>"},{"location":"architecture/#3_1","title":"3. \u7c7b\u578b\u7cfb\u7edf","text":"Python<pre><code># dtypes.py - \u7edf\u4e00\u7684\u6570\u636e\u7c7b\u578b\u7cfb\u7edf\nclass DType:\n    def __init__(self, name: str, torch_dtype, numpy_dtype, itemsize: int):\n        self.name = name\n        self.torch_dtype = torch_dtype\n        self.numpy_dtype = numpy_dtype  \n        self.itemsize = itemsize\n\n# \u652f\u6301\u7684\u6570\u636e\u7c7b\u578b\nfloat32 = DType(\"float32\", torch.float32, np.float32, 4)\nfloat16 = DType(\"float16\", torch.float16, np.float16, 2)\nbfloat16 = DType(\"bfloat16\", torch.bfloat16, np.dtype('uint16'), 2)\n</code></pre>"},{"location":"architecture/#_16","title":"\ud83d\ude80 \u6027\u80fd\u4f18\u5316\u7b56\u7565","text":""},{"location":"architecture/#1-triton","title":"1. Triton\u5185\u6838\u4f18\u5316","text":"<p>Softmax\u5b9e\u73b0\uff1a Python<pre><code>@triton.jit\ndef softmax_kernel(input_ptr, output_ptr, input_row_stride, output_row_stride, \n                  n_cols, BLOCK_SIZE: tl.constexpr):\n    # \u9ad8\u6548\u7684\u5e76\u884csoftmax\u5b9e\u73b0\n    row_idx = tl.program_id(0)\n    row_start_ptr = input_ptr + row_idx * input_row_stride\n    col_offsets = tl.arange(0, BLOCK_SIZE)\n    input_ptrs = row_start_ptr + col_offsets\n    row = tl.load(input_ptrs, mask=col_offsets &lt; n_cols, other=-float('inf'))\n\n    # \u6570\u503c\u7a33\u5b9a\u7684softmax\n    row_minus_max = row - tl.max(row, axis=0)\n    numerator = tl.exp(row_minus_max)\n    denominator = tl.sum(numerator, axis=0)\n    softmax_output = numerator / denominator\n\n    output_row_start_ptr = output_ptr + row_idx * output_row_stride\n    output_ptrs = output_row_start_ptr + col_offsets\n    tl.store(output_ptrs, softmax_output, mask=col_offsets &lt; n_cols)\n</code></pre></p>"},{"location":"architecture/#2_2","title":"2. \u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3","text":"Python<pre><code># amp.py - \u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6\nenable_autocast = False\n\ndef _cast(value, dtype):\n    \"\"\"\u81ea\u52a8\u7c7b\u578b\u8f6c\u6362\"\"\"\n    if isinstance(value, Tensor) and value.is_floating_point():\n        if dtype == genesis.float16:\n            return value.half()\n        else:\n            return value.float()\n    return value\n</code></pre>"},{"location":"architecture/#_17","title":"\ud83d\udd0d \u67b6\u6784\u4f18\u52bf","text":""},{"location":"architecture/#_18","title":"\u6559\u80b2\u4ef7\u503c","text":"<ol> <li>\u6e10\u8fdb\u5f0f\u590d\u6742\u5ea6\uff1a\u4ece\u7b80\u5355\u7684CPU\u5b9e\u73b0\u5230\u590d\u6742\u7684GPU\u4f18\u5316</li> <li>\u5b8c\u6574\u5b9e\u73b0\u5c55\u793a\uff1a\u5c55\u793a\u4e86\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7684\u5b8c\u6574\u6784\u5efa\u8fc7\u7a0b  </li> <li>\u6e05\u6670\u7684\u6a21\u5757\u8fb9\u754c\uff1a\u6bcf\u4e2a\u7ec4\u4ef6\u804c\u8d23\u660e\u786e\uff0c\u4fbf\u4e8e\u7406\u89e3</li> </ol>"},{"location":"architecture/#_19","title":"\u5de5\u7a0b\u5b9e\u8df5","text":"<ol> <li>\u53cc\u540e\u7aef\u8bbe\u8ba1\uff1aCPU\u7a33\u5b9a\u6027 + GPU\u9ad8\u6027\u80fd</li> <li>\u5185\u5b58\u5b89\u5168\uff1aRAII\u6a21\u5f0f\u7684\u5185\u5b58\u7ba1\u7406\uff0c\u9632\u6b62\u5185\u5b58\u6cc4\u6f0f</li> <li>\u7c7b\u578b\u5b89\u5168\uff1a\u7edf\u4e00\u7684\u7c7b\u578b\u7cfb\u7edf\uff0c\u907f\u514d\u7c7b\u578b\u9519\u8bef</li> </ol>"},{"location":"architecture/#_20","title":"\u6027\u80fd\u7279\u6027","text":"<ol> <li>Triton\u4f18\u5316\uff1a\u73b0\u4ee3GPU\u5185\u6838\u7f16\u5199\u65b9\u5f0f</li> <li>\u96f6\u62f7\u8d1d\u89c6\u56fe\uff1a\u9ad8\u6548\u7684\u5f20\u91cf\u89c6\u56fe\u64cd\u4f5c</li> <li>\u5e76\u884c\u8ba1\u7b97\uff1a\u5145\u5206\u5229\u7528GPU\u5e76\u884c\u80fd\u529b</li> </ol>"},{"location":"architecture/#_21","title":"\ud83c\udfaf \u8bbe\u8ba1\u6743\u8861","text":""},{"location":"architecture/#cpu-vs-gpu","title":"CPU vs GPU \u5b9e\u73b0\u9009\u62e9","text":"<ul> <li>CPU\uff1a\u4f7f\u7528PyTorch\u786e\u4fdd\u7a33\u5b9a\u6027\u548c\u517c\u5bb9\u6027</li> <li>GPU\uff1a\u72ec\u7acb\u5b9e\u73b0\u5c55\u793a\u5b8c\u6574\u7684GPU\u7f16\u7a0b\u6808</li> </ul>"},{"location":"architecture/#vs","title":"\u7b80\u6d01\u6027 vs \u6027\u80fd","text":"<ul> <li>\u4fdd\u6301API\u7b80\u6d01\u7684\u540c\u65f6\uff0c\u5e95\u5c42\u5b9e\u73b0\u9ad8\u5ea6\u4f18\u5316</li> <li>\u901a\u8fc7\u5206\u5c42\u67b6\u6784\u5c06\u590d\u6742\u6027\u9694\u79bb\u5728\u5e95\u5c42</li> </ul>"},{"location":"architecture/#vs_1","title":"\u6559\u80b2 vs \u751f\u4ea7","text":"<ul> <li>\u4ee3\u7801\u6ce8\u91cd\u53ef\u8bfb\u6027\u548c\u6559\u80b2\u4ef7\u503c</li> <li>\u6027\u80fd\u4ecd\u7136\u8fbe\u5230\u5b9e\u7528\u7ea7\u522b</li> </ul> <p>\u8fd9\u79cd\u67b6\u6784\u8bbe\u8ba1\u4f7f\u5f97Genesis\u65e2\u662f\u4e00\u4e2a\u4f18\u79c0\u7684\u5b66\u4e60\u8d44\u6e90\uff0c\u4e5f\u662f\u4e00\u4e2a\u529f\u80fd\u5b8c\u6574\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u3002</p>"},{"location":"benchmark/","title":"Genesis \u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\u62a5\u544a","text":"<p>\u6b22\u8fce\u8bbf\u95ee Genesis \u6846\u67b6\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\u62a5\u544a\u3002\u6b64\u76ee\u5f55\u5305\u542b Genesis \u4e0e PyTorch \u7684\u5168\u9762\u6027\u80fd\u5bf9\u6bd4\u5206\u6790\u3002</p>"},{"location":"benchmark/#genesis_1","title":"\u5173\u4e8e Genesis \u57fa\u51c6\u6d4b\u8bd5","text":"<p>Genesis \u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u8be6\u7ec6\u7684\u6027\u80fd\u5206\u6790\uff0c\u5e2e\u52a9\u7528\u6237\u4e86\u89e3\uff1a - \u64cd\u4f5c\u7ea7\u6027\u80fd\uff1a\u5355\u4e2a\u64cd\u4f5c\u4e0e PyTorch \u7684\u6bd4\u8f83 - \u7aef\u5230\u7aef\u6a21\u578b\u6027\u80fd\uff1a\u5305\u542b\u5185\u5b58\u4f7f\u7528\u7684\u5b8c\u6574\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5 - \u4f18\u5316\u673a\u4f1a\uff1a\u8be6\u7ec6\u7684\u6027\u80fd\u6539\u8fdb\u5efa\u8bae</p>"},{"location":"benchmark/#_1","title":"\u57fa\u51c6\u6d4b\u8bd5\u7c7b\u522b","text":""},{"location":"benchmark/#_2","title":"\ud83d\udcca \u64cd\u4f5c\u57fa\u51c6\u6d4b\u8bd5","text":"<p>\u5355\u4e2a\u64cd\u4f5c\u548c\u64cd\u4f5c\u7c7b\u522b\u7684\u8be6\u7ec6\u6027\u80fd\u5206\u6790\uff1a - \u9010\u5143\u7d20\u64cd\u4f5c\uff1a\u52a0\u6cd5\u3001\u51cf\u6cd5\u3001\u4e58\u6cd5\u3001\u9664\u6cd5\u7b49 - \u6fc0\u6d3b\u51fd\u6570\uff1aReLU\u3001sigmoid\u3001tanh \u7b49 - \u5f52\u7ea6\u64cd\u4f5c\uff1a\u6c42\u548c\u3001\u5e73\u5747\u3001\u6700\u5927\u503c\u7b49 - \u77e9\u9635\u64cd\u4f5c\uff1a\u77e9\u9635\u4e58\u6cd5 - \u5185\u5b58\u64cd\u4f5c\uff1a\u8f6c\u7f6e\u3001\u91cd\u5851\u7b49</p>"},{"location":"benchmark/#_3","title":"\ud83e\udd16 \u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5","text":"<p>\u5b8c\u6574\u6a21\u578b\u7684\u7aef\u5230\u7aef\u6027\u80fd\u5206\u6790\uff1a - Qwen \u8bed\u8a00\u6a21\u578b\uff1a\u524d\u5411/\u53cd\u5411\u4f20\u64ad\u65f6\u95f4\u548c\u5185\u5b58\u5206\u6790 - \u53ef\u6269\u5c55\u6027\u6d4b\u8bd5\uff1a\u4e0d\u540c\u6279\u91cf\u5927\u5c0f\u548c\u5e8f\u5217\u957f\u5ea6\u7684\u6027\u80fd\u8868\u73b0</p>"},{"location":"benchmark/#_4","title":"\u6027\u80fd\u6307\u6807","text":"<p>\u6211\u4eec\u4f7f\u7528\u6807\u51c6\u5316\u7684\u6027\u80fd\u8bc4\u5206\u7cfb\u7edf\uff1a</p> <ul> <li>\ud83d\udfe2 \u4f18\u79c0 (\u226590%)\uff1aGenesis \u6027\u80fd\u8fbe\u5230 PyTorch \u7684 90% \u6216\u66f4\u9ad8</li> <li>\ud83d\udfe1 \u826f\u597d (70-90%)\uff1a\u53ef\u63a5\u53d7\u7684\u6027\u80fd\u5dee\u8ddd</li> <li>\ud83d\udfe0 \u4e00\u822c (50-70%)\uff1a\u660e\u663e\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5efa\u8bae\u4f18\u5316</li> <li>\ud83d\udd34 \u8f83\u5dee (20-50%)\uff1a\u9700\u8981\u91cd\u5927\u4f18\u5316</li> <li>\u274c \u4e25\u91cd (&lt;20%)\uff1a\u5b58\u5728\u9700\u8981\u5173\u6ce8\u7684\u91cd\u5927\u6027\u80fd\u95ee\u9898</li> </ul>"},{"location":"benchmark/#_5","title":"\u5982\u4f55\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5","text":""},{"location":"benchmark/#_6","title":"\u5feb\u901f\u5f00\u59cb","text":"Bash<pre><code># \u5bfc\u822a\u5230\u57fa\u51c6\u6d4b\u8bd5\u76ee\u5f55\ncd benchmark\n\n# \u8fd0\u884c\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\uff08\u5728 docs/benchmark/ \u751f\u6210\u62a5\u544a\uff09\n./run.sh\n</code></pre>"},{"location":"benchmark/#_7","title":"\u7279\u5b9a\u57fa\u51c6\u6d4b\u8bd5","text":""},{"location":"benchmark/#_8","title":"\u64cd\u4f5c\u57fa\u51c6\u6d4b\u8bd5","text":"Bash<pre><code># \u6d4b\u8bd5\u6240\u6709\u64cd\u4f5c\uff08\u5168\u9762\uff09\npython bench_ops.py\n\n# \u6d4b\u8bd5\u7279\u5b9a\u64cd\u4f5c\u7c7b\u522b\npython bench_ops.py --category element\n\n# \u6d4b\u8bd5\u7279\u5b9a\u64cd\u4f5c\npython bench_ops.py --op add\n\n# \u5feb\u901f\u6a21\u5f0f\uff08\u51cf\u5c11\u8fed\u4ee3\u6b21\u6570\uff09\npython bench_ops.py --fast\n</code></pre>"},{"location":"benchmark/#_9","title":"\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5","text":"Bash<pre><code># \u6d4b\u8bd5 Qwen \u6a21\u578b\uff08\u5982\u679c\u53ef\u7528\uff09\npython bench_qwen.py --size 0.5B --batch-size 1,2,4 --seq-len 128,256,512\n\n# \u5feb\u901f\u6d4b\u8bd5\npython bench_qwen.py --size 0.5B --batch-size 1,2 --seq-len 128,256 --fast\n</code></pre>"},{"location":"benchmark/#_10","title":"\u7406\u89e3\u62a5\u544a","text":""},{"location":"benchmark/#_11","title":"\u64cd\u4f5c\u62a5\u544a","text":"<p>\u6bcf\u4e2a\u64cd\u4f5c\u57fa\u51c6\u6d4b\u8bd5\u62a5\u544a\u5305\u62ec\uff1a - \u7cfb\u7edf\u4fe1\u606f\uff1aGPU \u8be6\u60c5\u548c\u7406\u8bba\u6027\u80fd\u9650\u5236 - \u6027\u80fd\u6458\u8981\uff1a\u603b\u4f53\u7edf\u8ba1\u548c\u6210\u529f\u7387 - \u7c7b\u522b\u7ec6\u5206\uff1a\u6309\u64cd\u4f5c\u7c7b\u578b\u7684\u6027\u80fd\u8868\u73b0 - \u8be6\u7ec6\u7ed3\u679c\uff1a\u5305\u542b\u52a0\u901f\u6bd4\u548c\u5e26\u5bbd\u7684\u5355\u4e2a\u64cd\u4f5c\u7ed3\u679c - \u6700\u4f73\u8868\u73b0\uff1a\u6027\u80fd\u6700\u597d\u548c\u6700\u5dee\u7684\u64cd\u4f5c - \u4f18\u5316\u5efa\u8bae\uff1a\u5177\u4f53\u7684\u6539\u8fdb\u5efa\u8bae</p>"},{"location":"benchmark/#_12","title":"\u6a21\u578b\u62a5\u544a","text":"<p>\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u62a5\u544a\u63d0\u4f9b\uff1a - \u6a21\u578b\u914d\u7f6e\uff1a\u6a21\u578b\u5927\u5c0f\u3001\u6d4b\u8bd5\u7684\u6279\u91cf\u5927\u5c0f\u3001\u5e8f\u5217\u957f\u5ea6 - \u6027\u80fd\u6458\u8981\uff1a\u603b\u4f53\u52a0\u901f\u6bd4\u548c\u5185\u5b58\u6548\u7387 - \u64cd\u4f5c\u5206\u6790\uff1a\u6309\u6a21\u578b\u64cd\u4f5c\u7684\u6027\u80fd\u7ec6\u5206 - \u53ef\u6269\u5c55\u6027\u5206\u6790\uff1a\u4e0d\u540c\u8f93\u5165\u5927\u5c0f\u7684\u6027\u80fd\u8868\u73b0 - \u5185\u5b58\u5206\u6790\uff1a\u5185\u5b58\u4f7f\u7528\u6a21\u5f0f\u548c\u6548\u7387 - \u4f18\u5316\u4f18\u5148\u7ea7\uff1a\u96c6\u4e2d\u7684\u6539\u8fdb\u5efa\u8bae</p>"},{"location":"benchmark/#_13","title":"\u57fa\u51c6\u6d4b\u8bd5\u57fa\u7840\u8bbe\u65bd","text":""},{"location":"benchmark/#_14","title":"\u53ef\u9760\u6027\u529f\u80fd","text":"<ul> <li>\u7edf\u8ba1\u5f02\u5e38\u503c\u68c0\u6d4b\uff1a\u7a33\u5065\u7684\u65f6\u95f4\u6d4b\u91cf</li> <li>\u81ea\u9002\u5e94\u8fed\u4ee3\uff1a\u81ea\u52a8\u8c03\u6574\u8fed\u4ee3\u6b21\u6570</li> <li>\u5185\u5b58\u5e26\u5bbd\u5206\u6790\uff1a\u7406\u8bba\u6027\u80fd\u6bd4\u8f83</li> <li>\u9519\u8bef\u5904\u7406\uff1a\u4f18\u96c5\u5904\u7406\u5931\u8d25\u7684\u64cd\u4f5c</li> </ul>"},{"location":"benchmark/#_15","title":"\u8ba1\u65f6\u6a21\u5f0f","text":"<ul> <li>\u5b9e\u9645\u8ba1\u65f6\uff1a\u5305\u542b\u6240\u6709\u5f00\u9500\uff08\u771f\u5b9e\u7528\u6237\u4f53\u9a8c\uff09</li> <li>\u7eaf\u8ba1\u65f6\uff1a\u6700\u5c0f\u5316\u5f00\u9500\uff08\u5cf0\u503c\u8ba1\u7b97\u6027\u80fd\uff09</li> </ul>"},{"location":"benchmark/#_16","title":"\u5f00\u59cb\u4f7f\u7528","text":"<ol> <li>\u5b89\u88c5\u4f9d\u8d56\uff1a\u786e\u4fdd\u6b63\u786e\u5b89\u88c5 Genesis\u3001PyTorch \u548c CUDA</li> <li>\u8fd0\u884c\u5feb\u901f\u6d4b\u8bd5\uff1a<code>cd benchmark &amp;&amp; python bench_ops.py --fast</code></li> <li>\u751f\u6210\u62a5\u544a\uff1a<code>./run.sh</code> \u8fd0\u884c\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u5e76\u751f\u6210\u6587\u6863</li> <li>\u67e5\u770b\u7ed3\u679c\uff1a\u68c0\u67e5\u6b64\u76ee\u5f55\u4e2d\u751f\u6210\u7684\u62a5\u544a</li> </ol>"},{"location":"benchmark/#_17","title":"\u6301\u7eed\u6539\u8fdb","text":"<p>\u8fd9\u4e9b\u57fa\u51c6\u6d4b\u8bd5\u65e8\u5728\uff1a - \u8ddf\u8e2a Genesis \u6027\u80fd\u6539\u8fdb\u7684\u8fdb\u5c55 - \u8bc6\u522b\u4f18\u5316\u673a\u4f1a - \u9a8c\u8bc1\u65b0\u529f\u80fd\u548c\u4f18\u5316 - \u63d0\u4f9b\u6027\u80fd\u7279\u5f81\u7684\u900f\u660e\u5ea6</p> <p>\u6ce8\u610f\uff1a\u8981\u751f\u6210\u6700\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u62a5\u544a\uff0c\u8bf7\u4ece benchmark \u76ee\u5f55\u8fd0\u884c <code>./run.sh</code>\u3002\u8fd9\u5c06\u521b\u5efa\u5e26\u6709\u6700\u65b0\u6027\u80fd\u6570\u636e\u7684\u65f6\u95f4\u6233\u62a5\u544a\u3002</p> <p>\u6709\u5173\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u73b0\u7684\u6280\u672f\u7ec6\u8282\uff0c\u8bf7\u53c2\u89c1 <code>benchmark/</code> \u76ee\u5f55\u4e2d\u7684\u6e90\u4ee3\u7801\u3002</p>"},{"location":"benchmark/operations_element/","title":"Genesis \u64cd\u4f5c\u57fa\u51c6\u6d4b\u8bd5\u62a5\u544a","text":"<p>\u751f\u6210\u65f6\u95f4\uff1a2025-08-15 16:07:03</p>"},{"location":"benchmark/operations_element/#_1","title":"\u7cfb\u7edf\u4fe1\u606f","text":"<ul> <li>GPU\uff1aNVIDIA A100-SXM4-40GB</li> <li>\u5185\u5b58\uff1a39.4 GB</li> <li>\u7406\u8bba\u5e26\u5bbd\uff1a1555 GB/s</li> <li>\u591a\u5904\u7406\u5668\uff1a108</li> </ul>"},{"location":"benchmark/operations_element/#_2","title":"\u6d4b\u8bd5\u914d\u7f6e","text":"<ul> <li>\u6a21\u5f0f\uff1a\u5feb\u901f</li> <li>\u8ba1\u65f6\uff1a\u5b9e\u9645</li> <li>\u6570\u636e\u7c7b\u578b\uff1afloat32</li> <li>\u7c7b\u522b\uff1aelement</li> </ul>"},{"location":"benchmark/operations_element/#_3","title":"\u6027\u80fd\u6458\u8981","text":"\u6307\u6807 \u503c \u603b\u6d4b\u8bd5\u6570 28 \u6210\u529f\u6d4b\u8bd5 28 \u5931\u8d25\u6d4b\u8bd5 0 \u6210\u529f\u7387 100.0% \u5e73\u5747\u52a0\u901f\u6bd4 0.63x \u4e2d\u4f4d\u6570\u52a0\u901f\u6bd4 0.19x \u6700\u4f73\u52a0\u901f\u6bd4 3.62x \u6700\u5dee\u52a0\u901f\u6bd4 0.11x"},{"location":"benchmark/operations_element/#_4","title":"\u6309\u7c7b\u522b\u7684\u6027\u80fd","text":"\u7c7b\u522b \u6d4b\u8bd5\u6570 \u6210\u529f\u7387 \u5e73\u5747\u52a0\u901f\u6bd4 \u6700\u4f73\u52a0\u901f\u6bd4 \u72b6\u6001 element 28 100.0% 0.63x 3.62x \ud83d\udfe1 \u826f\u597d"},{"location":"benchmark/operations_element/#_5","title":"\u8be6\u7ec6\u7ed3\u679c","text":"\u64cd\u4f5c \u7c7b\u522b \u5f62\u72b6 PyTorch (ms) Genesis (ms) \u52a0\u901f\u6bd4 \u5e26\u5bbd (GB/s) \u72b6\u6001 cos element 256\u00d7256 0.039 0.011 3.62x 51.2 \ud83d\udfe2 \u4f18\u79c0 add_scalar element 512\u00d7512 0.024 0.011 2.20x 186.2 \ud83d\udfe2 \u4f18\u79c0 sub element 256\u00d7256 0.021 0.010 2.15x 76.8 \ud83d\udfe2 \u4f18\u79c0 negate element 256\u00d7256 0.021 0.010 2.12x 51.2 \ud83d\udfe2 \u4f18\u79c0 log element 256\u00d7256 0.014 0.010 1.43x 51.2 \ud83d\udfe2 \u4f18\u79c0 multiply element 256\u00d7256 0.012 0.010 1.22x 76.8 \ud83d\udfe2 \u4f18\u79c0 divide_scalar element 256\u00d7256 0.010 0.010 0.99x 51.2 \ud83d\udfe2 \u4f18\u79c0 sqrt element 256\u00d7256 0.020 0.041 0.49x 51.2 \ud83d\udd34 \u8f83\u5dee mul_scalar element 256\u00d7256 0.024 0.107 0.23x 4.9 \ud83d\udd34 \u8f83\u5dee add_scalar element 256\u00d7256 0.024 0.108 0.22x 4.9 \ud83d\udd34 \u8f83\u5dee mul_scalar element 512\u00d7512 0.026 0.121 0.21x 17.7 \ud83d\udd34 \u8f83\u5dee add element 256\u00d7256 0.016 0.076 0.21x 8.2 \ud83d\udd34 \u8f83\u5dee divide element 256\u00d7256 0.017 0.089 0.19x 6.9 \u274c \u4e25\u91cd sin element 256\u00d7256 0.020 0.106 0.19x 5.0 \u274c \u4e25\u91cd exp element 256\u00d7256 0.020 0.106 0.19x 5.0 \u274c \u4e25\u91cd sin element 512\u00d7512 0.013 0.069 0.19x 18.1 \u274c \u4e25\u91cd negate element 512\u00d7512 0.011 0.060 0.18x 186.2 \u274c \u4e25\u91cd sqrt element 512\u00d7512 0.021 0.117 0.18x 18.2 \u274c \u4e25\u91cd exp element 512\u00d7512 0.014 0.079 0.18x 21.2 \u274c \u4e25\u91cd multiply element 512\u00d7512 0.020 0.116 0.17x 16.4 \u274c \u4e25\u91cd log element 512\u00d7512 0.020 0.116 0.17x 18.3 \u274c \u4e25\u91cd pow_scalar element 256\u00d7256 0.023 0.139 0.16x 3.8 \u274c \u4e25\u91cd add element 512\u00d7512 0.021 0.132 0.16x 24.4 \u274c \u4e25\u91cd pow_scalar element 512\u00d7512 0.011 0.068 0.16x 186.2 \u274c \u4e25\u91cd divide element 512\u00d7512 0.017 0.130 0.13x 24.5 \u274c \u4e25\u91cd divide_scalar element 512\u00d7512 0.011 0.083 0.13x 17.1 \u274c \u4e25\u91cd sub element 512\u00d7512 0.015 0.132 0.11x 24.4 \u274c \u4e25\u91cd cos element 512\u00d7512 0.013 0.120 0.11x 17.8 \u274c \u4e25\u91cd"},{"location":"benchmark/operations_element/#_6","title":"\u6027\u80fd\u5206\u5e03","text":"<ul> <li>\ud83d\udfe2 \u4f18\u79c0 (\u226590%)\uff1a7 \u4e2a\u6d4b\u8bd5 (25.0%)</li> <li>\ud83d\udfe1 \u826f\u597d (70-90%)\uff1a0 \u4e2a\u6d4b\u8bd5 (0.0%)</li> <li>\ud83d\udfe0 \u4e00\u822c (50-70%)\uff1a0 \u4e2a\u6d4b\u8bd5 (0.0%)</li> <li>\ud83d\udd34 \u8f83\u5dee (20-50%)\uff1a5 \u4e2a\u6d4b\u8bd5 (17.9%)</li> <li>\u274c \u4e25\u91cd (&lt;20%)\uff1a16 \u4e2a\u6d4b\u8bd5 (57.1%)</li> </ul>"},{"location":"benchmark/operations_element/#10","title":"\u524d 10 \u540d\u8868\u73b0","text":"\u6392\u540d \u64cd\u4f5c \u5f62\u72b6 \u52a0\u901f\u6bd4 \u72b6\u6001 1 cos 256\u00d7256 3.62x \ud83d\udfe2 \u4f18\u79c0 2 add_scalar 512\u00d7512 2.20x \ud83d\udfe2 \u4f18\u79c0 3 sub 256\u00d7256 2.15x \ud83d\udfe2 \u4f18\u79c0 4 negate 256\u00d7256 2.12x \ud83d\udfe2 \u4f18\u79c0 5 log 256\u00d7256 1.43x \ud83d\udfe2 \u4f18\u79c0 6 multiply 256\u00d7256 1.22x \ud83d\udfe2 \u4f18\u79c0 7 divide_scalar 256\u00d7256 0.99x \ud83d\udfe2 \u4f18\u79c0 8 sqrt 256\u00d7256 0.49x \ud83d\udd34 \u8f83\u5dee 9 mul_scalar 256\u00d7256 0.23x \ud83d\udd34 \u8f83\u5dee 10 add_scalar 256\u00d7256 0.22x \ud83d\udd34 \u8f83\u5dee"},{"location":"contributing/","title":"\u8d21\u732e\u6307\u5357","text":"<p>\u6b22\u8fce\u4e3aGenesis\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u8d21\u732e\u4ee3\u7801\uff01\u672c\u6307\u5357\u5c06\u5e2e\u52a9\u4f60\u4e86\u89e3\u5982\u4f55\u53c2\u4e0e\u9879\u76ee\u5f00\u53d1\u3002</p>"},{"location":"contributing/#_2","title":"\ud83e\udd1d \u8d21\u732e\u65b9\u5f0f","text":""},{"location":"contributing/#_3","title":"\u4ee3\u7801\u8d21\u732e","text":"<ul> <li>\u4fee\u590dbug</li> <li>\u6dfb\u52a0\u65b0\u7279\u6027</li> <li>\u6027\u80fd\u4f18\u5316</li> <li>\u6d4b\u8bd5\u5b8c\u5584</li> </ul>"},{"location":"contributing/#_4","title":"\u6587\u6863\u8d21\u732e","text":"<ul> <li>\u6539\u8fdb\u73b0\u6709\u6587\u6863</li> <li>\u6dfb\u52a0\u6559\u7a0b\u548c\u793a\u4f8b</li> <li>\u7ffb\u8bd1\u6587\u6863</li> <li>API\u6587\u6863\u5b8c\u5584</li> </ul>"},{"location":"contributing/#_5","title":"\u793e\u533a\u8d21\u732e","text":"<ul> <li>\u56de\u7b54\u95ee\u9898</li> <li>\u4ee3\u7801\u5ba1\u67e5</li> <li>\u95ee\u9898\u62a5\u544a</li> <li>\u529f\u80fd\u5efa\u8bae</li> </ul>"},{"location":"contributing/#_6","title":"\ud83d\udccb \u5f00\u53d1\u6d41\u7a0b","text":""},{"location":"contributing/#1","title":"1. \u51c6\u5907\u5de5\u4f5c","text":"Bash<pre><code># Fork\u9879\u76ee\u5230\u4f60\u7684GitHub\u8d26\u6237\n# Clone\u4f60\u7684fork\ngit clone https://github.com/YOUR_USERNAME/genesis.git\ncd genesis\n\n# \u6dfb\u52a0\u4e0a\u6e38\u4ed3\u5e93\ngit remote add upstream https://github.com/phonism/genesis.git\n\n# \u521b\u5efa\u5f00\u53d1\u5206\u652f\ngit checkout -b feature/your-feature-name\n</code></pre>"},{"location":"contributing/#2","title":"2. \u5f00\u53d1\u73af\u5883\u642d\u5efa","text":"<p>\u8be6\u89c1\u5f00\u53d1\u73af\u5883\u914d\u7f6e\u6587\u6863\u3002</p>"},{"location":"contributing/#3","title":"3. \u4ee3\u7801\u5f00\u53d1","text":"<ul> <li>\u9075\u5faa\u4ee3\u7801\u89c4\u8303</li> <li>\u6dfb\u52a0\u5355\u5143\u6d4b\u8bd5</li> <li>\u66f4\u65b0\u76f8\u5173\u6587\u6863</li> <li>\u63d0\u4ea4\u6e05\u6670\u7684commit\u6d88\u606f</li> </ul>"},{"location":"contributing/#4","title":"4. \u6d4b\u8bd5\u9a8c\u8bc1","text":"Bash<pre><code># \u8fd0\u884c\u6d4b\u8bd5\u5957\u4ef6\npython -m pytest tests/ -v\n\n# \u8fd0\u884c\u4ee3\u7801\u683c\u5f0f\u68c0\u67e5\nblack genesis/ tests/\nflake8 genesis/ tests/\n\n# \u8fd0\u884c\u7c7b\u578b\u68c0\u67e5\nmypy genesis/\n</code></pre>"},{"location":"contributing/#5-pr","title":"5. \u63d0\u4ea4PR","text":"<ul> <li>\u786e\u4fdd\u6240\u6709\u6d4b\u8bd5\u901a\u8fc7</li> <li>\u586b\u5199\u8be6\u7ec6\u7684PR\u63cf\u8ff0</li> <li>\u94fe\u63a5\u76f8\u5173\u7684Issue</li> <li>\u7b49\u5f85\u4ee3\u7801\u5ba1\u67e5</li> </ul>"},{"location":"contributing/#_7","title":"\ud83d\udcdd \u4ee3\u7801\u89c4\u8303","text":""},{"location":"contributing/#python","title":"Python\u98ce\u683c\u6307\u5357","text":"<p>\u6211\u4eec\u9075\u5faaPEP 8\u89c4\u8303\uff1a</p> Python<pre><code># \u597d\u7684\u793a\u4f8b\ndef compute_attention_weights(query, key, scale_factor):\n    \"\"\"Compute scaled dot-product attention weights.\n\n    Args:\n        query: Query tensor of shape [batch, seq_len, hidden_dim]\n        key: Key tensor of shape [batch, seq_len, hidden_dim] \n        scale_factor: Scaling factor for attention scores\n\n    Returns:\n        Attention weights of shape [batch, seq_len, seq_len]\n    \"\"\"\n    scores = genesis.matmul(query, key.transpose(-2, -1))\n    scaled_scores = scores * scale_factor\n    return genesis.softmax(scaled_scores, dim=-1)\n</code></pre>"},{"location":"contributing/#_8","title":"\u6587\u6863\u5b57\u7b26\u4e32","text":"<p>\u4f7f\u7528Google\u98ce\u683c\u7684docstring\uff1a</p> Python<pre><code>def example_function(param1: int, param2: str = \"default\") -&gt; bool:\n    \"\"\"One line summary of the function.\n\n    More detailed description if needed. Can span multiple lines.\n\n    Args:\n        param1: Description of param1\n        param2: Description of param2 with default value\n\n    Returns:\n        Description of return value\n\n    Raises:\n        ValueError: When param1 is negative\n\n    Example:\n        &gt;&gt;&gt; result = example_function(42, \"test\")\n        &gt;&gt;&gt; print(result)\n        True\n    \"\"\"\n    if param1 &lt; 0:\n        raise ValueError(\"param1 must be non-negative\")\n    return param1 &gt; 0\n</code></pre>"},{"location":"contributing/#_9","title":"\u6d4b\u8bd5\u7f16\u5199","text":"Python<pre><code>import pytest\nimport genesis\n\nclass TestAttention:\n    \"\"\"Test attention mechanisms.\"\"\"\n\n    def test_basic_attention(self):\n        \"\"\"Test basic attention computation.\"\"\"\n        batch_size, seq_len, hidden_dim = 2, 4, 8\n\n        query = genesis.randn(batch_size, seq_len, hidden_dim)\n        key = genesis.randn(batch_size, seq_len, hidden_dim)\n        value = genesis.randn(batch_size, seq_len, hidden_dim)\n\n        attention = genesis.nn.MultiHeadAttention(hidden_dim, num_heads=2)\n        output = attention(query, key, value)\n\n        assert output.shape == (batch_size, seq_len, hidden_dim)\n\n    @pytest.mark.parametrize(\"num_heads\", [1, 2, 4, 8])\n    def test_different_head_counts(self, num_heads):\n        \"\"\"Test attention with different head counts.\"\"\"\n        # \u6d4b\u8bd5\u5b9e\u73b0\n        pass\n</code></pre>"},{"location":"contributing/#_10","title":"\ud83d\ude80 \u5f00\u53d1\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"contributing/#1_1","title":"1. \u5206\u652f\u7ba1\u7406","text":"Bash<pre><code># \u4e3b\u8981\u5206\u652f\nmain          # \u7a33\u5b9a\u7248\u672c\ndevelop       # \u5f00\u53d1\u7248\u672c\n\n# \u529f\u80fd\u5206\u652f\nfeature/xxx   # \u65b0\u529f\u80fd\u5f00\u53d1\nbugfix/xxx    # bug\u4fee\u590d\nhotfix/xxx    # \u7d27\u6025\u4fee\u590d\n</code></pre>"},{"location":"contributing/#2-commit","title":"2. Commit\u6d88\u606f\u683c\u5f0f","text":"Text Only<pre><code>type(scope): brief description\n\nDetailed description (optional)\n\nFixes #123\n</code></pre> <p>\u7c7b\u578b\u8bf4\u660e\uff1a - <code>feat</code>: \u65b0\u529f\u80fd - <code>fix</code>: bug\u4fee\u590d - <code>docs</code>: \u6587\u6863\u66f4\u65b0 - <code>style</code>: \u4ee3\u7801\u683c\u5f0f\u8c03\u6574 - <code>refactor</code>: \u91cd\u6784 - <code>perf</code>: \u6027\u80fd\u4f18\u5316 - <code>test</code>: \u6d4b\u8bd5\u76f8\u5173 - <code>chore</code>: \u6784\u5efa\u5de5\u5177\u7b49</p>"},{"location":"contributing/#3_1","title":"3. \u6027\u80fd\u8003\u8651","text":"<ul> <li>\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u5185\u5b58\u62f7\u8d1d</li> <li>\u4f7f\u7528in-place\u64cd\u4f5cwhen\u53ef\u80fd</li> <li>\u8003\u8651CUDA kernel\u7684\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f</li> <li>\u6dfb\u52a0\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5</li> </ul>"},{"location":"contributing/#bug","title":"\ud83d\udc1b Bug\u62a5\u544a","text":"<p>\u63d0\u4ea4bug\u65f6\u8bf7\u5305\u542b\uff1a</p> <ol> <li>\u73af\u5883\u4fe1\u606f</li> <li>Genesis\u7248\u672c</li> <li>Python\u7248\u672c</li> <li>CUDA\u7248\u672c</li> <li> <p>\u64cd\u4f5c\u7cfb\u7edf</p> </li> <li> <p>\u590d\u73b0\u6b65\u9aa4</p> </li> <li>\u6700\u5c0f\u53ef\u590d\u73b0\u4ee3\u7801</li> <li>\u9884\u671f\u884c\u4e3a</li> <li>\u5b9e\u9645\u884c\u4e3a</li> <li> <p>\u9519\u8bef\u4fe1\u606f</p> </li> <li> <p>\u76f8\u5173\u65e5\u5fd7</p> </li> <li>\u5b8c\u6574\u7684\u9519\u8bef\u5806\u6808</li> <li>\u76f8\u5173\u914d\u7f6e\u4fe1\u606f</li> </ol> <p>\u793a\u4f8b\uff1a Python<pre><code># \u6700\u5c0f\u590d\u73b0\u6848\u4f8b\nimport genesis\n\nmodel = genesis.nn.Linear(10, 5)\nx = genesis.randn(3, 10)\ny = model(x)  # \u8fd9\u91cc\u51fa\u73b0\u9519\u8bef\n\n# \u9519\u8bef\u4fe1\u606f\uff1a\n# RuntimeError: CUDA kernel launch failed\n</code></pre></p>"},{"location":"contributing/#_11","title":"\ud83c\udfaf \u8d21\u732e\u91cd\u70b9\u9886\u57df","text":"<p>\u5f53\u524d\u6211\u4eec\u7279\u522b\u6b22\u8fce\u4ee5\u4e0b\u9886\u57df\u7684\u8d21\u732e\uff1a</p>"},{"location":"contributing/#_12","title":"\u9ad8\u4f18\u5148\u7ea7","text":"<ul> <li> \u6027\u80fd\u4f18\u5316\u548c\u57fa\u51c6\u6d4b\u8bd5</li> <li> CUDA\u7b97\u5b50\u5b9e\u73b0</li> <li> \u6587\u6863\u548c\u6559\u7a0b\u5b8c\u5584</li> <li> \u6d4b\u8bd5\u8986\u76d6\u7387\u63d0\u5347</li> </ul>"},{"location":"contributing/#_13","title":"\u4e2d\u4f18\u5148\u7ea7","text":"<ul> <li> \u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u5c42</li> <li> \u6570\u636e\u52a0\u8f7d\u5668\u4f18\u5316</li> <li> \u5206\u5e03\u5f0f\u8bad\u7ec3\u652f\u6301</li> <li> \u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3</li> </ul>"},{"location":"contributing/#_14","title":"\u4f4e\u4f18\u5148\u7ea7","text":"<ul> <li> \u53ef\u89c6\u5316\u5de5\u5177</li> <li> \u6a21\u578b\u90e8\u7f72\u652f\u6301</li> <li> \u7b2c\u4e09\u65b9\u6846\u67b6\u96c6\u6210</li> </ul>"},{"location":"contributing/#_15","title":"\ud83d\udcde \u8054\u7cfb\u6211\u4eec","text":"<ul> <li>GitHub Issues: \u62a5\u544a\u95ee\u9898\u548c\u529f\u80fd\u8bf7\u6c42</li> <li>GitHub Discussions: \u6280\u672f\u8ba8\u8bba\u548c\u95ee\u7b54</li> <li>Email: genesis-dev@example.com</li> </ul>"},{"location":"contributing/#_16","title":"\ud83c\udfc6 \u8d21\u732e\u8005\u8ba4\u53ef","text":"<p>\u6211\u4eec\u91cd\u89c6\u6bcf\u4e00\u4f4d\u8d21\u732e\u8005\u7684\u52aa\u529b\uff1a</p> <ul> <li>\u8d21\u732e\u8005\u5c06\u5217\u5728\u9879\u76eeREADME\u4e2d</li> <li>\u91cd\u5927\u8d21\u732e\u8005\u5c06\u83b7\u5f97\u7ef4\u62a4\u8005\u6743\u9650</li> <li>\u5b9a\u671f\u53d1\u5e03\u8d21\u732e\u8005\u901a\u8baf</li> </ul>"},{"location":"contributing/#_17","title":"\ud83d\udcc4 \u8bb8\u53ef\u8bc1","text":"<p>\u901a\u8fc7\u8d21\u732e\u4ee3\u7801\uff0c\u4f60\u540c\u610f\u4f60\u7684\u8d21\u732e\u5c06\u5728MIT\u8bb8\u53ef\u8bc1\u4e0b\u53d1\u5e03\u3002</p> <p>\u5f00\u59cb\u8d21\u732e</p> <p>\u51c6\u5907\u597d\u5f00\u59cb\u8d21\u732e\u4e86\u5417\uff1f\u5148\u4ece\u5f00\u53d1\u73af\u5883\u914d\u7f6e\u5f00\u59cb\u5427\uff01</p> <p>\u611f\u8c22\u4f60\u4e3aGenesis\u9879\u76ee\u7684\u8d21\u732e\uff01\ud83c\udf89</p>"},{"location":"contributing/development/","title":"\u5f00\u53d1\u73af\u5883\u914d\u7f6e","text":"<p>\u672c\u6307\u5357\u5c06\u5e2e\u52a9\u4f60\u642d\u5efaGenesis\u5f00\u53d1\u73af\u5883\uff0c\u5305\u62ec\u4ee3\u7801\u7f16\u8f91\u3001\u8c03\u8bd5\u3001\u6d4b\u8bd5\u7b49\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u3002</p>"},{"location":"contributing/development/#_2","title":"\ud83d\udee0\ufe0f \u7cfb\u7edf\u8981\u6c42","text":""},{"location":"contributing/development/#_3","title":"\u786c\u4ef6\u8981\u6c42","text":"<ul> <li>CPU: x86_64\u67b6\u6784\uff0c\u652f\u6301AVX\u6307\u4ee4\u96c6</li> <li>\u5185\u5b58: \u6700\u5c1116GB\uff0c\u63a8\u835032GB+</li> <li>GPU: NVIDIA GPU with CUDA\u652f\u6301 (\u5f00\u53d1GPU\u7b97\u5b50\u65f6\u9700\u8981)</li> <li>\u5b58\u50a8: 20GB\u53ef\u7528\u7a7a\u95f4</li> </ul>"},{"location":"contributing/development/#_4","title":"\u8f6f\u4ef6\u8981\u6c42","text":"<ul> <li>\u64cd\u4f5c\u7cfb\u7edf: Linux (\u63a8\u8350Ubuntu 20.04+), macOS 10.15+</li> <li>Python: 3.8, 3.9, 3.10, 3.11</li> <li>Git: \u6700\u65b0\u7248\u672c</li> <li>CUDA: 11.8+ (GPU\u5f00\u53d1\u9700\u8981)</li> </ul>"},{"location":"contributing/development/#_5","title":"\ud83d\ude80 \u5feb\u901f\u5f00\u59cb","text":""},{"location":"contributing/development/#1","title":"1. \u514b\u9686\u4ed3\u5e93","text":"Bash<pre><code># \u514b\u9686\u4f60\u7684fork (\u63a8\u8350)\ngit clone https://github.com/YOUR_USERNAME/genesis.git\ncd genesis\n\n# \u6216\u514b\u9686\u4e3b\u4ed3\u5e93\ngit clone https://github.com/phonism/genesis.git\ncd genesis\n\n# \u6dfb\u52a0\u4e0a\u6e38\u4ed3\u5e93 (\u5982\u679cfork\u7684\u8bdd)\ngit remote add upstream https://github.com/phonism/genesis.git\n</code></pre>"},{"location":"contributing/development/#2-python","title":"2. \u521b\u5efaPython\u73af\u5883","text":"\u4f7f\u7528conda\u4f7f\u7528venv Bash<pre><code># \u521b\u5efa\u73af\u5883\nconda create -n genesis-dev python=3.9\nconda activate genesis-dev\n\n# \u5b89\u88c5\u57fa\u7840\u4f9d\u8d56\nconda install numpy matplotlib ipython jupyter\n</code></pre> Bash<pre><code># \u521b\u5efa\u73af\u5883\npython -m venv genesis-dev\nsource genesis-dev/bin/activate  # Linux/macOS\n# genesis-dev\\\\Scripts\\\\activate  # Windows\n\n# \u5347\u7ea7pip\npip install --upgrade pip setuptools wheel\n</code></pre>"},{"location":"contributing/development/#3","title":"3. \u5b89\u88c5\u5f00\u53d1\u4f9d\u8d56","text":"Bash<pre><code># \u5b89\u88c5PyTorch (\u6839\u636e\u4f60\u7684CUDA\u7248\u672c\u9009\u62e9)\n# CUDA 11.8\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n\n# CPU\u7248\u672c\n# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n\n# \u5b89\u88c5Triton\npip install triton\n\n# \u5b89\u88c5\u5f00\u53d1\u5de5\u5177\npip install -r requirements-dev.txt\n</code></pre>"},{"location":"contributing/development/#4-genesis","title":"4. \u5b89\u88c5Genesis (\u5f00\u53d1\u6a21\u5f0f)","text":"Bash<pre><code># \u5f00\u53d1\u6a21\u5f0f\u5b89\u88c5 (\u63a8\u8350)\npip install -e .\n\n# \u9a8c\u8bc1\u5b89\u88c5\npython -c \"import genesis; print('Genesis\u5f00\u53d1\u73af\u5883\u914d\u7f6e\u6210\u529f\uff01')\"\n</code></pre>"},{"location":"contributing/development/#_6","title":"\ud83d\udce6 \u4f9d\u8d56\u7ba1\u7406","text":""},{"location":"contributing/development/#requirementstxt","title":"\u6838\u5fc3\u4f9d\u8d56 (requirements.txt)","text":"Text Only<pre><code>torch&gt;=2.0.0\ntriton&gt;=2.0.0\nnumpy&gt;=1.21.0\ncuda-python&gt;=11.8.0\n</code></pre>"},{"location":"contributing/development/#requirements-devtxt","title":"\u5f00\u53d1\u4f9d\u8d56 (requirements-dev.txt)","text":"Text Only<pre><code>pytest&gt;=7.0.0\npytest-cov&gt;=4.0.0\nblack&gt;=22.0.0\nflake8&gt;=5.0.0\nmypy&gt;=1.0.0\nisort&gt;=5.0.0\npre-commit&gt;=2.20.0\nsphinx&gt;=5.0.0\nmatplotlib&gt;=3.5.0\njupyter&gt;=1.0.0\nipython&gt;=8.0.0\n</code></pre>"},{"location":"contributing/development/#_7","title":"\ud83d\udd27 \u5f00\u53d1\u5de5\u5177\u914d\u7f6e","text":""},{"location":"contributing/development/#1-git","title":"1. Git\u914d\u7f6e","text":"Bash<pre><code># \u914d\u7f6e\u7528\u6237\u4fe1\u606f\ngit config user.name \"Your Name\"\ngit config user.email \"your.email@example.com\"\n\n# \u914d\u7f6e\u63d0\u4ea4\u6a21\u677f\necho \"feat: brief description\n\nMore detailed explanation (optional)\n\n- Change 1\n- Change 2\n\nFixes #123\" &gt; ~/.gitmessage\ngit config commit.template ~/.gitmessage\n</code></pre>"},{"location":"contributing/development/#2-pre-commit","title":"2. Pre-commit\u94a9\u5b50","text":"Bash<pre><code># \u5b89\u88c5pre-commit\npip install pre-commit\n\n# \u5b89\u88c5\u94a9\u5b50\npre-commit install\n\n# \u624b\u52a8\u8fd0\u884c\u68c0\u67e5\npre-commit run --all-files\n</code></pre>"},{"location":"contributing/development/#3-ide","title":"3. IDE\u914d\u7f6e","text":"VS CodePyCharm <p>\u63a8\u8350\u5b89\u88c5\u4ee5\u4e0b\u6269\u5c55\uff1a</p> JSON<pre><code>// .vscode/extensions.json\n{\n    \"recommendations\": [\n        \"ms-python.python\",\n        \"ms-python.black-formatter\", \n        \"ms-python.flake8\",\n        \"ms-python.mypy-type-checker\",\n        \"ms-toolsai.jupyter\",\n        \"ms-vscode.cpptools\"\n    ]\n}\n</code></pre> <p>\u914d\u7f6e\u6587\u4ef6\uff1a JSON<pre><code>// .vscode/settings.json\n{\n    \"python.defaultInterpreterPath\": \"./genesis-dev/bin/python\",\n    \"python.linting.enabled\": true,\n    \"python.linting.flake8Enabled\": true,\n    \"python.formatting.provider\": \"black\",\n    \"python.formatting.blackArgs\": [\"--line-length=88\"],\n    \"python.testing.pytestEnabled\": true,\n    \"python.testing.pytestArgs\": [\"tests/\"]\n}\n</code></pre></p> <ol> <li>\u6253\u5f00\u9879\u76ee\u8bbe\u7f6e (File -&gt; Settings)</li> <li>\u914d\u7f6ePython\u89e3\u91ca\u5668\u6307\u5411\u865a\u62df\u73af\u5883</li> <li>\u542f\u7528\u4ee3\u7801\u683c\u5f0f\u5316\u5de5\u5177 (Black, isort)</li> <li>\u914d\u7f6e\u6d4b\u8bd5\u8fd0\u884c\u5668\u4e3apytest</li> </ol>"},{"location":"contributing/development/#4","title":"4. \u73af\u5883\u53d8\u91cf","text":"Bash<pre><code># \u5f00\u53d1\u73af\u5883\u53d8\u91cf\nexport GENESIS_DEV=1\nexport PYTHONPATH=\"${PWD}:${PYTHONPATH}\"\nexport CUDA_VISIBLE_DEVICES=0  # \u6307\u5b9aGPU\u8bbe\u5907\n\n# \u6dfb\u52a0\u5230 ~/.bashrc \u6216 ~/.zshrc\necho 'export GENESIS_DEV=1' &gt;&gt; ~/.bashrc\n</code></pre>"},{"location":"contributing/development/#_8","title":"\ud83e\uddea \u6d4b\u8bd5\u6846\u67b6","text":""},{"location":"contributing/development/#_9","title":"\u6d4b\u8bd5\u76ee\u5f55\u7ed3\u6784","text":"Text Only<pre><code>tests/\n\u251c\u2500\u2500 conftest.py              # pytest\u914d\u7f6e\n\u251c\u2500\u2500 test_autograd.py         # \u81ea\u52a8\u5fae\u5206\u6d4b\u8bd5\n\u251c\u2500\u2500 test_nn.py              # \u795e\u7ecf\u7f51\u7edc\u6d4b\u8bd5\n\u251c\u2500\u2500 test_cuda_tensor.py     # CUDA\u5f20\u91cf\u6d4b\u8bd5\n\u251c\u2500\u2500 test_functional.py      # \u51fd\u6570\u5f0f\u63a5\u53e3\u6d4b\u8bd5\n\u251c\u2500\u2500 benchmarks/             # \u6027\u80fd\u6d4b\u8bd5\n\u2502   \u251c\u2500\u2500 bench_matmul.py\n\u2502   \u2514\u2500\u2500 bench_attention.py\n\u2514\u2500\u2500 integration/            # \u96c6\u6210\u6d4b\u8bd5\n    \u251c\u2500\u2500 test_training.py\n    \u2514\u2500\u2500 test_models.py\n</code></pre>"},{"location":"contributing/development/#_10","title":"\u8fd0\u884c\u6d4b\u8bd5","text":"Bash<pre><code># \u8fd0\u884c\u6240\u6709\u6d4b\u8bd5\npytest tests/ -v\n\n# \u8fd0\u884c\u7279\u5b9a\u6d4b\u8bd5\u6587\u4ef6\npytest tests/test_nn.py -v\n\n# \u8fd0\u884c\u7279\u5b9a\u6d4b\u8bd5\u51fd\u6570\npytest tests/test_nn.py::test_linear_layer -v\n\n# \u8fd0\u884c\u5e26\u8986\u76d6\u7387\u7684\u6d4b\u8bd5\npytest tests/ --cov=genesis --cov-report=html\n\n# \u8fd0\u884c\u6027\u80fd\u6d4b\u8bd5\npytest tests/benchmarks/ -v --benchmark-only\n</code></pre>"},{"location":"contributing/development/#_11","title":"\u7f16\u5199\u6d4b\u8bd5","text":"Python<pre><code># tests/test_example.py\nimport pytest\nimport genesis\nimport genesis.nn as nn\n\nclass TestExample:\n    \"\"\"Example test class.\"\"\"\n\n    def setup_method(self):\n        \"\"\"Setup before each test method.\"\"\"\n        self.device = genesis.device('cuda' if genesis.cuda.is_available() else 'cpu')\n\n    def test_basic_operation(self):\n        \"\"\"Test basic tensor operations.\"\"\"\n        x = genesis.randn(3, 4, device=self.device)\n        y = genesis.randn(3, 4, device=self.device)\n        z = x + y\n\n        assert z.shape == (3, 4)\n        assert z.device == self.device\n\n    @pytest.mark.parametrize(\"input_size,output_size\", [\n        (10, 5),\n        (128, 64),\n        (512, 256)\n    ])\n    def test_linear_layers(self, input_size, output_size):\n        \"\"\"Test linear layers with different sizes.\"\"\"\n        layer = nn.Linear(input_size, output_size).to(self.device)\n        x = genesis.randn(32, input_size, device=self.device)\n\n        output = layer(x)\n        assert output.shape == (32, output_size)\n\n    @pytest.mark.cuda\n    def test_cuda_specific(self):\n        \"\"\"Test CUDA-specific functionality.\"\"\"\n        if not genesis.cuda.is_available():\n            pytest.skip(\"CUDA not available\")\n\n        x = genesis.randn(10, 10, device='cuda')\n        assert x.is_cuda\n</code></pre>"},{"location":"contributing/development/#_12","title":"\ud83d\udcca \u6027\u80fd\u5206\u6790","text":""},{"location":"contributing/development/#1-profiler","title":"1. \u5185\u7f6eprofiler","text":"Python<pre><code>import genesis.utils.profile as profiler\n\n# \u4f7f\u7528context manager\nwith profiler.profile() as prof:\n    # \u4f60\u7684\u4ee3\u7801\n    x = genesis.randn(1000, 1000)\n    y = genesis.matmul(x, x)\n\n# \u6253\u5370\u7ed3\u679c\nprof.print_stats()\n\n# \u4fdd\u5b58\u7ed3\u679c\nprof.export_chrome_trace(\"profile.json\")\n</code></pre>"},{"location":"contributing/development/#2","title":"2. \u5185\u5b58\u5206\u6790","text":"Python<pre><code>import genesis\n\n# \u542f\u7528\u5185\u5b58\u8ddf\u8e2a\ngenesis.cuda.memory.enable_debug()\n\n# \u4f60\u7684\u4ee3\u7801\nx = genesis.randn(1000, 1000, device='cuda')\ny = genesis.matmul(x, x)\n\n# \u67e5\u770b\u5185\u5b58\u4f7f\u7528\nprint(f\"\u5185\u5b58\u4f7f\u7528: {genesis.cuda.memory_allocated() / 1024**2:.1f} MB\")\nprint(f\"\u7f13\u5b58\u5185\u5b58: {genesis.cuda.memory_cached() / 1024**2:.1f} MB\")\n\n# \u5185\u5b58\u5feb\u7167\nsnapshot = genesis.cuda.memory.memory_snapshot()\n</code></pre>"},{"location":"contributing/development/#3_1","title":"3. \u57fa\u51c6\u6d4b\u8bd5","text":"Python<pre><code># benchmark/bench_example.py\nimport time\nimport genesis\nimport torch\n\ndef benchmark_matmul():\n    \"\"\"Benchmark matrix multiplication.\"\"\"\n    sizes = [128, 256, 512, 1024]\n\n    for size in sizes:\n        # Genesis\n        x_gen = genesis.randn(size, size, device='cuda')\n        y_gen = genesis.randn(size, size, device='cuda')\n\n        start_time = time.time()\n        for _ in range(100):\n            z_gen = genesis.matmul(x_gen, y_gen)\n        genesis_time = time.time() - start_time\n\n        # PyTorch\n        x_torch = torch.randn(size, size, device='cuda')\n        y_torch = torch.randn(size, size, device='cuda')\n\n        start_time = time.time()\n        for _ in range(100):\n            z_torch = torch.matmul(x_torch, y_torch)\n        torch_time = time.time() - start_time\n\n        print(f\"Size {size}x{size}:\")\n        print(f\"  Genesis: {genesis_time:.4f}s\")\n        print(f\"  PyTorch: {torch_time:.4f}s\")\n        print(f\"  Ratio: {genesis_time/torch_time:.2f}x\")\n\nif __name__ == \"__main__\":\n    benchmark_matmul()\n</code></pre>"},{"location":"contributing/development/#_13","title":"\ud83d\udc1b \u8c03\u8bd5\u6280\u5de7","text":""},{"location":"contributing/development/#1_1","title":"1. \u8c03\u8bd5\u73af\u5883\u53d8\u91cf","text":"Bash<pre><code># \u542f\u7528\u8c03\u8bd5\u6a21\u5f0f\nexport GENESIS_DEBUG=1\nexport CUDA_LAUNCH_BLOCKING=1  # \u540c\u6b65CUDA\u6267\u884c\nexport PYTHONFAULTHANDLER=1    # Python\u9519\u8bef\u5904\u7406\n</code></pre>"},{"location":"contributing/development/#2_1","title":"2. \u65e5\u5fd7\u914d\u7f6e","text":"Python<pre><code>import logging\nimport genesis\n\n# \u914d\u7f6e\u65e5\u5fd7\nlogging.basicConfig(level=logging.DEBUG)\ngenesis.set_log_level('DEBUG')\n\n# \u4f7f\u7528\u65e5\u5fd7\nlogger = logging.getLogger(__name__)\nlogger.debug(\"\u8c03\u8bd5\u4fe1\u606f\")\n</code></pre>"},{"location":"contributing/development/#3_2","title":"3. \u65ad\u70b9\u8c03\u8bd5","text":"Python<pre><code>import pdb\n\ndef buggy_function(x):\n    pdb.set_trace()  # \u8bbe\u7f6e\u65ad\u70b9\n    y = x * 2\n    return y\n\n# \u6216\u4f7f\u7528ipdb (\u9700\u8981\u5b89\u88c5: pip install ipdb)\nimport ipdb\nipdb.set_trace()\n</code></pre>"},{"location":"contributing/development/#_14","title":"\ud83d\udcda \u6587\u6863\u5f00\u53d1","text":""},{"location":"contributing/development/#_15","title":"\u6784\u5efa\u6587\u6863","text":"Bash<pre><code># \u5b89\u88c5\u6587\u6863\u4f9d\u8d56\npip install -r docs/requirements.txt\n\n# \u672c\u5730\u670d\u52a1\u5668\nmkdocs serve\n\n# \u6784\u5efa\u9759\u6001\u6587\u4ef6\nmkdocs build\n\n# \u90e8\u7f72\u5230GitHub Pages\nmkdocs gh-deploy\n</code></pre>"},{"location":"contributing/development/#api","title":"API\u6587\u6863\u751f\u6210","text":"Bash<pre><code># \u81ea\u52a8\u751f\u6210API\u6587\u6863\npython scripts/generate_api_docs.py\n\n# \u68c0\u67e5docstring\u683c\u5f0f\npydocstyle genesis/\n</code></pre>"},{"location":"contributing/development/#_16","title":"\ud83d\ude80 \u63d0\u4ea4\u4ee3\u7801","text":""},{"location":"contributing/development/#1_2","title":"1. \u4ee3\u7801\u68c0\u67e5","text":"Bash<pre><code># \u683c\u5f0f\u5316\u4ee3\u7801\nblack genesis/ tests/\nisort genesis/ tests/\n\n# \u7c7b\u578b\u68c0\u67e5\nmypy genesis/\n\n# \u4ee3\u7801\u8d28\u91cf\u68c0\u67e5\nflake8 genesis/ tests/\n\n# \u8fd0\u884c\u6d4b\u8bd5\npytest tests/ -x\n</code></pre>"},{"location":"contributing/development/#2_2","title":"2. \u63d0\u4ea4\u6d41\u7a0b","text":"Bash<pre><code># 1. \u540c\u6b65\u6700\u65b0\u4ee3\u7801\ngit fetch upstream\ngit rebase upstream/main\n\n# 2. \u521b\u5efa\u529f\u80fd\u5206\u652f\ngit checkout -b feature/your-feature\n\n# 3. \u5f00\u53d1\u548c\u6d4b\u8bd5\n# ... \u4f60\u7684\u5f00\u53d1\u5de5\u4f5c ...\n\n# 4. \u63d0\u4ea4\u4ee3\u7801\ngit add .\ngit commit -m \"feat: add your feature\"\n\n# 5. \u63a8\u9001\u5206\u652f\ngit push origin feature/your-feature\n\n# 6. \u521b\u5efaPull Request\n</code></pre>"},{"location":"contributing/development/#_17","title":"\u2753 \u5e38\u89c1\u95ee\u9898","text":""},{"location":"contributing/development/#q-cuda","title":"Q: CUDA\u76f8\u5173\u9519\u8bef\uff1f","text":"<p>A: \u68c0\u67e5CUDA\u7248\u672c\u517c\u5bb9\u6027\uff0c\u786e\u4fddPyTorch\u548cTriton\u7248\u672c\u5339\u914d\u3002</p>"},{"location":"contributing/development/#q","title":"Q: \u6d4b\u8bd5\u5931\u8d25\uff1f","text":"<p>A: \u8fd0\u884c <code>pytest tests/ -v</code> \u67e5\u770b\u8be6\u7ec6\u9519\u8bef\u4fe1\u606f\uff0c\u68c0\u67e5\u73af\u5883\u914d\u7f6e\u3002</p>"},{"location":"contributing/development/#q_1","title":"Q: \u6027\u80fd\u95ee\u9898\uff1f","text":"<p>A: \u4f7f\u7528profiler\u5206\u6790\u74f6\u9888\uff0c\u68c0\u67e5\u662f\u5426\u542f\u7528\u4e86GPU\u52a0\u901f\u3002</p>"},{"location":"contributing/development/#q_2","title":"Q: \u5185\u5b58\u4e0d\u8db3\uff1f","text":"<p>A: \u51cf\u5c0f\u6d4b\u8bd5\u7528\u4f8b\u7684\u6570\u636e\u89c4\u6a21\uff0c\u542f\u7528CPU\u56de\u9000\u6a21\u5f0f\u3002</p> <p>\u5f00\u53d1\u73af\u5883\u914d\u7f6e\u5b8c\u6210</p> <p>\u73b0\u5728\u4f60\u53ef\u4ee5\u5f00\u59cb\u4e3aGenesis\u8d21\u732e\u4ee3\u7801\u4e86\uff01</p> <p>\u4e0b\u4e00\u6b65\uff1a\u4e86\u89e3\u6d4b\u8bd5\u89c4\u8303 \u8fd4\u56de\u8d21\u732e\u6307\u5357</p>"},{"location":"contributing/testing/","title":"\u6d4b\u8bd5\u89c4\u8303","text":"<p>\u5f00\u53d1\u4e2d</p> <p>\u6b64\u6587\u6863\u6b63\u5728\u7f16\u5199\u4e2d\uff0c\u5185\u5bb9\u5c06\u6301\u7eed\u66f4\u65b0\u3002</p> <p>\u672c\u6587\u6863\u89c4\u5b9a\u4e86Genesis\u9879\u76ee\u7684\u6d4b\u8bd5\u6807\u51c6\u548c\u6700\u4f73\u5b9e\u8df5\u3002</p>"},{"location":"contributing/testing/#_2","title":"\ud83c\udfaf \u6d4b\u8bd5\u539f\u5219","text":""},{"location":"contributing/testing/#1","title":"1. \u6d4b\u8bd5\u91d1\u5b57\u5854","text":"<ul> <li>\u5355\u5143\u6d4b\u8bd5 (70%): \u6d4b\u8bd5\u5355\u4e2a\u51fd\u6570\u548c\u7c7b</li> <li>\u96c6\u6210\u6d4b\u8bd5 (20%): \u6d4b\u8bd5\u7ec4\u4ef6\u95f4\u4ea4\u4e92</li> <li>\u7aef\u5230\u7aef\u6d4b\u8bd5 (10%): \u6d4b\u8bd5\u5b8c\u6574\u5de5\u4f5c\u6d41</li> </ul>"},{"location":"contributing/testing/#2","title":"2. \u6d4b\u8bd5\u8986\u76d6\u7387","text":"<ul> <li>\u76ee\u6807\u8986\u76d6\u7387: 90%+</li> <li>\u5173\u952e\u6a21\u5757\u8981\u6c42: 95%+</li> <li>\u65b0\u4ee3\u7801\u8981\u6c42: 100%</li> </ul>"},{"location":"contributing/testing/#_3","title":"\ud83d\udccb \u6d4b\u8bd5\u5206\u7c7b","text":""},{"location":"contributing/testing/#_4","title":"\u5355\u5143\u6d4b\u8bd5","text":"Python<pre><code>def test_tensor_creation():\n    \"\"\"Test basic tensor creation.\"\"\"\n    x = genesis.randn(3, 4)\n    assert x.shape == (3, 4)\n    assert x.dtype == genesis.float32\n</code></pre>"},{"location":"contributing/testing/#_5","title":"\u6027\u80fd\u6d4b\u8bd5","text":"Python<pre><code>@pytest.mark.benchmark\ndef test_matmul_performance():\n    \"\"\"Benchmark matrix multiplication performance.\"\"\"\n    # WIP: \u6027\u80fd\u6d4b\u8bd5\u5b9e\u73b0\n    pass\n</code></pre>"},{"location":"contributing/testing/#gpu","title":"GPU\u6d4b\u8bd5","text":"Python<pre><code>@pytest.mark.cuda\ndef test_cuda_operations():\n    \"\"\"Test CUDA-specific operations.\"\"\"\n    if not genesis.cuda.is_available():\n        pytest.skip(\"CUDA not available\")\n\n    x = genesis.randn(10, 10, device='cuda')\n    y = genesis.matmul(x, x)\n    assert y.device.type == 'cuda'\n</code></pre>"},{"location":"contributing/testing/#_6","title":"\ud83d\ude80 \u8fd0\u884c\u6d4b\u8bd5","text":"Bash<pre><code># \u6240\u6709\u6d4b\u8bd5\npytest tests/ -v\n\n# \u7279\u5b9a\u6807\u8bb0\npytest tests/ -m \"not slow\" -v\n\n# \u8986\u76d6\u7387\u62a5\u544a\npytest tests/ --cov=genesis --cov-report=html\n</code></pre>"},{"location":"contributing/testing/#_7","title":"\ud83d\udcca \u6d4b\u8bd5\u5de5\u5177","text":"<ul> <li>pytest: \u4e3b\u8981\u6d4b\u8bd5\u6846\u67b6</li> <li>pytest-cov: \u8986\u76d6\u7387\u7edf\u8ba1</li> <li>pytest-benchmark: \u6027\u80fd\u6d4b\u8bd5</li> <li>pytest-xdist: \u5e76\u884c\u6d4b\u8bd5</li> </ul> <p>\ud83d\udcd8 \u6587\u6863\u72b6\u6001: \u6b63\u5728\u7f16\u5199\u4e2d\uff0c\u9884\u8ba1\u5728v0.2.0\u7248\u672c\u5b8c\u6210\u3002</p>"},{"location":"core-components/","title":"\u6838\u5fc3\u7ec4\u4ef6\u6982\u8ff0","text":"<p>Genesis\u6846\u67b6\u7684\u6838\u5fc3\u7ec4\u4ef6\u63d0\u4f9b\u4e86\u6df1\u5ea6\u5b66\u4e60\u8ba1\u7b97\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u5305\u62ec\u5f20\u91cf\u7cfb\u7edf\u3001\u81ea\u52a8\u5fae\u5206\u5f15\u64ce\u3001\u6570\u636e\u7c7b\u578b\u7cfb\u7edf\u548c\u51fd\u6570\u5f0f\u64cd\u4f5c\u63a5\u53e3\u3002</p>"},{"location":"core-components/#_2","title":"\ud83e\udde9 \u7ec4\u4ef6\u67b6\u6784","text":"<pre><code>graph TB\n    subgraph \"\u6838\u5fc3\u7ec4\u4ef6\"\n        A[Tensor\u5f20\u91cf] --&gt; B[\u81ea\u52a8\u5fae\u5206\u5f15\u64ce]\n        C[\u6570\u636e\u7c7b\u578b\u7cfb\u7edf] --&gt; A\n        D[\u51fd\u6570\u5f0f\u64cd\u4f5c] --&gt; A\n        E[\u521d\u59cb\u5316\u51fd\u6570] --&gt; A\n    end\n\n    subgraph \"\u81ea\u52a8\u5fae\u5206\u8be6\u7ec6\"\n        B --&gt; F[Function\u57fa\u7c7b]\n        B --&gt; G[Context\u4e0a\u4e0b\u6587]\n        B --&gt; H[\u8ba1\u7b97\u56fe\u6784\u5efa]\n        B --&gt; I[\u53cd\u5411\u4f20\u64ad]\n    end\n\n    subgraph \"\u7c7b\u578b\u7cfb\u7edf\"\n        C --&gt; J[DType\u7c7b]\n        C --&gt; K[\u7c7b\u578b\u8f6c\u6362]\n        C --&gt; L[\u7cbe\u5ea6\u7ba1\u7406]\n    end\n\n    style A fill:#e1f5fe\n    style B fill:#f3e5f5\n    style C fill:#e8f5e8\n    style D fill:#fff3e0</code></pre>"},{"location":"core-components/#_3","title":"\ud83c\udfaf \u6838\u5fc3\u7ec4\u4ef6\u6e05\u5355","text":"\u7ec4\u4ef6 \u6587\u4ef6 \u4e3b\u8981\u529f\u80fd \u5f20\u91cf\u7cfb\u7edf <code>autograd.py</code> \u57fa\u7840\u6570\u636e\u7ed3\u6784\u3001\u81ea\u52a8\u5fae\u5206 \u6570\u636e\u7c7b\u578b <code>dtypes.py</code> \u7edf\u4e00\u7c7b\u578b\u7cfb\u7edf\u3001\u7cbe\u5ea6\u7ba1\u7406 \u51fd\u6570\u5f0f\u64cd\u4f5c <code>functional.py</code> \u5f20\u91cf\u64cd\u4f5c\u7684\u51fd\u6570\u5f0f\u63a5\u53e3 \u521d\u59cb\u5316 <code>init.py</code> \u5f20\u91cf\u521b\u5efa\u548c\u521d\u59cb\u5316 \u540e\u7aef\u62bd\u8c61 <code>backend.py</code> \u8bbe\u5907\u548c\u540e\u7aef\u7ba1\u7406"},{"location":"core-components/#_4","title":"\ud83d\ude80 \u8bbe\u8ba1\u7279\u8272","text":""},{"location":"core-components/#1","title":"1. \u7edf\u4e00\u7684\u5f20\u91cf\u63a5\u53e3","text":"<ul> <li>\u4e00\u81f4\u7684API\uff1a\u65e0\u8bbaCPU\u8fd8\u662fGPU\uff0c\u7528\u6237\u4f7f\u7528\u76f8\u540c\u7684\u63a5\u53e3</li> <li>\u900f\u660e\u7684\u8bbe\u5907\u5207\u6362\uff1a\u81ea\u52a8\u5904\u7406\u4e0d\u540c\u8bbe\u5907\u95f4\u7684\u6570\u636e\u8f6c\u6362</li> <li>\u7c7b\u578b\u5b89\u5168\uff1a\u7f16\u8bd1\u65f6\u548c\u8fd0\u884c\u65f6\u7684\u7c7b\u578b\u68c0\u67e5</li> </ul>"},{"location":"core-components/#2","title":"2. \u9ad8\u6548\u7684\u81ea\u52a8\u5fae\u5206","text":"<ul> <li>\u60f0\u6027\u8ba1\u7b97\u56fe\uff1a\u6309\u9700\u6784\u5efa\u8ba1\u7b97\u56fe\uff0c\u8282\u7701\u5185\u5b58</li> <li>\u667a\u80fd\u68af\u5ea6\u4f20\u64ad\uff1a\u4f18\u5316\u7684\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5</li> <li>\u5185\u5b58\u4f18\u5316\uff1a\u81ea\u52a8\u91ca\u653e\u4e0d\u518d\u9700\u8981\u7684\u4e2d\u95f4\u7ed3\u679c</li> </ul>"},{"location":"core-components/#3","title":"3. \u7075\u6d3b\u7684\u7c7b\u578b\u7cfb\u7edf","text":"<ul> <li>\u6df7\u5408\u7cbe\u5ea6\u652f\u6301\uff1a\u81ea\u52a8\u5728FP32\u548cFP16\u95f4\u8f6c\u6362</li> <li>\u8bbe\u5907\u65e0\u5173\uff1a\u7c7b\u578b\u5b9a\u4e49\u72ec\u7acb\u4e8e\u5177\u4f53\u8bbe\u5907</li> <li>NumPy\u517c\u5bb9\uff1a\u65e0\u7f1d\u5bf9\u63a5NumPy\u751f\u6001</li> </ul>"},{"location":"core-components/#_5","title":"\ud83d\udcca \u6027\u80fd\u7279\u6027","text":""},{"location":"core-components/#_6","title":"\u5185\u5b58\u6548\u7387","text":"<ul> <li>\u89c6\u56fe\u64cd\u4f5c\u96f6\u62f7\u8d1d\uff1areshape\u3001transpose\u7b49\u64cd\u4f5c\u4e0d\u590d\u5236\u6570\u636e</li> <li>\u667a\u80fd\u5185\u5b58\u7ba1\u7406\uff1a\u57fa\u4e8e\u5f15\u7528\u8ba1\u6570\u7684\u81ea\u52a8\u5185\u5b58\u91ca\u653e</li> <li>\u68af\u5ea6\u7d2f\u79ef\u4f18\u5316\uff1a\u51cf\u5c11\u4e34\u65f6\u5f20\u91cf\u521b\u5efa</li> </ul>"},{"location":"core-components/#_7","title":"\u8ba1\u7b97\u4f18\u5316","text":"<ul> <li>\u5ef6\u8fdf\u6267\u884c\uff1a\u64cd\u4f5c\u5728\u9700\u8981\u65f6\u624d\u771f\u6b63\u6267\u884c</li> <li>\u878d\u5408\u4f18\u5316\uff1a\u76f8\u90bb\u64cd\u4f5c\u81ea\u52a8\u878d\u5408\u4ee5\u51cf\u5c11\u5185\u5b58\u8bbf\u95ee</li> <li>\u5e76\u884c\u8ba1\u7b97\uff1a\u5145\u5206\u5229\u7528GPU\u5e76\u884c\u80fd\u529b</li> </ul>"},{"location":"core-components/#_8","title":"\ud83d\udd17 \u7ec4\u4ef6\u95f4\u534f\u4f5c","text":""},{"location":"core-components/#_9","title":"\u5f20\u91cf\u521b\u5efa\u6d41\u7a0b","text":"Python<pre><code># \u7528\u6237\u8c03\u7528\nx = genesis.randn(3, 4)\n\n# \u5185\u90e8\u6d41\u7a0b\ninit.randn() -&gt; \nNDArray.randn() -&gt; \nDevice.randn() -&gt; \nTensor.__init__() -&gt;\n\u8bbe\u7f6erequires_grad\u7b49\u5c5e\u6027\n</code></pre>"},{"location":"core-components/#_10","title":"\u81ea\u52a8\u5fae\u5206\u6d41\u7a0b","text":"Python<pre><code># \u524d\u5411\u4f20\u64ad\nz = x * y + x.sum()\n\n# \u6784\u5efa\u8ba1\u7b97\u56fe\nMulFunction.apply(x, y) -&gt; \nSumFunction.apply(x) -&gt;\nAddFunction.apply(mul_result, sum_result) -&gt;\n\u8bbe\u7f6ecreator\u5173\u7cfb\n\n# \u53cd\u5411\u4f20\u64ad\nz.backward()\n\n# \u8ba1\u7b97\u68af\u5ea6\ntopo_sort(z) -&gt;\n\u9006\u62d3\u6251\u5e8f\u904d\u5386 -&gt;\n\u8c03\u7528\u5404Function\u7684backward() -&gt;\n\u68af\u5ea6\u7d2f\u79ef\u5230\u53f6\u5b50\u8282\u70b9\n</code></pre>"},{"location":"core-components/#_11","title":"\ud83c\udf93 \u5b66\u4e60\u8def\u5f84\u5efa\u8bae","text":""},{"location":"core-components/#_12","title":"\u521d\u7ea7\u7528\u6237","text":"<ol> <li>\u5f20\u91cf\u57fa\u7840 - \u4e86\u89e3Tensor\u7684\u521b\u5efa\u548c\u57fa\u672c\u64cd\u4f5c</li> <li>\u81ea\u52a8\u5fae\u5206 - \u7406\u89e3requires_grad\u548cbackward()</li> <li>\u8bbe\u5907\u7ba1\u7406 - \u5b66\u4e60CPU/GPU\u5207\u6362</li> </ol>"},{"location":"core-components/#_13","title":"\u4e2d\u7ea7\u7528\u6237","text":"<ol> <li>\u6570\u636e\u7c7b\u578b - \u638c\u63e1\u4e0d\u540c\u7cbe\u5ea6\u7684\u4f7f\u7528\u573a\u666f</li> <li>\u51fd\u6570\u5f0f\u63a5\u53e3 - \u4f7f\u7528functional\u6a21\u5757</li> <li>\u5185\u5b58\u4f18\u5316 - \u7406\u89e3\u89c6\u56fe\u64cd\u4f5c\u548c\u5185\u5b58\u7ba1\u7406</li> </ol>"},{"location":"core-components/#_14","title":"\u9ad8\u7ea7\u7528\u6237","text":"<ol> <li>\u81ea\u5b9a\u4e49Function - \u5b9e\u73b0\u81ea\u5b9a\u4e49\u7684\u524d\u5411\u548c\u53cd\u5411\u4f20\u64ad</li> <li>\u6027\u80fd\u8c03\u4f18 - \u4f18\u5316\u5185\u5b58\u4f7f\u7528\u548c\u8ba1\u7b97\u6548\u7387</li> <li>\u6e90\u7801\u7406\u89e3 - \u6df1\u5165\u7406\u89e3\u5404\u7ec4\u4ef6\u7684\u5b9e\u73b0\u7ec6\u8282</li> </ol> <p>\u5404\u7ec4\u4ef6\u7684\u8be6\u7ec6\u6587\u6863\u8bf7\u67e5\u770b\u5bf9\u5e94\u7684\u4e13\u95e8\u9875\u9762\uff1a</p> <ul> <li>\u81ea\u52a8\u5fae\u5206\u7cfb\u7edf - \u6df1\u5165\u7406\u89e3\u8ba1\u7b97\u56fe\u548c\u68af\u5ea6\u8ba1\u7b97</li> <li>\u5f20\u91cf\u64cd\u4f5c - \u5168\u9762\u7684\u5f20\u91cf\u64cd\u4f5c\u6307\u5357  </li> <li>\u6570\u636e\u7c7b\u578b - \u7c7b\u578b\u7cfb\u7edf\u548c\u7cbe\u5ea6\u7ba1\u7406</li> <li>\u51fd\u6570\u5f0f\u63a5\u53e3 - \u51fd\u6570\u5f0f\u7f16\u7a0b\u98ce\u683c\u7684\u64cd\u4f5c</li> </ul>"},{"location":"core-components/autograd/","title":"\u81ea\u52a8\u5fae\u5206\u7cfb\u7edf","text":"<p>Genesis\u7684\u81ea\u52a8\u5fae\u5206\u7cfb\u7edf\u662f\u6846\u67b6\u7684\u6838\u5fc3\uff0c\u8d1f\u8d23\u6784\u5efa\u8ba1\u7b97\u56fe\u3001\u6267\u884c\u524d\u5411\u4f20\u64ad\u548c\u53cd\u5411\u4f20\u64ad\u3002\u7cfb\u7edf\u8bbe\u8ba1\u7b80\u6d01\u800c\u9ad8\u6548\uff0c\u652f\u6301\u590d\u6742\u7684\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u3002</p>"},{"location":"core-components/autograd/#_2","title":"\ud83c\udfaf \u7cfb\u7edf\u6982\u8ff0","text":"<p>\u81ea\u52a8\u5fae\u5206\u7cfb\u7edf\u57fa\u4e8e\u52a8\u6001\u8ba1\u7b97\u56fe\u5b9e\u73b0\uff0c\u4e3b\u8981\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a</p> <ul> <li>Tensor - \u643a\u5e26\u68af\u5ea6\u4fe1\u606f\u7684\u5f20\u91cf</li> <li>Function - \u53ef\u5fae\u5206\u64cd\u4f5c\u7684\u62bd\u8c61\u57fa\u7c7b</li> <li>Context - \u4fdd\u5b58\u524d\u5411\u4f20\u64ad\u4e2d\u95f4\u7ed3\u679c\u7684\u4e0a\u4e0b\u6587</li> </ul>"},{"location":"core-components/autograd/#_3","title":"\ud83c\udfd7\ufe0f \u6838\u5fc3\u67b6\u6784","text":"<pre><code>graph TB\n    subgraph \"\u8ba1\u7b97\u56fe\u8282\u70b9\"\n        A[Tensor] --&gt; B[data NDArray]\n        A --&gt; C[grad Tensor]\n        A --&gt; D[creator Function]\n        A --&gt; E[requires_grad bool]\n    end\n\n    subgraph \"\u64cd\u4f5c\u8282\u70b9\"\n        F[Function] --&gt; G[forward]\n        F --&gt; H[backward]\n        F --&gt; I[Context]\n        I --&gt; J[saved_tensors]\n    end\n\n    subgraph \"\u6267\u884c\u6d41\u7a0b\"\n        K[\u524d\u5411\u4f20\u64ad] --&gt; L[\u6784\u5efa\u8ba1\u7b97\u56fe]\n        L --&gt; M[\u4fdd\u5b58\u4e2d\u95f4\u7ed3\u679c]\n        M --&gt; N[\u53cd\u5411\u4f20\u64ad]\n        N --&gt; O[\u68af\u5ea6\u8ba1\u7b97]\n        O --&gt; P[\u68af\u5ea6\u7d2f\u79ef]\n    end\n\n    A --&gt; F\n    F --&gt; A\n\n    style A fill:#e1f5fe\n    style F fill:#f3e5f5\n    style I fill:#e8f5e8</code></pre>"},{"location":"core-components/autograd/#tensor","title":"\ud83e\uddee Tensor\u7c7b\u8be6\u89e3","text":""},{"location":"core-components/autograd/#_4","title":"\u6838\u5fc3\u5c5e\u6027","text":"Python<pre><code>class Tensor:\n    grad: \"Tensor\"          # \u68af\u5ea6\u5f20\u91cf\n    creator: Function       # \u521b\u5efa\u6b64\u5f20\u91cf\u7684\u64cd\u4f5c\n    inputs: List[\"Tensor\"]  # \u8f93\u5165\u5f20\u91cf\u5217\u8868\n    data: NDArray          # \u5e95\u5c42\u6570\u636e\u5b58\u50a8\n    requires_grad: bool    # \u662f\u5426\u9700\u8981\u8ba1\u7b97\u68af\u5ea6\n    hooks: List[Callable]  # \u68af\u5ea6\u94a9\u5b50\u51fd\u6570\n</code></pre>"},{"location":"core-components/autograd/#_5","title":"\u5173\u952e\u65b9\u6cd5","text":""},{"location":"core-components/autograd/#1","title":"1. \u5f20\u91cf\u521b\u5efa","text":"Python<pre><code># \u4ece\u6570\u7ec4\u521b\u5efa\u5f20\u91cf\ndef __init__(self, array, *, device=None, dtype=None, requires_grad=True):\n    if dtype is not None:\n        dtype = get_dtype(dtype)  # \u8f6c\u6362\u4e3aDType\u5bf9\u8c61\n\n    # \u5904\u7406\u4e0d\u540c\u8f93\u5165\u7c7b\u578b\n    if isinstance(array, Tensor):\n        # \u4ece\u73b0\u6709\u5f20\u91cf\u521b\u5efa\n        data = array.data if same_device_dtype else convert_data\n    elif isinstance(array, NDArray):\n        # \u4eceNDArray\u521b\u5efa\n        data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\n    else:\n        # \u4ecePython\u5bf9\u8c61\u521b\u5efa\n        device = device if device else default_device()\n        data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\n\n    self.init([], data=data, requires_grad=requires_grad)\n</code></pre>"},{"location":"core-components/autograd/#2","title":"2. \u53cd\u5411\u4f20\u64ad","text":"Python<pre><code>def backward(self, out_grad=None):\n    # \u8bbe\u7f6e\u8f93\u51fa\u68af\u5ea6\n    out_grad = out_grad if out_grad else init.ones(*self.shape, dtype=self.dtype, device=self.device)\n\n    # \u521d\u59cb\u5316\u68af\u5ea6\u7d2f\u79ef\u5b57\u5178\n    node_to_output_grads_list: Dict[Tensor, List[Tensor]] = {}\n    node_to_output_grads_list[self] = [out_grad]\n\n    # \u62d3\u6251\u6392\u5e8f\u83b7\u53d6\u8ba1\u7b97\u987a\u5e8f\n    topo_order = topo_sort(self)\n\n    # \u9006\u62d3\u6251\u5e8f\u904d\u5386\u8ba1\u7b97\u68af\u5ea6\n    for node in reversed(topo_order):\n        if not node.requires_grad:\n            continue\n\n        # \u7d2f\u79ef\u5f53\u524d\u8282\u70b9\u7684\u68af\u5ea6\n        if node.grad is None:\n            node.grad = reduce(operator.add, node_to_output_grads_list[node])\n            # \u786e\u4fdd\u68af\u5ea6\u8fde\u7eed\u6027\uff08\u89e3\u51b3\u5e7f\u64ad\u5f20\u91cf\u95ee\u9898\uff09\n            if hasattr(node.grad, 'data') and hasattr(node.grad.data, 'data'):\n                cuda_tensor = node.grad.data.data\n                if hasattr(cuda_tensor, 'is_contiguous') and not cuda_tensor.is_contiguous():\n                    node.grad.data.data = cuda_tensor.contiguous()\n        else:\n            node.grad += reduce(operator.add, node_to_output_grads_list[node])\n\n        # \u5e94\u7528\u68af\u5ea6\u94a9\u5b50\n        node.apply_hooks(node.grad)\n\n        # \u8ba1\u7b97\u8f93\u5165\u8282\u70b9\u7684\u68af\u5ea6\n        if node.creator is not None:\n            # \u5904\u7406\u6df7\u5408\u7cbe\u5ea6\n            grad = node.grad.half() if check_dtype(node.creator.ctx.saved_tensors, genesis.float16) else node.grad\n\n            # \u8c03\u7528\u5bf9\u5e94\u64cd\u4f5c\u7684\u53cd\u5411\u4f20\u64ad\n            if node.creator.is_tuple_result:\n                backward_grad = node.creator.backward(node.creator.ctx, grad, node.idx)\n            else:\n                backward_grad = node.creator.backward(node.creator.ctx, grad)\n\n            # \u5206\u53d1\u68af\u5ea6\u5230\u8f93\u5165\u8282\u70b9\n            for i, input_node in enumerate(node.creator.inputs):\n                if input_node.requires_grad:\n                    if input_node not in node_to_output_grads_list:\n                        node_to_output_grads_list[input_node] = []\n                    node_to_output_grads_list[input_node].append(backward_grad[i].float())\n</code></pre>"},{"location":"core-components/autograd/#3","title":"3. \u62d3\u6251\u6392\u5e8f","text":"Python<pre><code>def topo_sort(node):\n    \"\"\"\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u5b9e\u73b0\u62d3\u6251\u6392\u5e8f\"\"\"\n    visited = set()\n    topo_order = []\n\n    def dfs(n):\n        if n in visited:\n            return\n        visited.add(n)\n\n        # \u9012\u5f52\u8bbf\u95ee\u8f93\u5165\u8282\u70b9\n        if n.creator is not None:\n            for input_node in n.creator.inputs:\n                if isinstance(input_node, Tensor):\n                    dfs(input_node)\n\n        topo_order.append(n)\n\n    dfs(node)\n    return topo_order\n</code></pre>"},{"location":"core-components/autograd/#function","title":"\u2699\ufe0f Function\u57fa\u7c7b","text":"<p>Function\u662f\u6240\u6709\u53ef\u5fae\u5206\u64cd\u4f5c\u7684\u57fa\u7c7b\uff0c\u5b9a\u4e49\u4e86\u524d\u5411\u548c\u53cd\u5411\u4f20\u64ad\u7684\u63a5\u53e3\u3002</p>"},{"location":"core-components/autograd/#_6","title":"\u57fa\u672c\u7ed3\u6784","text":"Python<pre><code>class Function:\n    @staticmethod\n    def forward(ctx: Context, *args) -&gt; Union[Tensor, Tuple[Tensor, ...]]:\n        \"\"\"\u524d\u5411\u4f20\u64ad\u5b9e\u73b0\"\"\"\n        raise NotImplementedError\n\n    @staticmethod  \n    def backward(ctx: Context, grad_output, out_idx=None) -&gt; Tuple[Tensor, ...]:\n        \"\"\"\u53cd\u5411\u4f20\u64ad\u5b9e\u73b0\"\"\"\n        raise NotImplementedError\n\n    @classmethod\n    def apply(cls, *args, **kwargs):\n        \"\"\"\u7edf\u4e00\u7684\u8c03\u7528\u63a5\u53e3\"\"\"\n        # \u5904\u7406\u6df7\u5408\u7cbe\u5ea6\n        instance = cls()\n        instance.ctx = Context()\n\n        # \u6267\u884c\u524d\u5411\u4f20\u64ad\n        if genesis.enable_autocast:\n            result = cls.forward(instance.ctx, *_cast(args, genesis.float32), **_cast(kwargs, genesis.float32))\n        else:\n            result = cls.forward(instance.ctx, *args, **kwargs)\n\n        # \u8bbe\u7f6e\u8ba1\u7b97\u56fe\u8fde\u63a5\n        instance.is_tuple_result = isinstance(result, tuple)\n\n        if instance.is_tuple_result:\n            for idx, res in enumerate(result):\n                if isinstance(res, Tensor) and res.requires_grad:\n                    res.set_creator(instance, idx)\n        elif isinstance(result, Tensor) and result.requires_grad:\n            result.set_creator(instance)\n\n        # \u8bb0\u5f55\u8f93\u5165\u5f20\u91cf\n        instance.inputs = []\n        for t in args:\n            if isinstance(t, Tensor):\n                instance.inputs.append(t)\n            elif isinstance(t, list) and all(isinstance(item, Tensor) for item in t):\n                instance.inputs.extend(t)\n\n        return result\n</code></pre>"},{"location":"core-components/autograd/#_7","title":"\u5b9e\u9645\u64cd\u4f5c\u793a\u4f8b","text":""},{"location":"core-components/autograd/#_8","title":"\u77e9\u9635\u4e58\u6cd5","text":"Python<pre><code>class MatMul(Function):\n    @staticmethod\n    def forward(ctx, a, b):\n        # \u4fdd\u5b58\u8f93\u5165\u7528\u4e8e\u53cd\u5411\u4f20\u64ad\n        ctx.save_for_backward(a, b)\n        return a @ b  # \u8c03\u7528\u5e95\u5c42NDArray\u7684\u77e9\u9635\u4e58\u6cd5\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        a, b = ctx.saved_tensors\n        # \u8ba1\u7b97\u8f93\u5165\u68af\u5ea6\n        grad_a = grad_output @ b.T\n        grad_b = a.T @ grad_output\n        return grad_a, grad_b\n</code></pre>"},{"location":"core-components/autograd/#_9","title":"\u52a0\u6cd5\uff08\u652f\u6301\u5e7f\u64ad\uff09","text":"Python<pre><code>class Add(Function):\n    @staticmethod\n    def forward(ctx, a, b):\n        ctx.a_shape = a.shape\n        ctx.b_shape = b.shape\n        return a + b\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        # \u5904\u7406\u5e7f\u64ad\u7684\u68af\u5ea6\n        grad_a = grad_output\n        grad_b = grad_output\n\n        # \u5bf9\u88ab\u5e7f\u64ad\u7684\u7ef4\u5ea6\u6c42\u548c\n        for i, (da, db) in enumerate(zip(ctx.a_shape, ctx.b_shape)):\n            if da == 1 and db &gt; 1:\n                grad_a = grad_a.sum(axis=i, keepdims=True)\n            elif db == 1 and da &gt; 1:\n                grad_b = grad_b.sum(axis=i, keepdims=True)\n\n        return grad_a, grad_b\n</code></pre>"},{"location":"core-components/autograd/#context","title":"\ud83d\udcdd Context\u7c7b","text":"<p>Context\u7c7b\u7528\u4e8e\u5728\u524d\u5411\u4f20\u64ad\u548c\u53cd\u5411\u4f20\u64ad\u4e4b\u95f4\u4f20\u9012\u4fe1\u606f\u3002</p> Python<pre><code>class Context:\n    def __init__(self):\n        self.saved_tensors = []\n\n    def save_for_backward(self, *tensors):\n        \"\"\"\u4fdd\u5b58\u5f20\u91cf\u7528\u4e8e\u53cd\u5411\u4f20\u64ad\"\"\"\n        self.saved_tensors.extend(tensors)\n\n    @property\n    def saved_tensors(self):\n        return self._saved_tensors\n\n    @saved_tensors.setter  \n    def saved_tensors(self, tensors):\n        self._saved_tensors = tensors\n</code></pre>"},{"location":"core-components/autograd/#_10","title":"\ud83d\udd04 \u6df7\u5408\u7cbe\u5ea6\u652f\u6301","text":"<p>\u81ea\u52a8\u5fae\u5206\u7cfb\u7edf\u5185\u7f6e\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u652f\u6301\uff1a</p> Python<pre><code># \u5168\u5c40\u5f00\u5173\ngenesis.enable_autocast = True\n\n# \u81ea\u52a8\u7c7b\u578b\u8f6c\u6362\ndef _cast(value, dtype):\n    if isinstance(value, Tensor) and value.is_floating_point():\n        if dtype == genesis.float16:\n            return value.half()\n        else:\n            return value.float()\n    return value\n\n# \u5728Function.apply\u4e2d\u5e94\u7528\nif genesis.enable_autocast:\n    result = cls.forward(instance.ctx, *_cast(args, genesis.float32), **_cast(kwargs, genesis.float32))\n</code></pre>"},{"location":"core-components/autograd/#_11","title":"\ud83e\ude9d \u68af\u5ea6\u94a9\u5b50\u7cfb\u7edf","text":"<p>\u652f\u6301\u5728\u68af\u5ea6\u8ba1\u7b97\u65f6\u6267\u884c\u81ea\u5b9a\u4e49\u51fd\u6570\uff1a</p> Python<pre><code>class Tensor:\n    def register_hook(self, hook):\n        \"\"\"\u6ce8\u518c\u68af\u5ea6\u94a9\u5b50\"\"\"\n        self.hooks.append(hook)\n\n    def apply_hooks(self, grad):\n        \"\"\"\u5e94\u7528\u6240\u6709\u94a9\u5b50\"\"\"\n        for hook in self.hooks:\n            hook(grad)\n\n# \u4f7f\u7528\u793a\u4f8b\ndef grad_clipping_hook(grad):\n    \"\"\"\u68af\u5ea6\u88c1\u526a\u94a9\u5b50\"\"\"\n    grad.clamp_(-1.0, 1.0)\n\ntensor.register_hook(grad_clipping_hook)\n</code></pre>"},{"location":"core-components/autograd/#_12","title":"\ud83d\ude80 \u6027\u80fd\u4f18\u5316","text":""},{"location":"core-components/autograd/#1_1","title":"1. \u5185\u5b58\u7ba1\u7406\u4f18\u5316","text":"<ul> <li>\u89c6\u56fe\u64cd\u4f5c\uff1areshape\u3001transpose\u7b49\u64cd\u4f5c\u521b\u5efa\u89c6\u56fe\u800c\u975e\u62f7\u8d1d\u6570\u636e</li> <li>\u5c31\u5730\u64cd\u4f5c\uff1a\u652f\u6301<code>+=</code>\u3001<code>*=</code>\u7b49\u5c31\u5730\u66f4\u65b0\u64cd\u4f5c</li> <li>\u68af\u5ea6\u7d2f\u79ef\u4f18\u5316\uff1a\u667a\u80fd\u7684\u68af\u5ea6\u7d2f\u79ef\u7b56\u7565</li> </ul>"},{"location":"core-components/autograd/#2_1","title":"2. \u8ba1\u7b97\u56fe\u4f18\u5316","text":"<ul> <li>\u60f0\u6027\u6784\u5efa\uff1a\u53ea\u6709\u5728\u9700\u8981\u68af\u5ea6\u65f6\u624d\u6784\u5efa\u8ba1\u7b97\u56fe</li> <li>\u667a\u80fd\u91ca\u653e\uff1a\u81ea\u52a8\u91ca\u653e\u4e0d\u518d\u9700\u8981\u7684\u4e2d\u95f4\u7ed3\u679c</li> <li>\u62d3\u6251\u6392\u5e8f\u7f13\u5b58\uff1a\u7f13\u5b58\u62d3\u6251\u6392\u5e8f\u7ed3\u679c</li> </ul>"},{"location":"core-components/autograd/#3_1","title":"3. \u8bbe\u5907\u95f4\u4f18\u5316","text":"<ul> <li>\u81ea\u52a8\u8bbe\u5907\u63a8\u65ad\uff1a\u81ea\u52a8\u9009\u62e9\u5408\u9002\u7684\u8ba1\u7b97\u8bbe\u5907</li> <li>\u5f02\u6b65\u6267\u884c\uff1a\u652f\u6301GPU\u5f02\u6b65\u8ba1\u7b97</li> <li>\u5185\u5b58\u9884\u5206\u914d\uff1a\u51cf\u5c11\u52a8\u6001\u5185\u5b58\u5206\u914d</li> </ul>"},{"location":"core-components/autograd/#_13","title":"\ud83c\udfaf \u4f7f\u7528\u793a\u4f8b","text":""},{"location":"core-components/autograd/#_14","title":"\u57fa\u7840\u7528\u6cd5","text":"Python<pre><code>import genesis\n\n# \u521b\u5efa\u9700\u8981\u68af\u5ea6\u7684\u5f20\u91cf\nx = genesis.randn(3, 4, requires_grad=True)\ny = genesis.randn(4, 2, requires_grad=True)\n\n# \u524d\u5411\u4f20\u64ad\uff08\u81ea\u52a8\u6784\u5efa\u8ba1\u7b97\u56fe\uff09\nz = x @ y\nloss = z.sum()\n\n# \u53cd\u5411\u4f20\u64ad\uff08\u8ba1\u7b97\u6240\u6709\u68af\u5ea6\uff09\nloss.backward()\n\nprint(f\"x\u7684\u68af\u5ea6: {x.grad}\")  # \u8f93\u51fax\u7684\u68af\u5ea6\nprint(f\"y\u7684\u68af\u5ea6: {y.grad}\")  # \u8f93\u51fay\u7684\u68af\u5ea6\n</code></pre>"},{"location":"core-components/autograd/#_15","title":"\u81ea\u5b9a\u4e49\u64cd\u4f5c","text":"Python<pre><code>class CustomFunction(genesis.autograd.Function):\n    @staticmethod\n    def forward(ctx, input_tensor):\n        # \u81ea\u5b9a\u4e49\u524d\u5411\u8ba1\u7b97\n        ctx.save_for_backward(input_tensor)\n        result = input_tensor ** 2 + 2 * input_tensor + 1\n        return result\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        input_tensor, = ctx.saved_tensors\n        # \u81ea\u5b9a\u4e49\u68af\u5ea6\u8ba1\u7b97\uff1ad/dx(x^2 + 2x + 1) = 2x + 2\n        grad_input = grad_output * (2 * input_tensor + 2)\n        return grad_input\n\n# \u4f7f\u7528\u81ea\u5b9a\u4e49\u64cd\u4f5c\nx = genesis.randn(3, 4, requires_grad=True)\ny = CustomFunction.apply(x)\ny.sum().backward()\n</code></pre>"},{"location":"core-components/autograd/#_16","title":"\u68af\u5ea6\u94a9\u5b50","text":"Python<pre><code># \u68af\u5ea6\u76d1\u63a7\u94a9\u5b50\ndef monitor_grad(grad):\n    print(f\"\u68af\u5ea6\u7edf\u8ba1: \u5747\u503c={grad.mean():.4f}, \u6807\u51c6\u5dee={grad.std():.4f}\")\n\n# \u68af\u5ea6\u88c1\u526a\u94a9\u5b50\ndef clip_grad(grad):\n    grad.data.clamp_(-1.0, 1.0)\n\nx = genesis.randn(10, requires_grad=True)\nx.register_hook(monitor_grad)\nx.register_hook(clip_grad)\n\n# \u6267\u884c\u4e00\u4e9b\u8ba1\u7b97\ny = (x ** 3).sum()\ny.backward()  # \u4f1a\u89e6\u53d1\u94a9\u5b50\u51fd\u6570\n</code></pre> <p>Genesis\u7684\u81ea\u52a8\u5fae\u5206\u7cfb\u7edf\u8bbe\u8ba1\u7b80\u6d01\u800c\u5f3a\u5927\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u68af\u5ea6\u8ba1\u7b97\u57fa\u7840\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002</p>"},{"location":"core-components/cuda-enhancements/","title":"CUDA \u589e\u5f3a\u529f\u80fd","text":"<p>Genesis \u5728 CUDA \u652f\u6301\u65b9\u9762\u8fdb\u884c\u4e86\u91cd\u5927\u6539\u8fdb\uff0c\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u8bbe\u5907\u7ba1\u7406\u3001\u5185\u5b58\u64cd\u4f5c\u548c\u9519\u8bef\u5904\u7406\u529f\u80fd\u3002</p>"},{"location":"core-components/cuda-enhancements/#_1","title":"\u8bbe\u5907\u7ba1\u7406\u589e\u5f3a","text":""},{"location":"core-components/cuda-enhancements/#cuda_1","title":"\u65b0\u589e\u7684 CUDA \u51fd\u6570","text":""},{"location":"core-components/cuda-enhancements/#set_devicedevice","title":"<code>set_device(device)</code>","text":"<p>\u8bbe\u7f6e\u5f53\u524d CUDA \u8bbe\u5907\u3002</p> Python<pre><code>import genesis.cuda as cuda\n\n# \u8bbe\u7f6e\u5f53\u524d\u8bbe\u5907\u4e3a GPU 1\ncuda.set_device(1)\nprint(f\"\u5f53\u524d\u8bbe\u5907: {cuda.current_device()}\")\n</code></pre>"},{"location":"core-components/cuda-enhancements/#device_count","title":"<code>device_count()</code>","text":"<p>\u83b7\u53d6\u53ef\u7528 CUDA \u8bbe\u5907\u6570\u91cf\u3002</p> Python<pre><code>device_count = cuda.device_count()\nprint(f\"\u53ef\u7528GPU\u6570\u91cf: {device_count}\")\n</code></pre>"},{"location":"core-components/cuda-enhancements/#get_device_namedevice","title":"<code>get_device_name(device)</code>","text":"<p>\u83b7\u53d6\u6307\u5b9a\u8bbe\u5907\u7684\u540d\u79f0\u3002</p> Python<pre><code>device_name = cuda.get_device_name(0)\nprint(f\"\u8bbe\u5907 0 \u540d\u79f0: {device_name}\")\n</code></pre>"},{"location":"core-components/cuda-enhancements/#synchronizedevicenone","title":"<code>synchronize(device=None)</code>","text":"<p>\u540c\u6b65 CUDA \u64cd\u4f5c\uff0c\u786e\u4fdd\u6240\u6709 CUDA \u64cd\u4f5c\u5b8c\u6210\u3002</p> Python<pre><code># \u540c\u6b65\u5f53\u524d\u8bbe\u5907\ncuda.synchronize()\n\n# \u540c\u6b65\u6307\u5b9a\u8bbe\u5907\ncuda.synchronize(device=1)\n</code></pre>"},{"location":"core-components/cuda-enhancements/#_2","title":"\u8bbe\u5907\u5c5e\u6027\u589e\u5f3a","text":""},{"location":"core-components/cuda-enhancements/#device","title":"Device \u7c7b\u65b0\u5c5e\u6027","text":"Python<pre><code>device = genesis.device('cuda:0')\n\n# PyTorch \u517c\u5bb9\u7684\u5c5e\u6027\nprint(f\"\u8bbe\u5907\u7c7b\u578b: {device.type}\")      # 'cuda'\nprint(f\"\u8bbe\u5907\u7d22\u5f15: {device.index}\")     # 0\n</code></pre> <p>\u8fd9\u4e9b\u5c5e\u6027\u63d0\u4f9b\u4e86\u4e0e PyTorch \u7684\u5b8c\u5168\u517c\u5bb9\u6027\uff0c\u4f7f\u8fc1\u79fb\u66f4\u52a0\u5bb9\u6613\u3002</p>"},{"location":"core-components/cuda-enhancements/#_3","title":"\u5f20\u91cf\u9a8c\u8bc1\u529f\u80fd","text":""},{"location":"core-components/cuda-enhancements/#_4","title":"\u6570\u503c\u6709\u6548\u6027\u68c0\u67e5","text":"<p>Genesis \u73b0\u5728\u63d0\u4f9b\u5b8c\u6574\u7684\u5f20\u91cf\u6570\u503c\u6709\u6548\u6027\u68c0\u67e5\u529f\u80fd\uff1a</p>"},{"location":"core-components/cuda-enhancements/#isinftensor","title":"<code>isinf(tensor)</code>","text":"<p>\u68c0\u67e5\u5f20\u91cf\u4e2d\u7684\u65e0\u7a77\u5927\u503c\u3002</p> Python<pre><code>import genesis\n\ntensor = genesis.tensor([1.0, float('inf'), -float('inf'), 2.0], device='cuda')\ninf_mask = genesis.isinf(tensor)\nprint(inf_mask)  # [False, True, True, False]\n\n# \u68c0\u67e5\u662f\u5426\u6709\u65e0\u7a77\u5927\u503c\nhas_inf = genesis.isinf(tensor).any()\nif has_inf:\n    print(\"\u5f20\u91cf\u5305\u542b\u65e0\u7a77\u5927\u503c!\")\n</code></pre>"},{"location":"core-components/cuda-enhancements/#isnantensor","title":"<code>isnan(tensor)</code>","text":"<p>\u68c0\u67e5\u5f20\u91cf\u4e2d\u7684 NaN \u503c\u3002</p> Python<pre><code>tensor = genesis.tensor([1.0, float('nan'), 2.0, 3.0], device='cuda')\nnan_mask = genesis.isnan(tensor)\nprint(nan_mask)  # [False, True, False, False]\n\n# \u68c0\u67e5\u662f\u5426\u6709 NaN \u503c\nhas_nan = genesis.isnan(tensor).any()\nif has_nan:\n    print(\"\u5f20\u91cf\u5305\u542b NaN \u503c!\")\n</code></pre>"},{"location":"core-components/cuda-enhancements/#isfinitetensor","title":"<code>isfinite(tensor)</code>","text":"<p>\u68c0\u67e5\u5f20\u91cf\u4e2d\u7684\u6709\u9650\u503c\u3002</p> Python<pre><code>tensor = genesis.tensor([1.0, float('inf'), float('nan'), 2.0], device='cuda')\nfinite_mask = genesis.isfinite(tensor)\nprint(finite_mask)  # [True, False, False, True]\n\n# \u53ea\u4fdd\u7559\u6709\u9650\u503c\nfinite_tensor = tensor[finite_mask]\n</code></pre>"},{"location":"core-components/cuda-enhancements/#_5","title":"\u5728\u8bad\u7ec3\u4e2d\u7684\u5e94\u7528","text":"Python<pre><code>def check_model_gradients(model):\n    \"\"\"\u68c0\u67e5\u6a21\u578b\u68af\u5ea6\u7684\u6570\u503c\u7a33\u5b9a\u6027\"\"\"\n    for name, param in model.named_parameters():\n        if param.grad is not None:\n            if genesis.isnan(param.grad).any():\n                print(f\"\u8b66\u544a: {name} \u7684\u68af\u5ea6\u5305\u542b NaN!\")\n                return False\n            if genesis.isinf(param.grad).any():\n                print(f\"\u8b66\u544a: {name} \u7684\u68af\u5ea6\u5305\u542b\u65e0\u7a77\u5927\u503c!\")\n                return False\n    return True\n\n# \u8bad\u7ec3\u5faa\u73af\u4e2d\u4f7f\u7528\nfor batch in dataloader:\n    optimizer.zero_grad()\n    loss = model(batch)\n    loss.backward()\n\n    if not check_model_gradients(model):\n        print(\"\u8df3\u8fc7\u6b64\u6279\u6b21\u7531\u4e8e\u68af\u5ea6\u5f02\u5e38\")\n        continue\n\n    optimizer.step()\n</code></pre>"},{"location":"core-components/cuda-enhancements/#_6","title":"\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u589e\u5f3a","text":""},{"location":"core-components/cuda-enhancements/#gradscaler","title":"GradScaler \u6539\u8fdb","text":"Python<pre><code>import genesis.amp as amp\n\n# \u521b\u5efa\u68af\u5ea6\u7f29\u653e\u5668\nscaler = amp.GradScaler()\n\n# \u8bad\u7ec3\u5faa\u73af\nfor batch in dataloader:\n    with amp.autocast():\n        outputs = model(batch['input'])\n        loss = criterion(outputs, batch['target'])\n\n    # \u7f29\u653e\u635f\u5931\u5e76\u53cd\u5411\u4f20\u64ad\n    scaler.scale(loss).backward()\n\n    # \u68c0\u67e5\u68af\u5ea6\u6709\u6548\u6027\uff08\u73b0\u5728\u4f7f\u7528 genesis \u539f\u751f\u51fd\u6570\uff09\n    scaler.step(optimizer)  # \u5185\u90e8\u4f7f\u7528 genesis.isinf/isnan \u68c0\u67e5\n    scaler.update()\n</code></pre>"},{"location":"core-components/cuda-enhancements/#cuda_2","title":"CUDA \u5185\u5b58\u7ba1\u7406","text":""},{"location":"core-components/cuda-enhancements/#_7","title":"\u6539\u8fdb\u7684\u5185\u5b58\u5206\u914d","text":"Python<pre><code>import genesis.cuda as cuda\n\n# \u68c0\u67e5 CUDA \u53ef\u7528\u6027\nif cuda.is_available():\n    print(f\"CUDA \u53ef\u7528\uff0c\u8bbe\u5907\u6570\u91cf: {cuda.device_count()}\")\n\n    # \u83b7\u53d6\u5f53\u524d\u8bbe\u5907\u4fe1\u606f\n    current_dev = cuda.current_device()\n    device_name = cuda.get_device_name(current_dev)\n    print(f\"\u5f53\u524d\u8bbe\u5907: {current_dev} ({device_name})\")\n\n    # \u8bbe\u7f6e\u7279\u5b9a\u8bbe\u5907\n    cuda.set_device(0)\n\n    # \u540c\u6b65\u786e\u4fdd\u64cd\u4f5c\u5b8c\u6210\n    cuda.synchronize()\n</code></pre>"},{"location":"core-components/cuda-enhancements/#triton","title":"Triton \u5185\u6838\u4f18\u5316","text":""},{"location":"core-components/cuda-enhancements/#_8","title":"\u6570\u503c\u68c0\u67e5\u5185\u6838","text":"<p>Genesis \u5b9e\u73b0\u4e86\u9ad8\u6548\u7684 Triton \u5185\u6838\u7528\u4e8e\u6570\u503c\u68c0\u67e5\uff1a</p> Python<pre><code># \u9ad8\u6027\u80fd\u7684\u6570\u503c\u68c0\u67e5\uff08\u5185\u90e8\u5b9e\u73b0\uff09\n@triton.jit\ndef isinf_kernel(input_ptr, output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n    \"\"\"Triton kernel to check if elements are infinite\"\"\"\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets &lt; n_elements\n\n    # Load input values\n    x = tl.load(input_ptr + offsets, mask=mask)\n\n    # Check for infinity\n    finite_max = 3.4028235e+38  # Maximum finite float32 value\n    is_pos_inf = x &gt; finite_max\n    is_neg_inf = x &lt; -finite_max\n    result = is_pos_inf | is_neg_inf\n\n    # Store result as boolean\n    tl.store(output_ptr + offsets, result.to(tl.int8), mask=mask)\n</code></pre>"},{"location":"core-components/cuda-enhancements/#_9","title":"\u9519\u8bef\u5904\u7406\u6539\u8fdb","text":""},{"location":"core-components/cuda-enhancements/#cuda_3","title":"CUDA \u9519\u8bef\u68c0\u67e5","text":"Python<pre><code>import genesis.cuda as cuda\n\ntry:\n    # CUDA \u64cd\u4f5c\n    cuda.set_device(0)\n    cuda.synchronize()\nexcept RuntimeError as e:\n    if \"CUDA\" in str(e):\n        print(f\"CUDA \u9519\u8bef: {e}\")\n        # \u5904\u7406 CUDA \u9519\u8bef\n    else:\n        raise\n</code></pre>"},{"location":"core-components/cuda-enhancements/#_10","title":"\u8bbe\u5907\u53ef\u7528\u6027\u68c0\u67e5","text":"Python<pre><code>def safe_cuda_operation():\n    \"\"\"\u5b89\u5168\u7684 CUDA \u64cd\u4f5c\u793a\u4f8b\"\"\"\n    if not cuda.is_available():\n        print(\"CUDA \u4e0d\u53ef\u7528\uff0c\u4f7f\u7528 CPU\")\n        return genesis.device('cpu')\n\n    try:\n        device_count = cuda.device_count()\n        if device_count == 0:\n            print(\"\u6ca1\u6709\u53ef\u7528\u7684 CUDA \u8bbe\u5907\")\n            return genesis.device('cpu')\n\n        # \u9009\u62e9\u8bbe\u5907\n        cuda.set_device(0)\n        return genesis.device('cuda:0')\n\n    except RuntimeError as e:\n        print(f\"CUDA \u521d\u59cb\u5316\u5931\u8d25: {e}\")\n        return genesis.device('cpu')\n</code></pre>"},{"location":"core-components/cuda-enhancements/#_11","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"core-components/cuda-enhancements/#1","title":"1. \u6570\u503c\u7a33\u5b9a\u6027\u68c0\u67e5","text":"Python<pre><code>def validate_tensor(tensor, name=\"tensor\"):\n    \"\"\"\u9a8c\u8bc1\u5f20\u91cf\u6570\u503c\u7a33\u5b9a\u6027\"\"\"\n    if genesis.isnan(tensor).any():\n        raise ValueError(f\"{name} \u5305\u542b NaN \u503c\")\n    if genesis.isinf(tensor).any():\n        raise ValueError(f\"{name} \u5305\u542b\u65e0\u7a77\u5927\u503c\")\n    return True\n\n# \u5728\u5173\u952e\u70b9\u4f7f\u7528\nloss = criterion(outputs, targets)\nvalidate_tensor(loss, \"loss\")\n\ngradients = model.get_gradients()\nfor name, grad in gradients.items():\n    validate_tensor(grad, f\"gradient_{name}\")\n</code></pre>"},{"location":"core-components/cuda-enhancements/#2","title":"2. \u8bbe\u5907\u7ba1\u7406","text":"Python<pre><code>class DeviceManager:\n    \"\"\"\u8bbe\u5907\u7ba1\u7406\u5668\"\"\"\n\n    def __init__(self):\n        self.available_devices = []\n        self._detect_devices()\n\n    def _detect_devices(self):\n        \"\"\"\u68c0\u6d4b\u53ef\u7528\u8bbe\u5907\"\"\"\n        if cuda.is_available():\n            for i in range(cuda.device_count()):\n                device_name = cuda.get_device_name(i)\n                self.available_devices.append({\n                    'index': i,\n                    'name': device_name,\n                    'type': 'cuda'\n                })\n        else:\n            self.available_devices.append({\n                'index': None,\n                'name': 'CPU',\n                'type': 'cpu'\n            })\n\n    def get_best_device(self):\n        \"\"\"\u83b7\u53d6\u6700\u4f73\u8bbe\u5907\"\"\"\n        if self.available_devices and self.available_devices[0]['type'] == 'cuda':\n            cuda.set_device(0)\n            return genesis.device('cuda:0')\n        return genesis.device('cpu')\n\n# \u4f7f\u7528\u793a\u4f8b\ndevice_manager = DeviceManager()\ndevice = device_manager.get_best_device()\nmodel = model.to(device)\n</code></pre>"},{"location":"core-components/cuda-enhancements/#3","title":"3. \u5185\u5b58\u7ba1\u7406","text":"Python<pre><code>def memory_safe_operation(tensor, operation):\n    \"\"\"\u5185\u5b58\u5b89\u5168\u7684\u64cd\u4f5c\"\"\"\n    try:\n        # \u786e\u4fdd\u5728\u6b63\u786e\u8bbe\u5907\u4e0a\n        if tensor.device.type == 'cuda':\n            cuda.set_device(tensor.device.index)\n\n        # \u6267\u884c\u64cd\u4f5c\n        result = operation(tensor)\n\n        # \u540c\u6b65\u786e\u4fdd\u5b8c\u6210\n        if tensor.device.type == 'cuda':\n            cuda.synchronize()\n\n        return result\n\n    except RuntimeError as e:\n        if \"out of memory\" in str(e).lower():\n            print(\"GPU \u5185\u5b58\u4e0d\u8db3\uff0c\u5c1d\u8bd5\u6e05\u7406\")\n            # \u53ef\u4ee5\u6dfb\u52a0\u5185\u5b58\u6e05\u7406\u903b\u8f91\n        raise\n\n# \u4f7f\u7528\u793a\u4f8b\nresult = memory_safe_operation(tensor, lambda x: x.matmul(weight))\n</code></pre>"},{"location":"core-components/cuda-enhancements/#_12","title":"\u6027\u80fd\u76d1\u63a7","text":""},{"location":"core-components/cuda-enhancements/#cuda_4","title":"CUDA \u64cd\u4f5c\u6027\u80fd\u76d1\u63a7","text":"Python<pre><code>import time\n\ndef profile_cuda_operation(operation, tensor, name=\"operation\"):\n    \"\"\"\u5206\u6790 CUDA \u64cd\u4f5c\u6027\u80fd\"\"\"\n    if tensor.device.type == 'cuda':\n        cuda.synchronize()  # \u786e\u4fdd\u4e4b\u524d\u64cd\u4f5c\u5b8c\u6210\n\n    start_time = time.time()\n    result = operation(tensor)\n\n    if tensor.device.type == 'cuda':\n        cuda.synchronize()  # \u786e\u4fdd\u64cd\u4f5c\u5b8c\u6210\n\n    end_time = time.time()\n    print(f\"{name} \u8017\u65f6: {(end_time - start_time)*1000:.2f} ms\")\n\n    return result\n\n# \u4f7f\u7528\u793a\u4f8b\nresult = profile_cuda_operation(\n    lambda x: genesis.matmul(x, weight),\n    input_tensor,\n    \"\u77e9\u9635\u4e58\u6cd5\"\n)\n</code></pre> <p>\u8fd9\u4e9b CUDA \u589e\u5f3a\u529f\u80fd\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u8bbe\u5907\u7ba1\u7406\u3001\u6570\u503c\u7a33\u5b9a\u6027\u68c0\u67e5\u548c\u9519\u8bef\u5904\u7406\uff0c\u4f7f Genesis \u66f4\u52a0\u7a33\u5b9a\u548c\u6613\u7528\u3002</p>"},{"location":"core-components/cuda-memory/","title":"CUDA\u5185\u5b58\u7ba1\u7406","text":"<p>Genesis\u5305\u542b\u4e86\u4e00\u4e2a\u5148\u8fdb\u7684\u9ad8\u6027\u80fdCUDA\u5185\u5b58\u7ba1\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u6bb5-\u5757\u5206\u914d\u5668\u67b6\u6784\u548c\u5148\u8fdb\u7684\u7f13\u5b58\u7b56\u7565\u63d0\u4f9b\u9ad8\u6548\u7684GPU\u5185\u5b58\u5206\u914d\u3002</p>"},{"location":"core-components/cuda-memory/#_1","title":"\u6982\u8ff0","text":"<p>CUDA\u5185\u5b58\u7ba1\u7406\u5668\u662f\u4e00\u4e2a\u751f\u4ea7\u7ea7\u5185\u5b58\u5206\u914d\u5668\uff0c\u76f8\u6bd4\u7b80\u5355\u7684\u5206\u914d\u7b56\u7565\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u5b83\u5177\u6709\u4e24\u7ea7\u7f13\u5b58\u7cfb\u7edf\u3001\u6bb5-\u5757\u5206\u914d\u548c\u5168\u9762\u7684\u6027\u80fd\u76d1\u63a7\u529f\u80fd\u3002</p>"},{"location":"core-components/cuda-memory/#_2","title":"\u67b6\u6784","text":""},{"location":"core-components/cuda-memory/#_3","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"core-components/cuda-memory/#cuda_1","title":"CUDA\u5185\u5b58\u7ba1\u7406\u5668","text":"<p>\u5177\u6709\u4f01\u4e1a\u7ea7\u7279\u6027\u7684\u4e3b\u8981\u5185\u5b58\u7ba1\u7406\u5668\u7c7b\uff1a - \u6bb5-\u5757\u5206\u914d\u5668\uff1a\u5206\u5c42\u5185\u5b58\u7ec4\u7ec7\u4ee5\u5b9e\u73b0\u9ad8\u6548\u5206\u914d - \u4e24\u7ea7\u7f13\u5b58\uff1a\u6d41\u672c\u5730\u7f13\u5b58 + \u5168\u5c40\u7f13\u5b58\u4ee5\u5b9e\u73b0\u6700\u5927\u6027\u80fd - \u9884\u70ed\u7f13\u5b58\uff1a\u5e38\u89c1\u5206\u914d\u6a21\u5f0f\u7684\u9884\u5206\u914d\u7b56\u7565 - \u6027\u80fd\u76d1\u63a7\uff1a\u8be6\u7ec6\u7684\u7edf\u8ba1\u548c\u57fa\u51c6\u6d4b\u8bd5\u529f\u80fd - \u6df7\u5408\u5206\u914d\u7b56\u7565\uff1a\u9488\u5bf9\u5c0f\u578b\u4e0e\u5927\u578b\u5206\u914d\u7684\u4f18\u5316\u8def\u5f84</p>"},{"location":"core-components/cuda-memory/#-","title":"\u6bb5-\u5757\u67b6\u6784","text":"Python<pre><code>@dataclass\nclass Block:\n    \"\"\"\n    \u6bb5\u5185\u7684\u5355\u4e2a\u5185\u5b58\u5757\n    \"\"\"\n    ptr: int          # GPU\u6307\u9488\n    size: int         # \u5757\u5927\u5c0f  \n    is_free: bool     # \u53ef\u7528\u72b6\u6001\n    segment_id: int   # \u7236\u6bb5ID\n\nclass Segment:\n    \"\"\"\n    \u5305\u542b\u591a\u4e2a\u5757\u7684\u5927\u578b\u8fde\u7eed\u5185\u5b58\u533a\u57df\n    \"\"\"\n    def __init__(self, segment_id: int, size: int):\n        # \u4eceCUDA\u5206\u914d\u6574\u4e2a\u6bb5\n        self.base_ptr = _ok(cuda.cuMemAlloc(size))\n\n        # \u5c06\u5185\u5b58\u521d\u59cb\u5316\u4e3a\u96f6\uff08\u9632\u6b62\u810f\u6570\u636e\u7cbe\u5ea6\u95ee\u9898\uff09\n        _ok(cuda.cuMemsetD8(self.base_ptr, 0, size))\n\n        # \u5f00\u59cb\u4f5c\u4e3a\u5355\u4e2a\u5927\u7684\u7a7a\u95f2\u5757\n        self.blocks: List[Block] = [...]\n        self.free_blocks_by_size: Dict[int, List[Block]] = {...}\n</code></pre>"},{"location":"core-components/cuda-memory/#_4","title":"\u5173\u952e\u7279\u6027","text":""},{"location":"core-components/cuda-memory/#1-","title":"1. \u9ad8\u6027\u80fd\u6bb5-\u5757\u5206\u914d","text":"<ul> <li>\u6700\u4f73\u9002\u914d\u7b97\u6cd5\uff1a\u627e\u5230\u6700\u4f18\u5757\u5927\u5c0f\u4ee5\u6700\u5c0f\u5316\u788e\u7247</li> <li>\u5757\u5206\u5272\uff1a\u5927\u5757\u81ea\u52a8\u5206\u5272\u4ee5\u6ee1\u8db3\u7cbe\u786e\u5927\u5c0f\u8bf7\u6c42</li> <li>\u5757\u5408\u5e76\uff1a\u76f8\u90bb\u7a7a\u95f2\u5757\u5408\u5e76\u4ee5\u9632\u6b62\u788e\u7247</li> <li>\u57fa\u4e8e\u5927\u5c0f\u7684\u7d22\u5f15\uff1a\u6309\u5927\u5c0fO(1)\u67e5\u627e\u7a7a\u95f2\u5757</li> </ul>"},{"location":"core-components/cuda-memory/#2","title":"2. \u4e24\u7ea7\u7f13\u5b58\u7cfb\u7edf","text":"Python<pre><code>class TwoLevelCache:\n    \"\"\"\n    \u5177\u6709\u6d41\u672c\u5730\u548c\u5168\u5c40\u7ea7\u522b\u7684\u5148\u8fdb\u7f13\u5b58\n    \"\"\"\n    def __init__(self):\n        self.stream_cache: Dict[int, Dict[int, List[int]]] = {}  # stream_id -&gt; size -&gt; [ptrs]\n        self.global_cache: Dict[int, List[int]] = {}             # size -&gt; [ptrs]\n        self.cache_stats = CacheStatistics()\n</code></pre> <p>\u6d41\u672c\u5730\u7f13\u5b58\uff1a - \u9488\u5bf9CUDA\u6d41\u6548\u7387\u7684\u6bcf\u6d41\u5757\u7f13\u5b58 - \u907f\u514d\u8de8\u6d41\u540c\u6b65\u5f00\u9500 - \u5bf9\u91cd\u590d\u5206\u914d\u6a21\u5f0f\u6700\u4f18</p> <p>\u5168\u5c40\u7f13\u5b58\uff1a - \u6240\u6709\u6d41\u4e4b\u95f4\u7684\u5171\u4eab\u7f13\u5b58 - \u6d41\u672c\u5730\u7f13\u5b58\u672a\u547d\u4e2d\u65f6\u7684\u56de\u9000 - \u6700\u5927\u5316\u8de8\u64cd\u4f5c\u7684\u5185\u5b58\u91cd\u7528</p>"},{"location":"core-components/cuda-memory/#3","title":"3. \u9884\u70ed\u7f13\u5b58\u9884\u5206\u914d","text":"Python<pre><code>def warmup_cache(self, sizes: List[int], counts: List[int]):\n    \"\"\"\n    \u7528\u5e38\u89c1\u5206\u914d\u5927\u5c0f\u9884\u586b\u5145\u7f13\u5b58\n\n    \u9488\u5bf9\u5df2\u77e5\u5206\u914d\u6a21\u5f0f\u7684\u6027\u80fd\u4f18\u5316\uff1a\n    - Transformer\u6ce8\u610f\u529b\u77e9\u9635\n    - \u5d4c\u5165\u67e5\u627e  \n    - \u68af\u5ea6\u7f13\u51b2\u533a\n    \"\"\"\n    for size, count in zip(sizes, counts):\n        for _ in range(count):\n            ptr = self.allocate_segment_block(size)\n            self.add_to_cache(ptr, size)\n</code></pre>"},{"location":"core-components/cuda-memory/#4","title":"4. \u81ea\u9002\u5e94\u5206\u914d\u7b56\u7565","text":"Python<pre><code>def allocate_memory(self, size: int) -&gt; int:\n    \"\"\"\n    \u9488\u5bf9\u4e0d\u540c\u5927\u5c0f\u8303\u56f4\u4f18\u5316\u7684\u6df7\u5408\u5206\u914d\u7b56\u7565\n    \"\"\"\n    if size &lt; self.SMALL_BLOCK_THRESHOLD:\n        # \u5c0f\u5206\u914d\uff1a\u4f18\u5148\u7f13\u5b58\u547d\u4e2d\n        return self.allocate_from_cache(size) or self.allocate_segment_block(size)\n    else:\n        # \u5927\u5206\u914d\uff1a\u76f4\u63a5\u6bb5\u5206\u914d\n        return self.allocate_large_block(size)\n</code></pre>"},{"location":"core-components/cuda-memory/#_5","title":"\u6027\u80fd\u7279\u5f81","text":""},{"location":"core-components/cuda-memory/#vs-pytorch","title":"\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\uff08vs PyTorch\uff09","text":"\u573a\u666f Genesis\u6027\u80fd \u72b6\u6001 \u76f8\u540c\u5927\u5c0f\u5206\u914d 1.43\u500d\u66f4\u5feb \u2705 \u4f18\u79c0 \u5927\u5185\u5b58(&gt;1MB) 3.92\u500d\u66f4\u5feb \u2705\u6770\u51fa Transformer\u8bad\u7ec3 1.89\u500d\u66f4\u5feb \u2705 \u4f18\u79c0 \u5185\u5b58\u538b\u529b 4.83\u500d\u66f4\u5feb \u2705 \u6770\u51fa \u53d8\u5316\u5927\u5c0f 0.83\u500d\uff08\u66f4\u6162\uff09 \ud83d\udd04 \u4f18\u5316\u76ee\u6807"},{"location":"core-components/cuda-memory/#_6","title":"\u5185\u5b58\u6548\u7387\u6539\u8fdb","text":"<ol> <li> <p>\u6d88\u9664cudaMalloc/cudaFree\u5f00\u9500\uff1a    Python<pre><code># \u4e4b\u524d\uff1a\u76f4\u63a5CUDA\u8c03\u7528\uff08\u6162\uff09\nptr = cuda.cuMemAlloc(size)  # ~100\u03bcs \u5f00\u9500\n\n# \u4e4b\u540e\uff1a\u57fa\u4e8e\u7f13\u5b58\u7684\u5206\u914d\uff08\u5feb\uff09\nptr = cache.get(size) or segment.allocate(size)  # ~1\u03bcs \u5f00\u9500\n</code></pre></p> </li> <li> <p>\u51cf\u5c11\u5185\u5b58\u788e\u7247\uff1a</p> </li> <li>\u5757\u5408\u5e76\u9632\u6b62\u788e\u7247</li> <li>\u6700\u4f73\u9002\u914d\u5206\u914d\u6700\u5c0f\u5316\u6d6a\u8d39</li> <li> <p>\u6bb5\u7ec4\u7ec7\u6539\u5584\u5c40\u90e8\u6027</p> </li> <li> <p>\u9488\u5bf9ML\u5de5\u4f5c\u8d1f\u8f7d\u4f18\u5316\uff1a</p> </li> <li>\u5e38\u89c1\u5f20\u91cf\u5927\u5c0f\u7684\u9884\u70ed\u7f13\u5b58</li> <li>\u5e76\u884c\u64cd\u4f5c\u7684\u6d41\u611f\u77e5\u5206\u914d</li> <li>\u591a\u5f20\u91cf\u64cd\u4f5c\u7684\u6279\u91cf\u5206\u914d\u652f\u6301</li> </ol>"},{"location":"core-components/cuda-memory/#_7","title":"\u9ad8\u7ea7\u7279\u6027","text":""},{"location":"core-components/cuda-memory/#1","title":"1. \u6027\u80fd\u76d1\u63a7","text":"Python<pre><code>@dataclass\nclass AllocationStatistics:\n    \"\"\"\u5168\u9762\u7684\u5206\u914d\u8ddf\u8e2a\"\"\"\n    total_allocations: int = 0\n    total_freed: int = 0\n    peak_memory_usage: int = 0\n    cache_hits: int = 0\n    cache_misses: int = 0\n    fragmentation_ratio: float = 0.0\n\n    def efficiency_score(self) -&gt; float:\n        \"\"\"\u8ba1\u7b97\u5185\u5b58\u7ba1\u7406\u5668\u6548\u7387\uff080-1\uff09\"\"\"\n        if self.total_allocations == 0:\n            return 1.0\n        return self.cache_hits / self.total_allocations\n</code></pre>"},{"location":"core-components/cuda-memory/#2_1","title":"2. \u5185\u5b58\u6c60\u4f18\u5316","text":"Python<pre><code>class AsyncMemoryPool:\n    \"\"\"\n    \u9ad8\u541e\u5410\u91cf\u573a\u666f\u7684\u5f02\u6b65\u5185\u5b58\u6c60\n    \"\"\"\n    def __init__(self, pool_size: int = 1024 * 1024 * 1024):  # \u9ed8\u8ba41GB\n        self.pool = MemoryPool(pool_size)\n        self.allocation_queue = AsyncQueue()\n        self.background_worker = Thread(target=self._allocation_worker)\n\n    def allocate_async(self, size: int) -&gt; Future[int]:\n        \"\"\"\u7ba1\u9053\u5e76\u884c\u7684\u975e\u963b\u585e\u5206\u914d\"\"\"\n        return self.allocation_queue.submit(self._allocate, size)\n</code></pre>"},{"location":"core-components/cuda-memory/#3_1","title":"3. \u6279\u91cf\u5206\u914d\u652f\u6301","text":"Python<pre><code>def allocate_batch(self, sizes: List[int]) -&gt; List[int]:\n    \"\"\"\n    \u591a\u5f20\u91cf\u64cd\u4f5c\u7684\u4f18\u5316\u6279\u91cf\u5206\u914d\n\n    \u4f18\u52bf\uff1a\n    - \u51cf\u5c11\u5206\u914d\u5f00\u9500\n    - \u66f4\u597d\u7684\u5185\u5b58\u5c40\u90e8\u6027  \n    - \u81ea\u52a8\u5927\u5c0f\u4f18\u5316\n    \"\"\"\n    # \u6309\u76f8\u4f3c\u5927\u5c0f\u5206\u7ec4\u4ee5\u9ad8\u6548\u4f7f\u7528\u6bb5\n    size_groups = self._group_by_size(sizes)\n\n    ptrs = []\n    for size_group in size_groups:\n        segment = self._find_or_create_segment(size_group.total_size)\n        group_ptrs = segment.allocate_batch(size_group.sizes)\n        ptrs.extend(group_ptrs)\n\n    return ptrs\n</code></pre>"},{"location":"core-components/cuda-memory/#_8","title":"\u5185\u5b58\u7ba1\u7406\u6a21\u5f0f","text":""},{"location":"core-components/cuda-memory/#1-transformer","title":"1. Transformer\u8bad\u7ec3\u4f18\u5316","text":"Python<pre><code># Transformer\u8bad\u7ec3\u7684\u4f18\u5316\u5185\u5b58\u5206\u914d\ndef allocate_transformer_tensors(batch_size: int, seq_len: int, hidden_size: int):\n    \"\"\"\n    \u9884\u5206\u914d\u5e38\u89c1\u7684transformer\u5f20\u91cf\u5927\u5c0f\n    \"\"\"\n    common_sizes = [\n        batch_size * seq_len * hidden_size,      # \u6ce8\u610f\u529b\u6743\u91cd\n        batch_size * seq_len * hidden_size * 4,  # \u524d\u9988\n        batch_size * seq_len * seq_len,          # \u6ce8\u610f\u529b\u5206\u6570\n    ]\n\n    # \u7528\u9884\u671f\u5206\u914d\u6a21\u5f0f\u9884\u70ed\u7f13\u5b58\n    memory_manager.warmup_cache(common_sizes, counts=[10, 5, 10])\n</code></pre>"},{"location":"core-components/cuda-memory/#2_2","title":"2. \u52a8\u6001\u5185\u5b58\u7f29\u653e","text":"Python<pre><code>def adaptive_memory_management(memory_pressure: float):\n    \"\"\"\n    \u6839\u636e\u5185\u5b58\u538b\u529b\u81ea\u52a8\u8c03\u6574\u7f13\u5b58\u5927\u5c0f\n    \"\"\"\n    if memory_pressure &gt; 0.8:\n        # \u9ad8\u538b\u529b\uff1a\u6fc0\u8fdb\u7684\u7f13\u5b58\u6e05\u7406\n        memory_manager.cleanup_cache(threshold=0.9)\n        memory_manager.enable_aggressive_coalescing()\n    elif memory_pressure &lt; 0.3:\n        # \u4f4e\u538b\u529b\uff1a\u6269\u5c55\u7f13\u5b58\u4ee5\u83b7\u5f97\u66f4\u597d\u6027\u80fd\n        memory_manager.expand_cache_size(factor=1.5)\n</code></pre>"},{"location":"core-components/cuda-memory/#_9","title":"\u4f7f\u7528\u793a\u4f8b","text":""},{"location":"core-components/cuda-memory/#_10","title":"\u57fa\u7840\u5206\u914d","text":"Python<pre><code>from genesis.ndarray.cuda_memory_manager import get_memory_manager\n\n# \u83b7\u53d6\u5168\u5c40\u5185\u5b58\u7ba1\u7406\u5668\u5b9e\u4f8b\nmm = get_memory_manager()\n\n# \u5206\u914dGPU\u5185\u5b58\nptr = mm.allocate_memory(1024 * 1024)  # 1MB\n\n# \u91ca\u653e\u5185\u5b58\uff08\u81ea\u52a8\u7f13\u5b58\uff09\nmm.free_memory(ptr, 1024 * 1024)\n\n# \u68c0\u67e5\u7edf\u8ba1\nstats = mm.get_statistics()\nprint(f\"\u7f13\u5b58\u547d\u4e2d\u7387: {stats.cache_hit_rate:.2%}\")\nprint(f\"\u5185\u5b58\u6548\u7387: {stats.efficiency_score():.2%}\")\n</code></pre>"},{"location":"core-components/cuda-memory/#_11","title":"\u9ad8\u7ea7\u914d\u7f6e","text":"Python<pre><code># \u4e3a\u7279\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u914d\u7f6e\u5185\u5b58\u7ba1\u7406\u5668\nmm.configure(\n    segment_size=512 * 1024 * 1024,    # 512MB\u6bb5\n    cache_sizes={\n        'stream_local': 100,            # \u6bcf\u6d41100\u4e2a\u5757\n        'global': 500,                  # \u5168\u5c40\u7f13\u5b58500\u4e2a\u5757\n    },\n    warmup_sizes=[\n        (4096, 50),    # 50\u4e2a4KB\u5757\n        (65536, 20),   # 20\u4e2a64KB\u5757  \n        (1048576, 10), # 10\u4e2a1MB\u5757\n    ]\n)\n</code></pre>"},{"location":"core-components/cuda-memory/#_12","title":"\u6027\u80fd\u76d1\u63a7","text":"Python<pre><code># \u542f\u7528\u8be6\u7ec6\u6027\u80fd\u8ddf\u8e2a\nwith mm.performance_context() as perf:\n    # \u8fd0\u884c\u5185\u5b58\u5bc6\u96c6\u578b\u64cd\u4f5c\n    tensors = [genesis.randn(1000, 1000) for _ in range(100)]\n\n# \u5206\u6790\u6027\u80fd\nprint(f\"\u603b\u5206\u914d\u6570: {perf.stats.total_allocations}\")\nprint(f\"\u5cf0\u503c\u5185\u5b58: {perf.stats.peak_memory_usage / 1024**3:.2f} GB\")\nprint(f\"\u788e\u7247\u5316: {perf.stats.fragmentation_ratio:.2%}\")\n</code></pre>"},{"location":"core-components/cuda-memory/#_13","title":"\u914d\u7f6e\u548c\u8c03\u4f18","text":""},{"location":"core-components/cuda-memory/#_14","title":"\u73af\u5883\u53d8\u91cf","text":"Bash<pre><code># \u5185\u5b58\u7ba1\u7406\u5668\u914d\u7f6e\nexport GENESIS_CUDA_SEGMENT_SIZE=1073741824     # 1GB\u6bb5\nexport GENESIS_CUDA_CACHE_SIZE=1000             # \u7f13\u5b581000\u4e2a\u5757\nexport GENESIS_CUDA_WARMUP_ENABLED=true         # \u542f\u7528\u9884\u70ed\nexport GENESIS_CUDA_STATS_ENABLED=true          # \u542f\u7528\u7edf\u8ba1\n</code></pre>"},{"location":"core-components/cuda-memory/#_15","title":"\u8fd0\u884c\u65f6\u914d\u7f6e","text":"Python<pre><code># \u8fd0\u884c\u65f6\u914d\u7f6e\ngenesis.cuda.configure_memory_manager({\n    'segment_size': 1024 * 1024 * 1024,  # 1GB\n    'enable_warmup': True,\n    'enable_stats': True,\n    'allocation_strategy': 'best_fit',\n    'coalescing_threshold': 0.1,\n})\n</code></pre>"},{"location":"core-components/cuda-memory/#_16","title":"\u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u4f7f\u7528\u9884\u70ed\u7f13\u5b58\uff1a\u9884\u5206\u914d\u5e38\u89c1\u5927\u5c0f\u4ee5\u83b7\u5f9738\u500d\u6027\u80fd\u63d0\u5347</li> <li>\u76d1\u63a7\u7edf\u8ba1\uff1a\u8ddf\u8e2a\u7f13\u5b58\u547d\u4e2d\u7387\u548c\u5185\u5b58\u6548\u7387</li> <li>\u6279\u91cf\u5206\u914d\uff1a\u5c06\u76f8\u4f3c\u64cd\u4f5c\u5206\u7ec4\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u5c40\u90e8\u6027</li> <li>\u907f\u514d\u9891\u7e41\u7684\u5c0f\u5206\u914d\uff1a\u5bf9\u4e8e\u5fae\u5c0f\u5757\uff0c\u7f13\u5b58\u5f00\u9500\u5360\u4e3b\u5bfc</li> <li>\u4f7f\u7528\u9002\u5f53\u7684\u6bb5\u5927\u5c0f\uff1a\u5c06\u6bb5\u5927\u5c0f\u4e0e\u5de5\u4f5c\u8d1f\u8f7d\u5185\u5b58\u6a21\u5f0f\u5339\u914d</li> </ol>"},{"location":"core-components/cuda-memory/#_17","title":"\u6545\u969c\u6392\u9664","text":""},{"location":"core-components/cuda-memory/#_18","title":"\u5185\u5b58\u6cc4\u6f0f","text":"Python<pre><code># \u8c03\u8bd5\u5185\u5b58\u6cc4\u6f0f\nstats = mm.get_statistics()\nif stats.total_allocations &gt; stats.total_freed + 1000:\n    print(\"\u8b66\u544a\uff1a\u68c0\u6d4b\u5230\u6f5c\u5728\u5185\u5b58\u6cc4\u6f0f\")\n    mm.dump_allocation_trace()\n</code></pre>"},{"location":"core-components/cuda-memory/#_19","title":"\u6027\u80fd\u95ee\u9898","text":"Python<pre><code># \u8bca\u65ad\u6027\u80fd\u95ee\u9898\nif stats.cache_hit_rate &lt; 0.5:\n    print(\"\u7f13\u5b58\u547d\u4e2d\u7387\u4f4e - \u8003\u8651\u9884\u70ed\u7f13\u5b58\")\n    mm.analyze_allocation_patterns()\n\nif stats.fragmentation_ratio &gt; 0.3:\n    print(\"\u9ad8\u788e\u7247\u5316 - \u542f\u7528\u6fc0\u8fdb\u5408\u5e76\")\n    mm.enable_aggressive_coalescing()\n</code></pre>"},{"location":"core-components/cuda-memory/#_20","title":"\u5185\u5b58\u538b\u529b","text":"Python<pre><code># \u5904\u7406\u5185\u5b58\u538b\u529b\ndef handle_oom():\n    \"\"\"\u5185\u5b58\u4e0d\u8db3\u5904\u7406\u7a0b\u5e8f\"\"\"\n    mm.cleanup_cache(force=True)\n    mm.coalesce_free_blocks()\n    mm.garbage_collect()\n</code></pre>"},{"location":"core-components/cuda-memory/#genesis","title":"\u4e0eGenesis\u7684\u96c6\u6210","text":"<p>\u5185\u5b58\u7ba1\u7406\u5668\u4e0eGenesis\u5f20\u91cf\u548c\u64cd\u4f5c\u65e0\u7f1d\u96c6\u6210\uff1a</p> Python<pre><code># \u4e0e\u5f20\u91cf\u64cd\u4f5c\u7684\u81ea\u52a8\u96c6\u6210\nx = genesis.randn(1000, 1000)  # \u81ea\u52a8\u4f7f\u7528\u5185\u5b58\u7ba1\u7406\u5668\ny = genesis.matmul(x, x)       # \u9ad8\u6548\u5185\u5b58\u91cd\u7528\nz = x + y                      # \u7f13\u5b58\u4f18\u5316\u5206\u914d\n</code></pre> <p>\u8fd9\u4e2a\u5148\u8fdb\u7684\u5185\u5b58\u7ba1\u7406\u7cfb\u7edf\u662fGenesis\u5728\u4fdd\u6301\u4ece\u96f6\u5f00\u59cb\u5b9e\u73b0\u7684\u6559\u80b2\u6e05\u6670\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u63a5\u8fd1PyTorch\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002</p>"},{"location":"core-components/cuda-storage/","title":"CUDA\u5b58\u50a8\u7cfb\u7edf","text":"<p>Genesis\u7684CUDA\u5b58\u50a8\uff08CUDAStorage\uff09\u662f\u6846\u67b6\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u63d0\u4f9b\u7eafCUDA\u5b9e\u73b0\u7684GPU\u5185\u5b58\u7ba1\u7406\u548c\u64cd\u4f5c\uff0c\u5b8c\u5168\u72ec\u7acb\u4e8ePyTorch\uff0c\u76f4\u63a5\u4f7f\u7528CUDA Python API\u3002</p>"},{"location":"core-components/cuda-storage/#_1","title":"\ud83c\udfaf \u8bbe\u8ba1\u76ee\u6807","text":""},{"location":"core-components/cuda-storage/#_2","title":"\u72ec\u7acb\u6027","text":"<ul> <li>\u7eafCUDA\u5b9e\u73b0\uff1a\u4e0d\u4f9d\u8d56PyTorch\u7684GPU\u540e\u7aef</li> <li>\u76f4\u63a5\u5185\u5b58\u7ba1\u7406\uff1a\u4f7f\u7528CUDA Python API\u76f4\u63a5\u7ba1\u7406GPU\u5185\u5b58</li> <li>\u9ad8\u6027\u80fd\uff1a\u9488\u5bf9GPU\u4f18\u5316\u7684\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f</li> </ul>"},{"location":"core-components/cuda-storage/#_3","title":"\u517c\u5bb9\u6027","text":"<ul> <li>PyTorch\u98ce\u683cAPI\uff1a\u4fdd\u6301\u4e0ePyTorch\u5f20\u91cf\u7684\u63a5\u53e3\u517c\u5bb9\u6027</li> <li>\u81ea\u52a8\u5fae\u5206\u652f\u6301\uff1a\u4e0eGenesis\u81ea\u52a8\u5fae\u5206\u7cfb\u7edf\u65e0\u7f1d\u96c6\u6210</li> <li>\u7c7b\u578b\u5b89\u5168\uff1a\u5b8c\u6574\u7684\u7c7b\u578b\u6ce8\u89e3\u548c\u8fd0\u884c\u65f6\u68c0\u67e5</li> </ul>"},{"location":"core-components/cuda-storage/#_4","title":"\ud83c\udfd7\ufe0f \u67b6\u6784\u8bbe\u8ba1","text":""},{"location":"core-components/cuda-storage/#indexplan","title":"IndexPlan\u67b6\u6784","text":"<p>CUDATensor\u4f7f\u7528\u5148\u8fdb\u7684IndexPlan\u67b6\u6784\u6765\u5904\u7406\u590d\u6742\u7684\u5f20\u91cf\u7d22\u5f15\u64cd\u4f5c\uff1a</p> Python<pre><code>class IndexKind(Enum):\n    VIEW = \"view\"           # \u7eaf\u89c6\u56fe\u64cd\u4f5c\uff0c\u96f6\u62f7\u8d1d\n    GATHER = \"gather\"       # \u6536\u96c6\u64cd\u4f5c\uff0c\u7528\u4e8e\u9ad8\u7ea7\u7d22\u5f15  \n    SCATTER = \"scatter\"     # \u6563\u5e03\u64cd\u4f5c\uff0c\u7528\u4e8e\u8d4b\u503c\n    COPY = \"copy\"          # \u6b65\u957f\u62f7\u8d1d\n    FILL = \"fill\"          # \u586b\u5145\u64cd\u4f5c\n\n@dataclass\nclass IndexPlan:\n    \"\"\"\u7edf\u4e00\u7684\u7d22\u5f15\u8ba1\u5212\"\"\"\n    kind: IndexKind\n    result_shape: Optional[Tuple[int, ...]] = None\n    result_strides: Optional[Tuple[int, ...]] = None\n    ptr_offset_bytes: int = 0\n    index_tensor: Optional['CUDATensor'] = None\n    needs_mask_compaction: bool = False\n    temp_memory_bytes: int = 0\n</code></pre>"},{"location":"core-components/cuda-storage/#_5","title":"\u5185\u5b58\u7ba1\u7406","text":"Python<pre><code>class AsyncMemoryPool:\n    \"\"\"\u5f02\u6b65\u5185\u5b58\u6c60\uff0c\u4f18\u5316GPU\u5185\u5b58\u5206\u914d\u6027\u80fd\"\"\"\n\n    def __init__(self):\n        self.free_blocks = {}  # \u6309\u5927\u5c0f\u7ec4\u7ec7\u7684\u7a7a\u95f2\u5757\n        self.allocated_blocks = {}  # \u5df2\u5206\u914d\u7684\u5757\n        self.alignment = 512  # \u5185\u5b58\u5bf9\u9f50\uff0c\u4e0ePyTorch\u4e00\u81f4\n\n    def allocate(self, size_bytes: int) -&gt; int:\n        \"\"\"\u5206\u914d\u5bf9\u9f50\u7684GPU\u5185\u5b58\"\"\"\n\n    def deallocate(self, ptr: int):\n        \"\"\"\u91ca\u653eGPU\u5185\u5b58\u5230\u6c60\u4e2d\u91cd\u7528\"\"\"\n</code></pre>"},{"location":"core-components/cuda-storage/#_6","title":"\ud83d\udca1 \u6838\u5fc3\u7279\u6027","text":""},{"location":"core-components/cuda-storage/#1","title":"1. \u9ad8\u6548\u7684\u7d22\u5f15\u64cd\u4f5c","text":"Python<pre><code>import genesis\n\n# \u521b\u5efaCUDA\u5f20\u91cf\nx = genesis.randn(1000, 1000, device='cuda')\n\n# \u57fa\u7840\u7d22\u5f15 - \u4f7f\u7528VIEW\u64cd\u4f5c\uff0c\u96f6\u62f7\u8d1d\ny = x[10:20, 50:100]  # IndexPlan.kind = VIEW\n\n# \u9ad8\u7ea7\u7d22\u5f15 - \u4f7f\u7528GATHER\u64cd\u4f5c  \nindices = genesis.tensor([1, 3, 5, 7], device='cuda')\nz = x[indices]  # IndexPlan.kind = GATHER\n\n# \u5e03\u5c14\u7d22\u5f15 - \u81ea\u52a8\u4f18\u5316\nmask = x &gt; 0.5\nw = x[mask]  # \u6839\u636e\u7a20\u5bc6\u5ea6\u9009\u62e9\u6700\u4f18\u7b56\u7565\n</code></pre>"},{"location":"core-components/cuda-storage/#2","title":"2. \u5185\u5b58\u9ad8\u6548\u7684\u64cd\u4f5c","text":"Python<pre><code># \u5c31\u5730\u64cd\u4f5c\uff0c\u907f\u514d\u5185\u5b58\u5206\u914d\nx = genesis.randn(1000, 1000, device='cuda')\nx += 1.0  # \u5c31\u5730\u52a0\u6cd5\n\n# \u89c6\u56fe\u64cd\u4f5c\uff0c\u96f6\u62f7\u8d1d\ny = x.view(100, 10000)  # \u6539\u53d8\u5f62\u72b6\u4f46\u4e0d\u590d\u5236\u6570\u636e\nz = x.transpose(0, 1)   # \u8f6c\u7f6e\u89c6\u56fe\n\n# \u6b65\u957f\u64cd\u4f5c\uff0c\u9ad8\u6548\u5b9e\u73b0\nw = x[::2, ::3]  # \u6b65\u957f\u7d22\u5f15\uff0c\u4f7f\u7528\u4f18\u5316\u7684COPY\u64cd\u4f5c\n</code></pre>"},{"location":"core-components/cuda-storage/#3-triton","title":"3. Triton\u5185\u6838\u96c6\u6210","text":"Python<pre><code>@triton.jit\ndef add_kernel(x_ptr, y_ptr, output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n    \"\"\"\u4f18\u5316\u7684Triton\u52a0\u6cd5\u5185\u6838\"\"\"\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets &lt; n_elements\n\n    x = tl.load(x_ptr + offsets, mask=mask)\n    y = tl.load(y_ptr + offsets, mask=mask)\n    output = x + y\n\n    tl.store(output_ptr + offsets, output, mask=mask)\n\n# CUDATensor\u81ea\u52a8\u8c03\u7528\u4f18\u5316\u7684Triton\u5185\u6838\ndef add_cuda_tensor(x: CUDATensor, y: CUDATensor) -&gt; CUDATensor:\n    \"\"\"CUDA\u5f20\u91cf\u52a0\u6cd5\uff0c\u4f7f\u7528Triton\u4f18\u5316\"\"\"\n    output = CUDATensor(x.shape, x.dtype)\n\n    n_elements = x.numel()\n    BLOCK_SIZE = 1024\n    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n\n    add_kernel[grid](x.data_ptr(), y.data_ptr(), output.data_ptr(), \n                     n_elements, BLOCK_SIZE=BLOCK_SIZE)\n\n    return output\n</code></pre>"},{"location":"core-components/cuda-storage/#_7","title":"\ud83d\ude80 \u57fa\u7840\u4f7f\u7528","text":""},{"location":"core-components/cuda-storage/#_8","title":"\u521b\u5efa\u5f20\u91cf","text":"Python<pre><code>import genesis\n\n# \u4ece\u6570\u636e\u521b\u5efa\ndata = [[1.0, 2.0], [3.0, 4.0]]\ntensor = genesis.tensor(data, device='cuda')\n\n# \u76f4\u63a5\u521b\u5efa\u7279\u5b9a\u5f62\u72b6\nzeros = genesis.zeros(100, 100, device='cuda')\nones = genesis.ones(50, 50, device='cuda')  \nrandom = genesis.randn(200, 200, device='cuda')\n\n# \u6307\u5b9a\u6570\u636e\u7c7b\u578b\nfloat16_tensor = genesis.randn(100, 100, dtype=genesis.float16, device='cuda')\nint_tensor = genesis.randint(0, 10, (50, 50), device='cuda')\n\nprint(f\"\u5f20\u91cf\u5f62\u72b6: {tensor.shape}\")\nprint(f\"\u6570\u636e\u7c7b\u578b: {tensor.dtype}\")\nprint(f\"\u8bbe\u5907: {tensor.device}\")\nprint(f\"\u6b65\u957f: {tensor.strides}\")\n</code></pre>"},{"location":"core-components/cuda-storage/#_9","title":"\u57fa\u7840\u64cd\u4f5c","text":"Python<pre><code># \u6570\u5b66\u8fd0\u7b97\nx = genesis.randn(100, 100, device='cuda')\ny = genesis.randn(100, 100, device='cuda')\n\n# \u9010\u5143\u7d20\u8fd0\u7b97\nz = x + y      # \u52a0\u6cd5\nw = x * y      # \u4e58\u6cd5  \nu = x.pow(2)   # \u5e42\u8fd0\u7b97\nv = x.exp()    # \u6307\u6570\u51fd\u6570\n\n# \u5f52\u7ea6\u64cd\u4f5c\nsum_all = x.sum()           # \u5168\u5c40\u6c42\u548c\nsum_dim = x.sum(dim=0)      # \u6309\u7ef4\u5ea6\u6c42\u548c\nmean_val = x.mean()         # \u5e73\u5747\u503c\nmax_val, indices = x.max(dim=1)  # \u6700\u5927\u503c\u548c\u7d22\u5f15\n\n# \u7ebf\u6027\u4ee3\u6570\na = genesis.randn(100, 50, device='cuda')\nb = genesis.randn(50, 200, device='cuda') \nc = genesis.matmul(a, b)    # \u77e9\u9635\u4e58\u6cd5\n\n# \u5f62\u72b6\u64cd\u4f5c\nreshaped = x.view(10, 1000)        # \u6539\u53d8\u5f62\u72b6\ntransposed = x.transpose(0, 1)     # \u8f6c\u7f6e  \nflattened = x.flatten()            # \u5c55\u5e73\n</code></pre>"},{"location":"core-components/cuda-storage/#_10","title":"\u9ad8\u7ea7\u7d22\u5f15","text":"Python<pre><code># \u521b\u5efa\u6d4b\u8bd5\u5f20\u91cf\ndata = genesis.arange(0, 100, device='cuda').view(10, 10)\nprint(\"\u539f\u59cb\u6570\u636e:\")\nprint(data)\n\n# \u57fa\u7840\u5207\u7247\nslice_basic = data[2:5, 3:7]  # \u884c2-4\uff0c\u52173-6\nprint(\"\u57fa\u7840\u5207\u7247:\", slice_basic.shape)\n\n# \u6b65\u957f\u7d22\u5f15\nslice_stride = data[::2, 1::2]  # \u6bcf\u9694\u4e00\u884c\uff0c\u4ece\u7b2c1\u5217\u5f00\u59cb\u6bcf\u9694\u4e00\u5217\nprint(\"\u6b65\u957f\u7d22\u5f15:\", slice_stride.shape)\n\n# \u9ad8\u7ea7\u7d22\u5f15 - \u6574\u6570\u6570\u7ec4\nrow_indices = genesis.tensor([0, 2, 4, 6], device='cuda')\ncol_indices = genesis.tensor([1, 3, 5, 7], device='cuda')\nadvanced = data[row_indices, col_indices]  # \u9009\u62e9\u7279\u5b9a\u4f4d\u7f6e\nprint(\"\u9ad8\u7ea7\u7d22\u5f15\u7ed3\u679c:\", advanced)\n\n# \u5e03\u5c14\u7d22\u5f15\nmask = data &gt; 50\nmasked_data = data[mask]  # \u9009\u62e9\u5927\u4e8e50\u7684\u5143\u7d20\nprint(\"\u5e03\u5c14\u7d22\u5f15\u7ed3\u679c:\", masked_data)\n\n# \u6df7\u5408\u7d22\u5f15\nmixed = data[row_indices, 2:8]  # \u7279\u5b9a\u884c\u7684\u5217\u8303\u56f4\nprint(\"\u6df7\u5408\u7d22\u5f15:\", mixed.shape)\n</code></pre>"},{"location":"core-components/cuda-storage/#_11","title":"\ud83d\udd27 \u5185\u5b58\u7ba1\u7406","text":""},{"location":"core-components/cuda-storage/#_12","title":"\u5185\u5b58\u6c60\u4f18\u5316","text":"Python<pre><code># \u67e5\u770b\u5185\u5b58\u4f7f\u7528\u60c5\u51b5\nprint(f\"\u5df2\u5206\u914d\u5185\u5b58: {genesis.cuda.memory_allocated() / 1024**2:.1f} MB\")\nprint(f\"\u7f13\u5b58\u5185\u5b58: {genesis.cuda.memory_cached() / 1024**2:.1f} MB\")\n\n# \u624b\u52a8\u5185\u5b58\u7ba1\u7406\nx = genesis.randn(1000, 1000, device='cuda')\nprint(f\"\u521b\u5efa\u5f20\u91cf\u540e: {genesis.cuda.memory_allocated() / 1024**2:.1f} MB\")\n\ndel x  # \u5220\u9664\u5f15\u7528\ngenesis.cuda.empty_cache()  # \u6e05\u7a7a\u7f13\u5b58\nprint(f\"\u6e05\u7406\u540e: {genesis.cuda.memory_allocated() / 1024**2:.1f} MB\")\n\n# \u5185\u5b58\u5feb\u7167\uff08\u8c03\u8bd5\u7528\uff09\nsnapshot = genesis.cuda.memory_snapshot()\nfor entry in snapshot[:3]:  # \u663e\u793a\u524d3\u4e2a\u6761\u76ee\n    print(f\"\u5730\u5740: {entry['address']}, \u5927\u5c0f: {entry['size']} bytes\")\n</code></pre>"},{"location":"core-components/cuda-storage/#_13","title":"\u5f02\u6b65\u64cd\u4f5c","text":"Python<pre><code># \u5f02\u6b65\u5185\u5b58\u64cd\u4f5c\nwith genesis.cuda.stream():\n    x = genesis.randn(1000, 1000, device='cuda')\n    y = genesis.randn(1000, 1000, device='cuda')\n    z = genesis.matmul(x, y)  # \u5f02\u6b65\u6267\u884c\n\n    # \u5176\u4ed6CPU\u5de5\u4f5c\u53ef\u4ee5\u5e76\u884c\u8fdb\u884c\n    print(\"\u77e9\u9635\u4e58\u6cd5\u6b63\u5728GPU\u4e0a\u5f02\u6b65\u6267\u884c...\")\n\n    # \u540c\u6b65\u7b49\u5f85\u7ed3\u679c  \n    genesis.cuda.synchronize()\n    print(\"\u8ba1\u7b97\u5b8c\u6210:\", z.shape)\n</code></pre>"},{"location":"core-components/cuda-storage/#_14","title":"\u26a1 \u6027\u80fd\u4f18\u5316","text":""},{"location":"core-components/cuda-storage/#1_1","title":"1. \u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u4f18\u5316","text":"Python<pre><code>def inefficient_access():\n    \"\"\"\u4f4e\u6548\u7684\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\"\"\"\n    x = genesis.randn(1000, 1000, device='cuda')\n    result = genesis.zeros(1000, device='cuda')\n\n    # \u975e\u8fde\u7eed\u8bbf\u95ee\uff0c\u7f13\u5b58\u672a\u547d\u4e2d\n    for i in range(1000):\n        result[i] = x[i, ::10].sum()  # \u6b65\u957f\u8bbf\u95ee\n\n    return result\n\ndef efficient_access():  \n    \"\"\"\u9ad8\u6548\u7684\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\"\"\"\n    x = genesis.randn(1000, 1000, device='cuda')\n\n    # \u8fde\u7eed\u8bbf\u95ee\uff0c\u5145\u5206\u5229\u7528\u7f13\u5b58\n    indices = genesis.arange(0, 1000, 10, device='cuda')\n    selected = x[:, indices]  # \u6279\u91cf\u9009\u62e9\n    result = selected.sum(dim=1)  # \u5411\u91cf\u5316\u6c42\u548c\n\n    return result\n\n# \u6027\u80fd\u5bf9\u6bd4\nimport time\n\nstart = time.time()\nresult1 = inefficient_access()\ntime1 = time.time() - start\n\nstart = time.time()  \nresult2 = efficient_access()\ntime2 = time.time() - start\n\nprint(f\"\u4f4e\u6548\u65b9\u6cd5: {time1:.4f}s\")\nprint(f\"\u9ad8\u6548\u65b9\u6cd5: {time2:.4f}s\")  \nprint(f\"\u52a0\u901f\u6bd4: {time1/time2:.2f}x\")\n</code></pre>"},{"location":"core-components/cuda-storage/#2_1","title":"2. \u6279\u91cf\u64cd\u4f5c\u4f18\u5316","text":"Python<pre><code>def batch_operations_demo():\n    \"\"\"\u5c55\u793a\u6279\u91cf\u64cd\u4f5c\u7684\u6027\u80fd\u4f18\u52bf\"\"\"\n\n    # \u521b\u5efa\u6d4b\u8bd5\u6570\u636e\n    matrices = [genesis.randn(100, 100, device='cuda') for _ in range(10)]\n\n    # \u65b9\u6cd51: \u9010\u4e2a\u5904\u7406\uff08\u4f4e\u6548\uff09\n    start = time.time()\n    results1 = []\n    for matrix in matrices:\n        result = matrix.exp().sum()\n        results1.append(result)\n    time1 = time.time() - start\n\n    # \u65b9\u6cd52: \u6279\u91cf\u5904\u7406\uff08\u9ad8\u6548\uff09\n    start = time.time()\n    batched = genesis.stack(matrices, dim=0)  # [10, 100, 100]\n    results2 = batched.exp().sum(dim=(1, 2))  # [10]\n    time2 = time.time() - start\n\n    print(f\"\u9010\u4e2a\u5904\u7406: {time1:.4f}s\")\n    print(f\"\u6279\u91cf\u5904\u7406: {time2:.4f}s\")\n    print(f\"\u52a0\u901f\u6bd4: {time1/time2:.2f}x\")\n\nbatch_operations_demo()\n</code></pre>"},{"location":"core-components/cuda-storage/#3","title":"3. \u5c31\u5730\u64cd\u4f5c","text":"Python<pre><code>def inplace_operations_demo():\n    \"\"\"\u5c55\u793a\u5c31\u5730\u64cd\u4f5c\u7684\u5185\u5b58\u6548\u7387\"\"\"\n\n    # \u975e\u5c31\u5730\u64cd\u4f5c\uff08\u521b\u5efa\u65b0\u5f20\u91cf\uff09\n    x = genesis.randn(1000, 1000, device='cuda')\n    start_memory = genesis.cuda.memory_allocated()\n\n    y = x + 1.0      # \u521b\u5efa\u65b0\u5f20\u91cf\n    z = y * 2.0      # \u518d\u521b\u5efa\u65b0\u5f20\u91cf\n    w = z.exp()      # \u53c8\u521b\u5efa\u65b0\u5f20\u91cf\n\n    memory_after = genesis.cuda.memory_allocated()\n    print(f\"\u975e\u5c31\u5730\u64cd\u4f5c\u5185\u5b58\u589e\u957f: {(memory_after - start_memory) / 1024**2:.1f} MB\")\n\n    # \u5c31\u5730\u64cd\u4f5c\uff08\u4fee\u6539\u539f\u5f20\u91cf\uff09\n    x = genesis.randn(1000, 1000, device='cuda')\n    start_memory = genesis.cuda.memory_allocated()\n\n    x += 1.0         # \u5c31\u5730\u52a0\u6cd5\n    x *= 2.0         # \u5c31\u5730\u4e58\u6cd5  \n    x.exp_()         # \u5c31\u5730\u6307\u6570\u51fd\u6570\n\n    memory_after = genesis.cuda.memory_allocated()\n    print(f\"\u5c31\u5730\u64cd\u4f5c\u5185\u5b58\u589e\u957f: {(memory_after - start_memory) / 1024**2:.1f} MB\")\n\ninplace_operations_demo()\n</code></pre>"},{"location":"core-components/cuda-storage/#_15","title":"\ud83d\udc1b \u8c03\u8bd5\u548c\u8bca\u65ad","text":""},{"location":"core-components/cuda-storage/#_16","title":"\u5185\u5b58\u6cc4\u6f0f\u68c0\u6d4b","text":"Python<pre><code>def detect_memory_leaks():\n    \"\"\"\u68c0\u6d4b\u5185\u5b58\u6cc4\u6f0f\"\"\"\n    genesis.cuda.empty_cache()\n    initial_memory = genesis.cuda.memory_allocated()\n\n    # \u6267\u884c\u4e00\u4e9b\u64cd\u4f5c\n    for i in range(100):\n        x = genesis.randn(100, 100, device='cuda')\n        y = x.matmul(x)\n        del x, y\n\n    genesis.cuda.empty_cache()\n    final_memory = genesis.cuda.memory_allocated()\n\n    if final_memory &gt; initial_memory:\n        print(f\"\u53ef\u80fd\u5b58\u5728\u5185\u5b58\u6cc4\u6f0f: {(final_memory - initial_memory) / 1024**2:.1f} MB\")\n    else:\n        print(\"\u672a\u68c0\u6d4b\u5230\u5185\u5b58\u6cc4\u6f0f\")\n\ndetect_memory_leaks()\n</code></pre>"},{"location":"core-components/cuda-storage/#_17","title":"\u9519\u8bef\u8bca\u65ad","text":"Python<pre><code>def diagnose_cuda_errors():\n    \"\"\"CUDA\u9519\u8bef\u8bca\u65ad\"\"\"\n    try:\n        # \u53ef\u80fd\u51fa\u9519\u7684\u64cd\u4f5c\n        x = genesis.randn(1000, 1000, device='cuda')\n        y = genesis.randn(500, 500, device='cuda')  # \u5f62\u72b6\u4e0d\u5339\u914d\n        z = genesis.matmul(x, y)\n\n    except RuntimeError as e:\n        print(f\"CUDA\u9519\u8bef: {e}\")\n\n        # \u68c0\u67e5CUDA\u72b6\u6001\n        if genesis.cuda.is_available():\n            print(f\"CUDA\u8bbe\u5907: {genesis.cuda.get_device_name()}\")\n            print(f\"CUDA\u80fd\u529b: {genesis.cuda.get_device_capability()}\")\n            print(f\"\u53ef\u7528\u5185\u5b58: {genesis.cuda.get_device_properties().total_memory / 1024**3:.1f} GB\")\n        else:\n            print(\"CUDA\u4e0d\u53ef\u7528\")\n\ndiagnose_cuda_errors()\n</code></pre>"},{"location":"core-components/cuda-storage/#pytorch","title":"\ud83d\udd04 \u4e0ePyTorch\u4e92\u64cd\u4f5c","text":"Python<pre><code>import torch\n\ndef pytorch_interop_demo():\n    \"\"\"\u5c55\u793a\u4e0ePyTorch\u7684\u4e92\u64cd\u4f5c\u6027\"\"\"\n\n    # Genesis\u5f20\u91cf\u8f6cPyTorch\n    genesis_tensor = genesis.randn(100, 100, device='cuda')\n\n    # \u8f6c\u6362\u4e3aPyTorch\uff08\u5171\u4eab\u5185\u5b58\uff09\n    pytorch_tensor = torch.as_tensor(genesis_tensor.detach().cpu().numpy()).cuda()\n\n    print(f\"Genesis\u5f62\u72b6: {genesis_tensor.shape}\")\n    print(f\"PyTorch\u5f62\u72b6: {pytorch_tensor.shape}\")\n\n    # PyTorch\u5f20\u91cf\u8f6cGenesis  \n    torch_data = torch.randn(50, 50, device='cuda')\n    genesis_from_torch = genesis.tensor(torch_data.cpu().numpy(), device='cuda')\n\n    print(f\"\u8f6c\u6362\u6210\u529f\uff0cGenesis\u5f20\u91cf: {genesis_from_torch.shape}\")\n\npytorch_interop_demo()\n</code></pre>"},{"location":"core-components/cuda-storage/#_18","title":"\ud83d\udcca \u6027\u80fd\u57fa\u51c6","text":"Python<pre><code>def benchmark_cuda_tensor():\n    \"\"\"CUDA\u5f20\u91cf\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\"\"\"\n\n    sizes = [100, 500, 1000, 2000]\n\n    print(\"\u77e9\u9635\u4e58\u6cd5\u6027\u80fd\u5bf9\u6bd4 (Genesis vs PyTorch):\")\n    print(\"-\" * 50)\n\n    for size in sizes:\n        # Genesis\u6d4b\u8bd5\n        x_gen = genesis.randn(size, size, device='cuda')\n        y_gen = genesis.randn(size, size, device='cuda')\n\n        genesis.cuda.synchronize()\n        start = time.time()\n        for _ in range(10):\n            z_gen = genesis.matmul(x_gen, y_gen)\n        genesis.cuda.synchronize()\n        genesis_time = (time.time() - start) / 10\n\n        # PyTorch\u6d4b\u8bd5\n        x_torch = torch.randn(size, size, device='cuda')\n        y_torch = torch.randn(size, size, device='cuda')\n\n        torch.cuda.synchronize()\n        start = time.time()\n        for _ in range(10):\n            z_torch = torch.matmul(x_torch, y_torch)\n        torch.cuda.synchronize() \n        pytorch_time = (time.time() - start) / 10\n\n        ratio = genesis_time / pytorch_time\n        print(f\"{size}x{size}: Genesis {genesis_time:.4f}s, PyTorch {pytorch_time:.4f}s, \u6bd4\u7387 {ratio:.2f}\")\n\nbenchmark_cuda_tensor()\n</code></pre>"},{"location":"core-components/cuda-storage/#_19","title":"\ud83c\udfaf \u6700\u4f73\u5b9e\u8df5","text":""},{"location":"core-components/cuda-storage/#1_2","title":"1. \u5185\u5b58\u7ba1\u7406\u6700\u4f73\u5b9e\u8df5","text":"Python<pre><code># \u2705 \u597d\u7684\u505a\u6cd5\ndef good_memory_practice():\n    with genesis.cuda.device(0):  # \u660e\u786e\u6307\u5b9a\u8bbe\u5907\n        x = genesis.randn(1000, 1000, device='cuda')\n\n        # \u4f7f\u7528\u5c31\u5730\u64cd\u4f5c\n        x += 1.0\n        x *= 0.5\n\n        # \u53ca\u65f6\u91ca\u653e\u5927\u5f20\u91cf\n        del x\n        genesis.cuda.empty_cache()\n\n# \u274c \u907f\u514d\u7684\u505a\u6cd5  \ndef bad_memory_practice():\n    tensors = []\n    for i in range(100):\n        x = genesis.randn(1000, 1000, device='cuda')\n        y = x + 1.0  # \u521b\u5efa\u989d\u5916\u526f\u672c\n        tensors.append(y)  # \u4fdd\u6301\u6240\u6709\u5f15\u7528\uff0c\u5185\u5b58\u65e0\u6cd5\u91ca\u653e\n    # \u5185\u5b58\u4f1a\u5feb\u901f\u8017\u5c3d\n</code></pre>"},{"location":"core-components/cuda-storage/#2_2","title":"2. \u6027\u80fd\u4f18\u5316\u6700\u4f73\u5b9e\u8df5","text":"Python<pre><code># \u2705 \u5411\u91cf\u5316\u64cd\u4f5c\ndef vectorized_operations():\n    x = genesis.randn(1000, 1000, device='cuda')\n\n    # \u4f7f\u7528\u5411\u91cf\u5316\u51fd\u6570\n    result = genesis.relu(x).sum(dim=1).mean()\n\n# \u274c \u907f\u514d\u5faa\u73af\ndef avoid_loops():\n    x = genesis.randn(1000, 1000, device='cuda')\n\n    # \u907f\u514dPython\u5faa\u73af\n    result = 0\n    for i in range(1000):\n        result += x[i].sum()  # \u6bcf\u6b21\u90fd\u542f\u52a8CUDA kernel\n</code></pre>"},{"location":"core-components/cuda-storage/#3_1","title":"3. \u8c03\u8bd5\u6700\u4f73\u5b9e\u8df5","text":"Python<pre><code># \u542f\u7528CUDA\u9519\u8bef\u68c0\u67e5\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n\n# \u4f7f\u7528\u65ad\u8a00\u68c0\u67e5\u5f20\u91cf\u5c5e\u6027\ndef safe_tensor_operation(x, y):\n    assert x.device == y.device, \"\u5f20\u91cf\u5fc5\u987b\u5728\u540c\u4e00\u8bbe\u5907\u4e0a\"\n    assert x.shape == y.shape, f\"\u5f62\u72b6\u4e0d\u5339\u914d: {x.shape} vs {y.shape}\"\n\n    return x + y\n</code></pre>"},{"location":"core-components/cuda-storage/#_20","title":"\u2753 \u5e38\u89c1\u95ee\u9898","text":""},{"location":"core-components/cuda-storage/#q-cuda","title":"Q: CUDA\u5185\u5b58\u4e0d\u8db3\u600e\u4e48\u529e\uff1f","text":"<p>A:  Python<pre><code># \u51cf\u5c0f\u6279\u91cf\u5927\u5c0f\nbatch_size = 32  # \u6539\u4e3a16\u62168\n\n# \u4f7f\u7528\u68af\u5ea6\u7d2f\u79ef\naccumulation_steps = 4\neffective_batch_size = batch_size * accumulation_steps\n\n# \u542f\u7528\u6df7\u5408\u7cbe\u5ea6\nx = genesis.randn(1000, 1000, dtype=genesis.float16, device='cuda')\n\n# \u5b9a\u671f\u6e05\u7406\u5185\u5b58\ngenesis.cuda.empty_cache()\n</code></pre></p>"},{"location":"core-components/cuda-storage/#q-cuda_1","title":"Q: \u4e3a\u4ec0\u4e48CUDA\u64cd\u4f5c\u5f88\u6162\uff1f","text":"<p>A: \u68c0\u67e5\u4ee5\u4e0b\u51e0\u70b9\uff1a Python<pre><code># 1. \u786e\u4fdd\u5f20\u91cf\u5728GPU\u4e0a\nassert x.device.type == 'cuda'\n\n# 2. \u907f\u514d\u9891\u7e41\u7684CPU-GPU\u4f20\u8f93\n# \u9519\u8bef\u505a\u6cd5\nfor i in range(1000):\n    cpu_data = x.cpu().numpy()  # \u6bcf\u6b21\u90fd\u4f20\u8f93\n\n# \u6b63\u786e\u505a\u6cd5\ncpu_data = x.cpu().numpy()  # \u53ea\u4f20\u8f93\u4e00\u6b21\n\n# 3. \u4f7f\u7528\u9002\u5f53\u7684\u6570\u636e\u7c7b\u578b\nx = genesis.randn(1000, 1000, dtype=genesis.float16, device='cuda')  # \u66f4\u5feb\n</code></pre></p>"},{"location":"core-components/cuda-storage/#q-cuda-kernel","title":"Q: \u5982\u4f55\u8c03\u8bd5CUDA kernel\u9519\u8bef\uff1f","text":"<p>A: Python<pre><code># 1. \u542f\u7528\u540c\u6b65\u9519\u8bef\u68c0\u67e5\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n\n# 2. \u68c0\u67e5tensor\u6709\u6548\u6027\ndef check_tensor(tensor, name):\n    assert not torch.isnan(tensor).any(), f\"{name}\u5305\u542bNaN\"\n    assert not torch.isinf(tensor).any(), f\"{name}\u5305\u542bInf\"\n    print(f\"{name}: shape={tensor.shape}, dtype={tensor.dtype}\")\n\n# 3. \u4f7f\u7528CUDA\u8c03\u8bd5\u5de5\u5177\n# cuda-memcheck python your_script.py\n# compute-sanitizer python your_script.py\n</code></pre></p> <p>\u6027\u80fd\u63d0\u793a</p> <p>CUDA\u5f20\u91cf\u7684\u6027\u80fd\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u51b3\u4e8e\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u548c\u6279\u91cf\u64cd\u4f5c\u7684\u4f7f\u7528\u3002\u4f18\u5148\u8003\u8651\u5411\u91cf\u5316\u64cd\u4f5c\u548c\u5408\u7406\u7684\u5185\u5b58\u5e03\u5c40\u3002</p> <p>\u51c6\u5907\u6df1\u5165\u4e86\u89e3\u66f4\u591a\u5417\uff1f</p> <p>\u4e0b\u4e00\u6b65\uff1a\u5f20\u91cf\u64cd\u4f5c\u6307\u5357 \u8fd4\u56de\u6838\u5fc3\u7ec4\u4ef6</p>"},{"location":"core-components/dtypes/","title":"\u6570\u636e\u7c7b\u578b\u7cfb\u7edf","text":"<p>Genesis\u5b9e\u73b0\u4e86\u4e00\u5957\u7edf\u4e00\u7684\u6570\u636e\u7c7b\u578b\u7cfb\u7edf\uff0c\u63d0\u4f9b\u4e0ePyTorch\u5bf9\u9f50\u7684\u7c7b\u578b\u7ba1\u7406\uff0c\u652f\u6301\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u548c\u8de8\u8bbe\u5907\u7c7b\u578b\u8f6c\u6362\u3002</p>"},{"location":"core-components/dtypes/#_2","title":"\ud83c\udfaf \u8bbe\u8ba1\u76ee\u6807","text":"<ul> <li>\u7edf\u4e00\u63a5\u53e3\uff1aCPU\u548cGPU\u540e\u7aef\u4f7f\u7528\u76f8\u540c\u7684\u7c7b\u578b\u5b9a\u4e49</li> <li>PyTorch\u517c\u5bb9\uff1a\u4e0ePyTorch\u7684dtype\u7cfb\u7edf\u4fdd\u6301\u4e00\u81f4\u6027</li> <li>\u6df7\u5408\u7cbe\u5ea6\uff1a\u65e0\u7f1d\u652f\u6301FP16\u3001BF16\u7b49\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3</li> <li>\u7c7b\u578b\u5b89\u5168\uff1a\u7f16\u8bd1\u65f6\u548c\u8fd0\u884c\u65f6\u7684\u7c7b\u578b\u68c0\u67e5</li> </ul>"},{"location":"core-components/dtypes/#_3","title":"\ud83c\udfd7\ufe0f \u6838\u5fc3\u67b6\u6784","text":"<pre><code>graph TB\n    subgraph \"DType\u6838\u5fc3\u7c7b\"\n        A[DType] --&gt; B[name str]\n        A --&gt; C[itemsize int]\n        A --&gt; D[numpy_dtype]\n        A --&gt; E[triton_name str]\n        A --&gt; F[is_floating_point bool]\n    end\n\n    subgraph \"\u9884\u5b9a\u4e49\u7c7b\u578b\"\n        G[\u6d6e\u70b9\u7c7b\u578b] --&gt; H[float32]\n        G --&gt; I[float16] \n        G --&gt; J[bfloat16]\n        G --&gt; K[float64]\n\n        L[\u6574\u6570\u7c7b\u578b] --&gt; M[int32]\n        L --&gt; N[int64]\n        L --&gt; O[int16]\n        L --&gt; P[int8]\n        L --&gt; Q[uint8]\n\n        R[\u5e03\u5c14\u7c7b\u578b] --&gt; S[bool]\n    end\n\n    subgraph \"\u7c7b\u578b\u8f6c\u6362\"\n        T[get_dtype] --&gt; U[\u5b57\u7b26\u4e32\u8f6c\u6362]\n        T --&gt; V[NumPy\u517c\u5bb9]\n        T --&gt; W[\u7c7b\u578b\u63a8\u65ad]\n    end\n\n    A --&gt; G\n    A --&gt; L  \n    A --&gt; R\n\n    style A fill:#e1f5fe\n    style G fill:#e8f5e8\n    style L fill:#fff3e0\n    style T fill:#fce4ec</code></pre>"},{"location":"core-components/dtypes/#dtype","title":"\ud83d\udcca DType\u7c7b\u8be6\u89e3","text":""},{"location":"core-components/dtypes/#_4","title":"\u7c7b\u5b9a\u4e49","text":"Python<pre><code>class DType:\n    \"\"\"Genesis\u6570\u636e\u7c7b\u578b\uff0c\u7c7b\u4f3ctorch.dtype\"\"\"\n\n    def __init__(self, name, itemsize, numpy_dtype, triton_name=None, is_floating_point=None):\n        self.name = name                    # \u7c7b\u578b\u540d\u79f0\uff0c\u5982\"float32\"\n        self.itemsize = itemsize           # \u5b57\u8282\u5927\u5c0f\n        self.numpy_dtype = numpy_dtype     # \u5bf9\u5e94\u7684NumPy\u7c7b\u578b\n        self.triton_name = triton_name or name  # Triton\u4e2d\u7684\u7c7b\u578b\u540d\n\n        # \u81ea\u52a8\u68c0\u6d4b\u662f\u5426\u4e3a\u6d6e\u70b9\u7c7b\u578b\n        if is_floating_point is None:\n            self.is_floating_point = np.issubdtype(numpy_dtype, np.floating)\n        else:\n            self.is_floating_point = is_floating_point\n</code></pre>"},{"location":"core-components/dtypes/#_5","title":"\u6838\u5fc3\u65b9\u6cd5","text":""},{"location":"core-components/dtypes/#_6","title":"\u5b57\u7b26\u4e32\u8868\u793a","text":"Python<pre><code>def __str__(self):\n    return f\"genesis.{self.name}\"\n\ndef __repr__(self):\n    return f\"genesis.{self.name}\"\n\n# \u4f7f\u7528\u793a\u4f8b\nprint(genesis.float32)  # \u8f93\u51fa: genesis.float32\n</code></pre>"},{"location":"core-components/dtypes/#_7","title":"\u76f8\u7b49\u6027\u6bd4\u8f83","text":"Python<pre><code>def __eq__(self, other):\n    if isinstance(other, DType):\n        return self.name == other.name\n    elif isinstance(other, str):\n        return self.name == other  # \u5411\u540e\u517c\u5bb9\u5b57\u7b26\u4e32\u6bd4\u8f83\n    return False\n\n# \u4f7f\u7528\u793a\u4f8b\ngenesis.float32 == genesis.float32  # True\ngenesis.float32 == \"float32\"        # True (\u5411\u540e\u517c\u5bb9)\ngenesis.float32 == genesis.float16  # False\n</code></pre>"},{"location":"core-components/dtypes/#_8","title":"\ud83d\udd22 \u9884\u5b9a\u4e49\u6570\u636e\u7c7b\u578b","text":""},{"location":"core-components/dtypes/#_9","title":"\u6d6e\u70b9\u7c7b\u578b","text":"\u7c7b\u578b \u5b57\u8282\u6570 \u7cbe\u5ea6 \u7528\u9014 <code>float32</code> 4 \u5355\u7cbe\u5ea6 \u9ed8\u8ba4\u6d6e\u70b9\u7c7b\u578b\uff0c\u5e73\u8861\u7cbe\u5ea6\u548c\u6027\u80fd <code>float16</code> 2 \u534a\u7cbe\u5ea6 \u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\uff0c\u8282\u7701\u5185\u5b58 <code>float64</code> 8 \u53cc\u7cbe\u5ea6 \u9ad8\u7cbe\u5ea6\u8ba1\u7b97\u9700\u6c42 <code>bfloat16</code> 2 \u8111\u6d6e\u70b9 Google TPU\u4f18\u5316\uff0c\u52a8\u6001\u8303\u56f4\u5927 Python<pre><code># \u6d6e\u70b9\u7c7b\u578b\u5b9a\u4e49\nfloat32 = DType(\"float32\", 4, np.float32)\nfloat16 = DType(\"float16\", 2, np.float16)\nfloat64 = DType(\"float64\", 8, np.float64)\n\n# bfloat16\u7279\u6b8a\u5904\u7406 - Triton\u652f\u6301\u4f46NumPy\u4e0d\u539f\u751f\u652f\u6301\nbfloat16 = DType(\"bfloat16\", 2, np.float32, \"bfloat16\", is_floating_point=True)\n</code></pre>"},{"location":"core-components/dtypes/#_10","title":"\u6574\u6570\u7c7b\u578b","text":"\u7c7b\u578b \u5b57\u8282\u6570 \u8303\u56f4 \u7528\u9014 <code>int64</code> 8 -2^63 ~ 2^63-1 \u9ed8\u8ba4\u6574\u6570\u7c7b\u578b <code>int32</code> 4 -2^31 ~ 2^31-1 \u5185\u5b58\u4f18\u5316\u7684\u6574\u6570 <code>int16</code> 2 -32,768 ~ 32,767 \u5c0f\u6574\u6570\u5b58\u50a8 <code>int8</code> 1 -128 ~ 127 \u91cf\u5316\u8ba1\u7b97 <code>uint8</code> 1 0 ~ 255 \u56fe\u50cf\u6570\u636e Python<pre><code># \u6574\u6570\u7c7b\u578b\u5b9a\u4e49\nint32 = DType(\"int32\", 4, np.int32)\nint64 = DType(\"int64\", 8, np.int64)\nint16 = DType(\"int16\", 2, np.int16)\nint8 = DType(\"int8\", 1, np.int8)\nuint8 = DType(\"uint8\", 1, np.uint8)\n</code></pre>"},{"location":"core-components/dtypes/#_11","title":"\u5e03\u5c14\u7c7b\u578b","text":"Python<pre><code># \u5e03\u5c14\u7c7b\u578b\nbool = DType(\"bool\", 1, np.bool_, is_floating_point=False)\n</code></pre>"},{"location":"core-components/dtypes/#_12","title":"\ud83d\udd04 \u7c7b\u578b\u8f6c\u6362\u7cfb\u7edf","text":""},{"location":"core-components/dtypes/#_13","title":"\u6838\u5fc3\u8f6c\u6362\u51fd\u6570","text":"Python<pre><code>def get_dtype(obj):\n    \"\"\"\n    \u5c06\u5404\u79cd\u7c7b\u578b\u8868\u793a\u8f6c\u6362\u4e3aGenesis DType\u5bf9\u8c61\n\n    \u652f\u6301\u7684\u8f93\u5165\u7c7b\u578b:\n    - DType\u5bf9\u8c61: \u76f4\u63a5\u8fd4\u56de\n    - \u5b57\u7b26\u4e32: \"float32\", \"int64\"\u7b49\n    - NumPy dtype: np.float32, np.int64\u7b49\n    - NumPy\u7c7b\u578b: np.float32, np.int64\u7c7b\u7b49\n    - None: \u8fd4\u56de\u9ed8\u8ba4float32\n    \"\"\"\n    if obj is None:\n        return float32  # \u9ed8\u8ba4\u7c7b\u578b\n    elif isinstance(obj, DType):\n        return obj\n    elif isinstance(obj, str):\n        return _name_to_dtype[obj]\n    elif isinstance(obj, np.dtype):\n        return _numpy_to_dtype[obj.type]\n    elif isinstance(obj, type) and issubclass(obj, np.generic):\n        return _numpy_to_dtype[obj]\n    else:\n        raise ValueError(f\"Cannot convert {type(obj)} to Genesis DType: {obj}\")\n</code></pre>"},{"location":"core-components/dtypes/#_14","title":"\u7c7b\u578b\u6620\u5c04\u8868","text":"Python<pre><code># \u540d\u79f0\u5230\u7c7b\u578b\u7684\u6620\u5c04\n_name_to_dtype = {\n    \"float32\": float32,\n    \"float16\": float16,\n    \"float64\": float64,\n    \"bfloat16\": bfloat16,\n    \"int32\": int32,\n    \"int64\": int64,\n    \"int16\": int16,\n    \"int8\": int8,\n    \"uint8\": uint8,\n    \"bool\": bool,\n}\n\n# NumPy\u7c7b\u578b\u5230Genesis\u7c7b\u578b\u7684\u6620\u5c04\n_numpy_to_dtype = {\n    np.float32: float32,\n    np.float16: float16,\n    np.float64: float64,\n    np.int32: int32,\n    np.int64: int64,\n    np.int16: int16,\n    np.int8: int8,\n    np.uint8: uint8,\n    np.bool_: bool,\n}\n</code></pre>"},{"location":"core-components/dtypes/#_15","title":"\ud83e\uddee \u7c7b\u578b\u68c0\u67e5\u5de5\u5177","text":""},{"location":"core-components/dtypes/#_16","title":"\u6d6e\u70b9\u7c7b\u578b\u68c0\u67e5","text":"Python<pre><code>def is_floating_point(dtype):\n    \"\"\"\u68c0\u67e5\u662f\u5426\u4e3a\u6d6e\u70b9\u7c7b\u578b\"\"\"\n    dtype = get_dtype(dtype)\n    return dtype.is_floating_point\n\n# \u4f7f\u7528\u793a\u4f8b\nis_floating_point(genesis.float32)  # True\nis_floating_point(genesis.int32)    # False\nis_floating_point(\"float16\")        # True\n</code></pre>"},{"location":"core-components/dtypes/#_17","title":"\u6574\u6570\u7c7b\u578b\u68c0\u67e5","text":"Python<pre><code>def is_integer(dtype):\n    \"\"\"\u68c0\u67e5\u662f\u5426\u4e3a\u6574\u6570\u7c7b\u578b\"\"\"\n    dtype = get_dtype(dtype)\n    return not dtype.is_floating_point and dtype != bool\n\n# \u4f7f\u7528\u793a\u4f8b\nis_integer(genesis.int32)   # True\nis_integer(genesis.float32) # False\nis_integer(genesis.bool)    # False\n</code></pre>"},{"location":"core-components/dtypes/#_18","title":"\u7c7b\u578b\u5206\u7c7b","text":"Python<pre><code># \u6240\u6709\u652f\u6301\u7684\u7c7b\u578b\nall_dtypes = [float32, float16, float64, bfloat16, int32, int64, int16, int8, uint8, bool]\n\n# \u6d6e\u70b9\u7c7b\u578b\u5217\u8868\nfloating_dtypes = [dt for dt in all_dtypes if dt.is_floating_point]\n# [float32, float16, float64, bfloat16]\n\n# \u6574\u6570\u7c7b\u578b\u5217\u8868\ninteger_dtypes = [dt for dt in all_dtypes if is_integer(dt)]\n# [int32, int64, int16, int8, uint8]\n</code></pre>"},{"location":"core-components/dtypes/#_19","title":"\ud83d\udd0d \u81ea\u52a8\u7c7b\u578b\u63a8\u65ad","text":"<p>Genesis\u63d0\u4f9b\u667a\u80fd\u7684dtype\u63a8\u65ad\uff0c\u9075\u5faaPyTorch\u7ea6\u5b9a\uff1a</p>"},{"location":"core-components/dtypes/#infer_dtype_from_dataarray","title":"<code>infer_dtype_from_data(array)</code>","text":"<p>\u4ece\u8f93\u5165\u6570\u636e\u81ea\u52a8\u63a8\u65ad\u5408\u9002\u7684Genesis dtype\uff1a</p> Python<pre><code>from genesis.dtypes import infer_dtype_from_data\n\n# Python\u6807\u91cf\u63a8\u65ad\ninfer_dtype_from_data(42)        # \u2192 genesis.int64\ninfer_dtype_from_data(3.14)      # \u2192 genesis.float32\ninfer_dtype_from_data(True)      # \u2192 genesis.bool\n\n# \u5217\u8868\u548c\u6570\u7ec4\u63a8\u65ad\ninfer_dtype_from_data([1, 2, 3])           # \u2192 genesis.int64\ninfer_dtype_from_data([1.0, 2.0, 3.0])     # \u2192 genesis.float32\ninfer_dtype_from_data(np.array([1, 2]))    # \u2192 \u4fdd\u6301numpy dtype\n\n# \u5f20\u91cf\u63a8\u65ad  \nexisting_tensor = genesis.tensor([1, 2, 3])\ninfer_dtype_from_data(existing_tensor)     # \u2192 existing_tensor.dtype\n</code></pre>"},{"location":"core-components/dtypes/#_20","title":"\u63a8\u65ad\u89c4\u5219","text":"\u8f93\u5165\u7c7b\u578b \u63a8\u65ad\u7684Genesis DType \u8bf4\u660e Python <code>int</code> <code>genesis.int64</code> PyTorch\u9ed8\u8ba4\u503c Python <code>float</code> <code>genesis.float32</code> PyTorch\u9ed8\u8ba4\u503c Python <code>bool</code> <code>genesis.bool</code> \u4fdd\u6301\u4e0d\u53d8 <code>np.int32</code>, <code>np.int64</code>\u7b49 \u5bf9\u5e94\u7684int\u7c7b\u578b \u4fdd\u6301\u4e0d\u53d8 <code>np.float16</code>, <code>np.float32</code> \u5bf9\u5e94\u7684float\u7c7b\u578b \u4fdd\u6301\u4e0d\u53d8 <code>np.float64</code> <code>genesis.float32</code> \u26a0\ufe0f \u4e3a\u4fdd\u6301\u4e00\u81f4\u6027\u800c\u8f6c\u6362 <code>np.bool_</code> <code>genesis.bool</code> \u4fdd\u6301\u4e0d\u53d8 Genesis <code>Tensor</code> <code>tensor.dtype</code> \u4fdd\u6301\u4e0d\u53d8 \u5217\u8868/\u5143\u7ec4 \u4ece\u9996\u6b21\u8f6c\u6362\u4e3anumpy\u63a8\u65ad \u53d6\u51b3\u4e8e\u5185\u5bb9 <p>\u5173\u952e\u7279\u6027\uff1a - PyTorch\u517c\u5bb9\u6027\uff1a\u9075\u5faaPyTorch\u7684\u9ed8\u8ba4\u7c7b\u578b\u63a8\u65ad\u89c4\u5219 - \u6027\u80fd\u4f18\u5316\uff1a\u81ea\u52a8\u5c06<code>float64</code>\u8f6c\u6362\u4e3a<code>float32</code>\u4ee5\u5339\u914dPyTorch\u884c\u4e3a - \u7c7b\u578b\u4fdd\u6301\uff1a\u4fdd\u6301numpy\u6570\u7ec4\u7684\u6574\u6570\u548c\u5e03\u5c14\u7c7b\u578b - \u4e00\u81f4\u884c\u4e3a\uff1a\u6574\u4e2a\u6846\u67b6\u4f7f\u7528\u76f8\u540c\u7684\u63a8\u65ad\u903b\u8f91</p>"},{"location":"core-components/dtypes/#_21","title":"\ud83d\udd00 \u6df7\u5408\u7cbe\u5ea6\u652f\u6301","text":""},{"location":"core-components/dtypes/#_22","title":"\u81ea\u52a8\u7c7b\u578b\u8f6c\u6362","text":"Python<pre><code>def _cast(value, dtype):\n    \"\"\"\u81ea\u52a8\u7c7b\u578b\u8f6c\u6362\uff0c\u7528\u4e8e\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\"\"\"\n    if isinstance(value, Tensor) and value.is_floating_point():\n        if dtype == genesis.float16:\n            return value.half()\n        else:\n            return value.float()\n    return value\n\n# \u5728autograd\u4e2d\u7684\u5e94\u7528\nif genesis.enable_autocast:\n    result = cls.forward(ctx, *_cast(args, genesis.float32), **_cast(kwargs, genesis.float32))\n</code></pre>"},{"location":"core-components/dtypes/#_23","title":"\u7c7b\u578b\u63a8\u65ad","text":"Python<pre><code>def check_dtype(value, dtype):\n    \"\"\"\u9012\u5f52\u68c0\u67e5\u6570\u636e\u7ed3\u6784\u4e2d\u662f\u5426\u5305\u542b\u6307\u5b9a\u7c7b\u578b\"\"\"\n    if isinstance(value, Tensor):\n        return value.dtype == dtype\n    elif isinstance(value, dict):\n        return any(check_dtype(k, dtype) or check_dtype(v, dtype) for k, v in value.items())\n    elif isinstance(value, (list, tuple)):\n        return any(check_dtype(v, dtype) for v in value)\n    else:\n        return False\n</code></pre>"},{"location":"core-components/dtypes/#_24","title":"\ud83c\udfaf \u4f7f\u7528\u793a\u4f8b","text":""},{"location":"core-components/dtypes/#_25","title":"\u57fa\u7840\u7c7b\u578b\u64cd\u4f5c","text":"Python<pre><code>import genesis\n\n# \u521b\u5efa\u4e0d\u540c\u7c7b\u578b\u7684\u5f20\u91cf\nx_f32 = genesis.randn(3, 4, dtype=genesis.float32)\nx_f16 = genesis.randn(3, 4, dtype=genesis.float16)\nx_int = genesis.randint(0, 10, (3, 4), dtype=genesis.int32)\n\n# \u68c0\u67e5\u7c7b\u578b\nprint(f\"x_f32\u7c7b\u578b: {x_f32.dtype}\")          # genesis.float32\nprint(f\"\u662f\u5426\u6d6e\u70b9: {x_f32.dtype.is_floating_point}\")  # True\nprint(f\"\u5b57\u8282\u5927\u5c0f: {x_f32.dtype.itemsize}\")          # 4\n</code></pre>"},{"location":"core-components/dtypes/#_26","title":"\u7c7b\u578b\u8f6c\u6362","text":"Python<pre><code># \u5b57\u7b26\u4e32\u5230\u7c7b\u578b\ndtype1 = genesis.get_dtype(\"float16\")    # genesis.float16\ndtype2 = genesis.get_dtype(np.float32)   # genesis.float32\ndtype3 = genesis.get_dtype(None)         # genesis.float32 (\u9ed8\u8ba4)\n\n# \u5f20\u91cf\u7c7b\u578b\u8f6c\u6362\nx = genesis.randn(3, 4, dtype=\"float32\")\nx_half = x.half()      # \u8f6c\u6362\u4e3afloat16\nx_float = x.float()    # \u8f6c\u6362\u4e3afloat32\n</code></pre>"},{"location":"core-components/dtypes/#_27","title":"\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3","text":"Python<pre><code># \u542f\u7528\u6df7\u5408\u7cbe\u5ea6\ngenesis.enable_autocast = True\n\n# \u6a21\u578b\u4f1a\u81ea\u52a8\u5728fp16\u548cfp32\u95f4\u8f6c\u6362\nimport genesis.nn as nn\n\nmodel = nn.Linear(784, 128)\nx = genesis.randn(32, 784, dtype=genesis.float16)\n\n# \u524d\u5411\u4f20\u64ad\u65f6\u81ea\u52a8\u5904\u7406\u7c7b\u578b\u8f6c\u6362\noutput = model(x)\n</code></pre>"},{"location":"core-components/dtypes/#_28","title":"\u8bbe\u5907\u95f4\u7c7b\u578b\u4e00\u81f4\u6027","text":"Python<pre><code># CPU\u548cGPU\u4f7f\u7528\u76f8\u540c\u7684\u7c7b\u578b\u7cfb\u7edf\ncpu_tensor = genesis.randn(3, 4, device=\"cpu\", dtype=genesis.float32)\ngpu_tensor = genesis.randn(3, 4, device=\"cuda\", dtype=genesis.float32)\n\nprint(cpu_tensor.dtype == gpu_tensor.dtype)  # True\nprint(cpu_tensor.dtype.name)                 # \"float32\"\nprint(gpu_tensor.dtype.name)                 # \"float32\"\n</code></pre>"},{"location":"core-components/dtypes/#bfloat16","title":"bfloat16\u7279\u6b8a\u5904\u7406","text":"Python<pre><code># bfloat16\u5728\u4e0d\u540c\u540e\u7aef\u7684\u5904\u7406\nx_bf16 = genesis.randn(3, 4, dtype=genesis.bfloat16)\n\n# CPU\u540e\u7aef: \u4f7f\u7528float32\u5b58\u50a8\u4f46\u6807\u8bb0\u4e3abfloat16\n# GPU\u540e\u7aef: \u539f\u751fbfloat16\u652f\u6301\uff08\u5982\u679c\u786c\u4ef6\u652f\u6301\uff09\nprint(f\"\u7c7b\u578b\u540d: {x_bf16.dtype.name}\")           # \"bfloat16\"\nprint(f\"Triton\u540d: {x_bf16.dtype.triton_name}\")  # \"bfloat16\"\nprint(f\"NumPy\u7c7b\u578b: {x_bf16.dtype.numpy_dtype}\") # &lt;class 'numpy.float32'&gt;\n</code></pre>"},{"location":"core-components/dtypes/#_29","title":"\ud83d\ude80 \u6027\u80fd\u4f18\u5316","text":""},{"location":"core-components/dtypes/#_30","title":"\u7c7b\u578b\u8f6c\u6362\u4f18\u5316","text":"<ul> <li>\u60f0\u6027\u8f6c\u6362\uff1a\u53ea\u6709\u5728\u771f\u6b63\u9700\u8981\u65f6\u624d\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362</li> <li>\u7f13\u5b58\u673a\u5236\uff1a\u5e38\u7528\u7684\u7c7b\u578b\u8f6c\u6362\u7ed3\u679c\u4f1a\u88ab\u7f13\u5b58</li> <li>\u96f6\u62f7\u8d1d\uff1a\u540c\u7c7b\u578b\u4e0d\u540c\u8bbe\u5907\u95f4\u7684\u8f6c\u6362\u5c3d\u53ef\u80fd\u96f6\u62f7\u8d1d</li> </ul>"},{"location":"core-components/dtypes/#_31","title":"\u5185\u5b58\u4f18\u5316","text":"<ul> <li>\u7d27\u51d1\u5b58\u50a8\uff1a\u4f7f\u7528\u5408\u9002\u7684\u6570\u636e\u7c7b\u578b\u51cf\u5c11\u5185\u5b58\u5360\u7528</li> <li>\u5bf9\u9f50\u4f18\u5316\uff1a\u6570\u636e\u7c7b\u578b\u5bf9\u9f50\u4ee5\u63d0\u9ad8\u8bbf\u95ee\u6548\u7387</li> <li>\u6279\u91cf\u8f6c\u6362\uff1a\u6279\u91cf\u5904\u7406\u7c7b\u578b\u8f6c\u6362\u4ee5\u63d0\u9ad8\u6548\u7387</li> </ul> <p>Genesis\u7684\u6570\u636e\u7c7b\u578b\u7cfb\u7edf\u4e3a\u6574\u4e2a\u6846\u67b6\u63d0\u4f9b\u4e86\u7edf\u4e00\u3001\u9ad8\u6548\u3001\u7c7b\u578b\u5b89\u5168\u7684\u6570\u636e\u8868\u793a\uff0c\u662f\u5b9e\u73b0\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u548c\u8de8\u8bbe\u5907\u8ba1\u7b97\u7684\u57fa\u7840\u3002</p>"},{"location":"core-components/tensor/","title":"Tensor Operations","text":"<p>Core tensor operations and data structures in Genesis.</p>"},{"location":"core-components/tensor/#overview","title":"Overview","text":"<p>Genesis tensors provide the fundamental data structure for all computations, similar to PyTorch tensors but optimized for our dual backend architecture.</p>"},{"location":"core-components/tensor/#creating-tensors","title":"Creating Tensors","text":"Python<pre><code>import genesis\n\n# Create tensors\nx = genesis.tensor([1, 2, 3, 4])\ny = genesis.zeros(3, 4)\nz = genesis.randn(2, 3, device='cuda')\n</code></pre>"},{"location":"core-components/tensor/#tensor-operations_1","title":"Tensor Operations","text":"Python<pre><code># Basic operations\nresult = x + y\nresult = genesis.matmul(x, y)\nresult = x.sum(dim=1)\n</code></pre>"},{"location":"core-components/tensor/#device-management","title":"Device Management","text":"Python<pre><code># Move tensors between devices\ncpu_tensor = gpu_tensor.cpu()\ngpu_tensor = cpu_tensor.cuda()\ngpu_tensor = cpu_tensor.to('cuda')\n</code></pre> <p>This documentation is under construction. More detailed tensor API documentation will be added.</p>"},{"location":"core-components/tensor/#see-also","title":"See Also","text":"<ul> <li>Autograd - Automatic differentiation with tensors</li> <li>CUDA Storage - GPU memory management</li> </ul>"},{"location":"getting-started/","title":"\u5feb\u901f\u5f00\u59cb","text":"<p>\u6b22\u8fce\u4f7f\u7528 Genesis \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff01\u672c\u6307\u5357\u5c06\u5e2e\u52a9\u60a8\u5728\u51e0\u5206\u949f\u5185\u5f00\u59cb\u4f7f\u7528 Genesis\u3002</p>"},{"location":"getting-started/#_2","title":"\ud83c\udfaf \u6982\u8ff0","text":"<p>Genesis \u662f\u4e00\u4e2a\u4e13\u4e3a\u5b66\u4e60\u548c\u7814\u7a76\u8bbe\u8ba1\u7684\u8f7b\u91cf\u7ea7\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5b83\u63d0\u4f9b\u4e86\uff1a</p> <ul> <li>\u7b80\u6d01\u76f4\u89c2\u7684API\u8bbe\u8ba1</li> <li>\u9ad8\u6027\u80fdGPU\u52a0\u901f\u8ba1\u7b97</li> <li>\u5b8c\u6574\u7684\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u529f\u80fd</li> <li>\u4e0ePyTorch\u751f\u6001\u826f\u597d\u7684\u517c\u5bb9\u6027</li> <li>\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u652f\u6301\uff08FP16/BF16\uff09</li> <li>\u5185\u7f6eLLM\u6a21\u578b\u5982Qwen</li> </ul>"},{"location":"getting-started/#5","title":"\u26a1 5\u5206\u949f\u5feb\u901f\u4f53\u9a8c","text":""},{"location":"getting-started/#1-genesis","title":"1. \u5b89\u88c5 Genesis","text":"Bash<pre><code># \u5b89\u88c5\u6838\u5fc3\u4f9d\u8d56\npip install torch triton numpy cuda-python\n\n# \u514b\u9686\u4ee3\u7801\u4ed3\u5e93\ngit clone https://github.com/phonism/genesis.git\ncd genesis\n\n# \u5b89\u88c5 Genesis\npip install -e .\n</code></pre>"},{"location":"getting-started/#2","title":"2. \u7b2c\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc","text":"Python<pre><code>import genesis\nimport genesis.nn as nn\n\n# \u5b9a\u4e49\u4e00\u4e2a\u7b80\u5355\u7684\u591a\u5c42\u611f\u77e5\u673a\nclass MLP(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.layer1 = nn.Linear(input_dim, hidden_dim)\n        self.layer2 = nn.Linear(hidden_dim, output_dim)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.relu(self.layer1(x))\n        return self.layer2(x)\n\n# \u521b\u5efa\u6a21\u578b\u548c\u6570\u636e\nmodel = MLP(784, 128, 10)\nx = genesis.randn(32, 784)  # \u6279\u6b21\u5927\u5c0f32\uff0c\u8f93\u5165\u7ef4\u5ea6784\n\n# \u524d\u5411\u4f20\u64ad\noutput = model(x)\nprint(f\"\u8f93\u51fa\u5f62\u72b6: {output.shape}\")  # torch.Size([32, 10])\n</code></pre>"},{"location":"getting-started/#3","title":"3. \u8bad\u7ec3\u5faa\u73af","text":"Python<pre><code>import genesis.optim as optim\n\n# \u521b\u5efa\u4f18\u5316\u5668\u548c\u635f\u5931\u51fd\u6570\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\n# \u6a21\u62df\u8bad\u7ec3\u6570\u636e\ntargets = genesis.randint(0, 10, (32,))\n\n# \u8bad\u7ec3\u4e00\u4e2a\u6279\u6b21\noptimizer.zero_grad()        # \u6e05\u96f6\u68af\u5ea6\noutput = model(x)           # \u524d\u5411\u4f20\u64ad\nloss = criterion(output, targets)  # \u8ba1\u7b97\u635f\u5931\nloss.backward()             # \u53cd\u5411\u4f20\u64ad\noptimizer.step()            # \u66f4\u65b0\u53c2\u6570\n\nprint(f\"\u635f\u5931: {loss.item():.4f}\")\n</code></pre>"},{"location":"getting-started/#_3","title":"\ud83d\udcda \u6838\u5fc3\u6982\u5ff5","text":""},{"location":"getting-started/#tensor","title":"\u5f20\u91cf (Tensor)","text":"<p>Genesis\u4e2d\u7684\u57fa\u7840\u6570\u636e\u7ed3\u6784\uff0c\u652f\u6301\u81ea\u52a8\u5fae\u5206\uff1a</p> Python<pre><code>import genesis\n\n# \u521b\u5efa\u5f20\u91cf\uff08\u81ea\u52a8\u6570\u636e\u7c7b\u578b\u63a8\u65ad\uff09\nx = genesis.tensor([1.0, 2.0, 3.0], requires_grad=True)  # \u2192 float32\ny = genesis.tensor([4, 5, 6])                           # \u2192 int64\nz = genesis.tensor([1, 2, 3], dtype=genesis.float32)     # \u663e\u5f0f\u6570\u636e\u7c7b\u578b\n\n# \u57fa\u7840\u64cd\u4f5c\nresult = x * y.float() + x.sum()  # \u5e7f\u64ad\u548c\u7c7b\u578b\u8f6c\u6362\n\n# PyTorch\u98ce\u683c\u7684\u5f52\u7ea6\u64cd\u4f5c\ntotal = x.sum()                      # \u6240\u6709\u5143\u7d20\u6c42\u548c\nmean_val = x.mean()                  # \u6240\u6709\u5143\u7d20\u5e73\u5747\u503c\nmax_val = x.max()                    # \u6700\u5927\u5143\u7d20\n\n# \u6309\u7ef4\u5ea6\u64cd\u4f5c\ndata = genesis.tensor([[1, 2, 3], [4, 5, 6]])\nrow_sums = data.sum(dim=1)                    # \u6309\u884c\u6c42\u548c\ncol_means = data.mean(dim=0, keepdim=True)   # \u6309\u5217\u6c42\u5e73\u5747\u503c\uff0c\u4fdd\u6301\u7ef4\u5ea6\n\n# \u4e5f\u652f\u6301NumPy\u98ce\u683c\uff08\u517c\u5bb9\u6027\uff09\nnumpy_style = data.sum(axis=0, keepdims=True)\n\n# \u8ba1\u7b97\u68af\u5ea6\nresult.backward()\nprint(f\"x\u7684\u68af\u5ea6: {x.grad}\")  # \u5173\u4e8ex\u7684\u68af\u5ea6\n</code></pre>"},{"location":"getting-started/#module","title":"\u6a21\u5757 (Module)","text":"<p>\u795e\u7ecf\u7f51\u7edc\u7ec4\u4ef6\u7684\u57fa\u7c7b\uff1a</p> Python<pre><code>import genesis.nn as nn\n\nclass CustomLayer(nn.Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        self.weight = genesis.randn(out_features, in_features, requires_grad=True)\n        self.bias = genesis.zeros(out_features, requires_grad=True)\n\n    def forward(self, x):\n        return genesis.functional.linear(x, self.weight, self.bias)\n\n# \u4f7f\u7528\u81ea\u5b9a\u4e49\u5c42\nlayer = CustomLayer(10, 5)\ninput_tensor = genesis.randn(3, 10)\noutput = layer(input_tensor)\n</code></pre>"},{"location":"getting-started/#optimizer","title":"\u4f18\u5316\u5668 (Optimizer)","text":"<p>\u53c2\u6570\u66f4\u65b0\u7b97\u6cd5\uff1a</p> Python<pre><code>import genesis.optim as optim\n\n# \u4e0d\u540c\u7684\u4f18\u5316\u5668\u9009\u62e9\nsgd_optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\nadam_optimizer = optim.Adam(model.parameters(), lr=0.001)\nadamw_optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n</code></pre>"},{"location":"getting-started/#_4","title":"\ud83d\udee0\ufe0f \u73af\u5883\u914d\u7f6e","text":""},{"location":"getting-started/#_5","title":"\u786c\u4ef6\u8981\u6c42","text":"<ul> <li>CPU: \u73b0\u4ee3\u591a\u6838\u5904\u7406\u5668</li> <li>\u5185\u5b58: \u6700\u5c118GB RAM\uff0c\u63a8\u835016GB+</li> <li>GPU: NVIDIA GPU with CUDA\u652f\u6301 (\u63a8\u8350)</li> <li>\u5b58\u50a8: \u81f3\u5c112GB\u53ef\u7528\u7a7a\u95f4</li> </ul>"},{"location":"getting-started/#_6","title":"\u8f6f\u4ef6\u4f9d\u8d56","text":"Bash<pre><code># Python\u73af\u5883\nPython &gt;= 3.8\n\n# \u6838\u5fc3\u4f9d\u8d56\ntorch &gt;= 2.0.0\ntriton &gt;= 2.0.0\nnumpy &gt;= 1.21.0\ncuda-python &gt;= 11.8.0  # GPU\u652f\u6301\n\n# \u53ef\u9009\u4f9d\u8d56\nmatplotlib &gt;= 3.5.0  # \u7528\u4e8e\u53ef\u89c6\u5316\ntqdm &gt;= 4.64.0      # \u8fdb\u5ea6\u6761\nwandb &gt;= 0.13.0     # \u5b9e\u9a8c\u8ddf\u8e2a\n</code></pre>"},{"location":"getting-started/#_7","title":"\ud83d\udcd6 \u4e0b\u4e00\u6b65","text":"<p>\u73b0\u5728\u4f60\u5df2\u7ecf\u4e86\u89e3\u4e86Genesis\u7684\u57fa\u7840\u7528\u6cd5\uff0c\u53ef\u4ee5\u7ee7\u7eed\u63a2\u7d22\uff1a</p>"},{"location":"getting-started/#_8","title":"\ud83c\udf93 \u6df1\u5165\u5b66\u4e60","text":"<ul> <li>\u5b8c\u6574\u5b89\u88c5\u6307\u5357 - \u8be6\u7ec6\u7684\u5b89\u88c5\u548c\u914d\u7f6e\u6b65\u9aa4</li> <li>\u7b2c\u4e00\u4e2a\u5b8c\u6574\u7a0b\u5e8f - \u6784\u5efa\u5b8c\u6574\u7684\u8bad\u7ec3\u6d41\u7a0b</li> <li>\u57fa\u7840\u8bad\u7ec3\u6559\u7a0b - \u7cfb\u7edf\u6027\u7684\u8bad\u7ec3\u6559\u7a0b</li> </ul>"},{"location":"getting-started/#_9","title":"\ud83d\udd0d \u67b6\u6784\u7406\u89e3","text":"<ul> <li>\u67b6\u6784\u6982\u8ff0 - \u4e86\u89e3Genesis\u7684\u6574\u4f53\u8bbe\u8ba1</li> <li>\u6838\u5fc3\u7ec4\u4ef6 - \u6df1\u5165\u7406\u89e3\u5185\u90e8\u5b9e\u73b0</li> <li>API\u53c2\u8003 - \u5b8c\u6574\u7684API\u6587\u6863</li> </ul>"},{"location":"getting-started/#_10","title":"\ud83d\ude80 \u9ad8\u7ea7\u7279\u6027","text":"<ul> <li>\u81ea\u5b9a\u4e49\u7b97\u5b50 - \u5b9e\u73b0\u81ea\u5b9a\u4e49\u64cd\u4f5c</li> <li>\u6027\u80fd\u4f18\u5316 - \u8bad\u7ec3\u6027\u80fd\u8c03\u4f18</li> <li>\u5206\u5e03\u5f0f\u8bad\u7ec3 - \u591aGPU\u8bad\u7ec3</li> </ul>"},{"location":"getting-started/#_11","title":"\u2753 \u5e38\u89c1\u95ee\u9898","text":""},{"location":"getting-started/#q-genesispytorch","title":"Q: Genesis\u4e0ePyTorch\u6709\u4ec0\u4e48\u533a\u522b\uff1f","text":"<p>A: Genesis\u662f\u6559\u80b2\u5bfc\u5411\u7684\u6846\u67b6\uff0c\u4ee3\u7801\u66f4\u7b80\u6d01\u6613\u61c2\uff0c\u9002\u5408\u5b66\u4e60\u6df1\u5ea6\u5b66\u4e60\u7684\u5185\u90e8\u5b9e\u73b0\u3002PyTorch\u66f4\u9002\u5408\u751f\u4ea7\u73af\u5883\u4f7f\u7528\u3002</p>"},{"location":"getting-started/#q-genesis","title":"Q: \u53ef\u4ee5\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u4f7f\u7528Genesis\u5417\uff1f","text":"<p>A: Genesis\u4e3b\u8981\u7528\u4e8e\u6559\u80b2\u548c\u7814\u7a76\uff0c\u867d\u7136\u529f\u80fd\u5b8c\u6574\uff0c\u4f46\u5efa\u8bae\u751f\u4ea7\u73af\u5883\u4f7f\u7528\u66f4\u6210\u719f\u7684\u6846\u67b6\u5982PyTorch\u3002</p>"},{"location":"getting-started/#q","title":"Q: \u5982\u4f55\u83b7\u5f97\u5e2e\u52a9\uff1f","text":"<p>A: \u53ef\u4ee5\u901a\u8fc7GitHub Issues\u3001Discussions\u6216\u67e5\u770b\u8be6\u7ec6\u6587\u6863\u83b7\u5f97\u5e2e\u52a9\u3002</p>"},{"location":"getting-started/#_12","title":"\ud83c\udf89 \u51c6\u5907\u597d\u4e86\u5417\uff1f","text":"<p>\u8ba9\u6211\u4eec\u5f00\u59cb\u6df1\u5165\u4e86\u89e3Genesis\u5427\uff01</p> <p>\u8be6\u7ec6\u5b89\u88c5\u6307\u5357 \u5b8c\u6574\u6559\u7a0b</p>"},{"location":"getting-started/first-steps/","title":"\u7b2c\u4e00\u4e2a\u5b8c\u6574\u7a0b\u5e8f","text":"<p>\u5b8c\u6210\u5b89\u88c5\u540e\uff0c\u8ba9\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u5b8c\u6574\u7684\u4f8b\u5b50\u6765\u5b66\u4e60Genesis\u7684\u57fa\u672c\u7528\u6cd5\u3002\u6211\u4eec\u5c06\u5b9e\u73b0\u4e00\u4e2a\u56fe\u50cf\u5206\u7c7b\u5668\u6765\u6f14\u793a\u5b8c\u6574\u7684\u6df1\u5ea6\u5b66\u4e60\u5de5\u4f5c\u6d41\u7a0b\u3002</p>"},{"location":"getting-started/first-steps/#_2","title":"\ud83c\udfaf \u9879\u76ee\u76ee\u6807","text":"<p>\u6784\u5efa\u4e00\u4e2a\u624b\u5199\u6570\u5b57\u8bc6\u522b\u5668\uff08\u7c7b\u4f3cMNIST\uff09\uff0c\u5b66\u4e60Genesis\u7684\u6838\u5fc3\u6982\u5ff5\uff1a</p> <ul> <li>\u6570\u636e\u52a0\u8f7d\u548c\u9884\u5904\u7406</li> <li>\u6a21\u578b\u5b9a\u4e49\u548c\u521d\u59cb\u5316</li> <li>\u8bad\u7ec3\u5faa\u73af\u548c\u9a8c\u8bc1</li> <li>\u6a21\u578b\u4fdd\u5b58\u548c\u52a0\u8f7d</li> </ul>"},{"location":"getting-started/first-steps/#_3","title":"\ud83d\udcca \u9879\u76ee\u7ed3\u6784","text":"<p>\u521b\u5efa\u9879\u76ee\u76ee\u5f55\u7ed3\u6784\uff1a</p> Text Only<pre><code>first_project/\n\u251c\u2500\u2500 data/                # \u6570\u636e\u76ee\u5f55\n\u251c\u2500\u2500 models/              # \u6a21\u578b\u4fdd\u5b58\u76ee\u5f55\n\u251c\u2500\u2500 train.py            # \u8bad\u7ec3\u811a\u672c\n\u251c\u2500\u2500 model.py            # \u6a21\u578b\u5b9a\u4e49\n\u251c\u2500\u2500 dataset.py          # \u6570\u636e\u52a0\u8f7d\n\u2514\u2500\u2500 utils.py            # \u5de5\u5177\u51fd\u6570\n</code></pre>"},{"location":"getting-started/first-steps/#1-datasetpy","title":"\ud83d\udcc1 1. \u6570\u636e\u5904\u7406 (<code>dataset.py</code>)","text":"Python<pre><code>\"\"\"\u6570\u636e\u52a0\u8f7d\u548c\u9884\u5904\u7406\u6a21\u5757\"\"\"\nimport genesis\nimport numpy as np\nfrom typing import Tuple, List\nimport pickle\nimport os\n\nclass SimpleDataset:\n    \"\"\"\u7b80\u5355\u7684\u6570\u636e\u96c6\u7c7b\"\"\"\n\n    def __init__(self, data: np.ndarray, labels: np.ndarray, transform=None):\n        \"\"\"\n        \u521d\u59cb\u5316\u6570\u636e\u96c6\n\n        Args:\n            data: \u8f93\u5165\u6570\u636e (N, H, W) \u6216 (N, D)\n            labels: \u6807\u7b7e (N,)\n            transform: \u6570\u636e\u53d8\u6362\u51fd\u6570\n        \"\"\"\n        self.data = data.astype(np.float32)\n        self.labels = labels.astype(np.int64)\n        self.transform = transform\n\n    def __len__(self) -&gt; int:\n        return len(self.data)\n\n    def __getitem__(self, idx: int) -&gt; Tuple[genesis.Tensor, genesis.Tensor]:\n        \"\"\"\u83b7\u53d6\u5355\u4e2a\u6837\u672c\"\"\"\n        x = self.data[idx]\n        y = self.labels[idx]\n\n        if self.transform:\n            x = self.transform(x)\n\n        return genesis.tensor(x), genesis.tensor(y)\n\nclass DataLoader:\n    \"\"\"\u7b80\u5355\u7684\u6570\u636e\u52a0\u8f7d\u5668\"\"\"\n\n    def __init__(self, dataset: SimpleDataset, batch_size: int = 32, shuffle: bool = True):\n        self.dataset = dataset\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self._reset_indices()\n\n    def _reset_indices(self):\n        \"\"\"\u91cd\u7f6e\u7d22\u5f15\"\"\"\n        self.indices = np.arange(len(self.dataset))\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n        self.current = 0\n\n    def __iter__(self):\n        self._reset_indices()\n        return self\n\n    def __next__(self):\n        if self.current &gt;= len(self.dataset):\n            raise StopIteration\n\n        # \u83b7\u53d6\u5f53\u524d\u6279\u6b21\u7684\u7d22\u5f15\n        end_idx = min(self.current + self.batch_size, len(self.dataset))\n        batch_indices = self.indices[self.current:end_idx]\n\n        # \u6536\u96c6\u6279\u6b21\u6570\u636e\n        batch_data = []\n        batch_labels = []\n\n        for idx in batch_indices:\n            x, y = self.dataset[idx]\n            batch_data.append(x)\n            batch_labels.append(y)\n\n        self.current = end_idx\n\n        # \u5806\u53e0\u6210\u6279\u6b21\n        batch_x = genesis.stack(batch_data, dim=0)\n        batch_y = genesis.stack(batch_labels, dim=0)\n\n        return batch_x, batch_y\n\ndef create_synthetic_data(n_samples: int = 1000, n_features: int = 784, n_classes: int = 10) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\u521b\u5efa\u5408\u6210\u6570\u636e\u7528\u4e8e\u6f14\u793a\"\"\"\n    np.random.seed(42)\n\n    # \u751f\u6210\u968f\u673a\u6570\u636e\n    data = np.random.randn(n_samples, n_features).astype(np.float32)\n\n    # \u4e3a\u6bcf\u4e2a\u7c7b\u522b\u6dfb\u52a0\u4e00\u4e9b\u6a21\u5f0f\n    labels = np.random.randint(0, n_classes, n_samples)\n    for i in range(n_classes):\n        mask = labels == i\n        # \u7ed9\u6bcf\u4e2a\u7c7b\u522b\u6dfb\u52a0\u7279\u5b9a\u7684\u504f\u7f6e\n        data[mask] += np.random.randn(n_features) * 0.5\n\n    return data, labels\n\ndef load_data() -&gt; Tuple[DataLoader, DataLoader]:\n    \"\"\"\u52a0\u8f7d\u8bad\u7ec3\u548c\u9a8c\u8bc1\u6570\u636e\"\"\"\n    print(\"\ud83d\udd04 \u52a0\u8f7d\u6570\u636e...\")\n\n    # \u521b\u5efa\u5408\u6210\u6570\u636e (\u5b9e\u9645\u9879\u76ee\u4e2d\u66ff\u6362\u4e3a\u771f\u5b9e\u6570\u636e)\n    train_data, train_labels = create_synthetic_data(800, 784, 10)\n    val_data, val_labels = create_synthetic_data(200, 784, 10)\n\n    # \u6570\u636e\u6807\u51c6\u5316\n    def normalize(x):\n        return (x - x.mean()) / (x.std() + 1e-8)\n\n    # \u521b\u5efa\u6570\u636e\u96c6\n    train_dataset = SimpleDataset(train_data, train_labels, transform=normalize)\n    val_dataset = SimpleDataset(val_data, val_labels, transform=normalize)\n\n    # \u521b\u5efa\u6570\u636e\u52a0\u8f7d\u5668\n    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n    print(f\"\u2705 \u6570\u636e\u52a0\u8f7d\u5b8c\u6210 - \u8bad\u7ec3\u96c6: {len(train_dataset)}, \u9a8c\u8bc1\u96c6: {len(val_dataset)}\")\n\n    return train_loader, val_loader\n</code></pre>"},{"location":"getting-started/first-steps/#2-modelpy","title":"\ud83e\udde0 2. \u6a21\u578b\u5b9a\u4e49 (<code>model.py</code>)","text":"Python<pre><code>\"\"\"\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5b9a\u4e49\"\"\"\nimport genesis\nimport genesis.nn as nn\nimport genesis.nn.functional as F\n\nclass MLP(nn.Module):\n    \"\"\"\u591a\u5c42\u611f\u77e5\u673a\u5206\u7c7b\u5668\"\"\"\n\n    def __init__(self, input_dim: int = 784, hidden_dims: list = None, num_classes: int = 10, dropout_rate: float = 0.2):\n        \"\"\"\n        \u521d\u59cb\u5316MLP\u6a21\u578b\n\n        Args:\n            input_dim: \u8f93\u5165\u7ef4\u5ea6\n            hidden_dims: \u9690\u85cf\u5c42\u7ef4\u5ea6\u5217\u8868\n            num_classes: \u5206\u7c7b\u6570\u91cf\n            dropout_rate: Dropout\u6bd4\u7387\n        \"\"\"\n        super().__init__()\n\n        if hidden_dims is None:\n            hidden_dims = [512, 256, 128]\n\n        # \u6784\u5efa\u7f51\u7edc\u5c42\n        layers = []\n        prev_dim = input_dim\n\n        for hidden_dim in hidden_dims:\n            layers.extend([\n                nn.Linear(prev_dim, hidden_dim),\n                nn.ReLU(),\n                nn.Dropout(dropout_rate)\n            ])\n            prev_dim = hidden_dim\n\n        # \u8f93\u51fa\u5c42\n        layers.append(nn.Linear(prev_dim, num_classes))\n\n        self.network = nn.Sequential(*layers)\n\n        # \u521d\u59cb\u5316\u6743\u91cd\n        self._init_weights()\n\n    def _init_weights(self):\n        \"\"\"\u6743\u91cd\u521d\u59cb\u5316\"\"\"\n        for module in self.modules():\n            if isinstance(module, nn.Linear):\n                # Xavier\u521d\u59cb\u5316\n                std = (2.0 / (module.in_features + module.out_features)) ** 0.5\n                module.weight.data.normal_(0, std)\n                if module.bias is not None:\n                    module.bias.data.zero_()\n\n    def forward(self, x: genesis.Tensor) -&gt; genesis.Tensor:\n        \"\"\"\u524d\u5411\u4f20\u64ad\"\"\"\n        # \u5c55\u5e73\u8f93\u5165 (\u5982\u679c\u662f\u56fe\u50cf\u6570\u636e)\n        if x.dim() &gt; 2:\n            x = x.view(x.size(0), -1)\n\n        return self.network(x)\n\nclass CNN(nn.Module):\n    \"\"\"\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u5668 (\u5982\u679c\u9700\u8981\u5904\u7406\u56fe\u50cf)\"\"\"\n\n    def __init__(self, num_classes: int = 10):\n        super().__init__()\n\n        # \u5377\u79ef\u5c42\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n\n        # \u6c60\u5316\u5c42\n        self.pool = nn.MaxPool2d(2, 2)\n\n        # \u5168\u8fde\u63a5\u5c42\n        self.fc1 = nn.Linear(128 * 3 * 3, 512)  # \u5047\u8bbe\u8f93\u5165\u662f28x28\n        self.fc2 = nn.Linear(512, num_classes)\n\n        # Dropout\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x: genesis.Tensor) -&gt; genesis.Tensor:\n        # \u5377\u79ef + \u6c60\u5316\n        x = self.pool(F.relu(self.conv1(x)))  # 28x28 -&gt; 14x14\n        x = self.pool(F.relu(self.conv2(x)))  # 14x14 -&gt; 7x7  \n        x = self.pool(F.relu(self.conv3(x)))  # 7x7 -&gt; 3x3\n\n        # \u5c55\u5e73\n        x = x.view(x.size(0), -1)\n\n        # \u5168\u8fde\u63a5\u5c42\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n\n        return x\n\ndef create_model(model_type: str = \"mlp\", **kwargs) -&gt; nn.Module:\n    \"\"\"\u5de5\u5382\u51fd\u6570\uff1a\u521b\u5efa\u6a21\u578b\"\"\"\n    if model_type.lower() == \"mlp\":\n        return MLP(**kwargs)\n    elif model_type.lower() == \"cnn\":\n        return CNN(**kwargs)\n    else:\n        raise ValueError(f\"\u672a\u77e5\u7684\u6a21\u578b\u7c7b\u578b: {model_type}\")\n</code></pre>"},{"location":"getting-started/first-steps/#3-utilspy","title":"\ud83d\udee0\ufe0f 3. \u5de5\u5177\u51fd\u6570 (<code>utils.py</code>)","text":"Python<pre><code>\"\"\"\u5de5\u5177\u51fd\u6570\u6a21\u5757\"\"\"\nimport genesis\nimport time\nimport os\nfrom typing import Dict, Any\nimport json\n\nclass AverageMeter:\n    \"\"\"\u5e73\u5747\u503c\u8ba1\u7b97\u5668\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val: float, n: int = 1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\nclass Timer:\n    \"\"\"\u8ba1\u65f6\u5668\"\"\"\n\n    def __init__(self):\n        self.start_time = None\n        self.end_time = None\n\n    def start(self):\n        self.start_time = time.time()\n\n    def stop(self):\n        self.end_time = time.time()\n        return self.end_time - self.start_time\n\n    def elapsed(self):\n        if self.start_time is None:\n            return 0\n        return time.time() - self.start_time\n\ndef accuracy(output: genesis.Tensor, target: genesis.Tensor, topk: tuple = (1,)) -&gt; list:\n    \"\"\"\u8ba1\u7b97\u51c6\u786e\u7387\"\"\"\n    with genesis.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n\n        return res\n\ndef save_checkpoint(model: genesis.nn.Module, optimizer: genesis.optim.Optimizer, \n                   epoch: int, loss: float, accuracy: float, filepath: str):\n    \"\"\"\u4fdd\u5b58\u68c0\u67e5\u70b9\"\"\"\n    checkpoint = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': loss,\n        'accuracy': accuracy\n    }\n\n    # \u786e\u4fdd\u76ee\u5f55\u5b58\u5728\n    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n\n    genesis.save(checkpoint, filepath)\n    print(f\"\ud83d\udcbe \u68c0\u67e5\u70b9\u5df2\u4fdd\u5b58: {filepath}\")\n\ndef load_checkpoint(filepath: str, model: genesis.nn.Module, optimizer: genesis.optim.Optimizer = None) -&gt; Dict[str, Any]:\n    \"\"\"\u52a0\u8f7d\u68c0\u67e5\u70b9\"\"\"\n    checkpoint = genesis.load(filepath)\n\n    model.load_state_dict(checkpoint['model_state_dict'])\n\n    if optimizer and 'optimizer_state_dict' in checkpoint:\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n\n    print(f\"\ud83d\udcc1 \u68c0\u67e5\u70b9\u5df2\u52a0\u8f7d: {filepath}\")\n    print(f\"   \u8f6e\u6b21: {checkpoint['epoch']}, \u635f\u5931: {checkpoint['loss']:.4f}, \u51c6\u786e\u7387: {checkpoint['accuracy']:.2f}%\")\n\n    return checkpoint\n\ndef save_training_history(history: Dict[str, list], filepath: str):\n    \"\"\"\u4fdd\u5b58\u8bad\u7ec3\u5386\u53f2\"\"\"\n    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n\n    with open(filepath, 'w') as f:\n        json.dump(history, f, indent=2)\n\n    print(f\"\ud83d\udcca \u8bad\u7ec3\u5386\u53f2\u5df2\u4fdd\u5b58: {filepath}\")\n\ndef print_model_summary(model: genesis.nn.Module, input_shape: tuple):\n    \"\"\"\u6253\u5370\u6a21\u578b\u6458\u8981\"\"\"\n    print(\"\ud83c\udfd7\ufe0f  \u6a21\u578b\u67b6\u6784:\")\n    print(\"=\" * 50)\n\n    # \u8ba1\u7b97\u53c2\u6570\u6570\u91cf\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n    print(f\"\u603b\u53c2\u6570\u91cf: {total_params:,}\")\n    print(f\"\u53ef\u8bad\u7ec3\u53c2\u6570: {trainable_params:,}\")\n    print(f\"\u8f93\u5165\u5f62\u72b6: {input_shape}\")\n\n    # \u6d4b\u8bd5\u524d\u5411\u4f20\u64ad\n    dummy_input = genesis.randn(*input_shape)\n    try:\n        with genesis.no_grad():\n            output = model(dummy_input)\n        print(f\"\u8f93\u51fa\u5f62\u72b6: {output.shape}\")\n    except Exception as e:\n        print(f\"\u524d\u5411\u4f20\u64ad\u6d4b\u8bd5\u5931\u8d25: {e}\")\n\n    print(\"=\" * 50)\n</code></pre>"},{"location":"getting-started/first-steps/#4-trainpy","title":"\ud83d\ude82 4. \u8bad\u7ec3\u811a\u672c (<code>train.py</code>)","text":"<p> [{\"id\": \"1\", \"content\": \"\\u521b\\u5efa\\u6587\\u6863\\u76ee\\u5f55\\u7ed3\\u6784\\u548c\\u914d\\u7f6e\\u6587\\u4ef6\", \"status\": \"completed\"}, {\"id\": \"2\", \"content\": \"\\u7f16\\u5199\\u9996\\u9875\\u548c\\u5feb\\u901f\\u5f00\\u59cb\\u6587\\u6863\", \"status\": \"completed\"}, {\"id\": \"3\", \"content\": \"\\u7f16\\u5199\\u67b6\\u6784\\u8bbe\\u8ba1\\u6587\\u6863\", \"status\": \"pending\"}, {\"id\": \"4\", \"content\": \"\\u7f16\\u5199\\u6838\\u5fc3\\u7ec4\\u4ef6\\u6587\\u6863\", \"status\": \"pending\"}, {\"id\": \"5\", \"content\": \"\\u7f16\\u5199\\u795e\\u7ecf\\u7f51\\u7edc\\u6a21\\u5757\\u6587\\u6863\", \"status\": \"pending\"}, {\"id\": \"6\", \"content\": \"\\u7f16\\u5199API\\u53c2\\u8003\\u6587\\u6863\", \"status\": \"pending\"}]"},{"location":"getting-started/installation/","title":"\u5b89\u88c5\u6307\u5357","text":"<p>\u672c\u6307\u5357\u5c06\u5e2e\u52a9\u4f60\u5728\u4e0d\u540c\u73af\u5883\u4e0b\u5b89\u88c5Genesis\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u3002</p>"},{"location":"getting-started/installation/#_2","title":"\ud83d\udccb \u7cfb\u7edf\u8981\u6c42","text":""},{"location":"getting-started/installation/#_3","title":"\u786c\u4ef6\u8981\u6c42","text":"<ul> <li>CPU: x86_64\u67b6\u6784\uff0c\u652f\u6301AVX\u6307\u4ee4\u96c6</li> <li>\u5185\u5b58: \u6700\u5c118GB\uff0c\u63a8\u835016GB+</li> <li>GPU: NVIDIA GPU with Compute Capability \u2265 6.0 (\u53ef\u9009\u4f46\u63a8\u8350)</li> <li>\u5b58\u50a8: 2GB\u53ef\u7528\u7a7a\u95f4</li> </ul>"},{"location":"getting-started/installation/#_4","title":"\u8f6f\u4ef6\u8981\u6c42","text":"<ul> <li>\u64cd\u4f5c\u7cfb\u7edf: Linux (Ubuntu 20.04+), macOS (10.15+), Windows 10+</li> <li>Python: 3.8, 3.9, 3.10, 3.11</li> <li>CUDA: 11.0+ (GPU\u52a0\u901f\u9700\u8981)</li> </ul>"},{"location":"getting-started/installation/#_5","title":"\ud83d\ude80 \u5feb\u901f\u5b89\u88c5","text":""},{"location":"getting-started/installation/#_6","title":"\u65b9\u5f0f\u4e00\uff1a\u4ece\u6e90\u7801\u5b89\u88c5 (\u63a8\u8350)","text":"Bash<pre><code># 1. \u514b\u9686\u4ed3\u5e93\ngit clone https://github.com/phonism/genesis.git\ncd genesis\n\n# 2. \u521b\u5efa\u865a\u62df\u73af\u5883 (\u63a8\u8350)\npython -m venv genesis-env\nsource genesis-env/bin/activate  # Linux/macOS\n# genesis-env\\\\Scripts\\\\activate  # Windows\n\n# 3. \u5b89\u88c5\u4f9d\u8d56\npip install -r genesis/requirements.txt\n\n# 4. \u5b89\u88c5Genesis\npip install -e genesis/\n</code></pre>"},{"location":"getting-started/installation/#pip","title":"\u65b9\u5f0f\u4e8c\uff1a\u4f7f\u7528pip\u5b89\u88c5","text":"Bash<pre><code># \u5b89\u88c5\u53d1\u5e03\u7248\u672c\npip install genesis-dl\n\n# \u5b89\u88c5\u9884\u53d1\u5e03\u7248\u672c\npip install --pre genesis-dl\n</code></pre>"},{"location":"getting-started/installation/#_7","title":"\ud83d\udd27 \u8be6\u7ec6\u5b89\u88c5\u6b65\u9aa4","text":""},{"location":"getting-started/installation/#python","title":"\u7b2c\u4e00\u6b65\uff1a\u51c6\u5907Python\u73af\u5883","text":"Ubuntu/DebianCentOS/RHELmacOSWindows Bash<pre><code># \u5b89\u88c5Python\u548cpip\nsudo apt update\nsudo apt install python3.9 python3.9-pip python3.9-venv\n\n# \u521b\u5efa\u8f6f\u94fe\u63a5 (\u53ef\u9009)\nsudo ln -sf /usr/bin/python3.9 /usr/bin/python\n</code></pre> Bash<pre><code># \u5b89\u88c5EPEL\u4ed3\u5e93\nsudo yum install epel-release\n\n# \u5b89\u88c5Python\nsudo yum install python39 python39-pip\n</code></pre> Bash<pre><code># \u4f7f\u7528Homebrew\u5b89\u88c5\nbrew install python@3.9\n\n# \u6216\u4f7f\u7528\u5b98\u65b9\u5b89\u88c5\u5305\n# \u4ece https://python.org \u4e0b\u8f7d\u5b89\u88c5\n</code></pre> PowerShell<pre><code># \u4e0b\u8f7dPython\u5b89\u88c5\u5305\n# https://python.org/downloads/windows/\n\n# \u6216\u4f7f\u7528Chocolatey\nchoco install python39\n</code></pre>"},{"location":"getting-started/installation/#cuda-gpu","title":"\u7b2c\u4e8c\u6b65\uff1a\u5b89\u88c5CUDA (GPU\u52a0\u901f)","text":"<p>GPU\u652f\u6301\u8bf4\u660e</p> <p>\u5982\u679c\u4f60\u53ea\u9700\u8981CPU\u7248\u672c\uff0c\u53ef\u4ee5\u8df3\u8fc7\u6b64\u6b65\u9aa4\u3002\u4f46\u5f3a\u70c8\u63a8\u8350\u5b89\u88c5CUDA\u4ee5\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u3002</p> Ubuntu/DebianCentOS/RHELWindows Bash<pre><code># \u4e0b\u8f7dCUDA Toolkit\nwget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run\nsudo sh cuda_11.8.0_520.61.05_linux.run\n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\necho 'export PATH=/usr/local/cuda/bin:$PATH' &gt;&gt; ~/.bashrc\necho 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> Bash<pre><code># \u5b89\u88c5NVIDIA\u9a71\u52a8\u4ed3\u5e93\nsudo yum-config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo\n\n# \u5b89\u88c5CUDA\nsudo yum install cuda-11-8\n</code></pre> PowerShell<pre><code># \u4e0b\u8f7dCUDA\u5b89\u88c5\u5305\n# https://developer.nvidia.com/cuda-downloads\n\n# \u8fd0\u884c\u5b89\u88c5\u7a0b\u5e8f\u5e76\u6309\u7167\u63d0\u793a\u64cd\u4f5c\n</code></pre>"},{"location":"getting-started/installation/#_8","title":"\u7b2c\u4e09\u6b65\uff1a\u5b89\u88c5\u6838\u5fc3\u4f9d\u8d56","text":"Bash<pre><code># \u521b\u5efa\u5e76\u6fc0\u6d3b\u865a\u62df\u73af\u5883\npython -m venv genesis-env\nsource genesis-env/bin/activate\n\n# \u5347\u7ea7pip\npip install --upgrade pip setuptools wheel\n\n# \u5b89\u88c5PyTorch (\u6839\u636e\u4f60\u7684CUDA\u7248\u672c\u9009\u62e9)\n# CUDA 11.8\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n\n# CPU\u7248\u672c\n# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n\n# \u5b89\u88c5Triton\npip install triton\n\n# \u5b89\u88c5\u5176\u4ed6\u4f9d\u8d56\npip install numpy matplotlib tqdm\n</code></pre>"},{"location":"getting-started/installation/#genesis","title":"\u7b2c\u56db\u6b65\uff1a\u5b89\u88c5Genesis","text":"Bash<pre><code># \u514b\u9686\u6e90\u7801\ngit clone https://github.com/phonism/genesis.git\ncd genesis\n\n# \u67e5\u770b\u53ef\u7528\u7248\u672c\ngit tag\n\n# \u5207\u6362\u5230\u7a33\u5b9a\u7248\u672c (\u53ef\u9009)\ngit checkout v0.1.0\n\n# \u5b89\u88c5Genesis\npip install -e genesis/\n</code></pre>"},{"location":"getting-started/installation/#_9","title":"\u2705 \u9a8c\u8bc1\u5b89\u88c5","text":"<p>\u8fd0\u884c\u4ee5\u4e0b\u4ee3\u7801\u9a8c\u8bc1\u5b89\u88c5\u662f\u5426\u6210\u529f\uff1a</p> Python<pre><code>#!/usr/bin/env python3\n\"\"\"Genesis\u5b89\u88c5\u9a8c\u8bc1\u811a\u672c\"\"\"\n\ndef test_basic_import():\n    \"\"\"\u6d4b\u8bd5\u57fa\u7840\u5bfc\u5165\"\"\"\n    try:\n        import genesis\n        import genesis.nn as nn\n        import genesis.optim as optim\n        print(\"\u2705 Genesis\u5bfc\u5165\u6210\u529f\")\n        print(f\"   \u6838\u5fc3\u6a21\u5757: genesis, nn, optim\")\n        print(f\"   \u53ef\u7528\u51fd\u6570: {len([x for x in dir(genesis) if not x.startswith('_')])}\")\n    except ImportError as e:\n        print(f\"\u274c Genesis\u5bfc\u5165\u5931\u8d25: {e}\")\n        return False\n    return True\n\ndef test_tensor_operations():\n    \"\"\"\u6d4b\u8bd5\u5f20\u91cf\u64cd\u4f5c\"\"\"\n    try:\n        import genesis\n\n        # \u521b\u5efa\u5f20\u91cf\n        x = genesis.randn(3, 4)\n        y = genesis.randn(3, 4)\n\n        # \u57fa\u7840\u8fd0\u7b97\n        z = x + y\n        w = genesis.matmul(x, y.T)  # \u4f7f\u7528\u5b9e\u9645\u7684Genesis API\n\n        print(\"\u2705 \u5f20\u91cf\u8fd0\u7b97\u6b63\u5e38\")\n        print(f\"   \u52a0\u6cd5\u7ed3\u679c\u5f62\u72b6: {z.shape}\")\n        print(f\"   \u77e9\u9635\u4e58\u6cd5\u5f62\u72b6: {w.shape}\")\n    except Exception as e:\n        print(f\"\u274c \u5f20\u91cf\u8fd0\u7b97\u5931\u8d25: {e}\")\n        return False\n    return True\n\ndef test_neural_networks():\n    \"\"\"\u6d4b\u8bd5\u795e\u7ecf\u7f51\u7edc\u6a21\u5757\"\"\"\n    try:\n        import genesis\n        import genesis.nn as nn\n\n        # \u4f7f\u7528\u5b9e\u9645\u7684Genesis\u6a21\u5757\u521b\u5efa\u7b80\u5355\u6a21\u578b\n        model = nn.Sequential([\n            nn.Linear(10, 5),\n            nn.ReLU(),\n            nn.Linear(5, 1)\n        ])\n\n        # \u6d4b\u8bd5\u524d\u5411\u4f20\u64ad\n        x = genesis.randn(2, 10)\n        y = model(x)\n        print(\"\u2705 \u795e\u7ecf\u7f51\u7edc\u6a21\u5757\u6b63\u5e38\")\n        print(f\"   \u6a21\u578b\u5c42\u6570: {len(list(model.parameters()))} \u4e2a\u53c2\u6570\u5f20\u91cf\")\n        print(f\"   \u8f93\u51fa\u5f62\u72b6: {y.shape}\")\n    except Exception as e:\n        print(f\"\u274c \u795e\u7ecf\u7f51\u7edc\u6a21\u5757\u5931\u8d25: {e}\")\n        return False\n    return True\n\ndef test_backend_support():\n    \"\"\"\u6d4b\u8bd5\u540e\u7aef\u652f\u6301\"\"\"\n    try:\n        import genesis\n        from genesis.backend import default_device\n\n        # \u6d4b\u8bd5\u57fa\u7840\u540e\u7aef\u529f\u80fd\n        device = default_device()\n        x = genesis.randn(5, 5)\n\n        print(\"\u2705 \u540e\u7aef\u652f\u6301\u6b63\u5e38\")\n        print(f\"   \u9ed8\u8ba4\u8bbe\u5907: {device}\")\n        print(f\"   \u5f20\u91cf\u8bbe\u5907: {x.device}\")\n\n        # \u5c1d\u8bd5\u68c0\u6d4bCUDA\u662f\u5426\u53ef\u7528\n        try:\n            # \u6d4b\u8bd5\u662f\u5426\u53ef\u4ee5\u521b\u5efaCUDA\u5f20\u91cf\n            import torch\n            if torch.cuda.is_available():\n                print(\"   \u68c0\u6d4b\u5230CUDA\uff08\u901a\u8fc7PyTorch\u540e\u7aef\uff09\")\n            else:\n                print(\"   CUDA\u4e0d\u53ef\u7528\uff08\u4ec5CPU\uff09\")\n        except:\n            print(\"   \u540e\u7aef: Genesis\u539f\u751f\")\n\n    except Exception as e:\n        print(f\"\u274c \u540e\u7aef\u6d4b\u8bd5\u5931\u8d25: {e}\")\n        return False\n    return True\n\ndef test_autograd():\n    \"\"\"\u6d4b\u8bd5\u81ea\u52a8\u5fae\u5206\"\"\"\n    try:\n        import genesis\n\n        # \u6d4b\u8bd5\u57fa\u7840\u81ea\u52a8\u5fae\u5206\n        x = genesis.randn(5, requires_grad=True)\n        y = genesis.functional.sum(x * x)  # \u4f7f\u7528\u5b9e\u9645\u7684Genesis API\n        y.backward()\n\n        print(\"\u2705 \u81ea\u52a8\u5fae\u5206\u6b63\u5e38\")\n        print(f\"   \u8f93\u5165\u5f62\u72b6: {x.shape}\")\n        print(f\"   \u68af\u5ea6\u5df2\u8ba1\u7b97: {x.grad is not None}\")\n        print(f\"   \u68af\u5ea6\u5f62\u72b6: {x.grad.shape if x.grad is not None else 'None'}\")\n    except Exception as e:\n        print(f\"\u274c \u81ea\u52a8\u5fae\u5206\u5931\u8d25: {e}\")\n        return False\n    return True\n\ndef test_optimizers():\n    \"\"\"\u6d4b\u8bd5\u4f18\u5316\u5668\u529f\u80fd\"\"\"\n    try:\n        import genesis\n        import genesis.nn as nn\n        import genesis.optim as optim\n\n        # \u521b\u5efa\u7b80\u5355\u6a21\u578b\u548c\u4f18\u5316\u5668\n        model = nn.Linear(5, 1)\n        optimizer = optim.Adam(model.parameters(), lr=0.01)\n\n        # \u6d4b\u8bd5\u57fa\u7840\u4f18\u5316\u6b65\u9aa4\n        x = genesis.randn(3, 5)\n        y_pred = model(x)\n        loss = genesis.functional.sum(y_pred * y_pred)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        print(\"\u2705 \u4f18\u5316\u5668\u529f\u80fd\u6b63\u5e38\")\n        print(f\"   \u4f18\u5316\u5668\u7c7b\u578b: {type(optimizer).__name__}\")\n        print(f\"   \u5b66\u4e60\u7387: 0.01\")\n        print(f\"   \u53c2\u6570\u5df2\u66f4\u65b0: {len(list(model.parameters()))}\")\n    except Exception as e:\n        print(f\"\u274c \u4f18\u5316\u5668\u6d4b\u8bd5\u5931\u8d25: {e}\")\n        return False\n    return True\n\ndef test_serialization():\n    \"\"\"\u6d4b\u8bd5\u6a21\u578b\u4fdd\u5b58/\u52a0\u8f7d\"\"\"\n    try:\n        import genesis\n        import genesis.nn as nn\n\n        # \u521b\u5efa\u5e76\u4fdd\u5b58\u6a21\u578b\n        model = nn.Linear(3, 2)\n        state_dict = model.state_dict()\n\n        # \u6d4b\u8bd5\u5e8f\u5217\u5316\u529f\u80fd\n        genesis.save(state_dict, 'test_model.pkl')\n        loaded_state = genesis.load('test_model.pkl')\n\n        print(\"\u2705 \u5e8f\u5217\u5316\u529f\u80fd\u6b63\u5e38\")\n        print(f\"   \u6a21\u578b\u4fdd\u5b58\u548c\u52a0\u8f7d\u6210\u529f\")\n        print(f\"   \u72b6\u6001\u5b57\u5178\u952e\u6570\u91cf: {len(state_dict)}\")\n\n        # \u6e05\u7406\n        import os\n        if os.path.exists('test_model.pkl'):\n            os.remove('test_model.pkl')\n\n    except Exception as e:\n        print(f\"\u274c \u5e8f\u5217\u5316\u6d4b\u8bd5\u5931\u8d25: {e}\")\n        return False\n    return True\n\nif __name__ == \"__main__\":\n    print(\"\ud83d\udd0d Genesis\u5b89\u88c5\u9a8c\u8bc1\\n\")\n\n    tests = [\n        test_basic_import,\n        test_tensor_operations,\n        test_neural_networks,\n        test_backend_support,\n        test_autograd,\n        test_optimizers,\n        test_serialization\n    ]\n\n    passed = 0\n    total = len(tests)\n\n    for test in tests:\n        try:\n            if test():\n                passed += 1\n        except Exception as e:\n            print(f\"\u274c \u6d4b\u8bd5\u5f02\u5e38\u5931\u8d25: {e}\")\n        print()\n\n    print(f\"\ud83d\udcca \u6d4b\u8bd5\u7ed3\u679c: {passed}/{total} \u901a\u8fc7\")\n\n    if passed == total:\n        print(\"\ud83c\udf89 \u606d\u559c\uff01Genesis\u5b89\u88c5\u6210\u529f\uff0c\u6240\u6709\u529f\u80fd\u6b63\u5e38\uff01\")\n    elif passed &gt;= total * 0.8:  # 80%\u901a\u8fc7\u7387\n        print(\"\u2705 Genesis\u5b89\u88c5\u57fa\u672c\u6210\u529f\uff01\u68c0\u6d4b\u5230\u5c11\u91cf\u95ee\u9898\u3002\")\n        print(\"   \u5927\u90e8\u5206\u529f\u80fd\u6b63\u5e38\u8fd0\u884c\u3002\u8bf7\u68c0\u67e5\u4e0a\u9762\u7684\u5931\u8d25\u6d4b\u8bd5\u3002\")\n    else:\n        print(\"\u26a0\ufe0f  Genesis\u5b89\u88c5\u5b58\u5728\u95ee\u9898\u3002\u8bf7\u68c0\u67e5\uff1a\")\n        print(\"   1. Genesis\u6b63\u786e\u5b89\u88c5: pip install -e .\")\n        print(\"   2. \u4f9d\u8d56\u5df2\u5b89\u88c5: pip install torch triton\")\n        print(\"   3. Python\u7248\u672c\u4e3a3.8+\")\n</code></pre> <p>\u5c06\u4e0a\u8ff0\u4ee3\u7801\u4fdd\u5b58\u4e3a <code>test_installation.py</code> \u5e76\u8fd0\u884c\uff1a</p> Bash<pre><code>python test_installation.py\n</code></pre>"},{"location":"getting-started/installation/#_10","title":"\ud83d\udd27 \u5e38\u89c1\u95ee\u9898\u89e3\u51b3","text":""},{"location":"getting-started/installation/#1cuda","title":"\u95ee\u98981\uff1aCUDA\u7248\u672c\u4e0d\u5339\u914d","text":"<p>\u9519\u8bef\u4fe1\u606f\uff1a Text Only<pre><code>RuntimeError: CUDA version mismatch\n</code></pre></p> <p>\u89e3\u51b3\u65b9\u6848\uff1a Bash<pre><code># \u68c0\u67e5\u7cfb\u7edfCUDA\u7248\u672c\nnvidia-smi\n\n# \u68c0\u67e5PyTorch CUDA\u7248\u672c\npython -c \"import torch; print(torch.version.cuda)\"\n\n# \u91cd\u65b0\u5b89\u88c5\u5339\u914d\u7248\u672c\u7684PyTorch\npip uninstall torch torchvision torchaudio\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n</code></pre></p>"},{"location":"getting-started/installation/#2triton","title":"\u95ee\u98982\uff1aTriton\u7f16\u8bd1\u5931\u8d25","text":"<p>\u9519\u8bef\u4fe1\u606f\uff1a Text Only<pre><code>Failed to compile Triton kernel\n</code></pre></p> <p>\u89e3\u51b3\u65b9\u6848\uff1a Bash<pre><code># \u5347\u7ea7Triton\npip install --upgrade triton\n\n# \u6216\u5b89\u88c5\u5f00\u53d1\u7248\u672c\npip install --pre triton\n</code></pre></p>"},{"location":"getting-started/installation/#3","title":"\u95ee\u98983\uff1a\u5185\u5b58\u4e0d\u8db3","text":"<p>\u9519\u8bef\u4fe1\u606f\uff1a Text Only<pre><code>CUDA out of memory\n</code></pre></p> <p>\u89e3\u51b3\u65b9\u6848\uff1a Python<pre><code>import genesis\n\n# \u542f\u7528\u5185\u5b58\u4f18\u5316\ngenesis.cuda.empty_cache()\n\n# \u51cf\u5c0f\u6279\u91cf\u5927\u5c0f\nbatch_size = 16  # \u66ff\u4ee3\u539f\u6765\u768432\n\n# \u542f\u7528\u68af\u5ea6\u68c0\u67e5\u70b9 (\u5982\u679c\u652f\u6301)\nmodel.gradient_checkpointing = True\n</code></pre></p>"},{"location":"getting-started/installation/#4","title":"\u95ee\u98984\uff1a\u5bfc\u5165\u9519\u8bef","text":"<p>\u9519\u8bef\u4fe1\u606f\uff1a Text Only<pre><code>ModuleNotFoundError: No module named 'genesis'\n</code></pre></p> <p>\u89e3\u51b3\u65b9\u6848\uff1a Bash<pre><code># \u68c0\u67e5\u865a\u62df\u73af\u5883\nwhich python\npip list | grep genesis\n\n# \u91cd\u65b0\u5b89\u88c5\npip uninstall genesis-dl\npip install -e genesis/\n</code></pre></p>"},{"location":"getting-started/installation/#docker","title":"\ud83d\udc33 Docker\u5b89\u88c5","text":"<p>\u5982\u679c\u4f60\u9047\u5230\u73af\u5883\u95ee\u9898\uff0c\u53ef\u4ee5\u4f7f\u7528Docker\uff1a</p> Bash<pre><code># \u4e0b\u8f7d\u9884\u6784\u5efa\u955c\u50cf\ndocker pull genesis/genesis:latest\n\n# \u6216\u6784\u5efa\u81ea\u5df1\u7684\u955c\u50cf\ngit clone https://github.com/phonism/genesis.git\ncd genesis\ndocker build -t genesis:local .\n\n# \u8fd0\u884c\u5bb9\u5668\ndocker run -it --gpus all genesis:local bash\n</code></pre> <p>Dockerfile\u5185\u5bb9\uff1a Docker<pre><code>FROM nvidia/cuda:11.8-devel-ubuntu22.04\n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nENV DEBIAN_FRONTEND=noninteractive\nENV PATH=\"/opt/conda/bin:$PATH\"\n\n# \u5b89\u88c5\u7cfb\u7edf\u4f9d\u8d56\nRUN apt-get update &amp;&amp; apt-get install -y \\\\\n    wget git build-essential &amp;&amp; \\\\\n    rm -rf /var/lib/apt/lists/*\n\n# \u5b89\u88c5Miniconda\nRUN wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh &amp;&amp; \\\\\n    bash Miniconda3-latest-Linux-x86_64.sh -b -p /opt/conda &amp;&amp; \\\\\n    rm Miniconda3-latest-Linux-x86_64.sh\n\n# \u521b\u5efa\u73af\u5883\u5e76\u5b89\u88c5\u4f9d\u8d56\nRUN conda create -n genesis python=3.9 -y\nSHELL [\"conda\", \"run\", \"-n\", \"genesis\", \"/bin/bash\", \"-c\"]\n\nRUN pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 &amp;&amp; \\\\\n    pip install triton numpy matplotlib tqdm\n\n# \u590d\u5236\u5e76\u5b89\u88c5Genesis\nCOPY . /workspace/genesis\nWORKDIR /workspace/genesis\nRUN pip install -e genesis/\n\n# \u8bbe\u7f6e\u542f\u52a8\u547d\u4ee4\nENTRYPOINT [\"conda\", \"run\", \"-n\", \"genesis\"]\nCMD [\"bash\"]\n</code></pre></p>"},{"location":"getting-started/installation/#_11","title":"\ud83d\udcca \u6027\u80fd\u4f18\u5316\u5efa\u8bae","text":"<p>\u5b89\u88c5\u5b8c\u6210\u540e\uff0c\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u4f18\u5316\u6027\u80fd\uff1a</p> Bash<pre><code># \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nexport CUDA_VISIBLE_DEVICES=0  # \u6307\u5b9aGPU\nexport PYTHONPATH=$PWD:$PYTHONPATH\n\n# \u542f\u7528\u4f18\u5316\u9009\u9879\nexport GENESIS_OPTIMIZE=1\nexport TRITON_CACHE_DIR=/tmp/triton_cache\n</code></pre>"},{"location":"getting-started/installation/#_12","title":"\ud83c\udfaf \u4e0b\u4e00\u6b65","text":"<p>\u5b89\u88c5\u5b8c\u6210\u540e\uff0c\u5efa\u8bae\uff1a</p> <ol> <li>\u8fd0\u884c\u7b2c\u4e00\u4e2a\u7a0b\u5e8f - \u9a8c\u8bc1\u5b89\u88c5\u5e76\u5b66\u4e60\u57fa\u7840\u7528\u6cd5</li> <li>\u67e5\u770b\u6559\u7a0b - \u7cfb\u7edf\u5b66\u4e60Genesis\u7684\u4f7f\u7528</li> <li>\u9605\u8bfb\u67b6\u6784\u6587\u6863 - \u7406\u89e3\u6846\u67b6\u8bbe\u8ba1\u7406\u5ff5</li> </ol> <p>\u5982\u679c\u5728\u5b89\u88c5\u8fc7\u7a0b\u4e2d\u9047\u5230\u95ee\u9898\uff0c\u8bf7\u67e5\u770bFAQ\u6216\u5728GitHub\u4e0a\u63d0\u4ea4issue\u3002</p>"},{"location":"models/qwen/","title":"Qwen\u6a21\u578b\u5b9e\u73b0","text":""},{"location":"models/qwen/#_1","title":"\u6982\u8ff0","text":"<p>Genesis\u5305\u542b\u4e86Qwen\uff08\u901a\u4e49\u5343\u95ee\uff09\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b8c\u6574\u5b9e\u73b0\uff0c\u652f\u6301\u5b8c\u6574\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u5de5\u4f5c\u6d41\u3002</p>"},{"location":"models/qwen/#_2","title":"\u6a21\u578b\u67b6\u6784","text":"<p>Qwen\u6a21\u578b\u57fa\u4e8eTransformer\u67b6\u6784\uff0c\u5177\u6709\u4ee5\u4e0b\u7279\u6027\uff1a</p> <ul> <li>\u6ce8\u610f\u529b\u673a\u5236: \u591a\u5934\u6ce8\u610f\u529b\u4e0eRoPE\uff08\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165\uff09</li> <li>\u6fc0\u6d3b\u51fd\u6570: SwiGLU\u6fc0\u6d3b\u51fd\u6570</li> <li>\u5c42\u5f52\u4e00\u5316: RMSNorm</li> <li>\u4f4d\u7f6e\u7f16\u7801: \u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165\uff08RoPE\uff09</li> </ul>"},{"location":"models/qwen/#_3","title":"\u5feb\u901f\u5f00\u59cb","text":""},{"location":"models/qwen/#_4","title":"\u57fa\u7840\u63a8\u7406","text":"Python<pre><code>import genesis\nfrom genesis.models.qwen import QwenModel, QwenConfig\n\n# \u521b\u5efa\u6a21\u578b\u914d\u7f6e\nconfig = QwenConfig(\n    vocab_size=32000,\n    n_layer=24,\n    n_head=16,\n    n_embd=2048,\n    max_seq_len=2048\n)\n\n# \u521b\u5efa\u6a21\u578b\nmodel = QwenModel(config)\n\n# \u63a8\u7406\ninput_ids = genesis.tensor([[1, 2, 3, 4, 5]])  # [batch_size, seq_len]\noutput = model(input_ids)\nprint(f\"\u8f93\u51fa\u5f62\u72b6: {output.shape}\")  # [1, 5, 32000]\n</code></pre>"},{"location":"models/qwen/#_5","title":"\u8bad\u7ec3\u793a\u4f8b","text":"Python<pre><code>import genesis.optim as optim\nimport genesis.nn as nn\n\n# \u521b\u5efa\u4f18\u5316\u5668\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n\n# \u8bad\u7ec3\u5faa\u73af\nfor batch in dataloader:\n    input_ids, labels = batch\n\n    # \u524d\u5411\u4f20\u64ad\n    logits = model(input_ids)\n\n    # \u8ba1\u7b97\u635f\u5931\n    loss = nn.functional.cross_entropy(\n        logits.view(-1, logits.size(-1)),\n        labels.view(-1)\n    )\n\n    # \u53cd\u5411\u4f20\u64ad\n    optimizer.zero_grad()\n    loss.backward()\n\n    # \u68af\u5ea6\u88c1\u526a\n    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n    # \u53c2\u6570\u66f4\u65b0\n    optimizer.step()\n</code></pre>"},{"location":"models/qwen/#_6","title":"\u914d\u7f6e\u53c2\u6570","text":""},{"location":"models/qwen/#qwenconfig","title":"QwenConfig","text":"\u53c2\u6570 \u7c7b\u578b \u9ed8\u8ba4\u503c \u63cf\u8ff0 <code>vocab_size</code> int 32000 \u8bcd\u6c47\u8868\u5927\u5c0f <code>n_layer</code> int 24 Transformer\u5c42\u6570 <code>n_head</code> int 16 \u6ce8\u610f\u529b\u5934\u6570 <code>n_embd</code> int 2048 \u9690\u85cf\u5c42\u7ef4\u5ea6 <code>max_seq_len</code> int 2048 \u6700\u5927\u5e8f\u5217\u957f\u5ea6 <code>dropout</code> float 0.1 Dropout\u6982\u7387 <code>bias</code> bool False \u662f\u5426\u4f7f\u7528\u504f\u7f6e\u9879"},{"location":"models/qwen/#_7","title":"\u6027\u80fd\u4f18\u5316","text":""},{"location":"models/qwen/#_8","title":"\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3","text":"Python<pre><code># \u542f\u7528\u6df7\u5408\u7cbe\u5ea6\nfrom genesis.amp import autocast, GradScaler\n\nscaler = GradScaler()\n\nwith autocast():\n    logits = model(input_ids)\n    loss = criterion(logits, labels)\n\n# \u68af\u5ea6\u7f29\u653e\nscaler.scale(loss).backward()\nscaler.step(optimizer)\nscaler.update()\n</code></pre>"},{"location":"models/qwen/#_9","title":"\u68af\u5ea6\u68c0\u67e5\u70b9","text":"Python<pre><code># \u542f\u7528\u68af\u5ea6\u68c0\u67e5\u70b9\u4ee5\u8282\u7701\u5185\u5b58\nmodel.enable_gradient_checkpointing()\n</code></pre>"},{"location":"models/qwen/#_10","title":"\u5e94\u7528\u793a\u4f8b","text":""},{"location":"models/qwen/#_11","title":"\u6587\u672c\u751f\u6210","text":"Python<pre><code>def generate_text(model, tokenizer, prompt, max_length=100):\n    input_ids = tokenizer.encode(prompt)\n    input_tensor = genesis.tensor([input_ids])\n\n    with genesis.no_grad():\n        for _ in range(max_length):\n            logits = model(input_tensor)\n            next_token = logits[0, -1].argmax()\n            input_tensor = genesis.cat([input_tensor, next_token.unsqueeze(0).unsqueeze(0)], dim=1)\n\n            if next_token.item() == tokenizer.eos_token_id:\n                break\n\n    return tokenizer.decode(input_tensor[0].tolist())\n\n# \u4f7f\u7528\u793a\u4f8b\ngenerated = generate_text(model, tokenizer, \"\u4eca\u5929\u7684\u5929\u6c14\")\nprint(generated)\n</code></pre>"},{"location":"models/qwen/#_12","title":"\u5fae\u8c03","text":"<p>\u53c2\u8003 <code>apps/llm/train_sft_qwen.py</code> \u83b7\u5f97\u5b8c\u6574\u7684SFT\uff08\u76d1\u7763\u5fae\u8c03\uff09\u5b9e\u73b0\u3002</p> Bash<pre><code># \u8fd0\u884cSFT\u8bad\u7ec3\ncd apps/llm\npython train_sft_qwen.py \\\n    --model_size 0.5b \\\n    --data_path /path/to/data \\\n    --batch_size 4 \\\n    --learning_rate 5e-5 \\\n    --num_epochs 3\n</code></pre>"},{"location":"models/qwen/#_13","title":"\u6587\u4ef6\u7ed3\u6784","text":"<ul> <li><code>genesis/models/qwen.py</code> - \u6a21\u578b\u5b9e\u73b0</li> <li><code>apps/llm/qwen_model.py</code> - \u8bad\u7ec3\u914d\u7f6e\u548c\u5de5\u5177</li> <li><code>apps/llm/train_sft_qwen.py</code> - SFT\u8bad\u7ec3\u811a\u672c</li> <li><code>apps/llm/chat_qwen.py</code> - \u63a8\u7406\u804a\u5929\u811a\u672c</li> </ul>"},{"location":"models/qwen/#2025-01","title":"\u6700\u65b0\u66f4\u65b0 (2025-01)","text":"<ul> <li>\u2705 \u5b8c\u6574\u7684Qwen\u6a21\u578b\u5b9e\u73b0\uff0c\u652f\u6301RoPE\u548cRMSNorm</li> <li>\u2705 \u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u652f\u6301 (FP16/BF16)</li> <li>\u2705 \u68af\u5ea6\u88c1\u526a\u548c\u5b66\u4e60\u7387\u8c03\u5ea6</li> <li>\u2705 SFT\u8bad\u7ec3\u811a\u672c\u548c\u804a\u5929\u754c\u9762</li> <li>\u2705 \u6a21\u578b\u68c0\u67e5\u70b9\u548c\u72b6\u6001\u7ba1\u7406</li> <li>\ud83d\udea7 \u6027\u80fd\u4f18\u5316\u6301\u7eed\u8fdb\u884c\u4e2d</li> </ul>"},{"location":"models/qwen/#_14","title":"\u76f8\u5173\u8d44\u6e90","text":"<ul> <li>Qwen\u5b98\u65b9\u8bba\u6587</li> <li>\u9ad8\u7ea7\u8bad\u7ec3\u7279\u6027</li> <li>\u6027\u80fd\u8c03\u4f18\u6307\u5357</li> <li>Genesis API\u53c2\u8003</li> </ul>"},{"location":"performance/gpu-operations/","title":"GPU\u64cd\u4f5c\u6027\u80fd\u6307\u5357","text":"<p>\u672c\u6307\u5357\u6db5\u76d6Genesis\u4e2dGPU\u64cd\u4f5c\u7684\u4f18\u5316\uff0c\u91cd\u70b9\u4ecb\u7ecd\u6a21\u5757\u5316GPU\u64cd\u4f5c\u7ed3\u6784\u3001Triton\u5185\u6838\u5b9e\u73b0\u548c\u6027\u80fd\u8c03\u4f18\u7b56\u7565\u3002</p>"},{"location":"performance/gpu-operations/#_1","title":"\u6982\u8ff0","text":"<p>Genesis\u5b9e\u73b0\u4e86\u590d\u6742\u7684GPU\u540e\u7aef\uff0c\u5305\u62ec\uff1a - \u4f7f\u7528Triton\u7684\u6a21\u5757\u5316GPU\u64cd\u4f5c - \u81ea\u5b9a\u4e49CUDA\u5185\u5b58\u7ba1\u7406 - \u81ea\u9002\u5e94\u5757\u5927\u5c0f\u4f18\u5316 - \u6027\u80fd\u76d1\u63a7\u548c\u5206\u6790\u5de5\u5177</p>"},{"location":"performance/gpu-operations/#_2","title":"\u67b6\u6784\u6982\u8ff0","text":""},{"location":"performance/gpu-operations/#gpu_1","title":"\u6a21\u5757\u5316GPU\u64cd\u4f5c\u7ed3\u6784","text":"<p>Genesis\u5c06GPU\u64cd\u4f5c\u5206\u79bb\u4e3a\u4e13\u95e8\u7684\u6a21\u5757\uff1a</p> Text Only<pre><code>genesis/ndarray/gpu_ops/\n\u251c\u2500\u2500 __init__.py          # \u64cd\u4f5c\u6ce8\u518c\u548c\u5206\u6d3e\n\u251c\u2500\u2500 basic_ops.py         # \u9010\u5143\u7d20\u64cd\u4f5c\uff08add\u3001mul\u7b49\uff09\n\u251c\u2500\u2500 tensor_ops.py        # \u5f20\u91cf\u64cd\u4f5c\uff08matmul\u3001conv\u7b49\uff09  \n\u251c\u2500\u2500 random_ops.py        # \u968f\u673a\u6570\u751f\u6210\n\u2514\u2500\u2500 reduction_ops.py     # \u7ea6\u7b80\u64cd\u4f5c\uff08sum\u3001mean\u7b49\uff09\n</code></pre>"},{"location":"performance/gpu-operations/#_3","title":"\u64cd\u4f5c\u5206\u6d3e\u7cfb\u7edf","text":"Python<pre><code># genesis/ndarray/gpu_ops/__init__.py\nfrom .basic_ops import add_triton, mul_triton, div_triton\nfrom .tensor_ops import matmul_triton, conv2d_triton  \nfrom .reduction_ops import sum_triton, mean_triton\n\n# \u52a8\u6001\u5206\u6d3e\u7684\u64cd\u4f5c\u6ce8\u518c\u8868\nGPU_OPS_REGISTRY = {\n    'add': add_triton,\n    'mul': mul_triton,\n    'div': div_triton,\n    'matmul': matmul_triton,\n    'sum': sum_triton,\n    'mean': mean_triton,\n}\n\ndef dispatch_gpu_op(op_name, *args, **kwargs):\n    \"\"\"\u5c06\u64cd\u4f5c\u5206\u6d3e\u5230\u76f8\u5e94\u7684GPU\u5185\u6838\u3002\"\"\"\n    if op_name not in GPU_OPS_REGISTRY:\n        raise NotImplementedError(f\"GPU\u64cd\u4f5c {op_name} \u672a\u5b9e\u73b0\")\n\n    return GPU_OPS_REGISTRY[op_name](*args, **kwargs)\n</code></pre>"},{"location":"performance/gpu-operations/#triton","title":"Triton\u5185\u6838\u5b9e\u73b0","text":""},{"location":"performance/gpu-operations/#_4","title":"\u57fa\u672c\u9010\u5143\u7d20\u64cd\u4f5c","text":"Python<pre><code># genesis/ndarray/gpu_ops/basic_ops.py\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef add_kernel(x_ptr, y_ptr, output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n    \"\"\"\u4f18\u5316\u7684\u9010\u5143\u7d20\u52a0\u6cd5\u5185\u6838\u3002\"\"\"\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets &lt; n_elements\n\n    # \u4f7f\u7528\u5411\u91cf\u5316\u52a0\u8f7d\u6570\u636e\n    x = tl.load(x_ptr + offsets, mask=mask, other=0.0)\n    y = tl.load(y_ptr + offsets, mask=mask, other=0.0)\n\n    # \u8ba1\u7b97\n    output = x + y\n\n    # \u5b58\u50a8\u7ed3\u679c\n    tl.store(output_ptr + offsets, output, mask=mask)\n\ndef add_triton(x, y):\n    \"\"\"\u57fa\u4e8eTriton\u7684\u5f20\u91cf\u52a0\u6cd5\u3002\"\"\"\n    output = genesis.empty_like(x)\n    n_elements = x.numel()\n\n    # \u57fa\u4e8e\u5f20\u91cf\u5927\u5c0f\u7684\u81ea\u9002\u5e94\u5757\u5927\u5c0f\n    if n_elements &lt; 262144:  # &lt; 256K\u5143\u7d20\n        BLOCK_SIZE = 256\n    elif n_elements &lt; 4194304:  # &lt; 4M\u5143\u7d20  \n        BLOCK_SIZE = 512\n    else:\n        BLOCK_SIZE = 1024\n\n    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n\n    add_kernel[grid](\n        x.data_ptr(), y.data_ptr(), output.data_ptr(),\n        n_elements, BLOCK_SIZE=BLOCK_SIZE\n    )\n\n    return output\n</code></pre>"},{"location":"performance/gpu-operations/#_5","title":"\u9ad8\u7ea7\u5f20\u91cf\u64cd\u4f5c","text":"Python<pre><code># genesis/ndarray/gpu_ops/tensor_ops.py\n@triton.jit  \ndef matmul_kernel(\n    a_ptr, b_ptr, c_ptr,\n    M, N, K,\n    stride_am, stride_ak,\n    stride_bk, stride_bn, \n    stride_cm, stride_cn,\n    BLOCK_SIZE_M: tl.constexpr,\n    BLOCK_SIZE_N: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    \"\"\"\u9ad8\u6027\u80fd\u77e9\u9635\u4e58\u6cd5\u5185\u6838\u3002\"\"\"\n    pid = tl.program_id(axis=0)\n    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n\n    pid_m = pid // num_pid_n\n    pid_n = pid % num_pid_n\n\n    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n    offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n\n    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n        a = tl.load(a_ptrs, mask=(offs_k[None, :] &lt; K - k * BLOCK_SIZE_K))\n        b = tl.load(b_ptrs, mask=(offs_k[:, None] &lt; K - k * BLOCK_SIZE_K))\n\n        accumulator += tl.dot(a, b)\n\n        a_ptrs += BLOCK_SIZE_K * stride_ak\n        b_ptrs += BLOCK_SIZE_K * stride_bk\n\n    c = accumulator.to(tl.float16)\n\n    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n\n    c_mask = (offs_cm[:, None] &lt; M) &amp; (offs_cn[None, :] &lt; N)\n    tl.store(c_ptrs, c, mask=c_mask)\n\ndef matmul_triton(a, b):\n    \"\"\"\u4f7f\u7528Triton\u4f18\u5316\u7684\u77e9\u9635\u4e58\u6cd5\u3002\"\"\"\n    assert a.shape[-1] == b.shape[-2], f\"\u5f62\u72b6\u4e0d\u5339\u914d: {a.shape} @ {b.shape}\"\n\n    M, K = a.shape[-2:]\n    K2, N = b.shape[-2:]\n    assert K == K2\n\n    c = genesis.empty((*a.shape[:-2], M, N), dtype=a.dtype, device=a.device)\n\n    # \u57fa\u4e8e\u95ee\u9898\u5927\u5c0f\u4f18\u5316\u5757\u5927\u5c0f\n    if M &gt;= 2048 and N &gt;= 2048:\n        BLOCK_SIZE_M, BLOCK_SIZE_N, BLOCK_SIZE_K = 128, 128, 32\n    elif M &gt;= 512 and N &gt;= 512:\n        BLOCK_SIZE_M, BLOCK_SIZE_N, BLOCK_SIZE_K = 64, 64, 32\n    else:\n        BLOCK_SIZE_M, BLOCK_SIZE_N, BLOCK_SIZE_K = 32, 32, 32\n\n    grid = lambda meta: (\n        triton.cdiv(M, meta['BLOCK_SIZE_M']) * triton.cdiv(N, meta['BLOCK_SIZE_N']),\n    )\n\n    matmul_kernel[grid](\n        a.data_ptr(), b.data_ptr(), c.data_ptr(),\n        M, N, K,\n        a.stride(-2), a.stride(-1),\n        b.stride(-2), b.stride(-1),\n        c.stride(-2), c.stride(-1),\n        BLOCK_SIZE_M=BLOCK_SIZE_M,\n        BLOCK_SIZE_N=BLOCK_SIZE_N, \n        BLOCK_SIZE_K=BLOCK_SIZE_K,\n    )\n\n    return c\n</code></pre>"},{"location":"performance/gpu-operations/#_6","title":"\u5185\u5b58\u4f18\u5316\u7684\u7ea6\u7b80\u64cd\u4f5c","text":"Python<pre><code># genesis/ndarray/gpu_ops/reduction_ops.py\n@triton.jit\ndef sum_kernel(\n    input_ptr, output_ptr, \n    n_elements,\n    BLOCK_SIZE: tl.constexpr\n):\n    \"\"\"\u5185\u5b58\u9ad8\u6548\u7684\u6c42\u548c\u5185\u6838\u3002\"\"\"\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets &lt; n_elements\n\n    # \u6309\u5757\u52a0\u8f7d\u548c\u6c42\u548c\n    x = tl.load(input_ptr + offsets, mask=mask, other=0.0)\n    block_sum = tl.sum(x)\n\n    # \u4f7f\u7528\u539f\u5b50\u52a0\u6cd5\u8fdb\u884c\u6700\u7ec8\u7ea6\u7b80\n    tl.atomic_add(output_ptr, block_sum)\n\n@triton.jit\ndef reduce_kernel(\n    input_ptr, output_ptr,\n    n_rows, n_cols,\n    BLOCK_SIZE_X: tl.constexpr,\n    BLOCK_SIZE_Y: tl.constexpr  \n):\n    \"\"\"\u5177\u6709\u6700\u4f18\u5185\u5b58\u8bbf\u95ee\u76842D\u7ea6\u7b80\u5185\u6838\u3002\"\"\"\n    pid_x = tl.program_id(axis=0)\n    pid_y = tl.program_id(axis=1)\n\n    offs_x = pid_x * BLOCK_SIZE_X + tl.arange(0, BLOCK_SIZE_X)\n    offs_y = pid_y * BLOCK_SIZE_Y + tl.arange(0, BLOCK_SIZE_Y)\n\n    mask_x = offs_x &lt; n_rows\n    mask_y = offs_y &lt; n_cols\n\n    # \u52a0\u8f7d\u5757\n    ptrs = input_ptr + offs_x[:, None] * n_cols + offs_y[None, :]\n    mask = mask_x[:, None] &amp; mask_y[None, :]\n    x = tl.load(ptrs, mask=mask, other=0.0)\n\n    # \u5757\u5185\u7ea6\u7b80\n    result = tl.sum(x, axis=1)  # \u8de8\u5217\u6c42\u548c\n\n    # \u5b58\u50a8\u7ed3\u679c\n    out_ptrs = output_ptr + offs_x\n    tl.store(out_ptrs, result, mask=mask_x)\n\ndef sum_triton(x, dim=None, keepdim=False):\n    \"\"\"\u4f18\u5316\u7684\u5f20\u91cf\u6c42\u548c\u3002\"\"\"\n    if dim is None:\n        # \u5168\u5c40\u6c42\u548c\n        result = genesis.zeros((), dtype=x.dtype, device=x.device)\n        n_elements = x.numel()\n\n        BLOCK_SIZE = min(1024, triton.next_power_of_2(n_elements))\n        grid = (triton.cdiv(n_elements, BLOCK_SIZE),)\n\n        sum_kernel[grid](\n            x.data_ptr(), result.data_ptr(),\n            n_elements, BLOCK_SIZE=BLOCK_SIZE\n        )\n\n        return result\n\n    else:\n        # \u7279\u5b9a\u7ef4\u5ea6\u7ea6\u7b80\n        # \u5b9e\u73b0\u7279\u5b9a\u7ef4\u5ea6\u7ea6\u7b80\n        return reduce_along_dim(x, dim, keepdim)\n</code></pre>"},{"location":"performance/gpu-operations/#_7","title":"\u6027\u80fd\u4f18\u5316\u7b56\u7565","text":""},{"location":"performance/gpu-operations/#1","title":"1. \u81ea\u9002\u5e94\u5757\u5927\u5c0f\u4f18\u5316","text":"Python<pre><code>class AdaptiveBlockSize:\n    \"\"\"\u57fa\u4e8e\u5f20\u91cf\u7279\u6027\u52a8\u6001\u4f18\u5316\u5757\u5927\u5c0f\u3002\"\"\"\n\n    def __init__(self):\n        self.cache = {}\n        self.performance_history = {}\n\n    def get_optimal_block_size(self, operation, tensor_size, dtype):\n        \"\"\"\u83b7\u53d6\u7ed9\u5b9a\u64cd\u4f5c\u548c\u5f20\u91cf\u7684\u6700\u4f18\u5757\u5927\u5c0f\u3002\"\"\"\n        cache_key = (operation, tensor_size, dtype.name)\n\n        if cache_key in self.cache:\n            return self.cache[cache_key]\n\n        # \u57fa\u4e8e\u5f20\u91cf\u5927\u5c0f\u548c\u64cd\u4f5c\u786e\u5b9a\u5757\u5927\u5c0f\n        if operation == 'elementwise':\n            if tensor_size &lt; 262144:  # &lt; 256K\u5143\u7d20\n                block_size = 256\n            elif tensor_size &lt; 4194304:  # &lt; 4M\u5143\u7d20\n                block_size = 512  \n            else:\n                block_size = 1024\n\n        elif operation == 'matmul':\n            # \u77e9\u9635\u4e58\u6cd5\u7279\u5b9a\u4f18\u5316\n            sqrt_size = int(tensor_size ** 0.5)\n            if sqrt_size &lt; 512:\n                block_size = (32, 32, 32)\n            elif sqrt_size &lt; 2048:\n                block_size = (64, 64, 32)\n            else:\n                block_size = (128, 128, 32)\n\n        elif operation == 'reduction':\n            # \u7ea6\u7b80\u64cd\u4f5c\u4f18\u5316\n            block_size = min(1024, triton.next_power_of_2(tensor_size))\n\n        else:\n            # \u9ed8\u8ba4\u56de\u9000\n            block_size = 512\n\n        self.cache[cache_key] = block_size\n        return block_size\n\n    def update_performance(self, operation, tensor_size, dtype, block_size, elapsed_time):\n        \"\"\"\u66f4\u65b0\u6027\u80fd\u5386\u53f2\u8bb0\u5f55\u7528\u4e8e\u672a\u6765\u4f18\u5316\u3002\"\"\"\n        key = (operation, tensor_size, dtype.name, block_size)\n        if key not in self.performance_history:\n            self.performance_history[key] = []\n\n        self.performance_history[key].append(elapsed_time)\n\n        # \u53ea\u4fdd\u7559\u6700\u8fd1\u7684\u6d4b\u91cf\n        if len(self.performance_history[key]) &gt; 10:\n            self.performance_history[key] = self.performance_history[key][-10:]\n\n# \u5168\u5c40\u4f18\u5316\u5668\u5b9e\u4f8b\nblock_optimizer = AdaptiveBlockSize()\n</code></pre>"},{"location":"performance/gpu-operations/#2","title":"2. \u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u4f18\u5316","text":"Python<pre><code>@triton.jit\ndef coalesced_copy_kernel(\n    src_ptr, dst_ptr,\n    n_elements, stride_src, stride_dst,\n    BLOCK_SIZE: tl.constexpr\n):\n    \"\"\"\u5185\u5b58\u5408\u5e76\u7684\u5f20\u91cf\u62f7\u8d1d\u5185\u6838\u3002\"\"\"\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n\n    # \u786e\u4fdd\u5408\u5e76\u7684\u5185\u5b58\u8bbf\u95ee\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets &lt; n_elements\n\n    # \u4f7f\u7528\u9002\u5f53\u7684\u6b65\u957f\u52a0\u8f7d\n    src_offsets = offsets * stride_src\n    dst_offsets = offsets * stride_dst\n\n    data = tl.load(src_ptr + src_offsets, mask=mask)\n    tl.store(dst_ptr + dst_offsets, data, mask=mask)\n\n@triton.jit  \ndef transpose_kernel(\n    input_ptr, output_ptr,\n    n_rows, n_cols,\n    BLOCK_SIZE: tl.constexpr\n):\n    \"\"\"\u7f13\u5b58\u53cb\u597d\u7684\u77e9\u9635\u8f6c\u7f6e\u3002\"\"\"\n    pid = tl.program_id(axis=0)\n\n    # \u57fa\u4e8etile\u7684\u8f6c\u7f6e\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u7f13\u5b58\u4f7f\u7528\n    row_start = (pid // (n_cols // BLOCK_SIZE)) * BLOCK_SIZE\n    col_start = (pid % (n_cols // BLOCK_SIZE)) * BLOCK_SIZE\n\n    rows = row_start + tl.arange(0, BLOCK_SIZE)\n    cols = col_start + tl.arange(0, BLOCK_SIZE)\n\n    row_mask = rows &lt; n_rows\n    col_mask = cols &lt; n_cols\n\n    # \u52a0\u8f7dtile\n    input_offsets = rows[:, None] * n_cols + cols[None, :]\n    mask = row_mask[:, None] &amp; col_mask[None, :]\n\n    tile = tl.load(input_ptr + input_offsets, mask=mask)\n\n    # \u5b58\u50a8\u8f6c\u7f6e\u7684tile\n    output_offsets = cols[:, None] * n_rows + rows[None, :]\n    tl.store(output_ptr + output_offsets, tl.trans(tile), mask=tl.trans(mask))\n</code></pre>"},{"location":"performance/gpu-operations/#3","title":"3. \u5185\u6838\u878d\u5408\u4f18\u5316","text":"Python<pre><code>@triton.jit\ndef fused_linear_relu_kernel(\n    x_ptr, weight_ptr, bias_ptr, output_ptr,\n    n_batch, n_input, n_output,\n    BLOCK_SIZE_M: tl.constexpr,\n    BLOCK_SIZE_N: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr\n):\n    \"\"\"\u878d\u5408\u7684\u7ebf\u6027\u5c42 + ReLU\u5185\u6838\u4ee5\u51cf\u5c11\u5185\u5b58\u5e26\u5bbd\u3002\"\"\"\n    pid = tl.program_id(axis=0)\n\n    # \u77e9\u9635\u4e58\u6cd5\u903b\u8f91\uff08\u7b80\u5316\uff09\n    # ... matmul computation ...\n\n    # \u878d\u5408\u7684ReLU\u6fc0\u6d3b\n    result = tl.maximum(matmul_result + bias, 0.0)\n\n    # \u5355\u6b21\u5185\u5b58\u5199\u5165\n    tl.store(output_ptr + offsets, result, mask=mask)\n\n@triton.jit\ndef fused_attention_kernel(\n    q_ptr, k_ptr, v_ptr, output_ptr,\n    seq_len, head_dim,\n    scale: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr\n):\n    \"\"\"\u878d\u5408\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\u5185\u6838\u3002\"\"\"\n    # \u8ba1\u7b97\u6ce8\u610f\u529b\u5206\u6570\n    scores = compute_qk_scores(q_ptr, k_ptr, seq_len, head_dim)\n\n    # \u5e94\u7528\u7f29\u653e\u548csoftmax\n    scores = scores * scale\n    attention_weights = tl_softmax(scores, axis=-1)\n\n    # \u5c06\u6ce8\u610f\u529b\u5e94\u7528\u5230\u503c\n    output = compute_attention_output(attention_weights, v_ptr, seq_len, head_dim)\n\n    # \u5355\u6b21\u8f93\u51fa\u5199\u5165\n    tl.store(output_ptr + offsets, output, mask=mask)\n\ndef fused_linear_relu(x, weight, bias):\n    \"\"\"\u878d\u5408\u7684\u7ebf\u6027\u5c42\u4e0eReLU\u6fc0\u6d3b\u3002\"\"\"\n    batch_size, input_size = x.shape\n    output_size = weight.shape[0]\n\n    output = genesis.empty(batch_size, output_size, dtype=x.dtype, device=x.device)\n\n    # \u878d\u5408\u7684\u6700\u4f18\u5757\u5927\u5c0f\n    BLOCK_SIZE_M = 64\n    BLOCK_SIZE_N = 64  \n    BLOCK_SIZE_K = 32\n\n    grid = lambda meta: (\n        triton.cdiv(batch_size, meta['BLOCK_SIZE_M']) * \n        triton.cdiv(output_size, meta['BLOCK_SIZE_N']),\n    )\n\n    fused_linear_relu_kernel[grid](\n        x.data_ptr(), weight.data_ptr(), bias.data_ptr(), output.data_ptr(),\n        batch_size, input_size, output_size,\n        BLOCK_SIZE_M=BLOCK_SIZE_M,\n        BLOCK_SIZE_N=BLOCK_SIZE_N,\n        BLOCK_SIZE_K=BLOCK_SIZE_K\n    )\n\n    return output\n</code></pre>"},{"location":"performance/gpu-operations/#_8","title":"\u6027\u80fd\u76d1\u63a7\u548c\u5206\u6790","text":""},{"location":"performance/gpu-operations/#1_1","title":"1. \u5185\u7f6e\u6027\u80fd\u6307\u6807","text":"Python<pre><code>import time\nimport contextlib\n\nclass GPUProfiler:\n    \"\"\"\u5206\u6790GPU\u64cd\u4f5c\u6027\u80fd\u3002\"\"\"\n\n    def __init__(self):\n        self.metrics = {}\n        self.current_operation = None\n\n    @contextlib.contextmanager\n    def profile_operation(self, operation_name):\n        \"\"\"\u7528\u4e8e\u5206\u6790\u64cd\u4f5c\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u3002\"\"\"\n        self.current_operation = operation_name\n\n        # \u8ba1\u65f6\u524d\u540c\u6b65\n        genesis.cuda.synchronize()\n        start_time = time.perf_counter()\n\n        try:\n            yield\n        finally:\n            genesis.cuda.synchronize()\n            end_time = time.perf_counter()\n\n            elapsed = end_time - start_time\n            if operation_name not in self.metrics:\n                self.metrics[operation_name] = []\n\n            self.metrics[operation_name].append(elapsed)\n\n    def get_stats(self, operation_name=None):\n        \"\"\"\u83b7\u53d6\u6027\u80fd\u7edf\u8ba1\u3002\"\"\"\n        if operation_name:\n            times = self.metrics.get(operation_name, [])\n            if not times:\n                return None\n\n            return {\n                'mean': sum(times) / len(times),\n                'min': min(times),\n                'max': max(times),\n                'count': len(times)\n            }\n        else:\n            stats = {}\n            for op_name in self.metrics:\n                stats[op_name] = self.get_stats(op_name)\n            return stats\n\n    def print_summary(self):\n        \"\"\"\u6253\u5370\u6027\u80fd\u6458\u8981\u3002\"\"\"\n        print(\"GPU\u64cd\u4f5c\u6027\u80fd\u6458\u8981:\")\n        print(\"-\" * 50)\n\n        for op_name, stats in self.get_stats().items():\n            print(f\"{op_name}:\")\n            print(f\"  \u5e73\u5747: {stats['mean']*1000:.3f}ms\")\n            print(f\"  \u6700\u5c0f:  {stats['min']*1000:.3f}ms\")\n            print(f\"  \u6700\u5927:  {stats['max']*1000:.3f}ms\")\n            print(f\"  \u6b21\u6570: {stats['count']}\")\n            print()\n\n# \u5168\u5c40\u5206\u6790\u5668\u5b9e\u4f8b\ngpu_profiler = GPUProfiler()\n\n# \u5728\u64cd\u4f5c\u4e2d\u4f7f\u7528\u5206\u6790\u5668\u7684\u793a\u4f8b\ndef add_with_profiling(x, y):\n    with gpu_profiler.profile_operation('add'):\n        return add_triton(x, y)\n</code></pre>"},{"location":"performance/gpu-operations/#2_1","title":"2. \u5185\u5b58\u5e26\u5bbd\u5206\u6790","text":"Python<pre><code>def analyze_memory_bandwidth(operation_func, tensor_sizes, dtype=genesis.float32):\n    \"\"\"\u5206\u6790\u64cd\u4f5c\u7684\u5185\u5b58\u5e26\u5bbd\u5229\u7528\u7387\u3002\"\"\"\n\n    results = []\n    theoretical_bandwidth = 1555e9  # A800 HBM2e\u5e26\u5bbd\uff0c\u5b57\u8282/\u79d2\n\n    for size in tensor_sizes:\n        # \u521b\u5efa\u6d4b\u8bd5\u5f20\u91cf\n        if isinstance(size, tuple):\n            x = genesis.randn(*size, dtype=dtype, device='cuda')\n            y = genesis.randn(*size, dtype=dtype, device='cuda')\n        else:\n            x = genesis.randn(size, dtype=dtype, device='cuda')\n            y = genesis.randn(size, dtype=dtype, device='cuda')\n\n        # \u8ba1\u7b97\u7406\u8bba\u4f20\u8f93\u7684\u5b57\u8282\u6570\n        bytes_per_element = dtype.itemsize\n        total_elements = x.numel()\n\n        # \u5bf9\u4e8e\u4e8c\u5143\u64cd\u4f5c\uff1a\u8bfb\u53d62\u4e2a\u5f20\u91cf + \u5199\u51651\u4e2a\u5f20\u91cf\n        total_bytes = total_elements * bytes_per_element * 3\n\n        # \u9884\u70ed\n        for _ in range(5):\n            _ = operation_func(x, y)\n\n        # \u8ba1\u65f6\u64cd\u4f5c\n        genesis.cuda.synchronize()\n        start_time = time.perf_counter()\n\n        num_iterations = 10\n        for _ in range(num_iterations):\n            result = operation_func(x, y)\n\n        genesis.cuda.synchronize()\n        end_time = time.perf_counter()\n\n        # \u8ba1\u7b97\u6307\u6807\n        elapsed_time = (end_time - start_time) / num_iterations\n        achieved_bandwidth = total_bytes / elapsed_time\n        bandwidth_efficiency = achieved_bandwidth / theoretical_bandwidth\n\n        results.append({\n            'size': size,\n            'elements': total_elements,\n            'elapsed_ms': elapsed_time * 1000,\n            'bandwidth_gb_s': achieved_bandwidth / 1e9,\n            'efficiency_percent': bandwidth_efficiency * 100,\n            'theoretical_gb_s': theoretical_bandwidth / 1e9\n        })\n\n        print(f\"\u5927\u5c0f {size}: {achieved_bandwidth/1e9:.1f} GB/s ({bandwidth_efficiency:.1%})\")\n\n    return results\n\n# \u5206\u6790\u52a0\u6cd5\u64cd\u4f5c\u6027\u80fd\nsizes = [(256, 256), (1024, 1024), (2048, 2048), (4096, 4096)]\nbandwidth_results = analyze_memory_bandwidth(add_triton, sizes)\n</code></pre>"},{"location":"performance/gpu-operations/#3_1","title":"3. \u81ea\u52a8\u6027\u80fd\u8c03\u4f18","text":"Python<pre><code>class AutoTuner:\n    \"\"\"\u81ea\u52a8\u8c03\u4f18\u5185\u6838\u53c2\u6570\u4ee5\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u3002\"\"\"\n\n    def __init__(self):\n        self.best_configs = {}\n\n    def tune_kernel(self, kernel_func, test_inputs, param_space):\n        \"\"\"\u81ea\u52a8\u8c03\u4f18\u5185\u6838\u53c2\u6570\u3002\"\"\"\n        best_time = float('inf')\n        best_config = None\n\n        print(f\"\u6b63\u5728\u8c03\u4f18\u5185\u6838\uff0c\u5171\u6709 {len(param_space)} \u4e2a\u914d\u7f6e...\")\n\n        for i, config in enumerate(param_space):\n            try:\n                # \u9884\u70ed\n                for _ in range(3):\n                    _ = kernel_func(*test_inputs, **config)\n\n                # \u8ba1\u65f6\u6267\u884c\n                genesis.cuda.synchronize()\n                start_time = time.perf_counter()\n\n                num_runs = 10\n                for _ in range(num_runs):\n                    result = kernel_func(*test_inputs, **config)\n\n                genesis.cuda.synchronize()\n                end_time = time.perf_counter()\n\n                elapsed = (end_time - start_time) / num_runs\n\n                if elapsed &lt; best_time:\n                    best_time = elapsed\n                    best_config = config\n\n                print(f\"\u914d\u7f6e {i+1}: {elapsed*1000:.3f}ms - {config}\")\n\n            except Exception as e:\n                print(f\"\u914d\u7f6e {i+1} \u5931\u8d25: {e}\")\n\n        print(f\"\u6700\u4f73\u914d\u7f6e: {best_config} ({best_time*1000:.3f}ms)\")\n        return best_config, best_time\n\n# \u77e9\u9635\u4e58\u6cd5\u81ea\u52a8\u8c03\u4f18\u793a\u4f8b\ndef tune_matmul():\n    # \u5b9a\u4e49\u53c2\u6570\u7a7a\u95f4\n    block_sizes = [\n        {'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32},\n        {'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32},\n        {'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32},\n        {'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64},\n    ]\n\n    # \u6d4b\u8bd5\u8f93\u5165\n    a = genesis.randn(1024, 1024, device='cuda')\n    b = genesis.randn(1024, 1024, device='cuda')\n\n    # \u8fd0\u884c\u81ea\u52a8\u8c03\u4f18\u5668\n    tuner = AutoTuner()\n    best_config, best_time = tuner.tune_kernel(\n        matmul_triton, [a, b], block_sizes\n    )\n\n    return best_config\n</code></pre>"},{"location":"performance/gpu-operations/#_9","title":"\u6700\u4f73\u5b9e\u8df5","text":""},{"location":"performance/gpu-operations/#1_2","title":"1. \u5185\u6838\u5f00\u53d1\u6307\u5357","text":"<ul> <li>\u5185\u5b58\u5408\u5e76: \u786e\u4fdd\u8fde\u7eed\u7684\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f</li> <li>\u5757\u5927\u5c0f\u4f18\u5316: \u4f7f\u75282\u7684\u5e42\uff0c\u8003\u8651\u5360\u7528\u7387</li> <li>\u5bc4\u5b58\u5668\u4f7f\u7528: \u76d1\u63a7\u5927\u5185\u6838\u7684\u5bc4\u5b58\u5668\u6ea2\u51fa</li> <li>\u5171\u4eab\u5185\u5b58: \u4e3a\u6570\u636e\u91cd\u7528\u4f7f\u7528\u5171\u4eab\u5185\u5b58</li> <li>\u5206\u652f\u53d1\u6563\u6700\u5c0f\u5316: \u53ef\u80fd\u65f6\u907f\u514d\u6761\u4ef6\u5206\u652f</li> </ul>"},{"location":"performance/gpu-operations/#2_2","title":"2. \u6027\u80fd\u4f18\u5316\u68c0\u67e5\u6e05\u5355","text":"<ul> <li> \u5206\u6790\u5185\u5b58\u5e26\u5bbd\u5229\u7528\u7387</li> <li> \u4e3a\u76ee\u6807GPU\u4f18\u5316\u5757\u5927\u5c0f</li> <li> \u6700\u5c0f\u5316\u5185\u6838\u542f\u52a8\u5f00\u9500</li> <li> \u4e3a\u76f8\u5173\u64cd\u4f5c\u4f7f\u7528\u5185\u6838\u878d\u5408</li> <li> \u76d1\u63a7GPU\u5360\u7528\u7387\u548c\u8d44\u6e90\u4f7f\u7528</li> <li> \u4f18\u5316\u540e\u9a8c\u8bc1\u6570\u503c\u7cbe\u5ea6</li> </ul>"},{"location":"performance/gpu-operations/#3-gpu","title":"3. \u8c03\u8bd5GPU\u64cd\u4f5c","text":"Python<pre><code>def debug_gpu_operation(operation_func, *inputs):\n    \"\"\"\u4f7f\u7528\u8be6\u7ec6\u5206\u6790\u8c03\u8bd5GPU\u64cd\u4f5c\u3002\"\"\"\n\n    print(\"GPU\u64cd\u4f5c\u8c03\u8bd5\u4fe1\u606f:\")\n    print(\"=\" * 40)\n\n    # \u8f93\u5165\u5206\u6790\n    for i, inp in enumerate(inputs):\n        print(f\"\u8f93\u5165 {i}:\")\n        print(f\"  \u5f62\u72b6: {inp.shape}\")\n        print(f\"  \u6570\u636e\u7c7b\u578b: {inp.dtype}\")\n        print(f\"  \u8bbe\u5907: {inp.device}\")\n        print(f\"  \u5185\u5b58\u4f7f\u7528: {inp.numel() * inp.dtype.itemsize / 1e6:.1f} MB\")\n        print(f\"  \u8fde\u7eed\u6027: {inp.is_contiguous()}\")\n        print()\n\n    # GPU\u5185\u5b58\u72b6\u6001\n    print(\"GPU\u5185\u5b58\u72b6\u6001:\")\n    print(f\"  \u5df2\u5206\u914d: {genesis.cuda.memory_allocated() / 1e6:.1f} MB\")\n    print(f\"  \u7f13\u5b58: {genesis.cuda.memory_cached() / 1e6:.1f} MB\")\n    print()\n\n    # \u6267\u884c\u5e26\u5206\u6790\u7684\u64cd\u4f5c\n    genesis.cuda.synchronize()\n    start_time = time.perf_counter()\n\n    result = operation_func(*inputs)\n\n    genesis.cuda.synchronize()\n    end_time = time.perf_counter()\n\n    # \u7ed3\u679c\u5206\u6790\n    print(\"\u64cd\u4f5c\u7ed3\u679c:\")\n    print(f\"  \u6267\u884c\u65f6\u95f4: {(end_time - start_time) * 1000:.3f}ms\")\n    print(f\"  \u8f93\u51fa\u5f62\u72b6: {result.shape}\")\n    print(f\"  \u8f93\u51fa\u6570\u636e\u7c7b\u578b: {result.dtype}\")\n    print(f\"  \u8f93\u51fa\u8bbe\u5907: {result.device}\")\n    print()\n\n    # \u6570\u503c\u9a8c\u8bc1\n    print(\"\u6570\u503c\u9a8c\u8bc1:\")\n    print(f\"  \u6700\u5c0f\u503c: {result.min().item():.6f}\")\n    print(f\"  \u6700\u5927\u503c: {result.max().item():.6f}\")\n    print(f\"  \u5e73\u5747\u503c: {result.mean().item():.6f}\")\n    print(f\"  \u5b58\u5728NaN: {genesis.isnan(result).any().item()}\")\n    print(f\"  \u5b58\u5728Inf: {genesis.isinf(result).any().item()}\")\n\n    return result\n\n# \u4f7f\u7528\u793a\u4f8b\nx = genesis.randn(1000, 1000, device='cuda')\ny = genesis.randn(1000, 1000, device='cuda')\nresult = debug_gpu_operation(add_triton, x, y)\n</code></pre> <p>\u8fd9\u4e2a\u5168\u9762\u7684\u6307\u5357\u6db5\u76d6\u4e86Genesis\u4e2d\u6a21\u5757\u5316GPU\u64cd\u4f5c\u67b6\u6784\uff0c\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u5b9e\u73b0\u793a\u4f8b\u548c\u4f18\u5316\u7b56\u7565\uff0c\u4ee5\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\u3002</p>"},{"location":"performance/optimization-guide/","title":"Genesis \u6027\u80fd\u4f18\u5316\u6307\u5357","text":""},{"location":"performance/optimization-guide/#_1","title":"\u6982\u8ff0","text":"<p>\u672c\u6587\u6863\u63d0\u4f9bGenesis\u6846\u67b6\u7684\u6027\u80fd\u7279\u5f81\u3001\u5f53\u524d\u5b9e\u73b0\u72b6\u6001\u548c\u4f18\u5316\u7b56\u7565\u7684\u5168\u9762\u6307\u5357\u3002Genesis\u8bbe\u8ba1\u4e3a\u8f7b\u91cf\u7ea7\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u6559\u80b2\u4ef7\u503c\u7684\u540c\u65f6\u8ffd\u6c42\u7ade\u4e89\u6027\u80fd\u3002</p>"},{"location":"performance/optimization-guide/#_2","title":"\u5f53\u524d\u6027\u80fd\u72b6\u6001","text":""},{"location":"performance/optimization-guide/#add","title":"\u5143\u7d20\u64cd\u4f5c (ADD) \u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c","text":"<p>\u6d4b\u8bd5\u73af\u5883: - GPU: NVIDIA A800-SXM4-80GB - \u663e\u5b58: 79.3 GB - \u7406\u8bba\u5e26\u5bbd: 1555 GB/s - \u6d4b\u8bd5\u65e5\u671f: 2025\u5e748\u6708</p> <p>\u6027\u80fd\u603b\u7ed3: - \u5e73\u5747\u6548\u7387: 18.0% \u7406\u8bba\u5e26\u5bbd\u5229\u7528\u7387 - \u6700\u4f73\u6027\u80fd: 33.1% (\u6279\u5904\u7406\u5f20\u91cf) - \u6700\u5dee\u6027\u80fd: 3.1% (\u5927\u5f20\u91cf) - \u6574\u4f53\u72b6\u6001: \u5f00\u53d1\u9636\u6bb5</p>"},{"location":"performance/optimization-guide/#_3","title":"\u6309\u5f20\u91cf\u5927\u5c0f\u5206\u7c7b\u7684\u6027\u80fd","text":"\u7c7b\u522b \u5e73\u5747\u6548\u7387 \u72b6\u6001 vs PyTorch \u5c0f\u5f20\u91cf (64K-262K) 18.9% \u274c \u4e25\u91cd 0.19x \u4e2d\u7b49\u5f20\u91cf (4.2M) 29.6% \ud83d\udd34 \u8f83\u5dee 0.27-0.32x \u5927\u5f20\u91cf (16.8M) 4.7% \u274c \u4e25\u91cd 0.03-0.06x \u8d85\u5927\u5f20\u91cf (67M) 5.4% \u274c \u4e25\u91cd 0.05-0.06x \u6279\u5904\u7406 31.2% \ud83d\udd34 \u8f83\u5dee 0.29-0.33x"},{"location":"performance/optimization-guide/#detailed-performance-data","title":"Detailed Performance Data","text":"Shape Size PyTorch Genesis Speed Ratio Efficiency Status Primary Issue 256\u00d7256 65.5K 0.019ms 0.104ms 0.19x 18.7% \u274c Critical Launch overhead 2048\u00d72048 4.2M 0.053ms 0.166ms 0.32x 32.0% \ud83d\udd34 Poor Autograd cost 4096\u00d74096 16.8M 0.147ms 2.334ms 0.06x 6.3% \u274c Critical Bandwidth limit 8192\u00d78192 67M 0.478ms 8.208ms 0.06x 5.8% \u274c Critical Memory bound"},{"location":"performance/optimization-guide/#matrix-multiplication-performance","title":"Matrix Multiplication Performance","text":"Matrix Size Genesis Time PyTorch Time Speed Ratio Status 512x512 0.087ms 0.024ms 0.28x \ud83d\udd34 Poor 1024x1024 0.243ms 0.089ms 0.37x \ud83d\udd34 Poor 2048x2048 1.456ms 0.387ms 0.27x \ud83d\udd34 Poor 4096x4096 8.932ms 2.234ms 0.25x \ud83d\udd34 Poor"},{"location":"performance/optimization-guide/#_4","title":"\u67b6\u6784\u5b9e\u73b0","text":""},{"location":"performance/optimization-guide/#add_1","title":"\u5f53\u524dADD\u64cd\u4f5c\u5b9e\u73b0","text":"<p>Genesis\u91c7\u7528\u53cc\u540e\u7aef\u67b6\u6784: - CPU\u540e\u7aef: PyTorch\u5f20\u91cf\u64cd\u4f5c - GPU\u540e\u7aef: \u81ea\u5b9a\u4e49CUDA + Triton\u5185\u6838</p>"},{"location":"performance/optimization-guide/#gpu","title":"GPU\u5185\u6838\u5b9e\u73b0","text":"Python<pre><code>@triton.jit\ndef add_kernel(x_ptr, y_ptr, output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n    \"\"\"\u4f18\u5316\u7684\u52a0\u6cd5\u5185\u6838\uff0c\u540c\u5f62\u72b6\u5f20\u91cf\uff0c\u66f4\u597d\u7684\u5185\u5b58\u8bbf\u95ee\"\"\"\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets &lt; n_elements\n\n    x = tl.load(x_ptr + offsets, mask=mask, other=0.0)\n    y = tl.load(y_ptr + offsets, mask=mask, other=0.0)\n    output = x + y\n    tl.store(output_ptr + offsets, output, mask=mask)\n</code></pre>"},{"location":"performance/optimization-guide/#_5","title":"\u81ea\u9002\u5e94\u5757\u5927\u5c0f\u914d\u7f6e","text":"<p>\u5f53\u524d\u4f18\u5316\u914d\u7f6e:</p> Python<pre><code>BLOCK_SIZE_CONFIGS = {\n    (0, 262144): 256,         # \u5c0f\u5f20\u91cf: \u66f4\u5c0f\u5757\u63d0\u5347\u7f13\u5b58\u5229\u7528\u7387\n    (262144, 4194304): 512,   # \u4e2d\u7b49\u5f20\u91cf: \u5e73\u8861\u5360\u7528\u7387\u4e0e\u7f13\u5b58\n    (4194304, float('inf')): 1024,  # \u5927\u5f20\u91cf: \u66f4\u5927\u5757\u63d0\u5347\u5e26\u5bbd\n}\n</code></pre>"},{"location":"performance/optimization-guide/#_6","title":"\u6027\u80fd\u74f6\u9888\u5206\u6790","text":""},{"location":"performance/optimization-guide/#1-triton","title":"1. \u4e3b\u8981\u74f6\u9888: Triton\u5185\u6838\u6027\u80fd","text":"<ul> <li>\u5185\u6838\u5f00\u9500: \u6bd4PyTorch\u616223.6\u500d</li> <li>\u6839\u672c\u539f\u56e0: Triton\u5185\u6838\u6548\u7387\u8fdc\u4f4e\u4e8ePyTorch\u4f18\u5316\u7684CUDA\u5185\u6838</li> <li>\u5f71\u54cd: \u5927\u5f20\u91cf(&gt;16M\u5143\u7d20)\u6700\u4e3a\u4e25\u91cd</li> </ul>"},{"location":"performance/optimization-guide/#2","title":"2. \u5185\u5b58\u5e26\u5bbd\u5229\u7528\u7387","text":"<ul> <li>PyTorch: 71.4% \u5e26\u5bbd\u6548\u7387</li> <li>Genesis: 18.0% \u5e73\u5747\u6548\u7387  </li> <li>\u7406\u8bba\u6700\u5927\u503c: 1555 GB/s (A800 HBM2e)</li> </ul> <p>\u95ee\u9898: - \u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u672a\u5145\u5206\u4f18\u5316 - \u5927\u5185\u6838\u53ef\u80fd\u5b58\u5728\u5bc4\u5b58\u5668\u6ea2\u51fa - \u5185\u5b58\u5408\u5e76\u8bbf\u95ee\u4e0d\u591f\u4f18\u5316</p>"},{"location":"performance/optimization-guide/#3-gpu","title":"3. GPU\u5360\u7528\u7387\u95ee\u9898","text":"<ul> <li>\u5757\u5927\u5c0f\u914d\u7f6e\u672a\u8fbe\u5230\u6700\u4f18\u5360\u7528\u7387</li> <li>\u8d85\u5927\u5f20\u91cfGPU\u5229\u7528\u7387\u663e\u8457\u4e0b\u964d</li> <li>\u8d44\u6e90\u9650\u5236\u963b\u6b62\u5145\u5206\u5229\u7528SM</li> </ul>"},{"location":"performance/optimization-guide/#_7","title":"\u4f18\u5316\u8def\u7ebf\u56fe","text":""},{"location":"performance/optimization-guide/#1","title":"\u9636\u6bb51: \u7acb\u5373\u6539\u8fdb (\u5df2\u5b8c\u6210)","text":"<p>\u2705 \u5df2\u5b8c\u6210: - \u7b80\u5316\u81ea\u9002\u5e94\u5757\u5927\u5c0f\u914d\u7f6e - \u4e13\u4e1a\u57fa\u51c6\u6d4b\u8bd5\u57fa\u7840\u8bbe\u65bd - \u6027\u80fd\u5206\u6790\u5de5\u5177</p> <p>\ud83d\udcca \u7ed3\u679c: - \u5e73\u5747\u6548\u7387\u4ece5.7%\u63d0\u5347\u523018.0% - \u4e2d\u7b49/\u6279\u5904\u7406\u5f20\u91cf\u8fbe\u523029-33%\u6548\u7387</p>"},{"location":"performance/optimization-guide/#2_1","title":"\u9636\u6bb52: \u5185\u6838\u4f18\u5316 (\u8fdb\u884c\u4e2d)","text":"<p>\ud83c\udfaf \u76ee\u6807\u9886\u57df: - \u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u4f18\u5316(\u5411\u91cf\u5316\u3001\u7f13\u5b58\u53cb\u597d\u5e73\u94fa) - \u5757\u5927\u5c0f\u81ea\u52a8\u8c03\u4f18 - \u5185\u6838\u878d\u5408\u51cf\u5c11\u5185\u5b58\u5e26\u5bbd\u538b\u529b</p>"},{"location":"performance/optimization-guide/#3","title":"\u9636\u6bb53: \u9ad8\u7ea7\u4f18\u5316 (\u672a\u6765)","text":"<ul> <li>\u81ea\u5b9a\u4e49CUDA\u5185\u6838\u624b\u5de5\u4f18\u5316</li> <li>\u5185\u5b58\u5e03\u5c40\u4f18\u5316</li> <li>\u591aGPU\u652f\u6301</li> </ul>"},{"location":"performance/optimization-guide/#_8","title":"\u4f7f\u7528\u5efa\u8bae","text":""},{"location":"performance/optimization-guide/#genesis-vs-pytorch","title":"Genesis vs PyTorch\u9009\u62e9","text":"<p>\u63a8\u8350\u4f7f\u7528Genesis: - \u6559\u80b2\u5b66\u4e60\u548c\u6846\u67b6\u7406\u89e3 - \u4e2d\u7b49\u6279\u5904\u7406\u64cd\u4f5c(\u6700\u4f73\u6027\u80fd31%\u6548\u7387) - \u9700\u8981\u81ea\u5b9a\u4e49\u5185\u6838\u5f00\u53d1\u7684\u7814\u7a76</p> <p>\u63a8\u8350\u4f7f\u7528PyTorch: - \u751f\u4ea7\u73af\u5883\u6700\u5927\u6027\u80fd\u9700\u6c42 - \u5927\u5f20\u91cf\u64cd\u4f5c(&gt;16M\u5143\u7d20) - \u5bf95-25\u500d\u6027\u80fd\u5dee\u5f02\u654f\u611f\u7684\u5e94\u7528</p>"},{"location":"performance/optimization-guide/#_9","title":"\u6027\u80fd\u6280\u5de7","text":"<ol> <li>\u5f20\u91cf\u5927\u5c0f\u610f\u8bc6</li> <li>\u6700\u4f73\u6027\u80fd\u8303\u56f4: 1M-4M\u5143\u7d20</li> <li>\u907f\u514d\u8d85\u5927\u5f20\u91cf(&gt;67M)</li> <li> <p>\u8003\u8651\u5927\u64cd\u4f5c\u7684\u5f20\u91cf\u5206\u5272</p> </li> <li> <p>\u5185\u5b58\u7ba1\u7406 Python<pre><code># \u4f7f\u7528\u5c31\u5730\u64cd\u4f5c\nresult = genesis.add(a, b, out=existing_tensor)\n</code></pre></p> </li> </ol>"},{"location":"performance/optimization-guide/#_10","title":"\u6027\u80fd\u76d1\u63a7","text":""},{"location":"performance/optimization-guide/#_11","title":"\u5185\u7f6e\u57fa\u51c6\u6d4b\u8bd5","text":"Bash<pre><code># \u5feb\u901f\u6027\u80fd\u68c0\u67e5\npython benchmark/bench_ops.py --op add --fast\n\n# \u5168\u9762\u5206\u6790\npython benchmark/bench_ops.py --op add --size large\n</code></pre>"},{"location":"performance/optimization-guide/#_12","title":"\u5173\u952e\u6307\u6807","text":"<ul> <li>\u5185\u5b58\u5e26\u5bbd\u6548\u7387: \u76ee\u6807&gt;50%</li> <li>GPU\u5229\u7528\u7387: \u7528<code>nvidia-smi</code>\u76d1\u63a7</li> <li>\u5185\u6838\u542f\u52a8\u5f00\u9500: \u7528Nsight Compute\u5206\u6790</li> </ul>"},{"location":"performance/optimization-guide/#_13","title":"\u6027\u80fd\u76ee\u6807","text":"\u5f20\u91cf\u7c7b\u522b \u6700\u5c0f\u6548\u7387 \u76ee\u6807\u6548\u7387 \u5c0f\u5f20\u91cf 15% 25% \u4e2d\u7b49\u5f20\u91cf 25% 40% \u5927\u5f20\u91cf 10% 30% \u8d85\u5927\u5f20\u91cf 10% 25% \u6279\u5904\u7406 25% 45% <p>\u6700\u540e\u66f4\u65b0: 2025\u5e748\u6708 \u6846\u67b6\u7248\u672c: Genesis 0.3.0-dev \u57fa\u51c6\u73af\u5883: A800-SXM4-80GB</p>"},{"location":"training/advanced-features/","title":"\u9ad8\u7ea7\u8bad\u7ec3\u7279\u6027","text":"<p>Genesis\u63d0\u4f9b\u4e86\u591a\u4e2a\u9ad8\u7ea7\u7279\u6027\u6765\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002</p>"},{"location":"training/advanced-features/#amp","title":"\ud83d\ude80 \u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3 (AMP)","text":"<p>\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6\uff08AMP\uff09\u5141\u8bb8\u4f60\u5728\u9002\u5f53\u7684\u5730\u65b9\u4f7f\u7528FP16/BF16\u8ba1\u7b97\u6765\u66f4\u5feb\u5730\u8bad\u7ec3\u6a21\u578b\uff0c\u540c\u65f6\u964d\u4f4e\u5185\u5b58\u4f7f\u7528\uff0c\u5e76\u901a\u8fc7\u7ef4\u6301FP32\u4e3b\u6743\u91cd\u6765\u4fdd\u6301\u6570\u503c\u7a33\u5b9a\u6027\u3002</p>"},{"location":"training/advanced-features/#_2","title":"\u57fa\u672c\u7528\u6cd5","text":"Python<pre><code>import genesis\nimport genesis.nn as nn\nimport genesis.optim as optim\nfrom genesis.amp import autocast, GradScaler\n\n# \u521b\u5efa\u6a21\u578b\u548c\u4f18\u5316\u5668\nmodel = nn.Linear(1024, 512)\noptimizer = optim.Adam(model.parameters())\n\n# \u4e3a\u6df7\u5408\u7cbe\u5ea6\u521d\u59cb\u5316\u68af\u5ea6\u7f29\u653e\u5668\nscaler = GradScaler()\n\n# \u4f7f\u7528AMP\u7684\u8bad\u7ec3\u5faa\u73af\nfor data, target in dataloader:\n    optimizer.zero_grad()\n\n    # \u4f7f\u7528autocast\u8fdb\u884c\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6\n    with autocast():\n        output = model(data)\n        loss = criterion(output, target)\n\n    # \u7f29\u653e\u635f\u5931\u5e76\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\n    scaler.scale(loss).backward()\n\n    # \u53cd\u7f29\u653e\u5e76\u6267\u884c\u4f18\u5316\u5668\u6b65\u9aa4\n    scaler.step(optimizer)\n    scaler.update()\n</code></pre>"},{"location":"training/advanced-features/#_3","title":"\u652f\u6301\u7684\u6570\u636e\u7c7b\u578b","text":"<p>Genesis\u652f\u6301\u591a\u79cd\u7cbe\u5ea6\u683c\u5f0f\uff1a</p> <ul> <li>float16 (FP16): \u534a\u7cbe\u5ea6\uff0c\u5728\u5927\u591a\u6570GPU\u4e0a\u6700\u5feb</li> <li>bfloat16 (BF16): \u8111\u6d6e\u70b9\u6570\uff0c\u6bd4FP16\u6709\u66f4\u597d\u7684\u6570\u503c\u8303\u56f4</li> <li>float32 (FP32): \u5355\u7cbe\u5ea6\uff0c\u4e3b\u6743\u91cd\u7684\u9ed8\u8ba4\u7c7b\u578b</li> </ul>"},{"location":"training/advanced-features/#_4","title":"\u4f18\u52bf","text":"<ul> <li>\u901f\u5ea6: \u5728\u73b0\u4ee3GPU\u4e0a\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe2\u500d</li> <li>\u5185\u5b58: \u51cf\u5c11\u5185\u5b58\u4f7f\u7528\uff0c\u5141\u8bb8\u66f4\u5927\u7684\u6279\u6b21\u5927\u5c0f</li> <li>\u7cbe\u5ea6: \u901a\u8fc7\u635f\u5931\u7f29\u653e\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6</li> </ul>"},{"location":"training/advanced-features/#_5","title":"\u2702\ufe0f \u68af\u5ea6\u88c1\u526a","text":"<p>\u68af\u5ea6\u88c1\u526a\u6709\u52a9\u4e8e\u9632\u6b62\u6df1\u5ea6\u7f51\u7edc\u4e2d\u7684\u68af\u5ea6\u7206\u70b8\uff0c\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8eRNN\u548cTransformer\u3002</p>"},{"location":"training/advanced-features/#_6","title":"\u68af\u5ea6\u8303\u6570\u88c1\u526a","text":"<p>\u5f53\u68af\u5ea6\u7684L2\u8303\u6570\u8d85\u8fc7\u9608\u503c\u65f6\u8fdb\u884c\u88c1\u526a\uff1a</p> Python<pre><code>import genesis.nn.utils as nn_utils\n\n# \u8bad\u7ec3\u8fc7\u7a0b\u4e2d\nloss.backward()\n\n# \u6309\u8303\u6570\u88c1\u526a\u68af\u5ea6\uff08\u5927\u591a\u6570\u60c5\u51b5\u63a8\u8350\uff09\nnn_utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\noptimizer.step()\n</code></pre>"},{"location":"training/advanced-features/#_7","title":"\u68af\u5ea6\u503c\u88c1\u526a","text":"<p>\u5c06\u68af\u5ea6\u503c\u88c1\u526a\u5230\u7279\u5b9a\u8303\u56f4\uff1a</p> Python<pre><code># \u6309\u503c\u88c1\u526a\u68af\u5ea6\nnn_utils.clip_grad_value_(model.parameters(), clip_value=0.5)\n</code></pre>"},{"location":"training/advanced-features/#_8","title":"\u4f55\u65f6\u4f7f\u7528","text":"<ul> <li>\u68af\u5ea6\u8303\u6570\u88c1\u526a: \u63a8\u8350\u7528\u4e8eRNN\u3001LSTM\u548cTransformer</li> <li>\u68af\u5ea6\u503c\u88c1\u526a: \u5f53\u9700\u8981\u5bf9\u68af\u5ea6\u503c\u8fdb\u884c\u786c\u9650\u5236\u65f6\u6709\u7528</li> <li>\u5178\u578b\u503c: \u5927\u591a\u6570\u6a21\u578b\u7684max_norm\u57280.5\u52305.0\u4e4b\u95f4</li> </ul>"},{"location":"training/advanced-features/#_9","title":"\ud83d\udcc8 \u5b66\u4e60\u7387\u8c03\u5ea6\u5668","text":"<p>\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u4ee5\u6539\u5584\u6536\u655b\u6027\u548c\u6700\u7ec8\u6a21\u578b\u6027\u80fd\u3002</p>"},{"location":"training/advanced-features/#steplr","title":"StepLR","text":"<p>\u6bcfstep_size\u4e2aepoch\u5c06\u5b66\u4e60\u7387\u8870\u51cfgamma\u500d\uff1a</p> Python<pre><code>from genesis.optim.lr_scheduler import StepLR\n\noptimizer = optim.Adam(model.parameters(), lr=0.1)\nscheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n\nfor epoch in range(100):\n    train(...)\n    scheduler.step()  # \u6bcf30\u4e2aepoch\u8870\u51cf\u5b66\u4e60\u7387\n</code></pre>"},{"location":"training/advanced-features/#exponentiallr","title":"ExponentialLR","text":"<p>\u6307\u6570\u8870\u51cf\u5b66\u4e60\u7387\uff1a</p> Python<pre><code>from genesis.optim.lr_scheduler import ExponentialLR\n\nscheduler = ExponentialLR(optimizer, gamma=0.95)\n\nfor epoch in range(100):\n    train(...)\n    scheduler.step()  # \u6bcf\u4e2aepoch\u5b66\u4e60\u7387 = \u5b66\u4e60\u7387 * 0.95\n</code></pre>"},{"location":"training/advanced-features/#cosineannealinglr","title":"CosineAnnealingLR","text":"<p>\u4f7f\u7528\u4f59\u5f26\u9000\u706b\u8c03\u5ea6\uff1a</p> Python<pre><code>from genesis.optim.lr_scheduler import CosineAnnealingLR\n\n# T_max: \u6700\u5927\u8fed\u4ee3\u6b21\u6570\nscheduler = CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6)\n\nfor epoch in range(100):\n    train(...)\n    scheduler.step()\n</code></pre>"},{"location":"training/advanced-features/#_10","title":"\u81ea\u5b9a\u4e49\u5b66\u4e60\u7387\u8c03\u5ea6","text":"<p>\u4f60\u4e5f\u53ef\u4ee5\u5b9e\u73b0\u81ea\u5b9a\u4e49\u8c03\u5ea6\uff1a</p> Python<pre><code>def custom_lr_lambda(epoch):\n    # \u524d10\u4e2aepoch\u9884\u70ed\uff0c\u7136\u540e\u8870\u51cf\n    if epoch &lt; 10:\n        return epoch / 10\n    else:\n        return 0.95 ** (epoch - 10)\n\nscheduler = LambdaLR(optimizer, lr_lambda=custom_lr_lambda)\n</code></pre>"},{"location":"training/advanced-features/#_11","title":"\ud83d\udcbe \u68c0\u67e5\u70b9","text":"<p>\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4fdd\u5b58\u548c\u6062\u590d\u6a21\u578b\u72b6\u6001\uff0c\u4ee5\u5b9e\u73b0\u5bb9\u9519\u548c\u6a21\u578b\u90e8\u7f72\u3002</p>"},{"location":"training/advanced-features/#_12","title":"\u4fdd\u5b58\u68c0\u67e5\u70b9","text":"Python<pre><code>import genesis\n\n# \u4fdd\u5b58\u6a21\u578b\u72b6\u6001\ngenesis.save_checkpoint({\n    'epoch': epoch,\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'loss': loss,\n    'best_accuracy': best_acc\n}, 'checkpoint_epoch_10.pth')\n</code></pre>"},{"location":"training/advanced-features/#_13","title":"\u52a0\u8f7d\u68c0\u67e5\u70b9","text":"Python<pre><code># \u52a0\u8f7d\u68c0\u67e5\u70b9\ncheckpoint = genesis.load_checkpoint('checkpoint_epoch_10.pth')\n\n# \u6062\u590d\u6a21\u578b\u548c\u4f18\u5316\u5668\u72b6\u6001\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n</code></pre>"},{"location":"training/advanced-features/#_14","title":"\u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u5b9a\u671f\u4fdd\u5b58: \u6bcfN\u4e2aepoch\u4fdd\u5b58\u68c0\u67e5\u70b9</li> <li>\u6700\u4f73\u6a21\u578b\u8ddf\u8e2a: \u4fdd\u7559\u6027\u80fd\u6700\u597d\u7684\u6a21\u578b</li> <li>\u5143\u6570\u636e\u5b58\u50a8: \u5305\u542b\u8bad\u7ec3\u914d\u7f6e\u548c\u6307\u6807</li> </ol> Python<pre><code># \u793a\u4f8b\uff1a\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4fdd\u5b58\u6700\u4f73\u6a21\u578b\nbest_loss = float('inf')\n\nfor epoch in range(num_epochs):\n    val_loss = validate(model, val_loader)\n\n    if val_loss &lt; best_loss:\n        best_loss = val_loss\n        genesis.save_checkpoint({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'best_loss': best_loss\n        }, 'best_model.pth')\n</code></pre>"},{"location":"training/advanced-features/#_15","title":"\ud83d\udd27 \u5b8c\u6574\u8bad\u7ec3\u793a\u4f8b","text":"<p>\u4ee5\u4e0b\u662f\u7ed3\u5408\u6240\u6709\u9ad8\u7ea7\u7279\u6027\u7684\u5b8c\u6574\u793a\u4f8b\uff1a</p> Python<pre><code>import genesis\nimport genesis.nn as nn\nimport genesis.optim as optim\nfrom genesis.amp import autocast, GradScaler\nfrom genesis.optim.lr_scheduler import CosineAnnealingLR\nimport genesis.nn.utils as nn_utils\n\n# \u6a21\u578b\u8bbe\u7f6e\nmodel = YourModel()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = CosineAnnealingLR(optimizer, T_max=100)\nscaler = GradScaler()\n\n# \u8bad\u7ec3\u914d\u7f6e\nmax_grad_norm = 1.0\ncheckpoint_interval = 10\n\nfor epoch in range(num_epochs):\n    for batch_idx, (data, target) in enumerate(train_loader):\n        optimizer.zero_grad()\n\n        # \u6df7\u5408\u7cbe\u5ea6\u524d\u5411\u4f20\u64ad\n        with autocast():\n            output = model(data)\n            loss = criterion(output, target)\n\n        # \u7f29\u653e\u7684\u53cd\u5411\u4f20\u64ad\n        scaler.scale(loss).backward()\n\n        # \u68af\u5ea6\u88c1\u526a\n        scaler.unscale_(optimizer)\n        nn_utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n\n        # \u5e26\u7f29\u653e\u7684\u4f18\u5316\u5668\u6b65\u9aa4\n        scaler.step(optimizer)\n        scaler.update()\n\n    # \u66f4\u65b0\u5b66\u4e60\u7387\n    scheduler.step()\n\n    # \u4fdd\u5b58\u68c0\u67e5\u70b9\n    if epoch % checkpoint_interval == 0:\n        genesis.save_checkpoint({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'scaler_state_dict': scaler.state_dict(),\n        }, f'checkpoint_epoch_{epoch}.pth')\n</code></pre>"},{"location":"training/advanced-features/#_16","title":"\ud83d\udcca \u6027\u80fd\u63d0\u793a","text":""},{"location":"training/advanced-features/#_17","title":"\u5185\u5b58\u4f18\u5316","text":"<ul> <li>\u4f7f\u7528\u68af\u5ea6\u7d2f\u79ef\u83b7\u5f97\u66f4\u5927\u7684\u6709\u6548\u6279\u6b21\u5927\u5c0f</li> <li>\u4e3a\u975e\u5e38\u6df1\u7684\u6a21\u578b\u542f\u7528\u68af\u5ea6\u68c0\u67e5\u70b9</li> <li>\u4f7f\u7528\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u51cf\u5c11\u5185\u5b58\u4f7f\u7528</li> </ul>"},{"location":"training/advanced-features/#_18","title":"\u901f\u5ea6\u4f18\u5316","text":"<ul> <li>\u4f7f\u7528\u9002\u5f53\u7684\u6570\u636e\u7c7b\u578b\uff08FP16\u7528\u4e8e\u901f\u5ea6\uff0cBF16\u7528\u4e8e\u7a33\u5b9a\u6027\uff09</li> <li>\u8c03\u6574\u68af\u5ea6\u7d2f\u79ef\u6b65\u6570</li> <li>\u5206\u6790\u8bad\u7ec3\u5faa\u73af\u4ee5\u8bc6\u522b\u74f6\u9888</li> </ul>"},{"location":"training/advanced-features/#_19","title":"\u6536\u655b\u6280\u5de7","text":"<ul> <li>\u4ece\u5b66\u4e60\u7387\u67e5\u627e\u5668\u5f00\u59cb\u8bc6\u522b\u6700\u4f18\u5b66\u4e60\u7387</li> <li>\u5bf9\u5927\u6279\u6b21\u8bad\u7ec3\u4f7f\u7528\u9884\u70ed</li> <li>\u76d1\u63a7\u68af\u5ea6\u8303\u6570\u4ee5\u65e9\u671f\u68c0\u6d4b\u4e0d\u7a33\u5b9a\u6027</li> </ul>"},{"location":"training/advanced-features/#_20","title":"\ud83d\udd17 \u76f8\u5173\u4e3b\u9898","text":"<ul> <li>\u57fa\u7840\u8bad\u7ec3\u6559\u7a0b</li> <li>\u6027\u80fd\u8c03\u4f18\u6307\u5357</li> <li>\u6a21\u578b\u67b6\u6784\u6307\u5357</li> <li>\u4f18\u5316\u5668\u6587\u6863</li> </ul>"},{"location":"tutorials/","title":"\u6559\u7a0b\u603b\u89c8","text":"<p>\u6b22\u8fce\u6765\u5230Genesis\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7684\u6559\u7a0b\u7cfb\u5217\uff01\u8fd9\u4e9b\u6559\u7a0b\u5c06\u5e2e\u52a9\u4f60\u4ece\u5165\u95e8\u5230\u7cbe\u901aGenesis\u6846\u67b6\u7684\u5404\u4e2a\u65b9\u9762\u3002</p>"},{"location":"tutorials/#_2","title":"\ud83d\udcda \u6559\u7a0b\u5206\u7c7b","text":""},{"location":"tutorials/#_3","title":"\ud83c\udfaf \u57fa\u7840\u6559\u7a0b","text":"<p>\u9002\u5408\u521d\u5b66\u8005\uff0c\u6db5\u76d6Genesis\u7684\u57fa\u672c\u6982\u5ff5\u548c\u7528\u6cd5\u3002</p> <ul> <li>\u57fa\u7840\u8bad\u7ec3\u6559\u7a0b - \u5b66\u4e60\u5982\u4f55\u4f7f\u7528Genesis\u8bad\u7ec3\u4f60\u7684\u7b2c\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc</li> <li>\u6570\u636e\u5904\u7406\u6559\u7a0b - \u6570\u636e\u52a0\u8f7d\u3001\u9884\u5904\u7406\u548c\u6570\u636e\u7ba1\u9053\u6784\u5efa</li> <li>\u6a21\u578b\u5b9a\u4e49\u6559\u7a0b - \u5982\u4f55\u5b9a\u4e49\u548c\u7ec4\u7ec7\u795e\u7ecf\u7f51\u7edc\u6a21\u578b</li> </ul>"},{"location":"tutorials/#_4","title":"\ud83d\ude80 \u8fdb\u9636\u6559\u7a0b","text":"<p>\u6df1\u5165\u4e86\u89e3Genesis\u7684\u9ad8\u7ea7\u7279\u6027\u548c\u4f18\u5316\u6280\u5de7\u3002</p> <ul> <li>\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3 - \u4f7f\u7528AMP\u52a0\u901f\u8bad\u7ec3\u5e76\u8282\u7701\u663e\u5b58</li> <li>\u81ea\u5b9a\u4e49\u7b97\u5b50 - \u5b9e\u73b0\u81ea\u5b9a\u4e49\u7684\u795e\u7ecf\u7f51\u7edc\u64cd\u4f5c</li> <li>\u6027\u80fd\u8c03\u4f18 - \u4f18\u5316\u8bad\u7ec3\u6027\u80fd\u548c\u5185\u5b58\u4f7f\u7528</li> <li>\u5206\u5e03\u5f0f\u8bad\u7ec3 - \u591aGPU\u5e76\u884c\u8bad\u7ec3\u5b9e\u73b0</li> </ul>"},{"location":"tutorials/#_5","title":"\ud83d\udee0\ufe0f \u5b9e\u6218\u9879\u76ee","text":"<p>\u901a\u8fc7\u5b8c\u6574\u7684\u9879\u76ee\u5b66\u4e60Genesis\u7684\u5b9e\u9645\u5e94\u7528\u3002</p> <ul> <li>LLM\u8bad\u7ec3\u5b9e\u6218 - \u4f7f\u7528Genesis\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b</li> <li>\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3 - AMP\u6280\u672f\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5e94\u7528</li> </ul>"},{"location":"tutorials/#_6","title":"\ud83c\udf93 \u5b66\u4e60\u8def\u5f84","text":""},{"location":"tutorials/#1-2","title":"\u521d\u5b66\u8005\u8def\u5f84 (1-2\u5468)","text":"<ol> <li>\u5b89\u88c5\u548c\u73af\u5883\u914d\u7f6e</li> <li>\u7b2c\u4e00\u4e2a\u7a0b\u5e8f </li> <li>\u57fa\u7840\u8bad\u7ec3\u6559\u7a0b</li> <li>\u6570\u636e\u5904\u7406\u6559\u7a0b</li> </ol>"},{"location":"tutorials/#2-4","title":"\u8fdb\u9636\u7528\u6237\u8def\u5f84 (2-4\u5468)","text":"<ol> <li>\u5b8c\u6210\u521d\u5b66\u8005\u8def\u5f84</li> <li>\u81ea\u5b9a\u4e49\u7b97\u5b50</li> <li>\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3 </li> <li>\u6027\u80fd\u8c03\u4f18</li> <li>\u5206\u5e03\u5f0f\u8bad\u7ec3</li> </ol>"},{"location":"tutorials/#4-8","title":"\u7814\u7a76\u8005\u8def\u5f84 (4-8\u5468)","text":"<ol> <li>\u5b8c\u6210\u8fdb\u9636\u7528\u6237\u8def\u5f84</li> <li>\u67b6\u6784\u6df1\u5165\u7406\u89e3</li> <li>\u6838\u5fc3\u7ec4\u4ef6\u6e90\u7801\u5206\u6790</li> <li>LLM\u8bad\u7ec3\u5b9e\u6218</li> <li>\u8d21\u732e\u4ee3\u7801</li> </ol>"},{"location":"tutorials/#_7","title":"\ud83d\udca1 \u6559\u7a0b\u7279\u8272","text":"<ul> <li>\ud83c\udfaf \u5b9e\u6218\u5bfc\u5411 - \u6bcf\u4e2a\u6559\u7a0b\u90fd\u5305\u542b\u5b8c\u6574\u7684\u53ef\u8fd0\u884c\u4ee3\u7801</li> <li>\ud83d\udcca \u6027\u80fd\u5bf9\u6bd4 - \u4e0e\u5176\u4ed6\u6846\u67b6\u7684\u6027\u80fd\u5bf9\u6bd4\u548c\u5206\u6790</li> <li>\ud83d\udd0d \u6e90\u7801\u89e3\u6790 - \u6df1\u5165\u7406\u89e3Genesis\u5185\u90e8\u5b9e\u73b0\u539f\u7406</li> <li>\u26a1 \u6700\u4f73\u5b9e\u8df5 - \u603b\u7ed3\u5b9e\u9645\u9879\u76ee\u4e2d\u7684\u7ecf\u9a8c\u548c\u6280\u5de7</li> </ul>"},{"location":"tutorials/#_8","title":"\ud83e\udd1d \u8d21\u732e\u6559\u7a0b","text":"<p>\u6211\u4eec\u6b22\u8fce\u793e\u533a\u8d21\u732e\u66f4\u591a\u9ad8\u8d28\u91cf\u7684\u6559\u7a0b\uff01</p>"},{"location":"tutorials/#_9","title":"\u5982\u4f55\u8d21\u732e","text":"<ol> <li>Fork\u9879\u76ee\u5230\u4f60\u7684GitHub\u8d26\u6237</li> <li>\u5728<code>docs/tutorials/</code>\u76ee\u5f55\u4e0b\u521b\u5efa\u65b0\u7684Markdown\u6587\u4ef6</li> <li>\u6309\u7167\u73b0\u6709\u6559\u7a0b\u7684\u683c\u5f0f\u7f16\u5199\u5185\u5bb9</li> <li>\u63d0\u4ea4Pull Request</li> </ol>"},{"location":"tutorials/#_10","title":"\u6559\u7a0b\u6807\u51c6","text":"<ul> <li>\u6e05\u6670\u7684\u6807\u9898\u548c\u7ed3\u6784 - \u4f7f\u7528\u9002\u5f53\u7684\u6807\u9898\u5c42\u7ea7</li> <li>\u5b8c\u6574\u7684\u4ee3\u7801\u793a\u4f8b - \u786e\u4fdd\u4ee3\u7801\u53ef\u4ee5\u76f4\u63a5\u8fd0\u884c</li> <li>\u8be6\u7ec6\u7684\u89e3\u91ca - \u89e3\u91ca\u6bcf\u4e2a\u6b65\u9aa4\u7684\u539f\u7406\u548c\u76ee\u7684</li> <li>\u5b9e\u9645\u7684\u5e94\u7528\u573a\u666f - \u7ed3\u5408\u771f\u5b9e\u7684\u4f7f\u7528\u6848\u4f8b</li> </ul>"},{"location":"tutorials/#_11","title":"\ud83d\udcde \u83b7\u53d6\u5e2e\u52a9","text":"<p>\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u9047\u5230\u95ee\u9898\uff1f</p> <ul> <li>GitHub Issues - \u62a5\u544a\u95ee\u9898\u6216\u5efa\u8bae\u6539\u8fdb</li> <li>Discussions - \u4e0e\u793e\u533a\u8ba8\u8bba\u6280\u672f\u95ee\u9898</li> <li>API\u6587\u6863 - \u67e5\u770b\u8be6\u7ec6\u7684API\u53c2\u8003\u6587\u6863</li> </ul> <p>\u5b66\u4e60\u5efa\u8bae</p> <p>\u5efa\u8bae\u6309\u7167\u63a8\u8350\u7684\u5b66\u4e60\u8def\u5f84\u5faa\u5e8f\u6e10\u8fdb\uff0c\u6bcf\u5b8c\u6210\u4e00\u4e2a\u6559\u7a0b\u540e\u5b9e\u9645\u52a8\u624b\u7ec3\u4e60\uff0c\u52a0\u6df1\u7406\u89e3\u3002</p> <p>\u51c6\u5907\u5f00\u59cb\u5b66\u4e60\u4e86\u5417\uff1f</p> <p>\u5f00\u59cb\u57fa\u7840\u6559\u7a0b \u67e5\u770bAPI\u6587\u6863</p>"},{"location":"tutorials/amp-training/","title":"Automatic Mixed Precision Training","text":"<p>Learn how to use AMP (Automatic Mixed Precision) training in Genesis for better performance and memory efficiency.</p>"},{"location":"tutorials/amp-training/#overview","title":"Overview","text":"<p>Genesis supports mixed precision training with FP16 and BF16 data types to accelerate training and reduce memory usage.</p>"},{"location":"tutorials/amp-training/#basic-amp-training","title":"Basic AMP Training","text":"Python<pre><code>import genesis\nimport genesis.nn as nn\nfrom genesis.amp import GradScaler, autocast\n\nmodel = MyModel()\noptimizer = genesis.optim.Adam(model.parameters())\nscaler = GradScaler()\n\nfor batch in dataloader:\n    optimizer.zero_grad()\n\n    with autocast():\n        output = model(batch.data)\n        loss = criterion(output, batch.targets)\n\n    scaler.scale(loss).backward()\n    scaler.step(optimizer)\n    scaler.update()\n</code></pre>"},{"location":"tutorials/amp-training/#advanced-configuration","title":"Advanced Configuration","text":"<p>This tutorial is under construction. More detailed examples and best practices will be added.</p>"},{"location":"tutorials/amp-training/#see-also","title":"See Also","text":"<ul> <li>Mixed Precision Training - Detailed mixed precision guide</li> <li>Performance Tuning - General performance optimization</li> </ul>"},{"location":"tutorials/basic-training/","title":"\u57fa\u7840\u8bad\u7ec3\u6559\u7a0b","text":"<p>\u672c\u6559\u7a0b\u5c06\u5e26\u4f60\u4ece\u96f6\u5f00\u59cb\uff0c\u4f7f\u7528Genesis\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u6784\u5efa\u548c\u8bad\u7ec3\u4f60\u7684\u7b2c\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u3002\u6211\u4eec\u5c06\u901a\u8fc7\u4e00\u4e2a\u5b8c\u6574\u7684\u56fe\u50cf\u5206\u7c7b\u9879\u76ee\u6765\u5b66\u4e60Genesis\u7684\u6838\u5fc3\u6982\u5ff5\u548c\u7528\u6cd5\u3002</p>"},{"location":"tutorials/basic-training/#_2","title":"\ud83c\udfaf \u5b66\u4e60\u76ee\u6807","text":"<p>\u901a\u8fc7\u672c\u6559\u7a0b\uff0c\u4f60\u5c06\u5b66\u4f1a\uff1a - Genesis\u7684\u57fa\u672cAPI\u548c\u6570\u636e\u7ed3\u6784 - \u5982\u4f55\u5b9a\u4e49\u548c\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u6a21\u578b - \u6570\u636e\u52a0\u8f7d\u548c\u9884\u5904\u7406 - \u8bad\u7ec3\u5faa\u73af\u7684\u6784\u5efa\u548c\u4f18\u5316 - \u6a21\u578b\u8bc4\u4f30\u548c\u4fdd\u5b58</p>"},{"location":"tutorials/basic-training/#_3","title":"\ud83d\udee0\ufe0f \u73af\u5883\u51c6\u5907","text":""},{"location":"tutorials/basic-training/#_4","title":"\u5b89\u88c5\u4f9d\u8d56","text":"Bash<pre><code># \u786e\u4fdd\u5df2\u5b89\u88c5Genesis\npip install torch triton numpy matplotlib tqdm\ngit clone https://github.com/phonism/genesis.git\ncd genesis\npip install -e .\n</code></pre>"},{"location":"tutorials/basic-training/#_5","title":"\u9a8c\u8bc1\u5b89\u88c5","text":"Python<pre><code>import genesis\nimport genesis.nn as nn\nimport genesis.optim as optim\n\n# \u6d4b\u8bd5\u57fa\u672c\u529f\u80fd\nx = genesis.randn(2, 3)\nprint(f\"Genesis\u5f20\u91cf\u5df2\u521b\u5efa: {x.shape}\")\nprint(f\"Genesis\u6a21\u5757\u53ef\u7528: {dir(nn)}\")\n</code></pre>"},{"location":"tutorials/basic-training/#_6","title":"\ud83d\udcca \u9879\u76ee\uff1a\u624b\u5199\u6570\u5b57\u8bc6\u522b","text":"<p>\u6211\u4eec\u5c06\u6784\u5efa\u4e00\u4e2a\u624b\u5199\u6570\u5b57\u8bc6\u522b\u7cfb\u7edf\uff0c\u4f7f\u7528\u7b80\u5355\u7684\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\u548c\u5408\u6210\u6570\u636e\u6765\u6f14\u793aGenesis\u7684\u529f\u80fd\u3002</p>"},{"location":"tutorials/basic-training/#1","title":"1. \u6570\u636e\u51c6\u5907","text":"<p>\u7531\u4e8eGenesis\u8fd8\u6ca1\u6709\u5185\u7f6e\u7684\u6570\u636e\u52a0\u8f7d\u5de5\u5177\uff0c\u6211\u4eec\u5c06\u521b\u5efa\u6a21\u4effMNIST\u7ed3\u6784\u7684\u5408\u6210\u6570\u636e\uff1a</p> Python<pre><code>import genesis\nimport genesis.nn as nn\nimport genesis.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass SimpleDataset:\n    \"\"\"\u6f14\u793a\u7528\u7684\u7b80\u5355\u6570\u636e\u96c6\u7c7b\"\"\"\n\n    def __init__(self, num_samples=1000, input_dim=784, num_classes=10):\n        # \u751f\u6210\u7c7b\u4f3c\u5c55\u5e73MNIST\u7684\u5408\u6210\u6570\u636e\n        self.data = genesis.randn(num_samples, input_dim)\n\n        # \u57fa\u4e8e\u6570\u636e\u6a21\u5f0f\u521b\u5efa\u6807\u7b7e\uff08\u5408\u6210\uff09\n        labels = genesis.randn(num_samples, num_classes)\n        self.labels = genesis.functional.max(labels, axis=1, keepdims=False)\n\n        self.num_samples = num_samples\n\n    def __len__(self):\n        return self.num_samples\n\n    def get_batch(self, batch_size=32, start_idx=0):\n        \"\"\"\u83b7\u53d6\u4e00\u6279\u6570\u636e\"\"\"\n        end_idx = min(start_idx + batch_size, self.num_samples)\n        return (self.data[start_idx:end_idx], \n                self.labels[start_idx:end_idx])\n\n# \u521b\u5efa\u6570\u636e\u96c6\ntrain_dataset = SimpleDataset(num_samples=800, input_dim=784, num_classes=10)\ntest_dataset = SimpleDataset(num_samples=200, input_dim=784, num_classes=10)\n\nprint(f\"\u8bad\u7ec3\u96c6\u5927\u5c0f: {len(train_dataset)}\")\nprint(f\"\u6d4b\u8bd5\u96c6\u5927\u5c0f: {len(test_dataset)}\")\nprint(f\"\u8f93\u5165\u7ef4\u5ea6: 784 (28x28\u5c55\u5e73)\")\nprint(f\"\u7c7b\u522b\u6570\u91cf: 10\")\n</code></pre>"},{"location":"tutorials/basic-training/#2","title":"2. \u6a21\u578b\u5b9a\u4e49","text":"<p>\u6211\u4eec\u5c06\u4f7f\u7528Genesis\u6a21\u5757\u6784\u5efa\u4e00\u4e2a\u7b80\u5355\u4f46\u6709\u6548\u7684\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\uff1a</p> Python<pre><code>class MNISTNet(nn.Module):\n    \"\"\"\u6570\u5b57\u8bc6\u522b\u7684\u7b80\u5355\u5168\u8fde\u63a5\u7f51\u7edc\"\"\"\n\n    def __init__(self, input_dim=784, hidden_dim=128, num_classes=10):\n        super(MNISTNet, self).__init__()\n\n        # \u4f7f\u7528\u5b9e\u9645\u7684Genesis\u6a21\u5757\u5b9a\u4e49\u5c42\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n        self.fc3 = nn.Linear(hidden_dim, num_classes)\n\n        # \u6fc0\u6d3b\u51fd\u6570\u548c\u6b63\u5219\u5316\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, x):\n        # \u5982\u679c\u9700\u8981\uff0c\u5c55\u5e73\u8f93\u5165\n        if len(x.shape) &gt; 2:\n            x = x.view(x.shape[0], -1)\n\n        # \u7b2c\u4e00\u4e2a\u9690\u85cf\u5c42\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n\n        # \u7b2c\u4e8c\u4e2a\u9690\u85cf\u5c42\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n\n        # \u8f93\u51fa\u5c42\n        x = self.fc3(x)\n\n        return x\n\n# \u521b\u5efa\u6a21\u578b\u5b9e\u4f8b\nmodel = MNISTNet(input_dim=784, hidden_dim=128, num_classes=10)\n\nprint(\"\u6a21\u578b\u7ed3\u6784:\")\nprint(f\"\u5c421: {model.fc1}\")\nprint(f\"\u5c422: {model.fc2}\")\nprint(f\"\u5c423: {model.fc3}\")\nprint(f\"\u53c2\u6570\u603b\u6570: {sum(p.data.size for p in model.parameters())}\")\n</code></pre>"},{"location":"tutorials/basic-training/#3","title":"3. \u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668","text":"Python<pre><code># \u4f7f\u7528Genesis\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\ncriterion = nn.SoftmaxLoss()  # \u4f7f\u7528Genesis\u7684SoftmaxLoss\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nprint(f\"\u635f\u5931\u51fd\u6570: {criterion}\")\nprint(f\"\u4f18\u5316\u5668: {optimizer}\")\nprint(f\"\u5b66\u4e60\u7387: 0.001\")\n</code></pre>"},{"location":"tutorials/basic-training/#4","title":"4. \u8bad\u7ec3\u5faa\u73af","text":"Python<pre><code>def train_epoch(model, dataset, criterion, optimizer, batch_size=32):\n    \"\"\"\u8bad\u7ec3\u4e00\u4e2aepoch\"\"\"\n    model.train()  # \u8bbe\u7f6e\u4e3a\u8bad\u7ec3\u6a21\u5f0f\n\n    total_loss = 0.0\n    num_batches = len(dataset) // batch_size\n\n    for i in range(num_batches):\n        # \u83b7\u53d6\u6279\u6570\u636e\n        start_idx = i * batch_size\n        batch_data, batch_labels = dataset.get_batch(batch_size, start_idx)\n\n        # \u524d\u5411\u4f20\u64ad\n        outputs = model(batch_data)\n        loss = criterion(outputs, batch_labels)\n\n        # \u53cd\u5411\u4f20\u64ad\n        optimizer.zero_grad()\n        loss.backward()\n\n        # \u5e94\u7528\u68af\u5ea6\u88c1\u526a\uff08\u53ef\u9009\uff09\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n        # \u66f4\u65b0\u6743\u91cd\n        optimizer.step()\n\n        total_loss += loss.data.item() if hasattr(loss.data, 'item') else float(loss.data)\n\n    return total_loss / num_batches\n\ndef evaluate(model, dataset, criterion, batch_size=32):\n    \"\"\"\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\"\"\"\n    model.eval()  # \u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f\n\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    num_batches = len(dataset) // batch_size\n\n    for i in range(num_batches):\n        start_idx = i * batch_size\n        batch_data, batch_labels = dataset.get_batch(batch_size, start_idx)\n\n        # \u524d\u5411\u4f20\u64ad\uff08\u4e0d\u9700\u8981\u68af\u5ea6\uff09\n        outputs = model(batch_data)\n        loss = criterion(outputs, batch_labels)\n\n        # \u8ba1\u7b97\u51c6\u786e\u7387\n        predicted = genesis.functional.max(outputs, axis=1, keepdims=False)\n        total += batch_labels.shape[0]\n        correct += (predicted == batch_labels).sum().data\n\n        total_loss += loss.data.item() if hasattr(loss.data, 'item') else float(loss.data)\n\n    accuracy = correct / total\n    avg_loss = total_loss / num_batches\n\n    return avg_loss, accuracy\n\n# \u8bad\u7ec3\u914d\u7f6e\nnum_epochs = 10\nbatch_size = 32\n\nprint(\"\u5f00\u59cb\u8bad\u7ec3...\")\nprint(f\"\u8f6e\u6570: {num_epochs}\")\nprint(f\"\u6279\u91cf\u5927\u5c0f: {batch_size}\")\nprint(\"-\" * 50)\n\n# \u8bad\u7ec3\u5faa\u73af\ntrain_losses = []\ntest_losses = []\ntest_accuracies = []\n\nfor epoch in range(num_epochs):\n    # \u8bad\u7ec3\u4e00\u4e2aepoch\n    train_loss = train_epoch(model, train_dataset, criterion, optimizer, batch_size)\n\n    # \u5728\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\n    test_loss, test_accuracy = evaluate(model, test_dataset, criterion, batch_size)\n\n    # \u8bb0\u5f55\u6307\u6807\n    train_losses.append(train_loss)\n    test_losses.append(test_loss)\n    test_accuracies.append(test_accuracy)\n\n    # \u6253\u5370\u8fdb\u5ea6\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"  \u8bad\u7ec3\u635f\u5931: {train_loss:.4f}\")\n    print(f\"  \u6d4b\u8bd5\u635f\u5931: {test_loss:.4f}\")\n    print(f\"  \u6d4b\u8bd5\u51c6\u786e\u7387: {test_accuracy:.4f}\")\n    print(\"-\" * 30)\n\nprint(\"\u8bad\u7ec3\u5b8c\u6210\uff01\")\n</code></pre>"},{"location":"tutorials/basic-training/#5","title":"5. \u6a21\u578b\u8bc4\u4f30\u548c\u53ef\u89c6\u5316","text":"Python<pre><code># \u7ed8\u5236\u8bad\u7ec3\u8fdb\u5ea6\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 4))\n\n# \u7ed8\u5236\u635f\u5931\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='\u8bad\u7ec3\u635f\u5931')\nplt.plot(test_losses, label='\u6d4b\u8bd5\u635f\u5931')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('\u8bad\u7ec3\u548c\u6d4b\u8bd5\u635f\u5931')\nplt.legend()\nplt.grid(True)\n\n# \u7ed8\u5236\u51c6\u786e\u7387\nplt.subplot(1, 2, 2)\nplt.plot(test_accuracies, label='\u6d4b\u8bd5\u51c6\u786e\u7387')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('\u6d4b\u8bd5\u51c6\u786e\u7387')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n# \u6700\u7ec8\u8bc4\u4f30\nfinal_test_loss, final_test_accuracy = evaluate(model, test_dataset, criterion, batch_size)\nprint(f\"\\n\u6700\u7ec8\u7ed3\u679c:\")\nprint(f\"\u6d4b\u8bd5\u635f\u5931: {final_test_loss:.4f}\")\nprint(f\"\u6d4b\u8bd5\u51c6\u786e\u7387: {final_test_accuracy:.4f}\")\n</code></pre>"},{"location":"tutorials/basic-training/#6","title":"6. \u6a21\u578b\u4fdd\u5b58\u548c\u52a0\u8f7d","text":"Python<pre><code># \u4f7f\u7528Genesis\u5e8f\u5217\u5316\u4fdd\u5b58\u6a21\u578b\nmodel_path = \"mnist_model.pkl\"\ngenesis.save(model.state_dict(), model_path)\nprint(f\"\u6a21\u578b\u5df2\u4fdd\u5b58\u5230 {model_path}\")\n\n# \u52a0\u8f7d\u6a21\u578b\nmodel_new = MNISTNet(input_dim=784, hidden_dim=128, num_classes=10)\nmodel_new.load_state_dict(genesis.load(model_path))\nprint(\"\u6a21\u578b\u52a0\u8f7d\u6210\u529f\uff01\")\n\n# \u9a8c\u8bc1\u52a0\u8f7d\u7684\u6a21\u578b\u662f\u5426\u5de5\u4f5c\ntest_loss, test_accuracy = evaluate(model_new, test_dataset, criterion, batch_size)\nprint(f\"\u52a0\u8f7d\u6a21\u578b\u7684\u51c6\u786e\u7387: {test_accuracy:.4f}\")\n</code></pre>"},{"location":"tutorials/basic-training/#_7","title":"\ud83c\udf93 \u5b66\u5230\u7684\u5173\u952e\u6982\u5ff5","text":""},{"location":"tutorials/basic-training/#1-genesis","title":"1. Genesis\u5f20\u91cf\u64cd\u4f5c","text":"<ul> <li>\u4f7f\u7528<code>genesis.randn()</code>, <code>genesis.tensor()</code>\u521b\u5efa\u5f20\u91cf</li> <li>\u57fa\u672c\u64cd\u4f5c\u5982\u77e9\u9635\u4e58\u6cd5\u548c\u9010\u5143\u7d20\u64cd\u4f5c</li> <li>\u4f7f\u7528<code>requires_grad</code>\u8fdb\u884c\u81ea\u52a8\u5fae\u5206</li> </ul>"},{"location":"tutorials/basic-training/#2_1","title":"2. \u795e\u7ecf\u7f51\u7edc\u6a21\u5757","text":"<ul> <li>\u901a\u8fc7\u7ee7\u627f<code>nn.Module</code>\u5b9a\u4e49\u6a21\u578b</li> <li>\u4f7f\u7528\u5185\u7f6e\u5c42\uff1a<code>nn.Linear</code>, <code>nn.ReLU</code>, <code>nn.Dropout</code></li> <li>\u7406\u89e3\u524d\u5411\u4f20\u64ad\u5b9e\u73b0</li> </ul>"},{"location":"tutorials/basic-training/#3_1","title":"3. \u8bad\u7ec3\u8fc7\u7a0b","text":"<ul> <li>\u8bbe\u7f6e\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668</li> <li>\u5b9e\u73b0\u8bad\u7ec3\u548c\u8bc4\u4f30\u5faa\u73af</li> <li>\u4f7f\u7528\u68af\u5ea6\u88c1\u526a\u548c\u6b63\u5219\u5316</li> </ul>"},{"location":"tutorials/basic-training/#4_1","title":"4. \u6a21\u578b\u7ba1\u7406","text":"<ul> <li>\u4f7f\u7528Genesis\u5e8f\u5217\u5316\u4fdd\u5b58\u548c\u52a0\u8f7d\u6a21\u578b\u72b6\u6001</li> <li>\u7ba1\u7406\u6a21\u578b\u53c2\u6570\u548c\u4f18\u5316\u72b6\u6001</li> </ul>"},{"location":"tutorials/basic-training/#_8","title":"\ud83d\ude80 \u4e0b\u4e00\u6b65","text":"<p>\u5b8c\u6210\u672c\u6559\u7a0b\u540e\uff0c\u4f60\u53ef\u4ee5\uff1a</p> <ol> <li>\u63a2\u7d22\u66f4\u590d\u6742\u7684\u6a21\u578b - \u5c1d\u8bd5\u5177\u6709\u66f4\u591a\u5c42\u7684\u4e0d\u540c\u67b6\u6784</li> <li>\u5b66\u4e60\u9ad8\u7ea7\u7279\u6027 - \u63a2\u7d22\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u548c\u5b66\u4e60\u7387\u8c03\u5ea6</li> <li>\u5904\u7406\u771f\u5b9e\u6570\u636e - \u5f53\u6570\u636e\u52a0\u8f7d\u5de5\u5177\u53ef\u7528\u65f6\u4e0e\u5b9e\u9645\u6570\u636e\u96c6\u96c6\u6210</li> <li>\u6027\u80fd\u4f18\u5316 - \u4e86\u89e3GPU\u52a0\u901f\u548cTriton\u5185\u6838\u4f7f\u7528</li> </ol>"},{"location":"tutorials/basic-training/#_9","title":"\ud83d\udcda \u5176\u4ed6\u8d44\u6e90","text":"<ul> <li>Genesis API\u53c2\u8003 - \u5b8c\u6574\u7684API\u6587\u6863</li> <li>\u9ad8\u7ea7\u8bad\u7ec3\u7279\u6027 - \u6df7\u5408\u7cbe\u5ea6\u3001\u8c03\u5ea6\u5668\u7b49</li> <li>\u6027\u80fd\u4f18\u5316 - \u66f4\u5feb\u8bad\u7ec3\u7684\u6280\u5de7</li> </ul>"},{"location":"tutorials/basic-training/#_10","title":"\ud83d\udc1b \u6545\u969c\u6392\u9664","text":""},{"location":"tutorials/basic-training/#_11","title":"\u5e38\u89c1\u95ee\u9898","text":"<ol> <li>\u5bfc\u5165\u9519\u8bef\uff1a\u786e\u4fdd\u4f7f\u7528<code>pip install -e .</code>\u6b63\u786e\u5b89\u88c5Genesis</li> <li>\u5f62\u72b6\u4e0d\u5339\u914d\uff1a\u68c0\u67e5\u524d\u5411\u4f20\u64ad\u4e2d\u7684\u5f20\u91cf\u7ef4\u5ea6</li> <li>\u5185\u5b58\u95ee\u9898\uff1a\u5982\u679c\u9047\u5230\u5185\u5b58\u4e0d\u8db3\u9519\u8bef\uff0c\u51cf\u5c11\u6279\u91cf\u5927\u5c0f</li> <li>\u8bad\u7ec3\u7f13\u6162\uff1a\u5728\u53ef\u7528\u65f6\u542f\u7528GPU\u652f\u6301</li> </ol>"},{"location":"tutorials/basic-training/#_12","title":"\u83b7\u53d6\u5e2e\u52a9","text":"<ul> <li>\u67e5\u770bGenesis\u6587\u6863</li> <li>\u5728GitHub Issues\u62a5\u544a\u95ee\u9898</li> <li>\u5728\u793e\u533a\u8bba\u575b\u52a0\u5165\u8ba8\u8bba</li> </ul>"},{"location":"tutorials/custom-ops/","title":"\u81ea\u5b9a\u4e49\u7b97\u5b50\u5f00\u53d1","text":"<p>\u5f00\u53d1\u4e2d</p> <p>\u6b64\u6587\u6863\u6b63\u5728\u7f16\u5199\u4e2d\uff0c\u5185\u5bb9\u5c06\u6301\u7eed\u66f4\u65b0\u3002</p> <p>Genesis\u6846\u67b6\u652f\u6301\u81ea\u5b9a\u4e49\u7b97\u5b50\u5f00\u53d1\uff0c\u8ba9\u4f60\u53ef\u4ee5\u5b9e\u73b0\u4e13\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u64cd\u4f5c\u3002\u672c\u6559\u7a0b\u5c06\u6559\u4f60\u5982\u4f55\u4ece\u96f6\u5f00\u59cb\u521b\u5efa\u9ad8\u6027\u80fd\u7684\u81ea\u5b9a\u4e49\u7b97\u5b50\u3002</p>"},{"location":"tutorials/custom-ops/#_2","title":"\ud83c\udfaf \u5b66\u4e60\u76ee\u6807","text":"<ul> <li>\u7406\u89e3Genesis\u7684\u7b97\u5b50\u7cfb\u7edf\u67b6\u6784</li> <li>\u5b66\u4f1a\u5b9e\u73b0CPU\u548cGPU\u7248\u672c\u7684\u81ea\u5b9a\u4e49\u7b97\u5b50</li> <li>\u638c\u63e1Triton kernel\u7f16\u7a0b\u6280\u5de7</li> <li>\u4e86\u89e3\u7b97\u5b50\u4f18\u5316\u548c\u6027\u80fd\u8c03\u8bd5\u65b9\u6cd5</li> </ul>"},{"location":"tutorials/custom-ops/#_3","title":"\ud83d\udccb \u9884\u5907\u77e5\u8bc6","text":"<p>\u5728\u5f00\u59cb\u4e4b\u524d\uff0c\u8bf7\u786e\u4fdd\u4f60\u5df2\u7ecf\uff1a - \u5b8c\u6210\u57fa\u7840\u8bad\u7ec3\u6559\u7a0b - \u4e86\u89e3CUDA\u7f16\u7a0b\u57fa\u7840 - \u719f\u6089Python C\u6269\u5c55\u5f00\u53d1</p>"},{"location":"tutorials/custom-ops/#_4","title":"\ud83d\udee0\ufe0f \u5f00\u53d1\u73af\u5883","text":"Bash<pre><code># \u5b89\u88c5\u5f00\u53d1\u4f9d\u8d56\npip install triton pybind11 cmake ninja\n</code></pre>"},{"location":"tutorials/custom-ops/#rmsnorm","title":"\ud83d\udcdd \u793a\u4f8b\uff1aRMSNorm\u7b97\u5b50","text":"<p>\u6211\u4eec\u5c06\u5b9e\u73b0RMSNorm\uff08Root Mean Square Normalization\uff09\u4f5c\u4e3a\u793a\u4f8b\u3002</p>"},{"location":"tutorials/custom-ops/#cpu","title":"CPU\u5b9e\u73b0","text":"Python<pre><code># WIP: CPU\u5b9e\u73b0\u4ee3\u7801\u5c06\u5728\u540e\u7eed\u7248\u672c\u4e2d\u6dfb\u52a0\n</code></pre>"},{"location":"tutorials/custom-ops/#gpu-triton","title":"GPU\u5b9e\u73b0 (Triton)","text":"Python<pre><code># WIP: Triton\u5b9e\u73b0\u4ee3\u7801\u5c06\u5728\u540e\u7eed\u7248\u672c\u4e2d\u6dfb\u52a0\n</code></pre>"},{"location":"tutorials/custom-ops/#_5","title":"\ud83d\ude80 \u9ad8\u7ea7\u7279\u6027","text":"<ul> <li>\u81ea\u52a8\u5fae\u5206\u652f\u6301</li> <li>\u5185\u5b58\u4f18\u5316\u6280\u5de7</li> <li>\u7b97\u5b50\u878d\u5408\u7b56\u7565</li> </ul> <p>\ud83d\udcd8 \u6587\u6863\u72b6\u6001: \u6b63\u5728\u7f16\u5199\u4e2d\uff0c\u9884\u8ba1\u5728v0.2.0\u7248\u672c\u5b8c\u6210\u3002</p>"},{"location":"tutorials/data-loading/","title":"Data Loading in Genesis","text":"<p>Learn how to efficiently load and preprocess data for training with Genesis.</p>"},{"location":"tutorials/data-loading/#overview","title":"Overview","text":"<p>Genesis provides flexible data loading utilities compatible with various data sources and formats.</p>"},{"location":"tutorials/data-loading/#basic-data-loading","title":"Basic Data Loading","text":"Python<pre><code>import genesis\nfrom genesis.data import DataLoader\n\n# Create a simple dataset\ndataset = MyDataset()  # Your custom dataset\nloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\nfor batch in loader:\n    data, targets = batch\n    # Process batch...\n</code></pre>"},{"location":"tutorials/data-loading/#custom-datasets","title":"Custom Datasets","text":"<p>This tutorial is under construction. More examples and detailed documentation will be added soon.</p>"},{"location":"tutorials/data-loading/#see-also","title":"See Also","text":"<ul> <li>Basic Training - Training loops with data loaders</li> <li>Performance Tuning - Optimizing data loading performance</li> </ul>"},{"location":"tutorials/distributed-training/","title":"Genesis \u5206\u5e03\u5f0f\u8bad\u7ec3","text":"<p>\u5b66\u4e60\u5982\u4f55\u4f7f\u7528 Genesis \u8fdb\u884c\u591aGPU\u548c\u591a\u8282\u70b9\u5206\u5e03\u5f0f\u8bad\u7ec3\u3002</p>"},{"location":"tutorials/distributed-training/#_1","title":"\u6982\u8ff0","text":"<p>Genesis \u63d0\u4f9b\u5b8c\u6574\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u652f\u6301\uff0c\u5305\u62ec\uff1a</p> <ul> <li>NCCL\u540e\u7aef - \u9ad8\u6027\u80fdGPU\u95f4\u901a\u4fe1</li> <li>DistributedDataParallel (DDP) - \u6570\u636e\u5e76\u884c\u8bad\u7ec3\u5305\u88c5\u5668</li> <li>\u96c6\u4f53\u901a\u4fe1\u64cd\u4f5c - all_reduce, broadcast, all_gather\u7b49</li> <li>\u5355\u8fdb\u7a0b\u6d4b\u8bd5 - \u65b9\u4fbf\u5f00\u53d1\u548c\u8c03\u8bd5</li> </ul>"},{"location":"tutorials/distributed-training/#_2","title":"\u5feb\u901f\u5f00\u59cb","text":""},{"location":"tutorials/distributed-training/#1","title":"1. \u57fa\u672c\u5206\u5e03\u5f0f\u8bad\u7ec3\u8bbe\u7f6e","text":"Python<pre><code>import genesis\nimport genesis.distributed as dist\nimport genesis.nn as nn\n\n# \u521d\u59cb\u5316\u5206\u5e03\u5f0f\u8fdb\u7a0b\u7ec4\ndist.init_process_group(backend='nccl', world_size=2, rank=0)  # rank\u6839\u636e\u8fdb\u7a0b\u8c03\u6574\n\n# \u521b\u5efa\u6a21\u578b\nclass MyModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(512, 256)\n        self.relu = nn.ReLU()\n        self.output = nn.Linear(256, 10)\n\n    def forward(self, x):\n        x = self.relu(self.linear(x))\n        return self.output(x)\n\nmodel = MyModel()\n\n# \u5305\u88c5\u4e3a\u5206\u5e03\u5f0f\u6570\u636e\u5e76\u884c\u6a21\u578b\ndevice = genesis.device('cuda')\nddp_model = dist.DistributedDataParallel(model, device_ids=[device.index])\n</code></pre>"},{"location":"tutorials/distributed-training/#2","title":"2. \u5206\u5e03\u5f0f\u8bad\u7ec3\u5faa\u73af","text":"Python<pre><code># \u4f18\u5316\u5668\u548c\u635f\u5931\u51fd\u6570\noptimizer = genesis.optim.Adam(ddp_model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\n# \u8bad\u7ec3\u5faa\u73af\nddp_model.train()\nfor epoch in range(num_epochs):\n    for batch_idx, (data, targets) in enumerate(dataloader):\n        # \u6570\u636e\u79fb\u52a8\u5230GPU\n        data = data.to(device)\n        targets = targets.to(device)\n\n        # \u524d\u5411\u4f20\u64ad\n        outputs = ddp_model(data)\n        loss = criterion(outputs, targets)\n\n        # \u53cd\u5411\u4f20\u64ad\uff08\u68af\u5ea6\u4f1a\u81ea\u52a8\u540c\u6b65\uff09\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch_idx % 100 == 0:\n            print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}')\n</code></pre>"},{"location":"tutorials/distributed-training/#3","title":"3. \u8fdb\u7a0b\u7ec4\u7ba1\u7406","text":"Python<pre><code># \u68c0\u67e5\u5206\u5e03\u5f0f\u72b6\u6001\nif dist.is_initialized():\n    print(f\"\u8fdb\u7a0b\u7ec4\u5df2\u521d\u59cb\u5316\")\n    print(f\"\u4e16\u754c\u5927\u5c0f: {dist.get_world_size()}\")\n    print(f\"\u5f53\u524drank: {dist.get_rank()}\")\n\n# \u540c\u6b65\u6240\u6709\u8fdb\u7a0b\ndist.barrier()\n\n# \u6e05\u7406\ndist.destroy_process_group()\n</code></pre>"},{"location":"tutorials/distributed-training/#_3","title":"\u9ad8\u7ea7\u529f\u80fd","text":""},{"location":"tutorials/distributed-training/#_4","title":"\u96c6\u4f53\u901a\u4fe1\u64cd\u4f5c","text":"Python<pre><code>import genesis\n\n# \u521b\u5efa\u6d4b\u8bd5\u5f20\u91cf\ndevice = genesis.device('cuda')\ntensor = genesis.ones([4], dtype=genesis.float32, device=device)\n\n# all_reduce - \u6240\u6709\u8fdb\u7a0b\u805a\u5408\ndist.all_reduce(tensor, dist.ReduceOp.SUM)  # \u6c42\u548c\ndist.all_reduce(tensor, dist.ReduceOp.MAX)  # \u6700\u5927\u503c\ndist.all_reduce(tensor, dist.ReduceOp.MIN)  # \u6700\u5c0f\u503c\n\n# broadcast - \u5e7f\u64ad\u64cd\u4f5c\nbroadcast_tensor = genesis.randn([8], device=device)\ndist.broadcast(broadcast_tensor, src=0)  # \u4ecerank 0\u5e7f\u64ad\n\n# all_gather - \u6536\u96c6\u6240\u6709\u6570\u636e\ninput_tensor = genesis.randn([4, 8], device=device)\noutput_list = [genesis.zeros_like(input_tensor) for _ in range(dist.get_world_size())]\ndist.all_gather(output_list, input_tensor)\n</code></pre>"},{"location":"tutorials/distributed-training/#_5","title":"\u5355\u8fdb\u7a0b\u6d4b\u8bd5\u6a21\u5f0f","text":"Python<pre><code># \u7528\u4e8e\u5f00\u53d1\u548c\u8c03\u8bd5\u7684\u5355\u8fdb\u7a0b\u6a21\u5f0f\ndef test_single_process():\n    # \u521d\u59cb\u5316\u5355\u8fdb\u7a0b\u5206\u5e03\u5f0f\u73af\u5883\n    dist.init_process_group(backend=\"nccl\", world_size=1, rank=0)\n\n    # \u521b\u5efa\u548c\u6d4b\u8bd5\u6a21\u578b\n    model = MyModel()\n    ddp_model = dist.DistributedDataParallel(model, device_ids=[0])\n\n    # \u6d4b\u8bd5\u524d\u5411\u4f20\u64ad\n    input_data = genesis.randn([8, 512], device='cuda')\n    output = ddp_model(input_data)\n\n    # \u6d4b\u8bd5\u53cd\u5411\u4f20\u64ad\n    loss = output.sum()\n    loss.backward()\n\n    print(\"\u5355\u8fdb\u7a0b\u5206\u5e03\u5f0f\u6d4b\u8bd5\u6210\u529f\uff01\")\n    dist.destroy_process_group()\n\n# \u8fd0\u884c\u6d4b\u8bd5\nif __name__ == \"__main__\":\n    test_single_process()\n</code></pre>"},{"location":"tutorials/distributed-training/#gpu","title":"\u591aGPU\u8bad\u7ec3\u811a\u672c","text":""},{"location":"tutorials/distributed-training/#launcherpy","title":"launcher.py","text":"Python<pre><code>#!/usr/bin/env python3\n\"\"\"\n\u591aGPU\u8bad\u7ec3\u542f\u52a8\u811a\u672c\n\u4f7f\u7528\u65b9\u6cd5: python launcher.py --gpus 2\n\"\"\"\n\nimport argparse\nimport subprocess\nimport sys\nimport os\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--gpus', type=int, default=1, help='GPU\u6570\u91cf')\n    parser.add_argument('--script', type=str, default='train.py', help='\u8bad\u7ec3\u811a\u672c')\n    args = parser.parse_args()\n\n    processes = []\n\n    try:\n        for rank in range(args.gpus):\n            env = os.environ.copy()\n            env['CUDA_VISIBLE_DEVICES'] = str(rank)\n            env['RANK'] = str(rank)\n            env['WORLD_SIZE'] = str(args.gpus)\n\n            cmd = [sys.executable, args.script]\n            proc = subprocess.Popen(cmd, env=env)\n            processes.append(proc)\n\n        # \u7b49\u5f85\u6240\u6709\u8fdb\u7a0b\u5b8c\u6210\n        for proc in processes:\n            proc.wait()\n\n    except KeyboardInterrupt:\n        print(\"\u505c\u6b62\u8bad\u7ec3...\")\n        for proc in processes:\n            proc.terminate()\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"tutorials/distributed-training/#trainpy","title":"train.py","text":"Python<pre><code>#!/usr/bin/env python3\n\"\"\"\n\u5206\u5e03\u5f0f\u8bad\u7ec3\u4e3b\u811a\u672c\n\"\"\"\n\nimport os\nimport genesis\nimport genesis.distributed as dist\nimport genesis.nn as nn\n\ndef main():\n    # \u4ece\u73af\u5883\u53d8\u91cf\u83b7\u53d6\u5206\u5e03\u5f0f\u53c2\u6570\n    rank = int(os.environ.get('RANK', 0))\n    world_size = int(os.environ.get('WORLD_SIZE', 1))\n\n    # \u521d\u59cb\u5316\u5206\u5e03\u5f0f\u8bad\u7ec3\n    dist.init_process_group(\n        backend='nccl',\n        world_size=world_size,\n        rank=rank\n    )\n\n    print(f\"\u8fdb\u7a0b {rank}/{world_size} \u542f\u52a8\")\n\n    try:\n        # \u521b\u5efa\u6a21\u578b\n        model = create_model()\n        ddp_model = dist.DistributedDataParallel(\n            model, \n            device_ids=[genesis.cuda.current_device()]\n        )\n\n        # \u521b\u5efa\u4f18\u5316\u5668\n        optimizer = genesis.optim.Adam(ddp_model.parameters(), lr=0.001)\n\n        # \u8bad\u7ec3\u5faa\u73af\n        train_loop(ddp_model, optimizer, rank)\n\n    finally:\n        # \u6e05\u7406\u5206\u5e03\u5f0f\u73af\u5883\n        dist.destroy_process_group()\n\ndef create_model():\n    \"\"\"\u521b\u5efa\u6a21\u578b\"\"\"\n    return nn.Sequential([\n        nn.Linear(784, 512),\n        nn.ReLU(),\n        nn.Linear(512, 256), \n        nn.ReLU(),\n        nn.Linear(256, 10)\n    ])\n\ndef train_loop(model, optimizer, rank):\n    \"\"\"\u8bad\u7ec3\u5faa\u73af\"\"\"\n    model.train()\n\n    for epoch in range(10):\n        # \u6a21\u62df\u8bad\u7ec3\u6570\u636e\n        data = genesis.randn([32, 784], device='cuda')\n        targets = genesis.randint(0, 10, [32], device='cuda')\n\n        # \u524d\u5411\u4f20\u64ad\n        outputs = model(data)\n        loss = nn.functional.cross_entropy(outputs, targets)\n\n        # \u53cd\u5411\u4f20\u64ad\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if rank == 0:  # \u53ea\u5728\u4e3b\u8fdb\u7a0b\u6253\u5370\n            print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"tutorials/distributed-training/#_6","title":"\u9519\u8bef\u5904\u7406\u548c\u8c03\u8bd5","text":""},{"location":"tutorials/distributed-training/#_7","title":"\u5e38\u89c1\u95ee\u9898","text":"<ol> <li> <p>NCCL\u4e0d\u53ef\u7528 Python<pre><code>try:\n    dist.init_process_group(backend=\"nccl\", world_size=1, rank=0)\nexcept RuntimeError as e:\n    if \"NCCL library not available\" in str(e):\n        print(\"NCCL\u5e93\u4e0d\u53ef\u7528\uff0c\u8bf7\u68c0\u67e5CUDA\u548cNCCL\u5b89\u88c5\")\n    else:\n        raise\n</code></pre></p> </li> <li> <p>\u8fdb\u7a0b\u7ec4\u672a\u521d\u59cb\u5316 Python<pre><code>if not dist.is_initialized():\n    print(\"\u9519\u8bef\uff1a\u5206\u5e03\u5f0f\u8fdb\u7a0b\u7ec4\u672a\u521d\u59cb\u5316\")\n    print(\"\u8bf7\u5148\u8c03\u7528 dist.init_process_group()\")\n</code></pre></p> </li> <li> <p>\u8bbe\u5907\u4e0d\u5339\u914d Python<pre><code># \u786e\u4fdd\u6a21\u578b\u548c\u6570\u636e\u5728\u76f8\u540c\u8bbe\u5907\u4e0a\ndevice = genesis.device(f'cuda:{genesis.cuda.current_device()}')\nmodel = model.to(device)\ndata = data.to(device)\n</code></pre></p> </li> </ol>"},{"location":"tutorials/distributed-training/#_8","title":"\u6027\u80fd\u4f18\u5316\u5efa\u8bae","text":""},{"location":"tutorials/distributed-training/#1_1","title":"1. \u68af\u5ea6\u7d2f\u79ef","text":"Python<pre><code>accumulation_steps = 4\n\nfor i, batch in enumerate(dataloader):\n    outputs = ddp_model(batch['input'])\n    loss = criterion(outputs, batch['target']) / accumulation_steps\n    loss.backward()\n\n    if (i + 1) % accumulation_steps == 0:\n        optimizer.step()\n        optimizer.zero_grad()\n</code></pre>"},{"location":"tutorials/distributed-training/#2_1","title":"2. \u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3","text":"Python<pre><code># \u7ed3\u5408\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6\u4f7f\u7528\u5206\u5e03\u5f0f\u8bad\u7ec3\nscaler = genesis.amp.GradScaler()\n\nwith genesis.amp.autocast():\n    outputs = ddp_model(data)\n    loss = criterion(outputs, targets)\n\nscaler.scale(loss).backward()\nscaler.step(optimizer)\nscaler.update()\n</code></pre>"},{"location":"tutorials/distributed-training/#3_1","title":"3. \u901a\u4fe1\u4f18\u5316","text":"Python<pre><code># \u521b\u5efaDDP\u65f6\u542f\u7528\u68af\u5ea6\u538b\u7f29\nddp_model = dist.DistributedDataParallel(\n    model,\n    device_ids=[device.index],\n    find_unused_parameters=False,  # \u63d0\u9ad8\u6027\u80fd\n    gradient_as_bucket_view=True   # \u51cf\u5c11\u5185\u5b58\u4f7f\u7528\n)\n</code></pre>"},{"location":"tutorials/distributed-training/#see-also","title":"See Also","text":"<ul> <li>Advanced Features - Advanced training techniques</li> <li>Performance Tuning - Optimizing distributed performance</li> </ul>"},{"location":"tutorials/llm-training/","title":"\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6307\u5357","text":"<p>\u672c\u5168\u9762\u6307\u5357\u6db5\u76d6\u4e86\u4f7f\u7528Genesis\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5168\u8fc7\u7a0b\uff0c\u4ece\u57fa\u7840\u8bbe\u7f6e\u5230\u9ad8\u7ea7\u4f18\u5316\u6280\u672f\u3002\u6211\u4eec\u5c06\u4ee5Qwen\u6a21\u578b\u4f5c\u4e3a\u4e3b\u8981\u793a\u4f8b\u3002</p>"},{"location":"tutorials/llm-training/#_2","title":"\u6982\u8ff0","text":"<p>Genesis\u4e3a\u8bad\u7ec3\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u6846\u67b6\uff0c\u5177\u6709\u4ee5\u4e0b\u7279\u6027\uff1a - Qwen\u6a21\u578b\u67b6\u6784\u5b9e\u73b0 - \u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\uff08FP16/BF16\uff09 - \u68af\u5ea6\u88c1\u526a\u548c\u5b66\u4e60\u7387\u8c03\u5ea6 - \u5206\u5e03\u5f0f\u8bad\u7ec3\u652f\u6301 - \u9ad8\u6548\u7684\u68c0\u67e5\u70b9\u7ba1\u7406</p>"},{"location":"tutorials/llm-training/#_3","title":"\u524d\u7f6e\u8981\u6c42","text":"<ul> <li>\u81f3\u5c1116GB\u663e\u5b58\u7684GPU\uff08\u63a8\u8350A100/A800\uff09</li> <li>CUDA 11.8+\u548c\u76f8\u5e94\u7684\u9a71\u52a8\u7a0b\u5e8f</li> <li>Python 3.8+\u5e76\u5df2\u5b89\u88c5Genesis</li> </ul>"},{"location":"tutorials/llm-training/#_4","title":"\u5feb\u901f\u5f00\u59cb","text":""},{"location":"tutorials/llm-training/#1-qwen","title":"1. \u57fa\u7840Qwen\u6a21\u578b\u8bbe\u7f6e","text":"Python<pre><code>import genesis\nimport genesis.nn as nn\nfrom genesis.models.qwen import QwenConfig, QwenModel\n\n# \u914d\u7f6e\u6a21\u578b\nconfig = QwenConfig(\n    vocab_size=32000,\n    hidden_size=2048,\n    num_attention_heads=16,\n    num_hidden_layers=24,\n    intermediate_size=5632,\n    max_position_embeddings=2048,\n    dtype=genesis.float16  # \u4f7f\u7528\u6df7\u5408\u7cbe\u5ea6\n)\n\n# \u521b\u5efa\u6a21\u578b\nmodel = QwenModel(config)\nprint(f\"\u6a21\u578b\u53c2\u6570\u91cf: {model.num_parameters() / 1e6:.1f}M\")\n</code></pre>"},{"location":"tutorials/llm-training/#2","title":"2. \u6570\u636e\u51c6\u5907","text":"Python<pre><code>import genesis\nfrom torch.utils.data import DataLoader\n\nclass TextDataset:\n    def __init__(self, texts, tokenizer, max_length=512):\n        self.texts = texts\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        # \u6807\u8bb0\u5316\u5e76\u586b\u5145/\u622a\u65ad\n        tokens = self.tokenizer.encode(text, max_length=self.max_length)\n\n        # \u8f6c\u6362\u4e3aGenesis\u5f20\u91cf\n        input_ids = genesis.tensor(tokens[:-1], dtype=genesis.int64)\n        labels = genesis.tensor(tokens[1:], dtype=genesis.int64)\n\n        return {\n            'input_ids': input_ids,\n            'labels': labels\n        }\n\n# \u52a0\u8f7d\u4f60\u7684\u6570\u636e\u96c6\ndataset = TextDataset(train_texts, tokenizer)\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n</code></pre>"},{"location":"tutorials/llm-training/#3","title":"3. \u8bad\u7ec3\u8bbe\u7f6e","text":"Python<pre><code>import genesis.optim as optim\nimport genesis.nn as nn\n\n# \u5c06\u6a21\u578b\u79fb\u52a8\u5230GPU\ndevice = genesis.cuda()\nmodel = model.to(device)\n\n# \u8bbe\u7f6e\u4f18\u5316\u5668\u548c\u6743\u91cd\u8870\u51cf\noptimizer = optim.AdamW(\n    model.parameters(),\n    lr=5e-4,\n    weight_decay=0.1,\n    beta1=0.9,\n    beta2=0.95,\n    eps=1e-8\n)\n\n# \u5e26\u9884\u70ed\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\ntotal_steps = len(dataloader) * num_epochs\nwarmup_steps = total_steps // 10\n\nscheduler = optim.get_cosine_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=warmup_steps,\n    num_training_steps=total_steps\n)\n\n# \u635f\u5931\u51fd\u6570\ncriterion = nn.CrossEntropyLoss()\n</code></pre>"},{"location":"tutorials/llm-training/#_5","title":"\u8bad\u7ec3\u5faa\u73af\u5b9e\u73b0","text":""},{"location":"tutorials/llm-training/#_6","title":"\u57fa\u7840\u8bad\u7ec3\u5faa\u73af","text":"Python<pre><code>def train_epoch(model, dataloader, optimizer, scheduler, criterion, device):\n    model.train()\n    total_loss = 0.0\n    num_batches = 0\n\n    for batch_idx, batch in enumerate(dataloader):\n        # \u5c06\u6279\u6b21\u79fb\u52a8\u5230\u8bbe\u5907\n        input_ids = batch['input_ids'].to(device)\n        labels = batch['labels'].to(device)\n\n        # \u524d\u5411\u4f20\u64ad\n        outputs = model(input_ids)\n        logits = outputs.logits\n\n        # \u8ba1\u7b97\u635f\u5931\n        shift_logits = logits[..., :-1, :].contiguous()\n        shift_labels = labels[..., 1:].contiguous()\n        loss = criterion(\n            shift_logits.view(-1, shift_logits.size(-1)),\n            shift_labels.view(-1)\n        )\n\n        # \u53cd\u5411\u4f20\u64ad\n        optimizer.zero_grad()\n        loss.backward()\n\n        # \u68af\u5ea6\u88c1\u526a\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n        # \u4f18\u5316\u5668\u6b65\u9aa4\n        optimizer.step()\n        scheduler.step()\n\n        # \u7d2f\u79ef\u635f\u5931\n        total_loss += loss.item()\n        num_batches += 1\n\n        # \u65e5\u5fd7\u8bb0\u5f55\n        if batch_idx % 100 == 0:\n            current_lr = scheduler.get_last_lr()\n            print(f'\u6279\u6b21 {batch_idx}: loss={loss.item():.4f}, lr={current_lr:.2e}')\n\n    return total_loss / num_batches\n\n# \u8bad\u7ec3\u5faa\u73af\nfor epoch in range(num_epochs):\n    avg_loss = train_epoch(model, dataloader, optimizer, scheduler, criterion, device)\n    print(f'\u8f6e\u6b21 {epoch}: \u5e73\u5747\u635f\u5931 = {avg_loss:.4f}')\n\n    # \u4fdd\u5b58\u68c0\u67e5\u70b9\n    if epoch % 10 == 0:\n        genesis.save_checkpoint(\n            model.state_dict(),\n            optimizer.state_dict(),\n            f'qwen_checkpoint_epoch_{epoch}.pth'\n        )\n</code></pre>"},{"location":"tutorials/llm-training/#_7","title":"\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3","text":"Python<pre><code>import genesis\n\ndef train_epoch_mixed_precision(model, dataloader, optimizer, scheduler, criterion, device):\n    model.train()\n    total_loss = 0.0\n\n    # \u542f\u7528\u6df7\u5408\u7cbe\u5ea6\n    genesis.enable_autocast = True\n\n    for batch_idx, batch in enumerate(dataloader):\n        input_ids = batch['input_ids'].to(device)\n        labels = batch['labels'].to(device)\n\n        # \u4f7f\u7528autocast\u8fdb\u884c\u524d\u5411\u4f20\u64ad\n        with genesis.autocast():\n            outputs = model(input_ids)\n            logits = outputs.logits\n\n            # \u8ba1\u7b97\u635f\u5931\n            shift_logits = logits[..., :-1, :].contiguous()\n            shift_labels = labels[..., 1:].contiguous()\n            loss = criterion(\n                shift_logits.view(-1, shift_logits.size(-1)),\n                shift_labels.view(-1)\n            )\n\n        # \u53cd\u5411\u4f20\u64ad\n        optimizer.zero_grad()\n        loss.backward()\n\n        # \u68af\u5ea6\u88c1\u526a\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n        # \u4f18\u5316\u5668\u6b65\u9aa4\n        optimizer.step()\n        scheduler.step()\n\n        total_loss += loss.item()\n\n        if batch_idx % 100 == 0:\n            print(f'\u6279\u6b21 {batch_idx}: loss={loss.item():.4f}')\n\n    return total_loss / len(dataloader)\n</code></pre>"},{"location":"tutorials/llm-training/#_8","title":"\u9ad8\u7ea7\u8bad\u7ec3\u6280\u672f","text":""},{"location":"tutorials/llm-training/#1","title":"1. \u68af\u5ea6\u7d2f\u79ef","text":"Python<pre><code>def train_with_gradient_accumulation(model, dataloader, optimizer, scheduler, \n                                   criterion, device, accumulation_steps=4):\n    model.train()\n    total_loss = 0.0\n    optimizer.zero_grad()\n\n    for batch_idx, batch in enumerate(dataloader):\n        input_ids = batch['input_ids'].to(device)\n        labels = batch['labels'].to(device)\n\n        # \u524d\u5411\u4f20\u64ad\n        outputs = model(input_ids)\n        logits = outputs.logits\n\n        # \u8ba1\u7b97\u635f\u5931\u5e76\u6309\u7d2f\u79ef\u6b65\u6570\u7f29\u653e\n        shift_logits = logits[..., :-1, :].contiguous()\n        shift_labels = labels[..., 1:].contiguous()\n        loss = criterion(\n            shift_logits.view(-1, shift_logits.size(-1)),\n            shift_labels.view(-1)\n        ) / accumulation_steps\n\n        # \u53cd\u5411\u4f20\u64ad\n        loss.backward()\n\n        # \u6bcfaccumulation_steps\u66f4\u65b0\u4e00\u6b21\n        if (batch_idx + 1) % accumulation_steps == 0:\n            # \u68af\u5ea6\u88c1\u526a\n            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n            # \u4f18\u5316\u5668\u6b65\u9aa4\n            optimizer.step()\n            scheduler.step()\n            optimizer.zero_grad()\n\n        total_loss += loss.item() * accumulation_steps\n\n        if batch_idx % (100 * accumulation_steps) == 0:\n            print(f'\u6279\u6b21 {batch_idx}: loss={loss.item() * accumulation_steps:.4f}')\n\n    return total_loss / len(dataloader)\n</code></pre>"},{"location":"tutorials/llm-training/#2_1","title":"2. \u52a8\u6001\u635f\u5931\u7f29\u653e","text":"Python<pre><code>class DynamicLossScaler:\n    def __init__(self, init_scale=2**16, scale_factor=2.0, scale_window=1000):\n        self.scale = init_scale\n        self.scale_factor = scale_factor\n        self.scale_window = scale_window\n        self._growth_tracker = 0\n\n    def scale_loss(self, loss):\n        return loss * self.scale\n\n    def unscale_gradients(self, optimizer):\n        for param_group in optimizer.param_groups:\n            for param in param_group['params']:\n                if param.grad is not None:\n                    param.grad.data /= self.scale\n\n    def step(self, optimizer, has_overflow=False):\n        if has_overflow:\n            self.scale = max(self.scale / self.scale_factor, 1.0)\n            self._growth_tracker = 0\n        else:\n            self._growth_tracker += 1\n            if self._growth_tracker &gt;= self.scale_window:\n                self.scale *= self.scale_factor\n                self._growth_tracker = 0\n\n        return not has_overflow\n\n# \u5728\u8bad\u7ec3\u5faa\u73af\u4e2d\u4f7f\u7528\nscaler = DynamicLossScaler()\n\nfor batch in dataloader:\n    # \u524d\u5411\u4f20\u64ad\n    loss = compute_loss(model, batch)\n    scaled_loss = scaler.scale_loss(loss)\n\n    # \u53cd\u5411\u4f20\u64ad\n    optimizer.zero_grad()\n    scaled_loss.backward()\n\n    # \u68c0\u67e5\u6ea2\u51fa\n    has_overflow = check_gradient_overflow(model.parameters())\n\n    # \u53cd\u7f29\u653e\u548c\u6b65\u8fdb\n    scaler.unscale_gradients(optimizer)\n    should_step = scaler.step(optimizer, has_overflow)\n\n    if should_step:\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n</code></pre>"},{"location":"tutorials/llm-training/#3_1","title":"3. \u68c0\u67e5\u70b9\u4fdd\u5b58\u548c\u6062\u590d\u8bad\u7ec3","text":"Python<pre><code>class TrainingManager:\n    def __init__(self, model, optimizer, scheduler, save_dir='checkpoints'):\n        self.model = model\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.save_dir = save_dir\n        self.current_epoch = 0\n        self.best_loss = float('inf')\n\n    def save_checkpoint(self, epoch, loss, metrics=None):\n        checkpoint = {\n            'epoch': epoch,\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'scheduler_state_dict': self.scheduler.state_dict(),\n            'loss': loss,\n            'best_loss': self.best_loss,\n            'metrics': metrics or {}\n        }\n\n        # \u4fdd\u5b58\u5e38\u89c4\u68c0\u67e5\u70b9\n        checkpoint_path = f'{self.save_dir}/checkpoint_epoch_{epoch}.pth'\n        genesis.save(checkpoint, checkpoint_path)\n\n        # \u4fdd\u5b58\u6700\u4f73\u6a21\u578b\n        if loss &lt; self.best_loss:\n            self.best_loss = loss\n            best_path = f'{self.save_dir}/best_model.pth'\n            genesis.save(checkpoint, best_path)\n            print(f\"\u4fdd\u5b58\u65b0\u7684\u6700\u4f73\u6a21\u578b\uff0c\u635f\u5931: {loss:.4f}\")\n\n        # \u4fdd\u5b58\u6700\u65b0\u68c0\u67e5\u70b9\n        latest_path = f'{self.save_dir}/latest_checkpoint.pth'\n        genesis.save(checkpoint, latest_path)\n\n    def load_checkpoint(self, checkpoint_path):\n        checkpoint = genesis.load(checkpoint_path)\n\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n\n        self.current_epoch = checkpoint['epoch']\n        self.best_loss = checkpoint['best_loss']\n\n        print(f\"\u4ece\u8f6e\u6b21 {self.current_epoch} \u6062\u590d\uff0c\u6700\u4f73\u635f\u5931: {self.best_loss:.4f}\")\n        return checkpoint\n\n# \u4f7f\u7528\u65b9\u6cd5\ntraining_manager = TrainingManager(model, optimizer, scheduler)\n\n# \u5982\u679c\u5b58\u5728\u68c0\u67e5\u70b9\u5219\u6062\u590d\ntry:\n    training_manager.load_checkpoint('checkpoints/latest_checkpoint.pth')\nexcept FileNotFoundError:\n    print(\"\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\")\n\n# \u5e26\u68c0\u67e5\u70b9\u4fdd\u5b58\u7684\u8bad\u7ec3\u5faa\u73af\nfor epoch in range(training_manager.current_epoch, num_epochs):\n    avg_loss = train_epoch(model, dataloader, optimizer, scheduler, criterion, device)\n\n    # \u4fdd\u5b58\u68c0\u67e5\u70b9\n    training_manager.save_checkpoint(epoch, avg_loss)\n\n    print(f'\u8f6e\u6b21 {epoch}: \u5e73\u5747\u635f\u5931 = {avg_loss:.4f}')\n</code></pre>"},{"location":"tutorials/llm-training/#_9","title":"\u6a21\u578b\u8bc4\u4f30\u548c\u63a8\u7406","text":""},{"location":"tutorials/llm-training/#1_1","title":"1. \u6a21\u578b\u8bc4\u4f30","text":"Python<pre><code>def evaluate_model(model, eval_dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    total_tokens = 0\n\n    with genesis.no_grad():\n        for batch in eval_dataloader:\n            input_ids = batch['input_ids'].to(device)\n            labels = batch['labels'].to(device)\n\n            # \u524d\u5411\u4f20\u64ad\n            outputs = model(input_ids)\n            logits = outputs.logits\n\n            # \u8ba1\u7b97\u635f\u5931\n            shift_logits = logits[..., :-1, :].contiguous()\n            shift_labels = labels[..., 1:].contiguous()\n            loss = criterion(\n                shift_logits.view(-1, shift_logits.size(-1)),\n                shift_labels.view(-1)\n            )\n\n            total_loss += loss.item() * shift_labels.numel()\n            total_tokens += shift_labels.numel()\n\n    avg_loss = total_loss / total_tokens\n    perplexity = genesis.exp(avg_loss)\n\n    return {\n        'loss': avg_loss,\n        'perplexity': perplexity.item()\n    }\n\n# \u8bc4\u4f30\u6a21\u578b\neval_metrics = evaluate_model(model, eval_dataloader, criterion, device)\nprint(f\"\u8bc4\u4f30\u635f\u5931: {eval_metrics['loss']:.4f}, \u56f0\u60d1\u5ea6: {eval_metrics['perplexity']:.2f}\")\n</code></pre>"},{"location":"tutorials/llm-training/#2_2","title":"2. \u6587\u672c\u751f\u6210","text":"Python<pre><code>def generate_text(model, tokenizer, prompt, max_length=100, temperature=0.8, top_p=0.9):\n    model.eval()\n    device = next(model.parameters()).device\n\n    # \u6807\u8bb0\u5316\u63d0\u793a\u8bcd\n    input_ids = tokenizer.encode(prompt)\n    input_tensor = genesis.tensor([input_ids], dtype=genesis.int64).to(device)\n\n    generated_ids = input_ids.copy()\n\n    with genesis.no_grad():\n        for _ in range(max_length):\n            # \u524d\u5411\u4f20\u64ad\n            outputs = model(input_tensor)\n            logits = outputs.logits[0, -1, :]  # \u6700\u540e\u4e00\u4e2atoken\u7684logits\n\n            # \u5e94\u7528\u6e29\u5ea6\n            logits = logits / temperature\n\n            # \u5e94\u7528top-p\u8fc7\u6ee4\n            sorted_logits, sorted_indices = genesis.sort(logits, descending=True)\n            cumulative_probs = genesis.cumsum(genesis.softmax(sorted_logits, dim=-1), dim=-1)\n\n            # \u79fb\u9664\u7d2f\u79ef\u6982\u7387\u8d85\u8fc7\u9608\u503c\u7684tokens\n            sorted_indices_to_remove = cumulative_probs &gt; top_p\n            sorted_indices_to_remove[1:] = sorted_indices_to_remove[:-1].clone()\n            sorted_indices_to_remove[0] = False\n\n            indices_to_remove = sorted_indices_to_remove.scatter(0, sorted_indices, sorted_indices_to_remove)\n            logits[indices_to_remove] = float('-inf')\n\n            # \u4ece\u8fc7\u6ee4\u540e\u7684\u5206\u5e03\u4e2d\u91c7\u6837\n            probs = genesis.softmax(logits, dim=-1)\n            next_token = genesis.multinomial(probs, 1).item()\n\n            # \u6dfb\u52a0\u5230\u751f\u6210\u5e8f\u5217\n            generated_ids.append(next_token)\n\n            # \u66f4\u65b0\u8f93\u5165\u5f20\u91cf\n            input_tensor = genesis.tensor([generated_ids], dtype=genesis.int64).to(device)\n\n            # \u68c0\u67e5\u7ed3\u675ftoken\n            if next_token == tokenizer.eos_token_id:\n                break\n\n    # \u89e3\u7801\u751f\u6210\u7684\u6587\u672c\n    generated_text = tokenizer.decode(generated_ids)\n    return generated_text\n\n# \u751f\u6210\u6587\u672c\nprompt = \"\u4eba\u5de5\u667a\u80fd\u7684\u672a\u6765\u662f\"\ngenerated = generate_text(model, tokenizer, prompt, max_length=50)\nprint(f\"\u751f\u6210\u7ed3\u679c: {generated}\")\n</code></pre>"},{"location":"tutorials/llm-training/#_10","title":"\u751f\u4ea7\u90e8\u7f72","text":""},{"location":"tutorials/llm-training/#1_2","title":"1. \u63a8\u7406\u4f18\u5316","text":"Python<pre><code>def optimize_for_inference(model, save_path):\n    \"\"\"\u4e3a\u751f\u4ea7\u63a8\u7406\u4f18\u5316\u6a21\u578b\u3002\"\"\"\n    model.eval()\n\n    # \u521b\u5efa\u63a8\u7406\u4f18\u5316\u72b6\u6001\n    inference_state = {\n        'model_state_dict': model.state_dict(),\n        'model_config': model.config.__dict__,\n        'inference_optimized': True,\n        'genesis_version': genesis.__version__\n    }\n\n    genesis.save(inference_state, save_path)\n    print(f\"\u63a8\u7406\u4f18\u5316\u6a21\u578b\u5df2\u4fdd\u5b58\u5230 {save_path}\")\n\ndef load_for_inference(model_path, device=None):\n    \"\"\"\u52a0\u8f7d\u63a8\u7406\u4f18\u5316\u7684\u6a21\u578b\u3002\"\"\"\n    checkpoint = genesis.load(model_path)\n    config = QwenConfig(**checkpoint['model_config'])\n\n    # \u521b\u5efa\u6a21\u578b\n    model = QwenModel(config)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.eval()\n\n    if device:\n        model = model.to(device)\n\n    return model\n\n# \u4f18\u5316\u5e76\u4fdd\u5b58\noptimize_for_inference(model, 'qwen_inference.pth')\n\n# \u52a0\u8f7d\u7528\u4e8e\u63a8\u7406\ninference_model = load_for_inference('qwen_inference.pth', device=genesis.cuda())\n</code></pre>"},{"location":"tutorials/llm-training/#2_3","title":"2. \u63a8\u7406\u670d\u52a1\u5668\u8bbe\u7f6e","text":"Python<pre><code>class LLMInferenceServer:\n    def __init__(self, model_path, tokenizer, device=None):\n        self.tokenizer = tokenizer\n        self.device = device or genesis.cuda()\n        self.model = load_for_inference(model_path, self.device)\n\n    def generate(self, prompt, max_length=100, temperature=0.8, top_p=0.9):\n        \"\"\"\u4ece\u63d0\u793a\u8bcd\u751f\u6210\u6587\u672c\u3002\"\"\"\n        return generate_text(\n            self.model, self.tokenizer, prompt,\n            max_length=max_length, temperature=temperature, top_p=top_p\n        )\n\n    def batch_generate(self, prompts, max_length=100, temperature=0.8, top_p=0.9):\n        \"\"\"\u4e3a\u591a\u4e2a\u63d0\u793a\u8bcd\u751f\u6210\u6587\u672c\u3002\"\"\"\n        results = []\n        for prompt in prompts:\n            result = self.generate(prompt, max_length, temperature, top_p)\n            results.append(result)\n        return results\n\n# \u521b\u5efa\u63a8\u7406\u670d\u52a1\u5668\nserver = LLMInferenceServer('qwen_inference.pth', tokenizer)\n\n# \u751f\u6210\u54cd\u5e94\nresponses = server.batch_generate([\n    \"\u751f\u547d\u7684\u610f\u4e49\u662f\u4ec0\u4e48\uff1f\",\n    \"\u7528\u7b80\u5355\u7684\u8bed\u8a00\u89e3\u91ca\u91cf\u5b50\u8ba1\u7b97\u3002\",\n    \"\u5199\u4e00\u4e2a\u5173\u4e8eAI\u7684\u77ed\u6545\u4e8b\u3002\"\n])\n</code></pre>"},{"location":"tutorials/llm-training/#_11","title":"\u6027\u80fd\u4f18\u5316\u6280\u5de7","text":""},{"location":"tutorials/llm-training/#1_3","title":"1. \u5185\u5b58\u4f18\u5316","text":"<ul> <li>\u5bf9\u5927\u6a21\u578b\u4f7f\u7528\u68af\u5ea6\u68c0\u67e5\u70b9</li> <li>\u542f\u7528\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\uff08FP16/BF16\uff09</li> <li>\u4f7f\u7528\u68af\u5ea6\u7d2f\u79ef\u5b9e\u73b0\u5927\u7684\u6709\u6548\u6279\u91cf\u5927\u5c0f</li> <li>\u5b9a\u671f\u6e05\u7406GPU\u7f13\u5b58</li> </ul>"},{"location":"tutorials/llm-training/#2_4","title":"2. \u8bad\u7ec3\u901f\u5ea6","text":"<ul> <li>\u4e3a\u4f60\u7684GPU\u4f7f\u7528\u9002\u5f53\u7684\u6279\u91cf\u5927\u5c0f</li> <li>\u5982\u679c\u53ef\u7528\uff0c\u542f\u7528\u7f16\u8bd1\u6a21\u5f0f</li> <li>\u4f7f\u7528\u591a\u8fdb\u7a0b\u8fdb\u884c\u9ad8\u6548\u7684\u6570\u636e\u52a0\u8f7d</li> <li>\u5bf9\u8bad\u7ec3\u8fdb\u884c\u6027\u80fd\u5206\u6790\u4ee5\u8bc6\u522b\u74f6\u9888</li> </ul>"},{"location":"tutorials/llm-training/#3_2","title":"3. \u6a21\u578b\u8d28\u91cf","text":"<ul> <li>\u4f7f\u7528\u9002\u5f53\u7684\u5b66\u4e60\u7387\u8c03\u5ea6</li> <li>\u5e94\u7528\u68af\u5ea6\u88c1\u526a\u6765\u7a33\u5b9a\u8bad\u7ec3</li> <li>\u5bc6\u5207\u76d1\u63a7\u8bad\u7ec3\u6307\u6807</li> <li>\u4f7f\u7528\u9a8c\u8bc1\u96c6\u9632\u6b62\u8fc7\u62df\u5408</li> </ul> <p>\u672c\u6307\u5357\u4e3a\u4f7f\u7528Genesis\u8bad\u7ec3LLM\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u57fa\u7840\u3002\u8bf7\u6839\u636e\u4f60\u7684\u5177\u4f53\u6a21\u578b\u5927\u5c0f\u3001\u6570\u636e\u96c6\u548c\u8ba1\u7b97\u8d44\u6e90\u6765\u8c03\u6574\u8fd9\u4e9b\u6280\u672f\u3002</p>"},{"location":"tutorials/mixed-precision/","title":"\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u6307\u5357","text":"<p>\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u662f\u4e00\u79cd\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u540c\u65f6\u4f7f\u752816\u4f4d\uff08\u534a\u7cbe\u5ea6\uff09\u548c32\u4f4d\uff08\u5355\u7cbe\u5ea6\uff09\u6d6e\u70b9\u6570\u7684\u6280\u672f\uff0c\u7528\u4e8e\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u5e76\u52a0\u901f\u8bad\u7ec3\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u3002Genesis\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u652f\u6301\u548c\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6\uff08AMP\uff09\u529f\u80fd\u3002</p>"},{"location":"tutorials/mixed-precision/#_2","title":"\u6982\u8ff0","text":""},{"location":"tutorials/mixed-precision/#_3","title":"\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u7684\u4f18\u52bf","text":"<ul> <li>\u5185\u5b58\u6548\u7387\uff1a\u51cf\u5c11\u7ea650%\u7684\u5185\u5b58\u4f7f\u7528</li> <li>\u901f\u5ea6\u63d0\u5347\uff1a\u5728\u5e26\u6709Tensor Cores\u7684\u73b0\u4ee3GPU\u4e0a\u8bad\u7ec3\u66f4\u5feb</li> <li>\u6a21\u578b\u7cbe\u5ea6\uff1a\u901a\u8fc7\u81ea\u52a8\u635f\u5931\u7f29\u653e\u4fdd\u6301\u8bad\u7ec3\u7a33\u5b9a\u6027</li> <li>\u66f4\u5927\u6a21\u578b\uff1a\u5728\u540c\u6837\u786c\u4ef6\u4e0a\u8bad\u7ec3\u66f4\u5927\u7684\u6a21\u578b</li> </ul>"},{"location":"tutorials/mixed-precision/#_4","title":"\u652f\u6301\u7684\u7cbe\u5ea6\u7c7b\u578b","text":"<p>Genesis\u652f\u6301\u591a\u79cd\u7cbe\u5ea6\u683c\u5f0f\uff1a</p> <ul> <li>float32 (FP32)\uff1a\u6807\u51c6\u5355\u7cbe\u5ea6\uff08\u9ed8\u8ba4\uff09</li> <li>float16 (FP16)\uff1aIEEE\u534a\u7cbe\u5ea6</li> <li>bfloat16 (BF16)\uff1a\u5177\u6709\u66f4\u5927\u52a8\u6001\u8303\u56f4\u7684Brain Float\u683c\u5f0f</li> </ul>"},{"location":"tutorials/mixed-precision/#_5","title":"\u6570\u636e\u7c7b\u578b\u7cfb\u7edf","text":""},{"location":"tutorials/mixed-precision/#genesis","title":"\u7406\u89e3Genesis\u6570\u636e\u7c7b\u578b","text":"Python<pre><code>import genesis\n\n# \u53ef\u7528\u7684\u7cbe\u5ea6\u7c7b\u578b\nprint(\"\u53ef\u7528\u7684\u6570\u636e\u7c7b\u578b\uff1a\")\nprint(f\"FP32: {genesis.float32}\")  # \u6807\u51c6\u7cbe\u5ea6\nprint(f\"FP16: {genesis.float16}\")  # \u534a\u7cbe\u5ea6\nprint(f\"BF16: {genesis.bfloat16}\") # Brain Float\n\n# \u68c0\u67e5\u6570\u636e\u7c7b\u578b\u5c5e\u6027\ndtype = genesis.float16\nprint(f\"\u540d\u79f0: {dtype.name}\")\nprint(f\"\u5927\u5c0f: {dtype.itemsize} \u5b57\u8282\")\nprint(f\"\u662f\u5426\u6d6e\u70b9: {dtype.is_floating_point}\")\nprint(f\"NumPy\u7c7b\u578b: {dtype.numpy_dtype}\")\n</code></pre>"},{"location":"tutorials/mixed-precision/#_6","title":"\u521b\u5efa\u6df7\u5408\u7cbe\u5ea6\u5f20\u91cf","text":"Python<pre><code>import genesis\n\n# \u521b\u5efa\u4e0d\u540c\u7cbe\u5ea6\u7684\u5f20\u91cf\nfp32_tensor = genesis.randn(1000, 1000, dtype=genesis.float32)\nfp16_tensor = genesis.randn(1000, 1000, dtype=genesis.float16) \nbf16_tensor = genesis.randn(1000, 1000, dtype=genesis.bfloat16)\n\nprint(f\"FP32\u5185\u5b58: {fp32_tensor.numel() * 4} \u5b57\u8282\")\nprint(f\"FP16\u5185\u5b58: {fp16_tensor.numel() * 2} \u5b57\u8282\") \nprint(f\"BF16\u5185\u5b58: {bf16_tensor.numel() * 2} \u5b57\u8282\")\n\n# \u7c7b\u578b\u8f6c\u6362\nfp16_from_fp32 = fp32_tensor.half()    # \u8f6c\u6362\u4e3aFP16\nfp32_from_fp16 = fp16_tensor.float()   # \u8f6c\u6362\u4e3aFP32\n</code></pre>"},{"location":"tutorials/mixed-precision/#amp","title":"\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6\uff08AMP\uff09","text":""},{"location":"tutorials/mixed-precision/#amp_1","title":"\u57fa\u7840AMP\u4f7f\u7528","text":"<p>Genesis\u901a\u8fc7<code>autocast</code>\u4e0a\u4e0b\u6587\u548c\u542f\u7528\u6807\u5fd7\u63d0\u4f9b\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6\uff1a</p> Python<pre><code>import genesis\nimport genesis.nn as nn\n\n# \u5168\u5c40\u542f\u7528\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6\ngenesis.enable_autocast = True\n\n# \u521b\u5efa\u6a21\u578b\u548c\u6570\u636e\nmodel = nn.Linear(784, 10).cuda()\nx = genesis.randn(32, 784, device='cuda')\nlabels = genesis.randint(0, 10, (32,), device='cuda')\n\n# \u4f7f\u7528\u81ea\u52a8\u7c7b\u578b\u8f6c\u6362\u7684\u524d\u5411\u4f20\u64ad\noutputs = model(x)  # \u81ea\u52a8\u4f7f\u7528\u6df7\u5408\u7cbe\u5ea6\n\n# \u635f\u5931\u8ba1\u7b97\uff08\u901a\u5e38\u5728FP32\u4e2d\u8fdb\u884c\uff09\ncriterion = nn.CrossEntropyLoss()\nloss = criterion(outputs, labels)\n\nprint(f\"\u8f93\u5165\u6570\u636e\u7c7b\u578b: {x.dtype}\")\nprint(f\"\u8f93\u51fa\u6570\u636e\u7c7b\u578b: {outputs.dtype}\")\nprint(f\"\u635f\u5931\u6570\u636e\u7c7b\u578b: {loss.dtype}\")\n</code></pre>"},{"location":"tutorials/mixed-precision/#amp_2","title":"\u624b\u52a8AMP\u63a7\u5236","text":"<p>\u5bf9\u4e8e\u7cbe\u7ec6\u63a7\u5236\uff0c\u4f7f\u7528<code>autocast</code>\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\uff1a</p> Python<pre><code>import genesis\n\n# \u7981\u7528\u5168\u5c40autocast\ngenesis.enable_autocast = False\n\n# \u6a21\u578b\u8bbe\u7f6e\nmodel = nn.Sequential(\n    nn.Linear(784, 256),\n    nn.ReLU(),\n    nn.Linear(256, 10)\n).cuda()\n\nx = genesis.randn(32, 784, device='cuda')\n\n# \u624b\u52a8\u6df7\u5408\u7cbe\u5ea6\u63a7\u5236\nwith genesis.autocast():\n    # \u6b64\u5757\u5185\u7684\u64cd\u4f5c\u4f7f\u7528FP16/BF16\n    hidden = model[0](x)  # Linear\u5c42\u4f7f\u7528FP16\n    activated = model[1](hidden)  # ReLU\u4f7f\u7528FP16\n\n# \u5757\u5916\u64cd\u4f5c\u4f7f\u7528\u9ed8\u8ba4\u7cbe\u5ea6\noutputs = model[2](activated)  # \u8fd9\u5c06\u662fFP32\n\nprint(f\"\u9690\u85cf\u5c42\u6570\u636e\u7c7b\u578b: {hidden.dtype}\")\nprint(f\"\u6fc0\u6d3b\u5c42\u6570\u636e\u7c7b\u578b: {activated.dtype}\")\nprint(f\"\u8f93\u51fa\u6570\u636e\u7c7b\u578b: {outputs.dtype}\")\n</code></pre>"},{"location":"tutorials/mixed-precision/#_7","title":"\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3","text":""},{"location":"tutorials/mixed-precision/#_8","title":"\u7b80\u5355\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u5faa\u73af","text":"Python<pre><code>import genesis\nimport genesis.nn as nn\nimport genesis.optim as optim\n\n# \u6a21\u578b\u8bbe\u7f6e\nmodel = nn.Sequential(\n    nn.Linear(784, 512),\n    nn.ReLU(),\n    nn.Dropout(0.2),\n    nn.Linear(512, 256),\n    nn.ReLU(),\n    nn.Dropout(0.2),\n    nn.Linear(256, 10)\n).cuda()\n\n# \u4f18\u5316\u5668\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# \u635f\u5931\u51fd\u6570\ncriterion = nn.CrossEntropyLoss()\n\n# \u542f\u7528\u6df7\u5408\u7cbe\u5ea6\ngenesis.enable_autocast = True\n\ndef train_epoch_amp(model, dataloader, optimizer, criterion):\n    model.train()\n    total_loss = 0.0\n\n    for batch_idx, (data, targets) in enumerate(dataloader):\n        data = data.cuda()\n        targets = targets.cuda()\n\n        # \u6e05\u96f6\u68af\u5ea6\n        optimizer.zero_grad()\n\n        # \u4f7f\u7528\u6df7\u5408\u7cbe\u5ea6\u7684\u524d\u5411\u4f20\u64ad\n        outputs = model(data)\n        loss = criterion(outputs, targets)\n\n        # \u53cd\u5411\u4f20\u64ad\n        loss.backward()\n\n        # \u68af\u5ea6\u88c1\u526a\uff08\u5bf9\u7a33\u5b9a\u6027\u5f88\u91cd\u8981\uff09\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n        # \u4f18\u5316\u5668\u6b65\u9aa4\n        optimizer.step()\n\n        total_loss += loss.item()\n\n        if batch_idx % 100 == 0:\n            print(f'\u6279\u6b21 {batch_idx}: loss={loss.item():.4f}')\n\n    return total_loss / len(dataloader)\n\n# \u8bad\u7ec3\nfor epoch in range(10):\n    avg_loss = train_epoch_amp(model, train_loader, optimizer, criterion)\n    print(f'\u8f6e\u6b21 {epoch}: \u5e73\u5747\u635f\u5931 = {avg_loss:.4f}')\n</code></pre>"},{"location":"tutorials/mixed-precision/#_9","title":"\u5e26\u635f\u5931\u7f29\u653e\u7684\u9ad8\u7ea7\u6df7\u5408\u7cbe\u5ea6","text":"<p>\u4e3a\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u7279\u522b\u662f\u4f7f\u7528FP16\u65f6\uff0c\u5efa\u8bae\u4f7f\u7528\u635f\u5931\u7f29\u653e\uff1a</p> Python<pre><code>class GradScaler:\n    \"\"\"\u7528\u4e8e\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u7684\u68af\u5ea6\u7f29\u653e\u5668\u3002\"\"\"\n\n    def __init__(self, init_scale=2**16, growth_factor=2.0, backoff_factor=0.5, \n                 growth_interval=2000):\n        self.scale = init_scale\n        self.growth_factor = growth_factor\n        self.backoff_factor = backoff_factor\n        self.growth_interval = growth_interval\n        self._growth_tracker = 0\n\n    def scale_loss(self, loss):\n        \"\"\"\u7f29\u653e\u635f\u5931\u4ee5\u9632\u6b62\u68af\u5ea6\u4e0b\u6ea2\u3002\"\"\"\n        return loss * self.scale\n\n    def unscale_gradients(self, optimizer):\n        \"\"\"\u5728\u4f18\u5316\u5668\u6b65\u9aa4\u524d\u53cd\u7f29\u653e\u68af\u5ea6\u3002\"\"\"\n        for param_group in optimizer.param_groups:\n            for param in param_group['params']:\n                if param.grad is not None:\n                    param.grad.data.div_(self.scale)\n\n    def step(self, optimizer):\n        \"\"\"\u5e26\u68af\u5ea6\u6ea2\u51fa\u68c0\u6d4b\u7684\u4f18\u5316\u5668\u6b65\u9aa4\u3002\"\"\"\n        # \u68c0\u67e5\u68af\u5ea6\u6ea2\u51fa\n        has_overflow = self._check_overflow(optimizer)\n\n        if has_overflow:\n            # \u8df3\u8fc7\u4f18\u5316\u5668\u6b65\u9aa4\u5e76\u51cf\u5c11\u7f29\u653e\n            self.scale *= self.backoff_factor\n            self.scale = max(self.scale, 1.0)\n            self._growth_tracker = 0\n            return False\n        else:\n            # \u6b63\u5e38\u4f18\u5316\u5668\u6b65\u9aa4\n            optimizer.step()\n\n            # \u5b9a\u671f\u589e\u52a0\u7f29\u653e\n            self._growth_tracker += 1\n            if self._growth_tracker &gt;= self.growth_interval:\n                self.scale *= self.growth_factor\n                self._growth_tracker = 0\n\n            return True\n\n    def _check_overflow(self, optimizer):\n        \"\"\"\u68c0\u67e5\u662f\u5426\u6709\u68af\u5ea6\u6ea2\u51fa\u3002\"\"\"\n        for param_group in optimizer.param_groups:\n            for param in param_group['params']:\n                if param.grad is not None:\n                    if genesis.isnan(param.grad).any() or genesis.isinf(param.grad).any():\n                        return True\n        return False\n\n# \u5e26\u68af\u5ea6\u7f29\u653e\u7684\u8bad\u7ec3\nscaler = GradScaler()\n\ndef train_with_scaling(model, dataloader, optimizer, criterion, scaler):\n    model.train()\n    total_loss = 0.0\n    successful_steps = 0\n\n    for batch_idx, (data, targets) in enumerate(dataloader):\n        data = data.cuda()\n        targets = targets.cuda()\n\n        optimizer.zero_grad()\n\n        # \u4f7f\u7528\u6df7\u5408\u7cbe\u5ea6\u7684\u524d\u5411\u4f20\u64ad\n        with genesis.autocast():\n            outputs = model(data)\n            loss = criterion(outputs, targets)\n\n        # \u7f29\u653e\u635f\u5931\u4ee5\u9632\u6b62\u68af\u5ea6\u4e0b\u6ea2\n        scaled_loss = scaler.scale_loss(loss)\n        scaled_loss.backward()\n\n        # \u53cd\u7f29\u653e\u68af\u5ea6\u5e76\u68c0\u67e5\u6ea2\u51fa\n        scaler.unscale_gradients(optimizer)\n\n        # \u5728\u53cd\u7f29\u653e\u68af\u5ea6\u4e0a\u8fdb\u884c\u68af\u5ea6\u88c1\u526a\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n        # \u5e26\u6ea2\u51fa\u68c0\u6d4b\u7684\u4f18\u5316\u5668\u6b65\u9aa4\n        if scaler.step(optimizer):\n            successful_steps += 1\n\n        total_loss += loss.item()\n\n        if batch_idx % 100 == 0:\n            print(f'\u6279\u6b21 {batch_idx}: loss={loss.item():.4f}, scale={scaler.scale:.0f}')\n\n    success_rate = successful_steps / len(dataloader)\n    print(f'\u8bad\u7ec3\u6210\u529f\u7387: {success_rate:.1%}')\n\n    return total_loss / len(dataloader)\n</code></pre>"},{"location":"tutorials/mixed-precision/#_10","title":"\u7cbe\u5ea6\u7279\u5b9a\u8003\u8651","text":""},{"location":"tutorials/mixed-precision/#fp16","title":"FP16\uff08\u534a\u7cbe\u5ea6\uff09","text":"Python<pre><code>import genesis\n\n# FP16\u7279\u6027\nfp16_info = {\n    'range': '\u00b165,504',\n    'precision': '\u7ea63-4\u4f4d\u5c0f\u6570',\n    'special_values': ['inf', '-inf', 'nan'],\n    'benefits': ['\u5728Tensor Cores\u4e0a\u66f4\u5feb', '50%\u5185\u5b58\u51cf\u5c11'],\n    'challenges': ['\u6709\u9650\u7684\u8303\u56f4', '\u68af\u5ea6\u4e0b\u6ea2']\n}\n\n# FP16\u6700\u4f73\u5b9e\u8df5\ndef create_fp16_model():\n    model = nn.Sequential(\n        nn.Linear(784, 256),\n        nn.LayerNorm(256),  # LayerNorm\u5728FP16\u4e0b\u8868\u73b0\u826f\u597d\n        nn.ReLU(),\n        nn.Linear(256, 10)\n    )\n\n    # \u4e3aFP16\u521d\u59cb\u5316\u9002\u5f53\u7684\u7f29\u653e\n    for module in model.modules():\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=1.0)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n\n    return model\n\n# \u76d1\u63a7FP16\u8bad\u7ec3\ndef check_fp16_health(model):\n    \"\"\"\u68c0\u67e5FP16\u8bad\u7ec3\u671f\u95f4\u7684\u6a21\u578b\u5065\u5eb7\u72b6\u51b5\u3002\"\"\"\n    for name, param in model.named_parameters():\n        if param.grad is not None:\n            grad_norm = param.grad.norm().item()\n            param_norm = param.norm().item()\n\n            print(f\"{name}:\")\n            print(f\"  \u53c2\u6570\u8303\u6570: {param_norm:.2e}\")\n            print(f\"  \u68af\u5ea6\u8303\u6570: {grad_norm:.2e}\")\n\n            # \u68c0\u67e5\u95ee\u9898\u503c\n            if grad_norm &lt; 1e-7:\n                print(f\"  \u8b66\u544a: \u68c0\u6d4b\u5230\u975e\u5e38\u5c0f\u7684\u68af\u5ea6!\")\n            if grad_norm &gt; 1e4:\n                print(f\"  \u8b66\u544a: \u68c0\u6d4b\u5230\u975e\u5e38\u5927\u7684\u68af\u5ea6!\")\n</code></pre>"},{"location":"tutorials/mixed-precision/#bf16brain-float","title":"BF16\uff08Brain Float\uff09","text":"Python<pre><code>import genesis\n\n# BF16\u4f18\u52bf\nbf16_info = {\n    'range': '\u4e0eFP32\u76f8\u540c (\u00b13.4\u00d710^38)',\n    'precision': '\u7ea62-3\u4f4d\u5c0f\u6570', \n    'benefits': ['\u6bd4FP16\u8303\u56f4\u66f4\u5927', '\u66f4\u7a33\u5b9a\u7684\u8bad\u7ec3'],\n    'hardware': ['A100', 'H100', 'TPUs']\n}\n\n# BF16\u901a\u5e38\u6bd4FP16\u66f4\u7a33\u5b9a\ndef train_with_bf16():\n    # \u4f7f\u7528BF16\u521b\u5efa\u6a21\u578b\n    model = nn.Linear(1000, 100).cuda()\n    x = genesis.randn(32, 1000, dtype=genesis.bfloat16, device='cuda')\n\n    # BF16\u524d\u5411\u4f20\u64ad\n    output = model(x)\n    print(f\"\u8f93\u5165: {x.dtype}, \u8f93\u51fa: {output.dtype}\")\n\n    # BF16\u901a\u5e38\u4e0d\u9700\u8981\u635f\u5931\u7f29\u653e\n    loss = output.sum()\n    loss.backward()\n\n    return model\n\n# \u6bd4\u8f83\u7cbe\u5ea6\ndef compare_precisions():\n    sizes = [100, 1000, 10000]\n\n    for size in sizes:\n        # \u521b\u5efa\u6d4b\u8bd5\u6570\u636e\n        data_fp32 = genesis.randn(size, size)\n        data_fp16 = data_fp32.half()\n        data_bf16 = data_fp32.to(genesis.bfloat16)\n\n        # \u7b80\u5355\u8ba1\u7b97\n        result_fp32 = genesis.matmul(data_fp32, data_fp32)\n        result_fp16 = genesis.matmul(data_fp16, data_fp16)\n        result_bf16 = genesis.matmul(data_bf16, data_bf16)\n\n        # \u6bd4\u8f83\u7cbe\u5ea6\n        error_fp16 = (result_fp32 - result_fp16.float()).abs().mean()\n        error_bf16 = (result_fp32 - result_bf16.float()).abs().mean()\n\n        print(f\"\u5927\u5c0f {size}x{size}:\")\n        print(f\"  FP16\u8bef\u5dee: {error_fp16:.2e}\")\n        print(f\"  BF16\u8bef\u5dee: {error_bf16:.2e}\")\n</code></pre>"},{"location":"tutorials/mixed-precision/#_11","title":"\u5185\u5b58\u4f18\u5316","text":""},{"location":"tutorials/mixed-precision/#_12","title":"\u5185\u5b58\u4f7f\u7528\u5206\u6790","text":"Python<pre><code>import genesis\n\ndef analyze_memory_usage():\n    \"\"\"\u5206\u6790\u4e0d\u540c\u7cbe\u5ea6\u7c7b\u578b\u7684\u5185\u5b58\u4f7f\u7528\u3002\"\"\"\n\n    # \u6a21\u578b\u5927\u5c0f\n    sizes = [(1000, 1000), (2000, 2000), (5000, 5000)]\n\n    for h, w in sizes:\n        print(f\"\\n\u5f20\u91cf\u5927\u5c0f: {h}x{w}\")\n\n        # \u521b\u5efa\u5f20\u91cf\n        fp32_tensor = genesis.randn(h, w, dtype=genesis.float32, device='cuda')\n        fp16_tensor = genesis.randn(h, w, dtype=genesis.float16, device='cuda')\n        bf16_tensor = genesis.randn(h, w, dtype=genesis.bfloat16, device='cuda')\n\n        # \u5185\u5b58\u4f7f\u7528\n        fp32_memory = fp32_tensor.numel() * 4  # \u6bcf\u4e2afloat32 4\u5b57\u8282\n        fp16_memory = fp16_tensor.numel() * 2  # \u6bcf\u4e2afloat16 2\u5b57\u8282\n        bf16_memory = bf16_tensor.numel() * 2  # \u6bcf\u4e2abfloat16 2\u5b57\u8282\n\n        print(f\"  FP32: {fp32_memory / 1e6:.1f} MB\")\n        print(f\"  FP16: {fp16_memory / 1e6:.1f} MB ({fp16_memory/fp32_memory:.1%})\")\n        print(f\"  BF16: {bf16_memory / 1e6:.1f} MB ({bf16_memory/fp32_memory:.1%})\")\n\n        # \u6e05\u7406\n        del fp32_tensor, fp16_tensor, bf16_tensor\n        genesis.cuda.empty_cache()\n\nanalyze_memory_usage()\n</code></pre>"},{"location":"tutorials/mixed-precision/#_13","title":"\u68af\u5ea6\u68c0\u67e5\u70b9\u4e0e\u6df7\u5408\u7cbe\u5ea6","text":"Python<pre><code>import genesis\nimport genesis.nn as nn\n\nclass CheckpointedModule(nn.Module):\n    \"\"\"\u652f\u6301\u68af\u5ea6\u68c0\u67e5\u70b9\u7684\u6a21\u5757\u3002\"\"\"\n\n    def __init__(self, layers):\n        super().__init__()\n        self.layers = nn.ModuleList(layers)\n        self.checkpoint = True\n\n    def forward(self, x):\n        def run_layers(x, layers):\n            for layer in layers:\n                x = layer(x)\n            return x\n\n        if self.training and self.checkpoint:\n            # \u4f7f\u7528\u68af\u5ea6\u68c0\u67e5\u70b9\u8282\u7701\u5185\u5b58\n            return genesis.utils.checkpoint(run_layers, x, self.layers)\n        else:\n            return run_layers(x, self.layers)\n\n# \u521b\u5efa\u5185\u5b58\u9ad8\u6548\u6a21\u578b\ndef create_checkpointed_model():\n    layers = [\n        nn.Linear(1024, 1024),\n        nn.ReLU(),\n        nn.Linear(1024, 1024),\n        nn.ReLU(),\n        nn.Linear(1024, 512),\n        nn.ReLU(),\n        nn.Linear(512, 10)\n    ]\n\n    return CheckpointedModule(layers)\n\n# \u4f7f\u7528\u68c0\u67e5\u70b9\u548c\u6df7\u5408\u7cbe\u5ea6\u8fdb\u884c\u8bad\u7ec3\ndef train_memory_efficient():\n    model = create_checkpointed_model().cuda()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    # \u542f\u7528\u6df7\u5408\u7cbe\u5ea6\n    genesis.enable_autocast = True\n\n    for epoch in range(10):\n        for batch in dataloader:\n            data, targets = batch\n            data = data.cuda()\n            targets = targets.cuda()\n\n            optimizer.zero_grad()\n\n            # \u4f7f\u7528\u68c0\u67e5\u70b9\u548c\u6df7\u5408\u7cbe\u5ea6\u7684\u524d\u5411\u4f20\u64ad\n            outputs = model(data)\n            loss = nn.CrossEntropyLoss()(outputs, targets)\n\n            # \u53cd\u5411\u4f20\u64ad\n            loss.backward()\n            optimizer.step()\n\n        print(f\"\u8f6e\u6b21 {epoch} \u5b8c\u6210\")\n</code></pre>"},{"location":"tutorials/mixed-precision/#_14","title":"\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5","text":""},{"location":"tutorials/mixed-precision/#_15","title":"\u6df7\u5408\u7cbe\u5ea6\u6027\u80fd\u6bd4\u8f83","text":"Python<pre><code>import genesis\nimport time\n\ndef benchmark_precision_performance():\n    \"\"\"\u57fa\u51c6\u6d4b\u8bd5\u4e0d\u540c\u7cbe\u5ea6\u683c\u5f0f\u3002\"\"\"\n\n    # \u6a21\u578b\u8bbe\u7f6e\n    sizes = [512, 1024, 2048]\n    batch_sizes = [16, 32, 64]\n\n    results = {}\n\n    for size in sizes:\n        for batch_size in batch_sizes:\n            print(f\"\\n\u57fa\u51c6\u6d4b\u8bd5: size={size}, batch_size={batch_size}\")\n\n            # \u521b\u5efa\u6a21\u578b\n            model_fp32 = nn.Linear(size, size).cuda()\n            model_fp16 = nn.Linear(size, size).cuda().half()\n\n            # \u521b\u5efa\u6570\u636e\n            data_fp32 = genesis.randn(batch_size, size, device='cuda')\n            data_fp16 = data_fp32.half()\n\n            # \u57fa\u51c6\u6d4b\u8bd5FP32\n            torch.cuda.synchronize()\n            start_time = time.time()\n\n            for _ in range(100):\n                output_fp32 = model_fp32(data_fp32)\n\n            torch.cuda.synchronize()\n            fp32_time = time.time() - start_time\n\n            # \u57fa\u51c6\u6d4b\u8bd5FP16\n            torch.cuda.synchronize()\n            start_time = time.time()\n\n            for _ in range(100):\n                output_fp16 = model_fp16(data_fp16)\n\n            torch.cuda.synchronize()\n            fp16_time = time.time() - start_time\n\n            # \u7ed3\u679c\n            speedup = fp32_time / fp16_time\n            print(f\"  FP32\u65f6\u95f4: {fp32_time:.3f}s\")\n            print(f\"  FP16\u65f6\u95f4: {fp16_time:.3f}s\") \n            print(f\"  \u52a0\u901f\u6bd4: {speedup:.2f}x\")\n\n            results[(size, batch_size)] = {\n                'fp32_time': fp32_time,\n                'fp16_time': fp16_time,\n                'speedup': speedup\n            }\n\n    return results\n\n# \u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5\nbenchmark_results = benchmark_precision_performance()\n</code></pre>"},{"location":"tutorials/mixed-precision/#_16","title":"\u6700\u4f73\u5b9e\u8df5\u548c\u6545\u969c\u6392\u9664","text":""},{"location":"tutorials/mixed-precision/#_17","title":"\u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u4ece\u7b80\u5355\u5f00\u59cb\uff1a\u5728\u624b\u52a8\u63a7\u5236\u4e4b\u524d\u5148\u5c1d\u8bd5\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6</li> <li>\u76d1\u63a7\u8bad\u7ec3\uff1a\u5173\u6ce8\u68af\u5ea6\u4e0b\u6ea2/\u6ea2\u51fa</li> <li>\u4f7f\u7528\u635f\u5931\u7f29\u653e\uff1a\u5bf9FP16\u7a33\u5b9a\u6027\u81f3\u5173\u91cd\u8981</li> <li>\u68af\u5ea6\u88c1\u526a\uff1a\u6709\u52a9\u4e8e\u9632\u6b62\u68af\u5ea6\u7206\u70b8</li> <li>\u5206\u5c42\u7cbe\u5ea6\uff1a\u67d0\u4e9b\u5c42\u53ef\u80fd\u9700\u8981FP32\uff08\u5982\u6279\u6807\u51c6\u5316\uff09</li> </ol>"},{"location":"tutorials/mixed-precision/#_18","title":"\u5e38\u89c1\u95ee\u9898\u548c\u89e3\u51b3\u65b9\u6848","text":"Python<pre><code># \u95ee\u98981: \u68af\u5ea6\u4e0b\u6ea2\ndef handle_gradient_underflow():\n    \"\"\"\u5904\u7406FP16\u8bad\u7ec3\u4e2d\u7684\u68af\u5ea6\u4e0b\u6ea2\u3002\"\"\"\n\n    # \u89e3\u51b3\u65b9\u68481: \u4f7f\u7528\u635f\u5931\u7f29\u653e\n    scaler = GradScaler(init_scale=2**16)\n\n    # \u89e3\u51b3\u65b9\u68482: \u8df3\u8fc7\u6709\u95ee\u9898\u7684\u6279\u6b21\n    def safe_backward(loss, scaler):\n        scaled_loss = scaler.scale_loss(loss)\n        scaled_loss.backward()\n\n        # \u5728\u4f18\u5316\u5668\u6b65\u9aa4\u524d\u68c0\u67e5\u95ee\u9898\n        has_inf_or_nan = any(\n            genesis.isinf(p.grad).any() or genesis.isnan(p.grad).any()\n            for p in model.parameters() \n            if p.grad is not None\n        )\n\n        if has_inf_or_nan:\n            print(\"\u7531\u4e8einf/nan\u68af\u5ea6\u8df3\u8fc7\u6b65\u9aa4\")\n            optimizer.zero_grad()\n            return False\n\n        return True\n\n# \u95ee\u98982: \u6a21\u578b\u53d1\u6563\ndef prevent_model_divergence():\n    \"\"\"\u9632\u6b62\u6df7\u5408\u7cbe\u5ea6\u4e2d\u7684\u6a21\u578b\u53d1\u6563\u3002\"\"\"\n\n    # \u89e3\u51b3\u65b9\u68481: \u964d\u4f4e\u5b66\u4e60\u7387\n    optimizer = optim.Adam(model.parameters(), lr=0.0001)  # \u66f4\u4f4e\u7684\u5b66\u4e60\u7387\n\n    # \u89e3\u51b3\u65b9\u68482: \u9884\u70ed\u8ba1\u5212\n    scheduler = optim.get_cosine_schedule_with_warmup(\n        optimizer, num_warmup_steps=1000, num_training_steps=10000\n    )\n\n    # \u89e3\u51b3\u65b9\u68483: \u5bc6\u5207\u76d1\u63a7\u635f\u5931\n    def check_loss_stability(loss, loss_history):\n        loss_history.append(loss.item())\n\n        if len(loss_history) &gt; 100:\n            recent_losses = loss_history[-50:]\n            if any(l &gt; 10 * min(recent_losses) for l in recent_losses):\n                print(\"\u8b66\u544a: \u68c0\u6d4b\u5230\u635f\u5931\u4e0d\u7a33\u5b9a!\")\n                return False\n\n        return True\n\n# \u95ee\u98983: \u7cbe\u5ea6\u964d\u4f4e\ndef maintain_accuracy():\n    \"\"\"\u4f7f\u7528\u6df7\u5408\u7cbe\u5ea6\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u3002\"\"\"\n\n    # \u89e3\u51b3\u65b9\u68481: \u4f7f\u7528BF16\u800c\u4e0d\u662fFP16\n    genesis.enable_autocast = True\n    default_dtype = genesis.bfloat16\n\n    # \u89e3\u51b3\u65b9\u68482: \u4fdd\u6301\u5173\u952e\u5c42\u5728FP32\n    class MixedPrecisionModel(nn.Module):\n        def __init__(self):\n            super().__init__()\n            self.features = nn.Sequential(\n                nn.Linear(784, 256),  # FP16/BF16\n                nn.ReLU(),\n                nn.Linear(256, 128),  # FP16/BF16\n                nn.ReLU()\n            )\n\n            # \u4fdd\u6301\u8f93\u51fa\u5c42\u5728FP32\u4ee5\u83b7\u5f97\u7a33\u5b9a\u6027\n            self.classifier = nn.Linear(128, 10).float()\n\n        def forward(self, x):\n            with genesis.autocast():\n                features = self.features(x)\n\n            # \u8f93\u51fa\u5c42\u5728FP32\n            output = self.classifier(features.float())\n            return output\n</code></pre>"},{"location":"tutorials/mixed-precision/#_19","title":"\u8c03\u8bd5\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3","text":"Python<pre><code>def debug_mixed_precision():\n    \"\"\"\u8c03\u8bd5\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u95ee\u9898\u3002\"\"\"\n\n    # 1. \u68c0\u67e5\u6574\u4e2a\u6a21\u578b\u7684\u5f20\u91cf\u6570\u636e\u7c7b\u578b\n    def print_tensor_info(tensor, name):\n        print(f\"{name}:\")\n        print(f\"  \u5f62\u72b6: {tensor.shape}\")\n        print(f\"  \u6570\u636e\u7c7b\u578b: {tensor.dtype}\")\n        print(f\"  \u8bbe\u5907: {tensor.device}\")\n        print(f\"  \u9700\u8981\u68af\u5ea6: {tensor.requires_grad}\")\n        print(f\"  \u6700\u5c0f/\u6700\u5927\u503c: {tensor.min():.2e} / {tensor.max():.2e}\")\n        print()\n\n    # 2. \u76d1\u63a7\u68af\u5ea6\u8303\u6570\n    def check_gradient_norms(model):\n        total_norm = 0.0\n        for name, param in model.named_parameters():\n            if param.grad is not None:\n                grad_norm = param.grad.norm().item()\n                total_norm += grad_norm ** 2\n                print(f\"{name}: grad_norm = {grad_norm:.2e}\")\n\n        total_norm = total_norm ** 0.5\n        print(f\"\u603b\u68af\u5ea6\u8303\u6570: {total_norm:.2e}\")\n        return total_norm\n\n    # 3. \u9a8c\u8bc1\u6570\u503c\u7a33\u5b9a\u6027\n    def check_numerical_stability(tensor):\n        \"\"\"\u68c0\u67e5\u6570\u503c\u95ee\u9898\u3002\"\"\"\n        has_nan = genesis.isnan(tensor).any()\n        has_inf = genesis.isinf(tensor).any()\n\n        if has_nan:\n            print(\"\u8b66\u544a: \u68c0\u6d4b\u5230NaN\u503c!\")\n        if has_inf:\n            print(\"\u8b66\u544a: \u68c0\u6d4b\u5230Inf\u503c!\")\n\n        return not (has_nan or has_inf)\n\n# \u5728\u8bad\u7ec3\u5faa\u73af\u4e2d\u4f7f\u7528\nfor epoch in range(num_epochs):\n    for batch_idx, (data, targets) in enumerate(dataloader):\n        # \u524d\u5411\u4f20\u64ad\n        outputs = model(data)\n        loss = criterion(outputs, targets)\n\n        # \u8c03\u8bd5\u4fe1\u606f\n        if batch_idx % 100 == 0:\n            print(f\"\u8f6e\u6b21 {epoch}, \u6279\u6b21 {batch_idx}:\")\n            print_tensor_info(data, \"\u8f93\u5165\")\n            print_tensor_info(outputs, \"\u8f93\u51fa\") \n            print_tensor_info(loss, \"\u635f\u5931\")\n\n            # \u53cd\u5411\u4f20\u64ad\u540e\u68c0\u67e5\u68af\u5ea6\n            loss.backward()\n            grad_norm = check_gradient_norms(model)\n\n            if grad_norm &gt; 10.0:\n                print(\"\u8b66\u544a: \u68c0\u6d4b\u5230\u5927\u68af\u5ea6\u8303\u6570!\")\n</code></pre> <p>\u8fd9\u4efd\u5168\u9762\u6307\u5357\u6db5\u76d6\u4e86Genesis\u4e2d\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u7684\u6240\u6709\u65b9\u9762\uff0c\u4ece\u57fa\u7840\u4f7f\u7528\u5230\u9ad8\u7ea7\u4f18\u5316\u6280\u672f\u548c\u6545\u969c\u6392\u9664\u7b56\u7565\u3002</p>"},{"location":"tutorials/model-definition/","title":"Model Definition in Genesis","text":"<p>Learn how to define neural network models using Genesis.</p>"},{"location":"tutorials/model-definition/#overview","title":"Overview","text":"<p>Genesis provides PyTorch-like APIs for defining neural network architectures.</p>"},{"location":"tutorials/model-definition/#basic-model-definition","title":"Basic Model Definition","text":"Python<pre><code>import genesis\nimport genesis.nn as nn\n\nclass SimpleNet(nn.Module):\n    def __init__(self, input_size, num_classes):\n        super().__init__()\n        self.linear1 = nn.Linear(input_size, 128)\n        self.relu = nn.ReLU()\n        self.linear2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        x = self.linear1(x)\n        x = self.relu(x)\n        x = self.linear2(x)\n        return x\n\n# Create model instance\nmodel = SimpleNet(784, 10)\n</code></pre>"},{"location":"tutorials/model-definition/#advanced-architectures","title":"Advanced Architectures","text":"<p>This tutorial is under construction. More examples and patterns will be added.</p>"},{"location":"tutorials/model-definition/#see-also","title":"See Also","text":"<ul> <li>Basic Training - Training your defined models</li> <li>Custom Operations - Creating custom layers</li> </ul>"},{"location":"tutorials/performance-tuning/","title":"\u6027\u80fd\u8c03\u4f18\u6307\u5357","text":"<p>\u5f00\u53d1\u4e2d</p> <p>\u6b64\u6587\u6863\u6b63\u5728\u7f16\u5199\u4e2d\uff0c\u5185\u5bb9\u5c06\u6301\u7eed\u66f4\u65b0\u3002</p> <p>\u672c\u6307\u5357\u5c06\u6559\u4f60\u5982\u4f55\u4f18\u5316Genesis\u6a21\u578b\u7684\u8bad\u7ec3\u6027\u80fd\uff0c\u5305\u62ec\u5185\u5b58\u4f7f\u7528\u3001\u8ba1\u7b97\u6548\u7387\u548cI/O\u4f18\u5316\u7b49\u65b9\u9762\u3002</p>"},{"location":"tutorials/performance-tuning/#_2","title":"\ud83c\udfaf \u4f18\u5316\u76ee\u6807","text":"<ul> <li>\u8bad\u7ec3\u901f\u5ea6: \u63d0\u9ad8\u6bcf\u79d2\u5904\u7406\u7684\u6837\u672c\u6570</li> <li>\u5185\u5b58\u6548\u7387: \u51cf\u5c11GPU\u663e\u5b58\u5360\u7528</li> <li>\u541e\u5410\u91cf: \u6700\u5927\u5316\u786c\u4ef6\u5229\u7528\u7387</li> </ul>"},{"location":"tutorials/performance-tuning/#_3","title":"\ud83d\udcca \u6027\u80fd\u5206\u6790\u5de5\u5177","text":""},{"location":"tutorials/performance-tuning/#_4","title":"\u5185\u7f6e\u6027\u80fd\u5206\u6790\u5668","text":"Python<pre><code>import genesis.utils.profile as profiler\n\n# WIP: \u6027\u80fd\u5206\u6790\u4ee3\u7801\u793a\u4f8b\nwith profiler.profile() as prof:\n    # \u8bad\u7ec3\u4ee3\u7801\n    pass\n\nprof.print_stats()\n</code></pre>"},{"location":"tutorials/performance-tuning/#_5","title":"\u26a1 \u4f18\u5316\u7b56\u7565","text":""},{"location":"tutorials/performance-tuning/#1","title":"1. \u5185\u5b58\u4f18\u5316","text":"<ul> <li>\u68af\u5ea6\u7d2f\u79ef</li> <li>\u68c0\u67e5\u70b9\u6280\u672f</li> <li>\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3</li> </ul>"},{"location":"tutorials/performance-tuning/#2","title":"2. \u8ba1\u7b97\u4f18\u5316","text":"<ul> <li>\u7b97\u5b50\u878d\u5408</li> <li>Triton kernel\u4f18\u5316</li> <li>CUDA\u6d41\u91cd\u53e0</li> </ul>"},{"location":"tutorials/performance-tuning/#3-io","title":"3. I/O\u4f18\u5316","text":"<ul> <li>\u6570\u636e\u9884\u53d6</li> <li>\u591a\u8fdb\u7a0b\u6570\u636e\u52a0\u8f7d</li> <li>\u5185\u5b58\u6620\u5c04</li> </ul>"},{"location":"tutorials/performance-tuning/#_6","title":"\ud83d\udcc8 \u57fa\u51c6\u6d4b\u8bd5","text":"<ul> <li>\u4e0ePyTorch\u6027\u80fd\u5bf9\u6bd4</li> <li>\u4e0d\u540c\u914d\u7f6e\u7684\u6027\u80fd\u6d4b\u8bd5</li> <li>\u74f6\u9888\u8bc6\u522b\u65b9\u6cd5</li> </ul> <p>\ud83d\udcd8 \u6587\u6863\u72b6\u6001: \u6b63\u5728\u7f16\u5199\u4e2d\uff0c\u9884\u8ba1\u5728v0.2.0\u7248\u672c\u5b8c\u6210\u3002</p>"}]}